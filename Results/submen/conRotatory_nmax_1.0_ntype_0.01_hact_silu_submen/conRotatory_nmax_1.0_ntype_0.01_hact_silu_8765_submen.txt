 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.01
max_norm:             	1.0
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	rotatory
position_concatenation: 	True
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11889541
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12850530230098892 HIT: 0.2911214227147694

#### val Acc: 0, NDCG: 0.47078871031512587 HIT: 0.5605113335801947
Epoch: 1, plus 0 steps train_loss: 0.7659

#### test Acc: 0, NDCG: 0.1308157422464278 HIT: 0.295994729951333

#### val Acc: 0, NDCG: 0.4775374739286799 HIT: 0.5744171207151926
Epoch: 2, plus 0 steps train_loss: 0.7812

#### test Acc: 0, NDCG: 0.12852323776887234 HIT: 0.2917553824587389

#### val Acc: 0, NDCG: 0.4825465454086777 HIT: 0.5757172754443504
Epoch: 3, plus 0 steps train_loss: 0.7632

#### test Acc: 0, NDCG: 0.12542216517652666 HIT: 0.2785910058717732

#### val Acc: 0, NDCG: 0.4863627373485746 HIT: 0.5764066136796445
Epoch: 4, plus 0 steps train_loss: 0.7555

#### test Acc: 0, NDCG: 0.1220375268556151 HIT: 0.26958910812526454

#### val Acc: 0, NDCG: 0.4755692077987438 HIT: 0.5727491536182818
Epoch: 5, plus 0 steps train_loss: 0.7541

#### test Acc: 0, NDCG: 0.12667766647690662 HIT: 0.28362879549301734

#### val Acc: 0, NDCG: 0.4689881223921908 HIT: 0.5618346315594583
Epoch: 6, plus 0 steps train_loss: 0.7568

#### test Acc: 0, NDCG: 0.1290065923147432 HIT: 0.2821889547185781

#### val Acc: 0, NDCG: 0.4810413758396231 HIT: 0.5775860928903935
Epoch: 7, plus 0 steps train_loss: 0.7588

#### test Acc: 0, NDCG: 0.1207003915381424 HIT: 0.27155380475031743

#### val Acc: 0, NDCG: 0.47782545473767707 HIT: 0.5777563610876005
Epoch: 8, plus 0 steps train_loss: 0.7605

#### test Acc: 0, NDCG: 0.1312185626335619 HIT: 0.28930054485823103

#### val Acc: 0, NDCG: 0.4876404508581416 HIT: 0.5845753544223444
Epoch: 9, plus 0 steps train_loss: 0.7398

#### test Acc: 0, NDCG: 0.12444587105025674 HIT: 0.2847719067393144

#### val Acc: 0, NDCG: 0.48178092948875717 HIT: 0.5807914330300465
Epoch: 10, plus 0 steps train_loss: 0.7501

#### test Acc: 0, NDCG: 0.12711329021800843 HIT: 0.28279977121244176

#### val Acc: 0, NDCG: 0.4897954050009261 HIT: 0.5848968802898857
Epoch: 12, plus 0 steps train_loss: 0.7411

#### test Acc: 0, NDCG: 0.13627405776510496 HIT: 0.29596993361193397

#### val Acc: 0, NDCG: 0.48873066693873285 HIT: 0.5803665890816758
Epoch: 14, plus 0 steps train_loss: 0.7557

#### test Acc: 0, NDCG: 0.12715332656667647 HIT: 0.2792034754549302

#### val Acc: 0, NDCG: 0.48235499708343105 HIT: 0.5761884058929327
Epoch: 16, plus 0 steps train_loss: 0.7452

#### test Acc: 0, NDCG: 0.12669845341208694 HIT: 0.2808177171498096

#### val Acc: 0, NDCG: 0.47246375729844453 HIT: 0.5636422847016505
Epoch: 18, plus 0 steps train_loss: 0.746

#### test Acc: 0, NDCG: 0.12305393731984401 HIT: 0.2738325883410918

#### val Acc: 0, NDCG: 0.48131746627892985 HIT: 0.5821395273487093
Epoch: 20, plus 0 steps train_loss: 0.7413

#### test Acc: 0, NDCG: 0.12589363226993183 HIT: 0.2791423111510791

#### val Acc: 0, NDCG: 0.48749384375373156 HIT: 0.5844298825645365
Epoch: 22, plus 0 steps train_loss: 0.7363

#### test Acc: 0, NDCG: 0.1266494603081883 HIT: 0.28571582072577234

#### val Acc: 0, NDCG: 0.48149930096289756 HIT: 0.5731475481379602
Epoch: 24, plus 0 steps train_loss: 0.7367

#### test Acc: 0, NDCG: 0.1256843712738705 HIT: 0.27614939298561153

#### val Acc: 0, NDCG: 0.4874436962791195 HIT: 0.5756387537029201
Epoch: 26, plus 0 steps train_loss: 0.7302

#### test Acc: 0, NDCG: 0.13257566435218593 HIT: 0.28773424275285653

#### val Acc: 0, NDCG: 0.4845569220646747 HIT: 0.5756329678903935
Epoch: 28, plus 0 steps train_loss: 0.7321

#### test Acc: 0, NDCG: 0.13296025969674044 HIT: 0.2858728642086331

#### val Acc: 0, NDCG: 0.48093182328029915 HIT: 0.5785531501269573
Epoch: 30, plus 0 steps train_loss: 0.722

#### test Acc: 0, NDCG: 0.16089959937448514 HIT: 0.328853185833686

#### val Acc: 0, NDCG: 0.49563031370361216 HIT: 0.5956832879284808
Epoch: 32, plus 0 steps train_loss: 0.726

#### test Acc: 0, NDCG: 0.2166626588432521 HIT: 0.3738213473338976

#### val Acc: 0, NDCG: 0.5345646291297468 HIT: 0.6261596421392298
Epoch: 36, plus 0 steps train_loss: 0.7233

#### test Acc: 0, NDCG: 0.3193502669768966 HIT: 0.4573767456622937

#### val Acc: 0, NDCG: 0.6022022482860347 HIT: 0.6889547185780787
Epoch: 40, plus 0 steps train_loss: 0.716

#### test Acc: 0, NDCG: 0.3219400157279012 HIT: 0.4662711926047397

#### val Acc: 0, NDCG: 0.5995009153460387 HIT: 0.6879570791895895
Epoch: 44, plus 0 steps train_loss: 0.7142

#### test Acc: 0, NDCG: 0.370012820692025 HIT: 0.5037252367223868

#### val Acc: 0, NDCG: 0.6205866355167752 HIT: 0.7084917543906052
Epoch: 48, plus 0 steps train_loss: 0.7163

#### test Acc: 0, NDCG: 0.45954363477299853 HIT: 0.5909306562103259

#### val Acc: 0, NDCG: 0.6536789256225116 HIT: 0.7310828726724502
Epoch: 52, plus 0 steps train_loss: 0.7127

#### test Acc: 0, NDCG: 0.38310165530014656 HIT: 0.5182129112886161

#### val Acc: 0, NDCG: 0.6189575187844862 HIT: 0.6960720945302581
Epoch: 56, plus 0 steps train_loss: 0.7137

#### test Acc: 0, NDCG: 0.47007588628334357 HIT: 0.5998556853046974

#### val Acc: 0, NDCG: 0.687037191864082 HIT: 0.7653315766504444
Epoch: 60, plus 0 steps train_loss: 0.7112

#### test Acc: 0, NDCG: 0.5468261574315175 HIT: 0.6670240094688955

#### val Acc: 0, NDCG: 0.72408170665575 HIT: 0.7910610849555649
Epoch: 64, plus 0 steps train_loss: 0.7077

#### test Acc: 0, NDCG: 0.5350691600399665 HIT: 0.6561880091515023

#### val Acc: 0, NDCG: 0.7132725764843821 HIT: 0.7878557448159119
Epoch: 68, plus 0 steps train_loss: 0.7076

#### test Acc: 0, NDCG: 0.566964127675387 HIT: 0.677840999259416

#### val Acc: 0, NDCG: 0.7376696334232367 HIT: 0.8054396556284384
Epoch: 72, plus 0 steps train_loss: 0.7082

#### test Acc: 0, NDCG: 0.5986105300443013 HIT: 0.7051789634468895

#### val Acc: 0, NDCG: 0.7620829119767832 HIT: 0.8267364049936522
Epoch: 80, plus 0 steps train_loss: 0.7088

#### test Acc: 0, NDCG: 0.6296391133723834 HIT: 0.7361190092044012

#### val Acc: 0, NDCG: 0.7732344038786059 HIT: 0.8344398011002961
Epoch: 88, plus 0 steps train_loss: 0.7025

#### test Acc: 0, NDCG: 0.6360736260121372 HIT: 0.7359751904358866

#### val Acc: 0, NDCG: 0.7653199549087574 HIT: 0.8273835894519679
Epoch: 96, plus 0 steps train_loss: 0.7009

#### test Acc: 0, NDCG: 0.6323976335178182 HIT: 0.7417370331675837

#### val Acc: 0, NDCG: 0.7839615348839857 HIT: 0.8451857080512061
Epoch: 104, plus 0 steps train_loss: 0.7066

#### test Acc: 0, NDCG: 0.6437511894165509 HIT: 0.7431462917900973

#### val Acc: 0, NDCG: 0.7768210269240348 HIT: 0.838194793429962
Epoch: 112, plus 0 steps train_loss: 0.7021

#### test Acc: 0, NDCG: 0.6626867293150118 HIT: 0.7608872460854845

#### val Acc: 0, NDCG: 0.7933053037660104 HIT: 0.8536015856432501
Epoch: 120, plus 0 steps train_loss: 0.7022

#### test Acc: 0, NDCG: 0.6587591743561886 HIT: 0.7548956239420228

#### val Acc: 0, NDCG: 0.781935339803038 HIT: 0.8403776978417267
Epoch: 128, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.6853234272814771 HIT: 0.7811979276872619

#### val Acc: 0, NDCG: 0.7961695565932844 HIT: 0.8476405456517139
Epoch: 136, plus 0 steps train_loss: 0.7012

#### test Acc: 0, NDCG: 0.6756328938782804 HIT: 0.7749037902031316

#### val Acc: 0, NDCG: 0.7982845450554115 HIT: 0.8517211965721541
Epoch: 144, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.6586574393135257 HIT: 0.751617547873466

#### val Acc: 0, NDCG: 0.7952831649586386 HIT: 0.8530883014176894
Epoch: 160, plus 0 steps train_loss: 0.6939

#### test Acc: 0, NDCG: 0.6760997869560429 HIT: 0.7699329506982648

#### val Acc: 0, NDCG: 0.8028164516235746 HIT: 0.8639358733601354
Epoch: 176, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.6948948611946311 HIT: 0.7836527652877698

#### val Acc: 0, NDCG: 0.8097424304458798 HIT: 0.8679264309140923
Epoch: 192, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.6826740355005164 HIT: 0.7769775907215405

#### val Acc: 0, NDCG: 0.8078651399205257 HIT: 0.8681198423614049
Epoch: 208, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.6776732807676008 HIT: 0.7695097598391875

#### val Acc: 0, NDCG: 0.7982404899506728 HIT: 0.854091726618705
Epoch: 224, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.6692613946866148 HIT: 0.7635354951333051

#### val Acc: 0, NDCG: 0.7974144175726641 HIT: 0.8489522720059247
Epoch: 240, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.6561261864392192 HIT: 0.7496586370609395

#### val Acc: 0, NDCG: 0.8081028946139643 HIT: 0.8639416591726619
Epoch: 256, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.6674937665106032 HIT: 0.7623080763330512

#### val Acc: 0, NDCG: 0.7898456206903726 HIT: 0.8483108733601354
Epoch: 272, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.6904469399708013 HIT: 0.7764395101565806

#### val Acc: 0, NDCG: 0.8028938268638938 HIT: 0.8525617924777825
Epoch: 288, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.6638496658861859 HIT: 0.7539574957680915

#### val Acc: 0, NDCG: 0.7833804927854358 HIT: 0.8407703065488786
Epoch: 304, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.6705534882996333 HIT: 0.761691474026661

#### val Acc: 0, NDCG: 0.8152643616968179 HIT: 0.8656170651713924
Epoch: 320, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.28954080343412786 HIT: 0.4252134138277613

#### val Acc: 0, NDCG: 0.5815828018768608 HIT: 0.6677249193292425
Epoch: 352, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.6713984742869618 HIT: 0.7567338592361404

#### val Acc: 0, NDCG: 0.8108338121025348 HIT: 0.8558456543588658
Epoch: 384, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.6677005990908493 HIT: 0.7652588407215405

#### val Acc: 0, NDCG: 0.8009014476835263 HIT: 0.8617835511002961
Epoch: 416, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.665614444684492 HIT: 0.7617394136161659

#### val Acc: 0, NDCG: 0.7968984966929832 HIT: 0.8556580287240796
Epoch: 448, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.6741296021788924 HIT: 0.7644967665573423

#### val Acc: 0, NDCG: 0.7989201528597445 HIT: 0.8597097505818875
Epoch: 480, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.6576938975569241 HIT: 0.7583175187790944

#### val Acc: 0, NDCG: 0.8133226746970244 HIT: 0.8689488666419806
Epoch: 512, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.68209492217038 HIT: 0.7740210405205248

#### val Acc: 0, NDCG: 0.7982709455018779 HIT: 0.8535478602412188
Epoch: 544, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.6709774737998688 HIT: 0.7624957019678374

#### val Acc: 0, NDCG: 0.8034245488826078 HIT: 0.857997976618705
Epoch: 576, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.6657189196863121 HIT: 0.7618063637325434

#### val Acc: 0, NDCG: 0.7912392831971299 HIT: 0.8516732569826492
Epoch: 608, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.6625657149199576 HIT: 0.7613947444985188

#### val Acc: 0, NDCG: 0.8021705038962414 HIT: 0.8606825936309775
Epoch: 640, plus 0 steps train_loss: 0.6949

#### test Acc: 0, NDCG: 0.6972698841109579 HIT: 0.7801887166737198

#### val Acc: 0, NDCG: 0.8072181263271917 HIT: 0.8580285587706306
Epoch: 704, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.6570534309766866 HIT: 0.7552154967202709

#### val Acc: 0, NDCG: 0.783470960902104 HIT: 0.8392345865954296
Epoch: 768, plus 0 steps train_loss: 0.6944

#### test Acc: 0, NDCG: 0.6431581255943494 HIT: 0.7464780932606855

#### val Acc: 0, NDCG: 0.7804526040549841 HIT: 0.8411091898539992
Epoch: 832, plus 0 steps train_loss: 0.6948

#### test Acc: 0, NDCG: 0.6661206650408095 HIT: 0.7552576504972492

#### val Acc: 0, NDCG: 0.7833039499671419 HIT: 0.8418712640181972
Epoch: 896, plus 0 steps train_loss: 0.6953

#### test Acc: 0, NDCG: 0.6534112850711322 HIT: 0.7546352623783326

#### val Acc: 0, NDCG: 0.7977230830300527 HIT: 0.8512136981591197
Epoch: 960, plus 0 steps train_loss: 0.6944

#### test Acc: 0, NDCG: 0.6734448685316756 HIT: 0.7659118109923826

#### val Acc: 0, NDCG: 0.7932347605978606 HIT: 0.8537049037240796
Epoch: 1017, plus 0 steps train_loss: 0.6963
Done: it took 142239.83519244194
max value of NDCG: 0.6972698841109579
max value of HIT: 0.7836527652877698

After 20 validations
max value of NDCG: 0.6972698841109579
max value of HIT: 0.7836527652877698
