 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	0.5
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	rotatory
position_concatenation: 	True
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11889541
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.1357242569593243 HIT: 0.30141190356538294

#### val Acc: 0, NDCG: 0.4791445555295764 HIT: 0.5729789330300465
Epoch: 1, plus 0 steps train_loss: 0.7549

#### test Acc: 0, NDCG: 0.13479696913140018 HIT: 0.29569800042319083

#### val Acc: 0, NDCG: 0.4701363108912805 HIT: 0.5624396622407957
Epoch: 2, plus 0 steps train_loss: 0.757

#### test Acc: 0, NDCG: 0.1323951508673031 HIT: 0.2911272085272958

#### val Acc: 0, NDCG: 0.48512176528485246 HIT: 0.5795450037029201
Epoch: 3, plus 0 steps train_loss: 0.7423

#### test Acc: 0, NDCG: 0.1295908456559914 HIT: 0.2917132286817605

#### val Acc: 0, NDCG: 0.4695514098350606 HIT: 0.5691379800571308
Epoch: 4, plus 0 steps train_loss: 0.7482

#### test Acc: 0, NDCG: 0.1318734717942098 HIT: 0.29659232173085065

#### val Acc: 0, NDCG: 0.48879596590635743 HIT: 0.576364459902666
Epoch: 5, plus 0 steps train_loss: 0.7602

#### test Acc: 0, NDCG: 0.13096054303937632 HIT: 0.29696178718789673

#### val Acc: 0, NDCG: 0.4843815618688622 HIT: 0.5777737185251799
Epoch: 6, plus 0 steps train_loss: 0.7546

#### test Acc: 0, NDCG: 0.13267631334959964 HIT: 0.29480946492805754

#### val Acc: 0, NDCG: 0.4824907872421181 HIT: 0.5859118771159543
Epoch: 7, plus 0 steps train_loss: 0.7469

#### test Acc: 0, NDCG: 0.12530324728251024 HIT: 0.2780413536817605

#### val Acc: 0, NDCG: 0.47755215324436373 HIT: 0.5743807527507405
Epoch: 8, plus 0 steps train_loss: 0.7488

#### test Acc: 0, NDCG: 0.1261157822910272 HIT: 0.28488679644519677

#### val Acc: 0, NDCG: 0.49160528219015887 HIT: 0.591964663563267
Epoch: 9, plus 0 steps train_loss: 0.7379

#### test Acc: 0, NDCG: 0.13478411207537677 HIT: 0.2940110227994075

#### val Acc: 0, NDCG: 0.46915006621333527 HIT: 0.5626504311256877
Epoch: 10, plus 0 steps train_loss: 0.7376

#### test Acc: 0, NDCG: 0.13247766980302633 HIT: 0.291006533008887

#### val Acc: 0, NDCG: 0.48333777616714146 HIT: 0.5736740570778671
Epoch: 12, plus 0 steps train_loss: 0.7397

#### test Acc: 0, NDCG: 0.1299533074621694 HIT: 0.28474711039991535

#### val Acc: 0, NDCG: 0.4846724025988613 HIT: 0.5789647693609818
Epoch: 14, plus 0 steps train_loss: 0.7404

#### test Acc: 0, NDCG: 0.1334954137473442 HIT: 0.29621872355057133

#### val Acc: 0, NDCG: 0.48539108392922126 HIT: 0.5887055980215827
Epoch: 16, plus 0 steps train_loss: 0.7328

#### test Acc: 0, NDCG: 0.1410109898086111 HIT: 0.3023616033643673

#### val Acc: 0, NDCG: 0.4835146675851009 HIT: 0.5796598934088024
Epoch: 18, plus 0 steps train_loss: 0.7265

#### test Acc: 0, NDCG: 0.13435818199045466 HIT: 0.2914107133410918

#### val Acc: 0, NDCG: 0.4785460009192634 HIT: 0.5717878821942446
Epoch: 20, plus 0 steps train_loss: 0.7345

#### test Acc: 0, NDCG: 0.12911155221083953 HIT: 0.2812103258569615

#### val Acc: 0, NDCG: 0.48347832562190973 HIT: 0.5735343710325856
Epoch: 22, plus 0 steps train_loss: 0.7219

#### test Acc: 0, NDCG: 0.1334067256482492 HIT: 0.2870697008569615

#### val Acc: 0, NDCG: 0.4752291963122072 HIT: 0.5623173336330936
Epoch: 24, plus 0 steps train_loss: 0.7169

#### test Acc: 0, NDCG: 0.12540896416727182 HIT: 0.27617997513753706

#### val Acc: 0, NDCG: 0.4720610836500936 HIT: 0.5641977227041896
Epoch: 26, plus 0 steps train_loss: 0.7263

#### test Acc: 0, NDCG: 0.12618746745713452 HIT: 0.28166409886796445

#### val Acc: 0, NDCG: 0.47577336563024486 HIT: 0.571303527031316
Epoch: 28, plus 0 steps train_loss: 0.723

#### test Acc: 0, NDCG: 0.13313683562365028 HIT: 0.2888236285971223

#### val Acc: 0, NDCG: 0.4847498852562766 HIT: 0.580071512642827
Epoch: 30, plus 0 steps train_loss: 0.7226

#### test Acc: 0, NDCG: 0.12544296052350148 HIT: 0.28362879549301734

#### val Acc: 0, NDCG: 0.48947903408328947 HIT: 0.5829916948793906
Epoch: 32, plus 0 steps train_loss: 0.7243

#### test Acc: 0, NDCG: 0.12961934580800186 HIT: 0.28714243678586543

#### val Acc: 0, NDCG: 0.47516954687707225 HIT: 0.5654978774333475
Epoch: 36, plus 0 steps train_loss: 0.7189

#### test Acc: 0, NDCG: 0.12844518489570547 HIT: 0.2756476803851037

#### val Acc: 0, NDCG: 0.48281418180582264 HIT: 0.5764181853046974
Epoch: 40, plus 0 steps train_loss: 0.7201

#### test Acc: 0, NDCG: 0.13298043766705317 HIT: 0.28004407136055864

#### val Acc: 0, NDCG: 0.4803533973446376 HIT: 0.5746295426893779
Epoch: 44, plus 0 steps train_loss: 0.7108

#### test Acc: 0, NDCG: 0.12246596685512096 HIT: 0.2709429882564537

#### val Acc: 0, NDCG: 0.4811906009351758 HIT: 0.5794970641134152
Epoch: 48, plus 0 steps train_loss: 0.7097

#### test Acc: 0, NDCG: 0.12382233779824361 HIT: 0.2711363997037664

#### val Acc: 0, NDCG: 0.4814390324236385 HIT: 0.5680196651502327
Epoch: 52, plus 0 steps train_loss: 0.7108

#### test Acc: 0, NDCG: 0.13785613357924187 HIT: 0.2972163629390605

#### val Acc: 0, NDCG: 0.47952493905937127 HIT: 0.5731111801735083
Epoch: 56, plus 0 steps train_loss: 0.7072

#### test Acc: 0, NDCG: 0.14329528701033764 HIT: 0.2965022283643673

#### val Acc: 0, NDCG: 0.47972500478117996 HIT: 0.5769331226195513
Epoch: 60, plus 0 steps train_loss: 0.7081

#### test Acc: 0, NDCG: 0.16063388616300783 HIT: 0.31649882300042315

#### val Acc: 0, NDCG: 0.48975722329346494 HIT: 0.5862507604210749
Epoch: 64, plus 0 steps train_loss: 0.7132

#### test Acc: 0, NDCG: 0.14002976319064098 HIT: 0.2951119802687262

#### val Acc: 0, NDCG: 0.4912744664012735 HIT: 0.5905686296550995
Epoch: 68, plus 0 steps train_loss: 0.7047

#### test Acc: 0, NDCG: 0.13253048286589064 HIT: 0.2844578197735929

#### val Acc: 0, NDCG: 0.48604643415395116 HIT: 0.5842364711172239
Epoch: 72, plus 0 steps train_loss: 0.7084

#### test Acc: 0, NDCG: 0.159725135876664 HIT: 0.31241238626745665

#### val Acc: 0, NDCG: 0.49916439605674723 HIT: 0.588475818609818
Epoch: 80, plus 0 steps train_loss: 0.7044

#### test Acc: 0, NDCG: 0.1314831665478763 HIT: 0.287837560833686

#### val Acc: 0, NDCG: 0.4826146466542961 HIT: 0.5808451584320778
Epoch: 88, plus 0 steps train_loss: 0.7065

#### test Acc: 0, NDCG: 0.13885099430553738 HIT: 0.2872688981168007

#### val Acc: 0, NDCG: 0.4908709263061294 HIT: 0.5796962613732544
Epoch: 96, plus 0 steps train_loss: 0.7037

#### test Acc: 0, NDCG: 0.2972135416675289 HIT: 0.4467763105691917

#### val Acc: 0, NDCG: 0.58727325823777 HIT: 0.6672174209162083
Epoch: 104, plus 0 steps train_loss: 0.7118

#### test Acc: 0, NDCG: 0.5980488588722673 HIT: 0.7089091594371562

#### val Acc: 0, NDCG: 0.7558379818938232 HIT: 0.8238335801946678
Epoch: 112, plus 0 steps train_loss: 0.7053

#### test Acc: 0, NDCG: 0.5963396030475505 HIT: 0.6974086172238679

#### val Acc: 0, NDCG: 0.7648040077938177 HIT: 0.8266578832522217
Epoch: 120, plus 0 steps train_loss: 0.7023

#### test Acc: 0, NDCG: 0.49450225514205404 HIT: 0.6229543019995768

#### val Acc: 0, NDCG: 0.676640243060065 HIT: 0.7562073502962336
Epoch: 128, plus 0 steps train_loss: 0.7031

#### test Acc: 0, NDCG: 0.6287342876094426 HIT: 0.7346923931443081

#### val Acc: 0, NDCG: 0.7694302871498682 HIT: 0.8310906421921287
Epoch: 136, plus 0 steps train_loss: 0.705

#### test Acc: 0, NDCG: 0.6109736086412852 HIT: 0.7087636875793484

#### val Acc: 0, NDCG: 0.7615986086344533 HIT: 0.8276133688637326
Epoch: 144, plus 0 steps train_loss: 0.7037

#### test Acc: 0, NDCG: 0.41602602982597237 HIT: 0.5475635116906474

#### val Acc: 0, NDCG: 0.6468727801548997 HIT: 0.7276725494604317
Epoch: 160, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.5182527799770875 HIT: 0.6300526674248835

#### val Acc: 0, NDCG: 0.6966451836007856 HIT: 0.7725084638171815
Epoch: 176, plus 0 steps train_loss: 0.7007

#### test Acc: 0, NDCG: 0.6279674492719044 HIT: 0.7236208276026238

#### val Acc: 0, NDCG: 0.7677992013867198 HIT: 0.8298210696148963
Epoch: 192, plus 0 steps train_loss: 0.7052

#### test Acc: 0, NDCG: 0.6286036966038046 HIT: 0.733610446201862

#### val Acc: 0, NDCG: 0.7775230381753834 HIT: 0.8449121217731697
Epoch: 208, plus 0 steps train_loss: 0.702

#### test Acc: 0, NDCG: 0.6102576277692906 HIT: 0.7158331239420228

#### val Acc: 0, NDCG: 0.7796286443182794 HIT: 0.8373541975243335
Epoch: 224, plus 0 steps train_loss: 0.7016

#### test Acc: 0, NDCG: 0.13054155919271748 HIT: 0.28435450169276344

#### val Acc: 0, NDCG: 0.4745999701306693 HIT: 0.5583267760791367
Epoch: 240, plus 0 steps train_loss: 0.7009

#### test Acc: 0, NDCG: 0.36475907856406864 HIT: 0.5077273659013964

#### val Acc: 0, NDCG: 0.6137078450300539 HIT: 0.6958307434934405
Epoch: 256, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.6481636149182116 HIT: 0.7422751137325434

#### val Acc: 0, NDCG: 0.7917563671704767 HIT: 0.8484505594054168
Epoch: 272, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.6621744815777594 HIT: 0.7577546418747355

#### val Acc: 0, NDCG: 0.8086126556426818 HIT: 0.8620496984765129
Epoch: 288, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.5283854023920267 HIT: 0.6409018924566229

#### val Acc: 0, NDCG: 0.7227389375785145 HIT: 0.7914173256982648
Epoch: 304, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.654439954353514 HIT: 0.7506256942975033

#### val Acc: 0, NDCG: 0.7905154040665702 HIT: 0.8494176166419806
Epoch: 320, plus 0 steps train_loss: 0.7

#### test Acc: 0, NDCG: 0.6527700979296276 HIT: 0.7511943570143885

#### val Acc: 0, NDCG: 0.7947818278642407 HIT: 0.852211337547609
Epoch: 352, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.2103228978948397 HIT: 0.36809587256665255

#### val Acc: 0, NDCG: 0.5260997148101815 HIT: 0.6166601645154465
Epoch: 384, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.6026700539177489 HIT: 0.7112796894837071

#### val Acc: 0, NDCG: 0.7682728938343721 HIT: 0.8305583474396954
Epoch: 416, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.6466904875937592 HIT: 0.7408600692975033

#### val Acc: 0, NDCG: 0.7857572909735037 HIT: 0.8419076319826492
Epoch: 448, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.6344894357738078 HIT: 0.7287487105903513

#### val Acc: 0, NDCG: 0.7842793813008654 HIT: 0.8421795651713924
Epoch: 480, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.632421870663618 HIT: 0.7336947537558189

#### val Acc: 0, NDCG: 0.7888300963760403 HIT: 0.847948846804909
Epoch: 512, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.6311130391719316 HIT: 0.7298976076491748

#### val Acc: 0, NDCG: 0.7968562404509267 HIT: 0.8546298071836649
Epoch: 544, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.625742342234648 HIT: 0.7243043800253914

#### val Acc: 0, NDCG: 0.7655184455126164 HIT: 0.8211489631823953
Epoch: 576, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.639180789872018 HIT: 0.7373174989420228

#### val Acc: 0, NDCG: 0.7813184806770761 HIT: 0.8424399267350825
Epoch: 608, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.5612520361080143 HIT: 0.6701243784384258

#### val Acc: 0, NDCG: 0.7327516984963038 HIT: 0.8083598378650021
Epoch: 640, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.62903622636618 HIT: 0.723438987780364

#### val Acc: 0, NDCG: 0.7975410007796354 HIT: 0.8547083289250952
Epoch: 704, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.6352467653547984 HIT: 0.7312093340033856

#### val Acc: 0, NDCG: 0.7793939831762101 HIT: 0.8358969993123149
Epoch: 768, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.6538193767375582 HIT: 0.747711297873466

#### val Acc: 0, NDCG: 0.7880086833277244 HIT: 0.8430928970059247
Epoch: 832, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.6442446453485389 HIT: 0.74138657823741

#### val Acc: 0, NDCG: 0.7847863230889124 HIT: 0.8429780073000424
Epoch: 896, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.663405852730168 HIT: 0.7547790811468472

#### val Acc: 0, NDCG: 0.7996496599946056 HIT: 0.8527973577020737
Epoch: 960, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.651713091372106 HIT: 0.745746601248413

#### val Acc: 0, NDCG: 0.785222685693071 HIT: 0.8429664356749894
Epoch: 1017, plus 0 steps train_loss: 0.6963
Done: it took 87860.50762820244
max value of NDCG: 0.663405852730168
max value of HIT: 0.7577546418747355

After 20 validations
max value of NDCG: 0.663405852730168
max value of HIT: 0.7577546418747355
