 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	0.1
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11571301
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12654112478052493 HIT: 0.2772255541155311

#### val Acc: 0, NDCG: 0.48257399679467866 HIT: 0.5677840999259416
Epoch: 1, plus 0 steps train_loss: 0.7838

#### test Acc: 0, NDCG: 0.1251226663703841 HIT: 0.27477650232754974

#### val Acc: 0, NDCG: 0.4755961912105858 HIT: 0.5622884045704613
Epoch: 2, plus 0 steps train_loss: 0.7676

#### test Acc: 0, NDCG: 0.13977835554428897 HIT: 0.30001008384468897

#### val Acc: 0, NDCG: 0.47912912580303435 HIT: 0.5743749669382142
Epoch: 3, plus 0 steps train_loss: 0.7605

#### test Acc: 0, NDCG: 0.1268174839942698 HIT: 0.27759501957257726

#### val Acc: 0, NDCG: 0.4802837169009642 HIT: 0.5673609090668642
Epoch: 4, plus 0 steps train_loss: 0.7631

#### test Acc: 0, NDCG: 0.11905652844716655 HIT: 0.2641107702073635

#### val Acc: 0, NDCG: 0.4904428738582618 HIT: 0.5734558492911553
Epoch: 5, plus 0 steps train_loss: 0.7533

#### test Acc: 0, NDCG: 0.12848934482045454 HIT: 0.27994075327972917

#### val Acc: 0, NDCG: 0.4725675339164641 HIT: 0.5648639176893779
Epoch: 6, plus 0 steps train_loss: 0.7582

#### test Acc: 0, NDCG: 0.12372179561822139 HIT: 0.2723406752539145

#### val Acc: 0, NDCG: 0.4757674732061736 HIT: 0.5650763396635633
Epoch: 7, plus 0 steps train_loss: 0.75

#### test Acc: 0, NDCG: 0.12410789311689807 HIT: 0.27420205379813795

#### val Acc: 0, NDCG: 0.4768474971359909 HIT: 0.5699727901502327
Epoch: 8, plus 0 steps train_loss: 0.7513

#### test Acc: 0, NDCG: 0.12518937165313346 HIT: 0.2762758543165468

#### val Acc: 0, NDCG: 0.47972599402903504 HIT: 0.579617739631824
Epoch: 9, plus 0 steps train_loss: 0.7439

#### test Acc: 0, NDCG: 0.12928679623732517 HIT: 0.28074498122090563

#### val Acc: 0, NDCG: 0.4831775747202753 HIT: 0.5761214557765553
Epoch: 10, plus 0 steps train_loss: 0.7417

#### test Acc: 0, NDCG: 0.133723866250118 HIT: 0.29254803877486246

#### val Acc: 0, NDCG: 0.4742400788855933 HIT: 0.5663574838658485
Epoch: 12, plus 0 steps train_loss: 0.7465

#### test Acc: 0, NDCG: 0.1277891120049165 HIT: 0.2747037663986458

#### val Acc: 0, NDCG: 0.4862051131417239 HIT: 0.5790490769149387
Epoch: 14, plus 0 steps train_loss: 0.7299

#### test Acc: 0, NDCG: 0.1323345932022892 HIT: 0.29430775232754974

#### val Acc: 0, NDCG: 0.47715259164219265 HIT: 0.5737947325962759
Epoch: 16, plus 0 steps train_loss: 0.7321

#### test Acc: 0, NDCG: 0.1302437913448027 HIT: 0.28029120820990266

#### val Acc: 0, NDCG: 0.4636654793114513 HIT: 0.548258635738468
Epoch: 18, plus 0 steps train_loss: 0.733

#### test Acc: 0, NDCG: 0.12437756116834138 HIT: 0.2879582363520948

#### val Acc: 0, NDCG: 0.47055660505362246 HIT: 0.5574324547714768
Epoch: 20, plus 0 steps train_loss: 0.7285

#### test Acc: 0, NDCG: 0.12349487079828085 HIT: 0.2741772574587389

#### val Acc: 0, NDCG: 0.46615045360406643 HIT: 0.5623537015975455
Epoch: 22, plus 0 steps train_loss: 0.726

#### test Acc: 0, NDCG: 0.14800590110148185 HIT: 0.30301457363520945

#### val Acc: 0, NDCG: 0.48417850876983043 HIT: 0.5771802594688955
Epoch: 24, plus 0 steps train_loss: 0.7199

#### test Acc: 0, NDCG: 0.12182015116644523 HIT: 0.27547162637537026

#### val Acc: 0, NDCG: 0.4814042875224313 HIT: 0.5798533048561151
Epoch: 26, plus 0 steps train_loss: 0.7147

#### test Acc: 0, NDCG: 0.1377058304873919 HIT: 0.2918529147270419

#### val Acc: 0, NDCG: 0.4814098363792289 HIT: 0.5721135407850191
Epoch: 28, plus 0 steps train_loss: 0.7239

#### test Acc: 0, NDCG: 0.18685946840728881 HIT: 0.33656815356538294

#### val Acc: 0, NDCG: 0.5138327117728676 HIT: 0.6034536341515023
Epoch: 30, plus 0 steps train_loss: 0.7156

#### test Acc: 0, NDCG: 0.18481493704546006 HIT: 0.34263251163774866

#### val Acc: 0, NDCG: 0.5067152262820811 HIT: 0.5977818847862887
Epoch: 32, plus 0 steps train_loss: 0.7182

#### test Acc: 0, NDCG: 0.17282624050133197 HIT: 0.33267926100296236

#### val Acc: 0, NDCG: 0.4954444223723952 HIT: 0.5895825618916631
Epoch: 36, plus 0 steps train_loss: 0.7141

#### test Acc: 0, NDCG: 0.20749970913127866 HIT: 0.36218855797714766

#### val Acc: 0, NDCG: 0.5120499724055406 HIT: 0.6009566427740162
Epoch: 40, plus 0 steps train_loss: 0.712

#### test Acc: 0, NDCG: 0.318850901664238 HIT: 0.4624434643461701

#### val Acc: 0, NDCG: 0.5943910704339482 HIT: 0.6814025801417689
Epoch: 44, plus 0 steps train_loss: 0.713

#### test Acc: 0, NDCG: 0.5330060358813346 HIT: 0.6417119062103259

#### val Acc: 0, NDCG: 0.7235714077528184 HIT: 0.7928860955353364
Epoch: 48, plus 0 steps train_loss: 0.7111

#### test Acc: 0, NDCG: 0.5687085587308739 HIT: 0.6731363071307659

#### val Acc: 0, NDCG: 0.7491449169743127 HIT: 0.8133612595217943
Epoch: 52, plus 0 steps train_loss: 0.7105

#### test Acc: 0, NDCG: 0.5100537799088153 HIT: 0.6326719874100719

#### val Acc: 0, NDCG: 0.6900687563668149 HIT: 0.7685600600402032
Epoch: 56, plus 0 steps train_loss: 0.711

#### test Acc: 0, NDCG: 0.1659931338102915 HIT: 0.32830188055438003

#### val Acc: 0, NDCG: 0.49733514344073804 HIT: 0.5852646926576386
Epoch: 60, plus 0 steps train_loss: 0.7071

#### test Acc: 0, NDCG: 0.43756781411426426 HIT: 0.5728086648328397

#### val Acc: 0, NDCG: 0.6425503387151409 HIT: 0.7265963883305121
Epoch: 64, plus 0 steps train_loss: 0.7069

#### test Acc: 0, NDCG: 0.4672812008905361 HIT: 0.5953154755607278

#### val Acc: 0, NDCG: 0.6989706971560197 HIT: 0.7722786844054168
Epoch: 68, plus 0 steps train_loss: 0.7075

#### test Acc: 0, NDCG: 0.5941676555657516 HIT: 0.6955951782691494

#### val Acc: 0, NDCG: 0.7515483341859734 HIT: 0.8161186124629708
Epoch: 72, plus 0 steps train_loss: 0.7057

#### test Acc: 0, NDCG: 0.3920260566616845 HIT: 0.5303664237727466

#### val Acc: 0, NDCG: 0.6288141011238948 HIT: 0.7101555887642828
Epoch: 80, plus 0 steps train_loss: 0.7069

#### test Acc: 0, NDCG: 0.24663737724606 HIT: 0.39644883358019467

#### val Acc: 0, NDCG: 0.5252593662460315 HIT: 0.6190480519995768
Epoch: 88, plus 0 steps train_loss: 0.7038

#### test Acc: 0, NDCG: 0.40826210546300623 HIT: 0.5527699164198053

#### val Acc: 0, NDCG: 0.6199938504460913 HIT: 0.6992220561785866
Epoch: 96, plus 0 steps train_loss: 0.7086

#### test Acc: 0, NDCG: 0.5017910393306058 HIT: 0.6254033537875582

#### val Acc: 0, NDCG: 0.6982646536632792 HIT: 0.7699387365107914
Epoch: 104, plus 0 steps train_loss: 0.7046

#### test Acc: 0, NDCG: 0.26098587589193584 HIT: 0.4146014071096064

#### val Acc: 0, NDCG: 0.5465833435580428 HIT: 0.6328290308929327
Epoch: 112, plus 0 steps train_loss: 0.7029

#### test Acc: 0, NDCG: 0.42810923193447054 HIT: 0.5605824164198053

#### val Acc: 0, NDCG: 0.6750648506510495 HIT: 0.7525002975560727
Epoch: 120, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.15720728216155616 HIT: 0.3179634601142616

#### val Acc: 0, NDCG: 0.48728658242340067 HIT: 0.5782448489737622
Epoch: 128, plus 0 steps train_loss: 0.7018

#### test Acc: 0, NDCG: 0.1254810069698541 HIT: 0.2748012986669488

#### val Acc: 0, NDCG: 0.4763759442297731 HIT: 0.5633703515129074
Epoch: 136, plus 0 steps train_loss: 0.6995

#### test Acc: 0, NDCG: 0.12756909564488583 HIT: 0.28029699402242914

#### val Acc: 0, NDCG: 0.4784638752568862 HIT: 0.5750948873254337
Epoch: 144, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.1508609991900997 HIT: 0.307368810833686

#### val Acc: 0, NDCG: 0.4948437299014585 HIT: 0.5922250251269573
Epoch: 160, plus 0 steps train_loss: 0.7003

#### test Acc: 0, NDCG: 0.4249491705620929 HIT: 0.5628322709479475

#### val Acc: 0, NDCG: 0.6488701098293151 HIT: 0.7291049513330512
Epoch: 176, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.5972822192487245 HIT: 0.7038655840033856

#### val Acc: 0, NDCG: 0.776317300282078 HIT: 0.8405711092890394
Epoch: 192, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.6160900834579345 HIT: 0.7200170929432924

#### val Acc: 0, NDCG: 0.771971739519811 HIT: 0.8334843154887854
Epoch: 208, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.5927958784429878 HIT: 0.6963382419064749

#### val Acc: 0, NDCG: 0.7522732686035021 HIT: 0.814818457733813
Epoch: 224, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.5422480668276999 HIT: 0.6648890446466357

#### val Acc: 0, NDCG: 0.7247827748289575 HIT: 0.8017383887008042
Epoch: 240, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.5618600561988126 HIT: 0.6895713208844689

#### val Acc: 0, NDCG: 0.7389267624459773 HIT: 0.8089169289568345
Epoch: 256, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.5830651271917864 HIT: 0.7025728681760475

#### val Acc: 0, NDCG: 0.7469456498310793 HIT: 0.8170493017350825
Epoch: 272, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.5889834751913883 HIT: 0.7093687182606855

#### val Acc: 0, NDCG: 0.7562659104924493 HIT: 0.8217349833368599
Epoch: 288, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.614100990651407 HIT: 0.7250474436627169

#### val Acc: 0, NDCG: 0.7675697186394976 HIT: 0.8353952867118071
Epoch: 304, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.5998298353510549 HIT: 0.7160381070143885

#### val Acc: 0, NDCG: 0.7713655711106363 HIT: 0.8388056099238256
Epoch: 320, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.5960124432558951 HIT: 0.7021000846381719

#### val Acc: 0, NDCG: 0.765313390916008 HIT: 0.8335934193821413
Epoch: 352, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.351205425378187 HIT: 0.4893144308082945

#### val Acc: 0, NDCG: 0.6059927880095692 HIT: 0.684988957363521
Epoch: 384, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.2321165175477759 HIT: 0.37698453369657214

#### val Acc: 0, NDCG: 0.5385225707210693 HIT: 0.6276705657532797
Epoch: 416, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.2970716699509269 HIT: 0.43210679618070247

#### val Acc: 0, NDCG: 0.5765098224588635 HIT: 0.6599545731062209
Epoch: 448, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.28553730966071356 HIT: 0.42695576994286927

#### val Acc: 0, NDCG: 0.5754178513096837 HIT: 0.6543671312949639
Epoch: 480, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.5936230301593187 HIT: 0.710343214399069

#### val Acc: 0, NDCG: 0.7654270348955992 HIT: 0.835039045969107
Epoch: 512, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.5823512473204187 HIT: 0.7045317789885738

#### val Acc: 0, NDCG: 0.7540763004384368 HIT: 0.8253271463711384
Epoch: 544, plus 0 steps train_loss: 0.6937

#### test Acc: 0, NDCG: 0.6126203187480148 HIT: 0.7253441731908591

#### val Acc: 0, NDCG: 0.7653861591210436 HIT: 0.8318874312314853
Epoch: 576, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.6087101419084632 HIT: 0.7195211661553111

#### val Acc: 0, NDCG: 0.7651097412912321 HIT: 0.8336413589716463
Epoch: 608, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.5478296756179956 HIT: 0.6729428956834532

#### val Acc: 0, NDCG: 0.7151148669523836 HIT: 0.7897609302264071
Epoch: 640, plus 0 steps train_loss: 0.6917

#### test Acc: 0, NDCG: 0.3568230797494997 HIT: 0.4989841766292848

#### val Acc: 0, NDCG: 0.6190918402087324 HIT: 0.7003172278353788
Epoch: 704, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.4503597830168022 HIT: 0.5904710973867965

#### val Acc: 0, NDCG: 0.6647928303456413 HIT: 0.7446877975560727
Epoch: 768, plus 0 steps train_loss: 0.6917

#### test Acc: 0, NDCG: 0.3417816854180696 HIT: 0.5079513595006349

#### val Acc: 0, NDCG: 0.5988168443025145 HIT: 0.6962655059775709
Epoch: 832, plus 0 steps train_loss: 0.6911

#### test Acc: 0, NDCG: 0.24644307353238806 HIT: 0.43034129681548877

#### val Acc: 0, NDCG: 0.5453014481088276 HIT: 0.6503228483389759
Epoch: 896, plus 0 steps train_loss: 0.6922

#### test Acc: 0, NDCG: 0.2383992345718715 HIT: 0.4233710458104105

#### val Acc: 0, NDCG: 0.5378258152301874 HIT: 0.6444750449640287
Epoch: 960, plus 0 steps train_loss: 0.6895

#### test Acc: 0, NDCG: 0.25248764728400547 HIT: 0.43728261875793484

#### val Acc: 0, NDCG: 0.5536637084079808 HIT: 0.6590660376110876
Epoch: 1017, plus 0 steps train_loss: 0.693
Done: it took 79121.78483939171
max value of NDCG: 0.6160900834579345
max value of HIT: 0.7253441731908591

After 20 validations
max value of NDCG: 0.6160900834579345
max value of HIT: 0.7253441731908591
