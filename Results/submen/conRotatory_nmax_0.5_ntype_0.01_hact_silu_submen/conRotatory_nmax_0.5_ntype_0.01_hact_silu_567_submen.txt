 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.01
max_norm:             	0.5
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	rotatory
position_concatenation: 	True
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11889541
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13501731746291953 HIT: 0.30100193742065173

#### val Acc: 0, NDCG: 0.48884279924062757 HIT: 0.578256420598815
Epoch: 1, plus 0 steps train_loss: 0.7656

#### test Acc: 0, NDCG: 0.1386469574632374 HIT: 0.30784572709479474

#### val Acc: 0, NDCG: 0.47624959484616947 HIT: 0.5672402335484553
Epoch: 2, plus 0 steps train_loss: 0.766

#### test Acc: 0, NDCG: 0.1394465716380724 HIT: 0.3056454652454507

#### val Acc: 0, NDCG: 0.48116773270050467 HIT: 0.5773794567287346
Epoch: 3, plus 0 steps train_loss: 0.7673

#### test Acc: 0, NDCG: 0.13351553416383238 HIT: 0.2960137404782057

#### val Acc: 0, NDCG: 0.47978733940438306 HIT: 0.5744650603046974
Epoch: 4, plus 0 steps train_loss: 0.7623

#### test Acc: 0, NDCG: 0.13543095102782035 HIT: 0.30070520789250954

#### val Acc: 0, NDCG: 0.4856742191977118 HIT: 0.5801558201967838
Epoch: 5, plus 0 steps train_loss: 0.748

#### test Acc: 0, NDCG: 0.13959037607772198 HIT: 0.3079184630236987

#### val Acc: 0, NDCG: 0.4809246587185211 HIT: 0.5731723444773592
Epoch: 6, plus 0 steps train_loss: 0.7687

#### test Acc: 0, NDCG: 0.13654345686058733 HIT: 0.3004390605162928

#### val Acc: 0, NDCG: 0.48514455867474726 HIT: 0.575711489631824
Epoch: 7, plus 0 steps train_loss: 0.7552

#### test Acc: 0, NDCG: 0.13521107680161099 HIT: 0.2995141570567076

#### val Acc: 0, NDCG: 0.4839988604326142 HIT: 0.5736798428903935
Epoch: 8, plus 0 steps train_loss: 0.7622

#### test Acc: 0, NDCG: 0.14034268621742116 HIT: 0.3029418377063055

#### val Acc: 0, NDCG: 0.4755397354272477 HIT: 0.5675063809246721
Epoch: 9, plus 0 steps train_loss: 0.7514

#### test Acc: 0, NDCG: 0.1349004551719215 HIT: 0.29293486166948796

#### val Acc: 0, NDCG: 0.47780898527307836 HIT: 0.5700761082310623
Epoch: 10, plus 0 steps train_loss: 0.7582

#### test Acc: 0, NDCG: 0.1325598973498074 HIT: 0.28955512060939487

#### val Acc: 0, NDCG: 0.4737823602019411 HIT: 0.5643316229369446
Epoch: 12, plus 0 steps train_loss: 0.74

#### test Acc: 0, NDCG: 0.13726236524440955 HIT: 0.2967568041155311

#### val Acc: 0, NDCG: 0.4726826807517129 HIT: 0.5689520075116378
Epoch: 14, plus 0 steps train_loss: 0.752

#### test Acc: 0, NDCG: 0.12632042048875822 HIT: 0.2713661791155311

#### val Acc: 0, NDCG: 0.47741233864153 HIT: 0.5591615861722387
Epoch: 16, plus 0 steps train_loss: 0.7496

#### test Acc: 0, NDCG: 0.13244023861738657 HIT: 0.29709568742065173

#### val Acc: 0, NDCG: 0.4765948351368703 HIT: 0.5618462031845112
Epoch: 18, plus 0 steps train_loss: 0.7411

#### test Acc: 0, NDCG: 0.1358244580895605 HIT: 0.2963088169170546

#### val Acc: 0, NDCG: 0.46863160563682527 HIT: 0.5627058096170122
Epoch: 20, plus 0 steps train_loss: 0.7339

#### test Acc: 0, NDCG: 0.12550785371370574 HIT: 0.2815376375370292

#### val Acc: 0, NDCG: 0.48914749929269674 HIT: 0.584678672503174
Epoch: 22, plus 0 steps train_loss: 0.7352

#### test Acc: 0, NDCG: 0.12616504426370279 HIT: 0.27367554485823103

#### val Acc: 0, NDCG: 0.48097839548812743 HIT: 0.5800525021159543
Epoch: 24, plus 0 steps train_loss: 0.7309

#### test Acc: 0, NDCG: 0.12792125583413874 HIT: 0.2813979514917478

#### val Acc: 0, NDCG: 0.4724549543261265 HIT: 0.5623247725349133
Epoch: 26, plus 0 steps train_loss: 0.7295

#### test Acc: 0, NDCG: 0.1263252083079987 HIT: 0.27403922450275076

#### val Acc: 0, NDCG: 0.4788930873327665 HIT: 0.5738616827126534
Epoch: 28, plus 0 steps train_loss: 0.7283

#### test Acc: 0, NDCG: 0.12027444712970119 HIT: 0.2741772574587389

#### val Acc: 0, NDCG: 0.47811326063814796 HIT: 0.5680866152666102
Epoch: 30, plus 0 steps train_loss: 0.7283

#### test Acc: 0, NDCG: 0.1304949911827439 HIT: 0.28937906659966145

#### val Acc: 0, NDCG: 0.47642781120433547 HIT: 0.5658251891134152
Epoch: 32, plus 0 steps train_loss: 0.7244

#### test Acc: 0, NDCG: 0.12771329003517504 HIT: 0.2803639441388066

#### val Acc: 0, NDCG: 0.4742308885736071 HIT: 0.56356376296022
Epoch: 36, plus 0 steps train_loss: 0.7271

#### test Acc: 0, NDCG: 0.13174004956869334 HIT: 0.2963815528459585

#### val Acc: 0, NDCG: 0.47043653696755927 HIT: 0.5594583157003808
Epoch: 40, plus 0 steps train_loss: 0.7185

#### test Acc: 0, NDCG: 0.14110223065432279 HIT: 0.29709568742065173

#### val Acc: 0, NDCG: 0.4660979265491959 HIT: 0.5612486114049937
Epoch: 44, plus 0 steps train_loss: 0.7156

#### test Acc: 0, NDCG: 0.21643020357803935 HIT: 0.36386974978840453

#### val Acc: 0, NDCG: 0.5255242715366389 HIT: 0.6118769506453661
Epoch: 48, plus 0 steps train_loss: 0.7161

#### test Acc: 0, NDCG: 0.38714242416169375 HIT: 0.5201660362886161

#### val Acc: 0, NDCG: 0.6502005264881714 HIT: 0.7283255197312738
Epoch: 52, plus 0 steps train_loss: 0.7062

#### test Acc: 0, NDCG: 0.3378372767938173 HIT: 0.47892641768937794

#### val Acc: 0, NDCG: 0.6001253574952973 HIT: 0.6866875066123572
Epoch: 56, plus 0 steps train_loss: 0.7119

#### test Acc: 0, NDCG: 0.27145543861191457 HIT: 0.41887133675412613

#### val Acc: 0, NDCG: 0.5620163886611764 HIT: 0.650522045598815
Epoch: 60, plus 0 steps train_loss: 0.7153

#### test Acc: 0, NDCG: 0.2295539167978663 HIT: 0.38620050650655946

#### val Acc: 0, NDCG: 0.5348877837483256 HIT: 0.6217938333157004
Epoch: 64, plus 0 steps train_loss: 0.7105

#### test Acc: 0, NDCG: 0.3431727599656272 HIT: 0.47766263092467204

#### val Acc: 0, NDCG: 0.5930201152006717 HIT: 0.6794800372936944
Epoch: 68, plus 0 steps train_loss: 0.7101

#### test Acc: 0, NDCG: 0.36562248193345165 HIT: 0.5134602795704613

#### val Acc: 0, NDCG: 0.6055362402240827 HIT: 0.68572623518832
Epoch: 72, plus 0 steps train_loss: 0.7072

#### test Acc: 0, NDCG: 0.38586328445730583 HIT: 0.5221249471011427

#### val Acc: 0, NDCG: 0.6302093071773482 HIT: 0.7097745516821836
Epoch: 80, plus 0 steps train_loss: 0.7071

#### test Acc: 0, NDCG: 0.5151241411263083 HIT: 0.6261960101036818

#### val Acc: 0, NDCG: 0.7135967444510064 HIT: 0.7778967083685993
Epoch: 88, plus 0 steps train_loss: 0.707

#### test Acc: 0, NDCG: 0.6227358657211359 HIT: 0.7246548349555649

#### val Acc: 0, NDCG: 0.7803902615698535 HIT: 0.8389874497460855
Epoch: 96, plus 0 steps train_loss: 0.703

#### test Acc: 0, NDCG: 0.6514993882729253 HIT: 0.7429165123783326

#### val Acc: 0, NDCG: 0.7877928487357371 HIT: 0.8428325354422345
Epoch: 104, plus 0 steps train_loss: 0.7021

#### test Acc: 0, NDCG: 0.607209184071514 HIT: 0.6986781898011003

#### val Acc: 0, NDCG: 0.7779875286324023 HIT: 0.8385146662082099
Epoch: 112, plus 0 steps train_loss: 0.705

#### test Acc: 0, NDCG: 0.625252018624426 HIT: 0.719938571201862

#### val Acc: 0, NDCG: 0.7504175196059295 HIT: 0.8120668906051629
Epoch: 120, plus 0 steps train_loss: 0.702

#### test Acc: 0, NDCG: 0.5693800251320613 HIT: 0.682128286341515

#### val Acc: 0, NDCG: 0.7262923276823418 HIT: 0.7994116655205248
Epoch: 128, plus 0 steps train_loss: 0.701

#### test Acc: 0, NDCG: 0.5905535400100115 HIT: 0.6984368387642828

#### val Acc: 0, NDCG: 0.7472153230644984 HIT: 0.8131430517350825
Epoch: 136, plus 0 steps train_loss: 0.7002

#### test Acc: 0, NDCG: 0.584894025192205 HIT: 0.689105976248413

#### val Acc: 0, NDCG: 0.7653610141361017 HIT: 0.8231748241112992
Epoch: 144, plus 0 steps train_loss: 0.7022

#### test Acc: 0, NDCG: 0.6359152855017985 HIT: 0.7349353972704189

#### val Acc: 0, NDCG: 0.7932878858614703 HIT: 0.8470660971223021
Epoch: 160, plus 0 steps train_loss: 0.7031

#### test Acc: 0, NDCG: 0.5941722803784151 HIT: 0.6992352808929327

#### val Acc: 0, NDCG: 0.756247844766515 HIT: 0.8145886783220483
Epoch: 176, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.6309178689825279 HIT: 0.7228471818133728

#### val Acc: 0, NDCG: 0.7853290394366614 HIT: 0.841599330829454
Epoch: 192, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.6224295223948243 HIT: 0.7253326015658061

#### val Acc: 0, NDCG: 0.7665966724284786 HIT: 0.8323717863944138
Epoch: 208, plus 0 steps train_loss: 0.7

#### test Acc: 0, NDCG: 0.6916919987324208 HIT: 0.7829997950169276

#### val Acc: 0, NDCG: 0.7916097122213122 HIT: 0.8480331543588658
Epoch: 224, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.6671533291202288 HIT: 0.7573926153195091

#### val Acc: 0, NDCG: 0.7914842592602281 HIT: 0.8453121693821413
Epoch: 240, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.6695223667645256 HIT: 0.7560312962865002

#### val Acc: 0, NDCG: 0.8083153607124159 HIT: 0.8640449772534913
Epoch: 256, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.6667398320104938 HIT: 0.7566115306284384

#### val Acc: 0, NDCG: 0.8091169366941102 HIT: 0.858807990372408
Epoch: 272, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.6875858994129471 HIT: 0.7697395392509522

#### val Acc: 0, NDCG: 0.7976002501349053 HIT: 0.8541586767350825
Epoch: 288, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.6894723757569733 HIT: 0.7687782678269149

#### val Acc: 0, NDCG: 0.7944590565783924 HIT: 0.8473132339716463
Epoch: 304, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.6873382830377038 HIT: 0.7847710801946678

#### val Acc: 0, NDCG: 0.7987435074071005 HIT: 0.8491820514176894
Epoch: 320, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.6672639912862098 HIT: 0.7580397997778248

#### val Acc: 0, NDCG: 0.8106500230364535 HIT: 0.863022541525603
Epoch: 352, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.6824080145166274 HIT: 0.7740747659225561

#### val Acc: 0, NDCG: 0.7977404718121061 HIT: 0.8544363957363521
Epoch: 384, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.6674027201989857 HIT: 0.7576819059458315

#### val Acc: 0, NDCG: 0.8089177398277364 HIT: 0.8573871601248414
Epoch: 416, plus 0 steps train_loss: 0.6945

#### test Acc: 0, NDCG: 0.6751468664165579 HIT: 0.7666680993440542

#### val Acc: 0, NDCG: 0.8083154969155998 HIT: 0.8574483244286923
Epoch: 448, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.6890659010301128 HIT: 0.775755957733813

#### val Acc: 0, NDCG: 0.8060238535888888 HIT: 0.85342718472281
Epoch: 480, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.6918249623584815 HIT: 0.7716505104739738

#### val Acc: 0, NDCG: 0.8061502380922723 HIT: 0.8590204123465933
Epoch: 512, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.6831314469107248 HIT: 0.7688146357913669

#### val Acc: 0, NDCG: 0.8048809116424436 HIT: 0.8588501441493864
Epoch: 544, plus 0 steps train_loss: 0.6948

#### test Acc: 0, NDCG: 0.6851063479226372 HIT: 0.7805085894519679

#### val Acc: 0, NDCG: 0.8060472961469872 HIT: 0.8560870053956835
Epoch: 576, plus 0 steps train_loss: 0.6949

#### test Acc: 0, NDCG: 0.6776783281955718 HIT: 0.7637652745450698

#### val Acc: 0, NDCG: 0.8128065105533597 HIT: 0.8620554842890394
Epoch: 608, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.6837564808081663 HIT: 0.7673152838023699

#### val Acc: 0, NDCG: 0.8106267189857164 HIT: 0.8621397918429963
Epoch: 640, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.6432985252901755 HIT: 0.7486725692975033

#### val Acc: 0, NDCG: 0.7937955660959242 HIT: 0.8542239737621667
Epoch: 704, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.6763623385036742 HIT: 0.7688204216038934

#### val Acc: 0, NDCG: 0.8146517703037176 HIT: 0.8608222796762589
Epoch: 768, plus 0 steps train_loss: 0.6943

#### test Acc: 0, NDCG: 0.6610816620564848 HIT: 0.7548096632987727

#### val Acc: 0, NDCG: 0.7956762310810748 HIT: 0.8589898301946678
Epoch: 832, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.6479508647547444 HIT: 0.7516712732754973

#### val Acc: 0, NDCG: 0.7838012528323238 HIT: 0.8472347122302158
Epoch: 896, plus 0 steps train_loss: 0.6941

#### test Acc: 0, NDCG: 0.6615797659148746 HIT: 0.7616972598391875

#### val Acc: 0, NDCG: 0.7910876338465258 HIT: 0.8524469027719002
Epoch: 960, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.6445864101848875 HIT: 0.7463747751798562

#### val Acc: 0, NDCG: 0.7951744371893595 HIT: 0.8563052131823953
Epoch: 1017, plus 0 steps train_loss: 0.6955
Done: it took 138551.43867111206
max value of NDCG: 0.6918249623584815
max value of HIT: 0.7847710801946678

After 20 validations
max value of NDCG: 0.6918249623584815
max value of HIT: 0.7847710801946678
