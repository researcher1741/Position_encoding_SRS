 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	0.1
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13132869505332015 HIT: 0.28698539330300465

#### val Acc: 0, NDCG: 0.4864522273867467 HIT: 0.5851076491747778
Epoch: 1, plus 0 steps train_loss: 0.7961

#### test Acc: 0, NDCG: 0.13018680397292393 HIT: 0.2940110227994075

#### val Acc: 0, NDCG: 0.46956178476126115 HIT: 0.5569538854210749
Epoch: 2, plus 0 steps train_loss: 0.7681

#### test Acc: 0, NDCG: 0.13333708918086623 HIT: 0.2911272085272958

#### val Acc: 0, NDCG: 0.4733183551914646 HIT: 0.5659400788192975
Epoch: 3, plus 0 steps train_loss: 0.7771

#### test Acc: 0, NDCG: 0.13235597719680317 HIT: 0.28787392879813795

#### val Acc: 0, NDCG: 0.47418479390512924 HIT: 0.5713266702814219
Epoch: 4, plus 0 steps train_loss: 0.7501

#### test Acc: 0, NDCG: 0.13541139686069797 HIT: 0.30083166922344473

#### val Acc: 0, NDCG: 0.4789294721404474 HIT: 0.5762132022323319
Epoch: 5, plus 0 steps train_loss: 0.7468

#### test Acc: 0, NDCG: 0.13210109905055986 HIT: 0.292088479951333

#### val Acc: 0, NDCG: 0.4772319606923827 HIT: 0.5670757511637748
Epoch: 6, plus 0 steps train_loss: 0.748

#### test Acc: 0, NDCG: 0.13486029360457885 HIT: 0.29293486166948796

#### val Acc: 0, NDCG: 0.48437043394772866 HIT: 0.5754453422556073
Epoch: 7, plus 0 steps train_loss: 0.7416

#### test Acc: 0, NDCG: 0.13958025229872295 HIT: 0.2989818623042742

#### val Acc: 0, NDCG: 0.48752808392745806 HIT: 0.583462825327973
Epoch: 8, plus 0 steps train_loss: 0.7326

#### test Acc: 0, NDCG: 0.14640635040426192 HIT: 0.3062488428374947

#### val Acc: 0, NDCG: 0.4853062172219167 HIT: 0.5823081424566229
Epoch: 9, plus 0 steps train_loss: 0.7328

#### test Acc: 0, NDCG: 0.13620955393913217 HIT: 0.2859381612357173

#### val Acc: 0, NDCG: 0.4834175343280279 HIT: 0.5750948873254337
Epoch: 10, plus 0 steps train_loss: 0.7257

#### test Acc: 0, NDCG: 0.13504125739001818 HIT: 0.2832419725983919

#### val Acc: 0, NDCG: 0.48674284598016215 HIT: 0.5819213195619974
Epoch: 12, plus 0 steps train_loss: 0.7225

#### test Acc: 0, NDCG: 0.1409788588905247 HIT: 0.28878726063267035

#### val Acc: 0, NDCG: 0.4784643323056058 HIT: 0.5747750145471858
Epoch: 14, plus 0 steps train_loss: 0.7198

#### test Acc: 0, NDCG: 0.37627698236769536 HIT: 0.515926688796022

#### val Acc: 0, NDCG: 0.6325057810580714 HIT: 0.7129782387325434
Epoch: 16, plus 0 steps train_loss: 0.7102

#### test Acc: 0, NDCG: 0.20922935418954466 HIT: 0.35392228496614475

#### val Acc: 0, NDCG: 0.5197840108970496 HIT: 0.6081583262801523
Epoch: 18, plus 0 steps train_loss: 0.717

#### test Acc: 0, NDCG: 0.1409165836297905 HIT: 0.2931704268937791

#### val Acc: 0, NDCG: 0.4820955206708362 HIT: 0.5787713579136691
Epoch: 20, plus 0 steps train_loss: 0.7098

#### test Acc: 0, NDCG: 0.14260491370752112 HIT: 0.2924025669170546

#### val Acc: 0, NDCG: 0.4928109891607484 HIT: 0.5849563915044436
Epoch: 22, plus 0 steps train_loss: 0.7147

#### test Acc: 0, NDCG: 0.15235962084710877 HIT: 0.3029666340457046

#### val Acc: 0, NDCG: 0.4837992509704699 HIT: 0.5722647984553533
Epoch: 24, plus 0 steps train_loss: 0.7087

#### test Acc: 0, NDCG: 0.3491353507573801 HIT: 0.48133331570038085

#### val Acc: 0, NDCG: 0.6234710467144011 HIT: 0.7068411447312738
Epoch: 26, plus 0 steps train_loss: 0.711

#### test Acc: 0, NDCG: 0.21146388927015927 HIT: 0.3532213751057977

#### val Acc: 0, NDCG: 0.5271193224899292 HIT: 0.6136730321625052
Epoch: 28, plus 0 steps train_loss: 0.7093

#### test Acc: 0, NDCG: 0.4227172108264549 HIT: 0.5589144493228946

#### val Acc: 0, NDCG: 0.648227499348669 HIT: 0.7342022521688532
Epoch: 30, plus 0 steps train_loss: 0.7059

#### test Acc: 0, NDCG: 0.4204791503166891 HIT: 0.557715959585273

#### val Acc: 0, NDCG: 0.6400469008695048 HIT: 0.7196856485399915
Epoch: 32, plus 0 steps train_loss: 0.7093

#### test Acc: 0, NDCG: 0.41980413764244545 HIT: 0.5591062076809141

#### val Acc: 0, NDCG: 0.6456977692967669 HIT: 0.7309258291895895
Epoch: 36, plus 0 steps train_loss: 0.7076

#### test Acc: 0, NDCG: 0.16945509602711017 HIT: 0.3224193623042742

#### val Acc: 0, NDCG: 0.5022526681335768 HIT: 0.5983447616906474
Epoch: 40, plus 0 steps train_loss: 0.7032

#### test Acc: 0, NDCG: 0.23305548223641293 HIT: 0.37318160177740156

#### val Acc: 0, NDCG: 0.5448713421988732 HIT: 0.6358583170228522
Epoch: 44, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.4768783470733543 HIT: 0.5962651753597122

#### val Acc: 0, NDCG: 0.6829901582357134 HIT: 0.7587407096381719
Epoch: 48, plus 0 steps train_loss: 0.704

#### test Acc: 0, NDCG: 0.5509179569128061 HIT: 0.6683894612251375

#### val Acc: 0, NDCG: 0.7330189793437816 HIT: 0.8043386981591197
Epoch: 52, plus 0 steps train_loss: 0.7054

#### test Acc: 0, NDCG: 0.5648564685892852 HIT: 0.6752654861404993

#### val Acc: 0, NDCG: 0.7404599811555453 HIT: 0.8071630012166737
Epoch: 56, plus 0 steps train_loss: 0.702

#### test Acc: 0, NDCG: 0.4821678347856563 HIT: 0.6069366932924248

#### val Acc: 0, NDCG: 0.7092587938284611 HIT: 0.786210920969107
Epoch: 60, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.5079877200241413 HIT: 0.6319826491747778

#### val Acc: 0, NDCG: 0.7319191134064444 HIT: 0.8034981022534913
Epoch: 64, plus 0 steps train_loss: 0.6989

#### test Acc: 0, NDCG: 0.5341665129405371 HIT: 0.6573178956834532

#### val Acc: 0, NDCG: 0.7413587592822426 HIT: 0.8106096923931443
Epoch: 68, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.5373764961088086 HIT: 0.6586238362251375

#### val Acc: 0, NDCG: 0.7345947233201503 HIT: 0.8020772720059247
Epoch: 72, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.5336252540563821 HIT: 0.6449767575645365

#### val Acc: 0, NDCG: 0.7340374643644134 HIT: 0.8074770881823953
Epoch: 80, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.5730455680134824 HIT: 0.6797519704824376

#### val Acc: 0, NDCG: 0.7568986390717204 HIT: 0.8253155747460855
Epoch: 88, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.5454639436381188 HIT: 0.6537447431760475

#### val Acc: 0, NDCG: 0.7296156050998945 HIT: 0.8030749113944138
Epoch: 96, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.5440013108904855 HIT: 0.6580609593207787

#### val Acc: 0, NDCG: 0.7236033122359045 HIT: 0.7927290520524757
Epoch: 104, plus 0 steps train_loss: 0.69

#### test Acc: 0, NDCG: 0.5161180708413442 HIT: 0.63494498518832

#### val Acc: 0, NDCG: 0.7180084895484481 HIT: 0.7925298547926365
Epoch: 112, plus 0 steps train_loss: 0.6914

#### test Acc: 0, NDCG: 0.5877160095273438 HIT: 0.6920393831993229

#### val Acc: 0, NDCG: 0.7687276653441321 HIT: 0.8365078158061785
Epoch: 120, plus 0 steps train_loss: 0.6906

#### test Acc: 0, NDCG: 0.6050819337354286 HIT: 0.7115995622619551

#### val Acc: 0, NDCG: 0.7681724117898308 HIT: 0.8337926166419806
Epoch: 128, plus 0 steps train_loss: 0.6887

#### test Acc: 0, NDCG: 0.5837222984382194 HIT: 0.6934354171074905

#### val Acc: 0, NDCG: 0.7574759830107055 HIT: 0.8216333183453237
Epoch: 136, plus 0 steps train_loss: 0.6917

#### test Acc: 0, NDCG: 0.5742895331690067 HIT: 0.6793287796233601

#### val Acc: 0, NDCG: 0.7654402989970642 HIT: 0.8294400325327973
Epoch: 144, plus 0 steps train_loss: 0.6865

#### test Acc: 0, NDCG: 0.6098235104267186 HIT: 0.7124591686944561

#### val Acc: 0, NDCG: 0.7553698323947158 HIT: 0.8220259270524757
Epoch: 160, plus 0 steps train_loss: 0.6826

#### test Acc: 0, NDCG: 0.6346149835198417 HIT: 0.7326301642509522

#### val Acc: 0, NDCG: 0.7858988107398112 HIT: 0.8456932064642404
Epoch: 176, plus 0 steps train_loss: 0.6862

#### test Acc: 0, NDCG: 0.6251758423447129 HIT: 0.7314581239420228

#### val Acc: 0, NDCG: 0.768278832266235 HIT: 0.8354010725243335
Epoch: 192, plus 0 steps train_loss: 0.6801

#### test Acc: 0, NDCG: 0.6149974701147263 HIT: 0.7275328634151502

#### val Acc: 0, NDCG: 0.7659422172366842 HIT: 0.8382733151713924
Epoch: 208, plus 0 steps train_loss: 0.6713

#### test Acc: 0, NDCG: 0.5488637335466473 HIT: 0.6660495133305121

#### val Acc: 0, NDCG: 0.7243128898185209 HIT: 0.8042064510156581
Epoch: 224, plus 0 steps train_loss: 0.668

#### test Acc: 0, NDCG: 0.5591045843402691 HIT: 0.6773029186944561

#### val Acc: 0, NDCG: 0.7642806556516787 HIT: 0.8426449098074481
Epoch: 240, plus 0 steps train_loss: 0.6681

#### test Acc: 0, NDCG: 0.5732480416165582 HIT: 0.6961084624947101

#### val Acc: 0, NDCG: 0.7630097029879783 HIT: 0.8335091118281844
Epoch: 256, plus 0 steps train_loss: 0.6641

#### test Acc: 0, NDCG: 0.5698042277148465 HIT: 0.6914095561785866

#### val Acc: 0, NDCG: 0.7303328544348754 HIT: 0.8090433902877698
Epoch: 272, plus 0 steps train_loss: 0.6564

#### test Acc: 0, NDCG: 0.5563024084242633 HIT: 0.6830837719530258

#### val Acc: 0, NDCG: 0.7270986664749435 HIT: 0.8022591118281844
Epoch: 288, plus 0 steps train_loss: 0.6473

#### test Acc: 0, NDCG: 0.5361151347660443 HIT: 0.6703921789039358

#### val Acc: 0, NDCG: 0.7293173426988422 HIT: 0.8058992144519679
Epoch: 304, plus 0 steps train_loss: 0.6328

#### test Acc: 0, NDCG: 0.5428085880594579 HIT: 0.66814811018832

#### val Acc: 0, NDCG: 0.7230713627335534 HIT: 0.8041700830512061
Epoch: 320, plus 0 steps train_loss: 0.6371

#### test Acc: 0, NDCG: 0.5173988818535599 HIT: 0.6491797370926788

#### val Acc: 0, NDCG: 0.7085386994315456 HIT: 0.7907817128650021
Epoch: 352, plus 0 steps train_loss: 0.6311

#### test Acc: 0, NDCG: 0.48042548163445414 HIT: 0.6158501507617435

#### val Acc: 0, NDCG: 0.6939574093652744 HIT: 0.7832601565806179
Epoch: 384, plus 0 steps train_loss: 0.6315

#### test Acc: 0, NDCG: 0.5288489913649255 HIT: 0.6586734289039358

#### val Acc: 0, NDCG: 0.7215110730575592 HIT: 0.8044056482754973
Epoch: 416, plus 0 steps train_loss: 0.6276

#### test Acc: 0, NDCG: 0.23875202867716888 HIT: 0.4140096011426153

#### val Acc: 0, NDCG: 0.5607902106506427 HIT: 0.6681233138489208
Epoch: 448, plus 0 steps train_loss: 0.6115

#### test Acc: 0, NDCG: 0.2553579259777108 HIT: 0.46760771529834955

#### val Acc: 0, NDCG: 0.5468819415331919 HIT: 0.6733181469530258
Epoch: 480, plus 0 steps train_loss: 0.5795

#### test Acc: 0, NDCG: 0.2556066284449955 HIT: 0.46277656183876426

#### val Acc: 0, NDCG: 0.5498315292073264 HIT: 0.6704153221540414
Epoch: 512, plus 0 steps train_loss: 0.5891

#### test Acc: 0, NDCG: 0.25251280976174334 HIT: 0.46056307527507406

#### val Acc: 0, NDCG: 0.5485878477764387 HIT: 0.6763168509310199
Epoch: 544, plus 0 steps train_loss: 0.5733

#### test Acc: 0, NDCG: 0.2624094530158317 HIT: 0.4730075314748201

#### val Acc: 0, NDCG: 0.550170431768411 HIT: 0.6727015446466357
Epoch: 576, plus 0 steps train_loss: 0.579

#### test Acc: 0, NDCG: 0.25910217945799546 HIT: 0.4690822709479475

#### val Acc: 0, NDCG: 0.5460586643427784 HIT: 0.6653965430596699
Epoch: 608, plus 0 steps train_loss: 0.5751

#### test Acc: 0, NDCG: 0.25804391033508756 HIT: 0.4619723338975878

#### val Acc: 0, NDCG: 0.5577870985909427 HIT: 0.6792981974714346
Epoch: 640, plus 0 steps train_loss: 0.5494

#### test Acc: 0, NDCG: 0.2667806215735837 HIT: 0.47482675624206516

#### val Acc: 0, NDCG: 0.5593546465676389 HIT: 0.6759300280363945
Epoch: 704, plus 0 steps train_loss: 0.5268

#### test Acc: 0, NDCG: 0.26054596292214915 HIT: 0.4693062645471858

#### val Acc: 0, NDCG: 0.561416047718852 HIT: 0.6785476949322895
Epoch: 768, plus 0 steps train_loss: 0.5312

#### test Acc: 0, NDCG: 0.2680783655418235 HIT: 0.4761021146318239

#### val Acc: 0, NDCG: 0.5478462827416892 HIT: 0.6713286539885738
Epoch: 832, plus 0 steps train_loss: 0.5215

#### test Acc: 0, NDCG: 0.2677206267796974 HIT: 0.48582723894413876

#### val Acc: 0, NDCG: 0.5593529408460557 HIT: 0.679413087177317
Epoch: 896, plus 0 steps train_loss: 0.5146

#### test Acc: 0, NDCG: 0.25780489838191567 HIT: 0.45695934061574267

#### val Acc: 0, NDCG: 0.5664129573606179 HIT: 0.6847707495768091
Epoch: 960, plus 0 steps train_loss: 0.5258

#### test Acc: 0, NDCG: 0.26365299927050984 HIT: 0.4720884138277613

#### val Acc: 0, NDCG: 0.5537773234228484 HIT: 0.6701491747778248
Epoch: 1017, plus 0 steps train_loss: 0.5386
Done: it took 146083.03077101707
max value of NDCG: 0.6346149835198417
max value of HIT: 0.7326301642509522

After 20 validations
max value of NDCG: 0.6346149835198417
max value of HIT: 0.7326301642509522
