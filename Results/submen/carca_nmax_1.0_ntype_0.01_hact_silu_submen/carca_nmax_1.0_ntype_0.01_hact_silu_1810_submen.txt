 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.01
max_norm:             	1.0
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11571301
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12836030232257525 HIT: 0.2869490253385527

#### val Acc: 0, NDCG: 0.476115917749123 HIT: 0.5671427012801523
Epoch: 1, plus 0 steps train_loss: 0.8205

#### test Acc: 0, NDCG: 0.12895139917961432 HIT: 0.2868705035971223

#### val Acc: 0, NDCG: 0.47696721697649974 HIT: 0.5719564973021583
Epoch: 2, plus 0 steps train_loss: 0.814

#### test Acc: 0, NDCG: 0.12729597758765196 HIT: 0.28214680094159966

#### val Acc: 0, NDCG: 0.4769732412666836 HIT: 0.5681287690435886
Epoch: 3, plus 0 steps train_loss: 0.7922

#### test Acc: 0, NDCG: 0.12441520909044751 HIT: 0.27579893805543804

#### val Acc: 0, NDCG: 0.4847346554837781 HIT: 0.576829804538722
Epoch: 4, plus 0 steps train_loss: 0.8246

#### test Acc: 0, NDCG: 0.12844889892356268 HIT: 0.28561250264494287

#### val Acc: 0, NDCG: 0.4740966238558998 HIT: 0.5686726354210749
Epoch: 5, plus 0 steps train_loss: 0.8077

#### test Acc: 0, NDCG: 0.12619770070939318 HIT: 0.28457270947947527

#### val Acc: 0, NDCG: 0.4738931310183792 HIT: 0.5699000542213288
Epoch: 6, plus 0 steps train_loss: 0.7765

#### test Acc: 0, NDCG: 0.12992768478346783 HIT: 0.29133219159966145

#### val Acc: 0, NDCG: 0.4733961613831761 HIT: 0.5631463579136691
Epoch: 7, plus 0 steps train_loss: 0.7776

#### test Acc: 0, NDCG: 0.12326145696805343 HIT: 0.2793357225983919

#### val Acc: 0, NDCG: 0.47134874560602746 HIT: 0.5650689007617435
Epoch: 8, plus 0 steps train_loss: 0.7834

#### test Acc: 0, NDCG: 0.1349731914487391 HIT: 0.2938366218789674

#### val Acc: 0, NDCG: 0.4747866288676043 HIT: 0.5697793787029201
Epoch: 9, plus 0 steps train_loss: 0.7804

#### test Acc: 0, NDCG: 0.13060782918204628 HIT: 0.2918396900126957

#### val Acc: 0, NDCG: 0.4773237090338815 HIT: 0.5692834519149387
Epoch: 10, plus 0 steps train_loss: 0.7607

#### test Acc: 0, NDCG: 0.13018200235533886 HIT: 0.2838527890922556

#### val Acc: 0, NDCG: 0.48527646659215207 HIT: 0.5815039145154465
Epoch: 12, plus 0 steps train_loss: 0.7761

#### test Acc: 0, NDCG: 0.1258413767311032 HIT: 0.2775760090457046

#### val Acc: 0, NDCG: 0.48037617068947364 HIT: 0.5788135116906474
Epoch: 14, plus 0 steps train_loss: 0.759

#### test Acc: 0, NDCG: 0.1264402216075642 HIT: 0.2776966845641134

#### val Acc: 0, NDCG: 0.47698341905141944 HIT: 0.5721019691599661
Epoch: 16, plus 0 steps train_loss: 0.7626

#### test Acc: 0, NDCG: 0.1245860261773138 HIT: 0.27419626798561153

#### val Acc: 0, NDCG: 0.47285338534649624 HIT: 0.565528459585273
Epoch: 18, plus 0 steps train_loss: 0.7425

#### test Acc: 0, NDCG: 0.12505899210174323 HIT: 0.2825220522111722

#### val Acc: 0, NDCG: 0.46029225730864043 HIT: 0.5585028300888701
Epoch: 20, plus 0 steps train_loss: 0.7542

#### test Acc: 0, NDCG: 0.12257721329029672 HIT: 0.2754294725983919

#### val Acc: 0, NDCG: 0.47757718198744525 HIT: 0.569053672503174
Epoch: 22, plus 0 steps train_loss: 0.7463

#### test Acc: 0, NDCG: 0.12695416332129514 HIT: 0.27708008225772324

#### val Acc: 0, NDCG: 0.4779073720549459 HIT: 0.5727243572788827
Epoch: 24, plus 0 steps train_loss: 0.753

#### test Acc: 0, NDCG: 0.12173400825496997 HIT: 0.26799222386796445

#### val Acc: 0, NDCG: 0.4732198566279731 HIT: 0.5737831609712231
Epoch: 26, plus 0 steps train_loss: 0.7317

#### test Acc: 0, NDCG: 0.12866723317168008 HIT: 0.2879582363520948

#### val Acc: 0, NDCG: 0.4694533837892685 HIT: 0.5600021820778671
Epoch: 28, plus 0 steps train_loss: 0.7607

#### test Acc: 0, NDCG: 0.1273863965259606 HIT: 0.27737681178586543

#### val Acc: 0, NDCG: 0.481271322989526 HIT: 0.5763950420545916
Epoch: 30, plus 0 steps train_loss: 0.7508

#### test Acc: 0, NDCG: 0.12741052003454878 HIT: 0.2774917014917478

#### val Acc: 0, NDCG: 0.48909755902490415 HIT: 0.5861895961172239
Epoch: 32, plus 0 steps train_loss: 0.7591

#### test Acc: 0, NDCG: 0.1273638965298074 HIT: 0.28478926417689376

#### val Acc: 0, NDCG: 0.475965426530853 HIT: 0.5703116734553533
Epoch: 36, plus 0 steps train_loss: 0.7424

#### test Acc: 0, NDCG: 0.12439452605408942 HIT: 0.2757088446889547

#### val Acc: 0, NDCG: 0.4833958122555124 HIT: 0.5715928176576386
Epoch: 40, plus 0 steps train_loss: 0.7334

#### test Acc: 0, NDCG: 0.13370822854355047 HIT: 0.28859384918535763

#### val Acc: 0, NDCG: 0.4699315257106753 HIT: 0.5640348934088024
Epoch: 44, plus 0 steps train_loss: 0.7287

#### test Acc: 0, NDCG: 0.13304272993248947 HIT: 0.2854976129390605

#### val Acc: 0, NDCG: 0.4762840107053459 HIT: 0.5664533630448583
Epoch: 48, plus 0 steps train_loss: 0.7353

#### test Acc: 0, NDCG: 0.12708183170945367 HIT: 0.275247632776132

#### val Acc: 0, NDCG: 0.47511988401819527 HIT: 0.5698273182924248
Epoch: 52, plus 0 steps train_loss: 0.7298

#### test Acc: 0, NDCG: 0.1256782684042468 HIT: 0.28512814748201437

#### val Acc: 0, NDCG: 0.4656941407225785 HIT: 0.5547536235717309
Epoch: 56, plus 0 steps train_loss: 0.7254

#### test Acc: 0, NDCG: 0.12866231374586903 HIT: 0.28480248889123994

#### val Acc: 0, NDCG: 0.475303616061512 HIT: 0.572506149492171
Epoch: 60, plus 0 steps train_loss: 0.7163

#### test Acc: 0, NDCG: 0.1310324443520773 HIT: 0.2867671855162928

#### val Acc: 0, NDCG: 0.48549443594933145 HIT: 0.5878592163034279
Epoch: 64, plus 0 steps train_loss: 0.7192

#### test Acc: 0, NDCG: 0.1365244235895847 HIT: 0.2940473907638595

#### val Acc: 0, NDCG: 0.48362232734763033 HIT: 0.5752998703977994
Epoch: 68, plus 0 steps train_loss: 0.7266

#### test Acc: 0, NDCG: 0.13206951627057628 HIT: 0.29144129549301734

#### val Acc: 0, NDCG: 0.46985898971528706 HIT: 0.5625776951967838
Epoch: 72, plus 0 steps train_loss: 0.723

#### test Acc: 0, NDCG: 0.12136302927260348 HIT: 0.2728481736669488

#### val Acc: 0, NDCG: 0.47112710451463213 HIT: 0.5598567102200592
Epoch: 80, plus 0 steps train_loss: 0.7181

#### test Acc: 0, NDCG: 0.13179801671027813 HIT: 0.28715979422344473

#### val Acc: 0, NDCG: 0.47753929071578005 HIT: 0.5716845641134152
Epoch: 88, plus 0 steps train_loss: 0.7155

#### test Acc: 0, NDCG: 0.13055844984960058 HIT: 0.2794506123042742

#### val Acc: 0, NDCG: 0.4816447568441121 HIT: 0.5744650603046974
Epoch: 96, plus 0 steps train_loss: 0.7149

#### test Acc: 0, NDCG: 0.1274396841680586 HIT: 0.27844140129073214

#### val Acc: 0, NDCG: 0.4860415862178216 HIT: 0.5738178758463817
Epoch: 104, plus 0 steps train_loss: 0.7056

#### test Acc: 0, NDCG: 0.13229565664738405 HIT: 0.29088420440118495

#### val Acc: 0, NDCG: 0.48486526433232036 HIT: 0.5691991443609818
Epoch: 112, plus 0 steps train_loss: 0.7086

#### test Acc: 0, NDCG: 0.14655567552437032 HIT: 0.29641213499788405

#### val Acc: 0, NDCG: 0.4841207283689452 HIT: 0.5694537201121456
Epoch: 120, plus 0 steps train_loss: 0.7119

#### test Acc: 0, NDCG: 0.25104135459862564 HIT: 0.4032331120397799

#### val Acc: 0, NDCG: 0.5483281680995954 HIT: 0.6395042054591621
Epoch: 128, plus 0 steps train_loss: 0.7035

#### test Acc: 0, NDCG: 0.24812450606916295 HIT: 0.3868303335272958

#### val Acc: 0, NDCG: 0.5482154559778317 HIT: 0.6398430887642828
Epoch: 136, plus 0 steps train_loss: 0.7105

#### test Acc: 0, NDCG: 0.31733424189195564 HIT: 0.45656673190859076

#### val Acc: 0, NDCG: 0.6082002634010432 HIT: 0.6880777547079983
Epoch: 144, plus 0 steps train_loss: 0.7064

#### test Acc: 0, NDCG: 0.5429424941371004 HIT: 0.6470869260473974

#### val Acc: 0, NDCG: 0.7286761700874971 HIT: 0.7951301642509522
Epoch: 160, plus 0 steps train_loss: 0.7044

#### test Acc: 0, NDCG: 0.6156239537237617 HIT: 0.7072585497778248

#### val Acc: 0, NDCG: 0.7692312166558666 HIT: 0.8325651978417267
Epoch: 176, plus 0 steps train_loss: 0.7036

#### test Acc: 0, NDCG: 0.649298715999458 HIT: 0.7389796802264071

#### val Acc: 0, NDCG: 0.7828513525889651 HIT: 0.8348324098074481
Epoch: 192, plus 0 steps train_loss: 0.7025

#### test Acc: 0, NDCG: 0.655226317453201 HIT: 0.7458309088023699

#### val Acc: 0, NDCG: 0.7937662346222298 HIT: 0.8478281712865002
Epoch: 208, plus 0 steps train_loss: 0.702

#### test Acc: 0, NDCG: 0.6477230793877586 HIT: 0.7384589570990266

#### val Acc: 0, NDCG: 0.7945547281112315 HIT: 0.8512194839716463
Epoch: 224, plus 0 steps train_loss: 0.7016

#### test Acc: 0, NDCG: 0.6230094372975866 HIT: 0.71599595323741

#### val Acc: 0, NDCG: 0.7891160322711954 HIT: 0.8422043615107914
Epoch: 240, plus 0 steps train_loss: 0.7013

#### test Acc: 0, NDCG: 0.6437372373246228 HIT: 0.7330781514494288

#### val Acc: 0, NDCG: 0.7882873272758211 HIT: 0.844423633887008
Epoch: 256, plus 0 steps train_loss: 0.702

#### test Acc: 0, NDCG: 0.653935557051901 HIT: 0.7395541287558189

#### val Acc: 0, NDCG: 0.790891897930941 HIT: 0.8456568384997883
Epoch: 272, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.6762596952071652 HIT: 0.7639950539568345

#### val Acc: 0, NDCG: 0.7942873039546278 HIT: 0.8493390949005502
Epoch: 288, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.6838328248814951 HIT: 0.7750781911235718

#### val Acc: 0, NDCG: 0.7988831564877085 HIT: 0.8472041300782903
Epoch: 304, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.6449037286928553 HIT: 0.7357511968366482

#### val Acc: 0, NDCG: 0.7855089264317374 HIT: 0.8425779596910707
Epoch: 320, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.6286743268701167 HIT: 0.7180333857913669

#### val Acc: 0, NDCG: 0.7954713451692992 HIT: 0.8488737502644943
Epoch: 352, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.6641069497843143 HIT: 0.7516902838023699

#### val Acc: 0, NDCG: 0.8132287390234355 HIT: 0.8632523209373677
Epoch: 384, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.6776927173251955 HIT: 0.7642669871455777

#### val Acc: 0, NDCG: 0.8111427914038712 HIT: 0.8599816837706306
Epoch: 416, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.6558797987243948 HIT: 0.7419304446148963

#### val Acc: 0, NDCG: 0.8010805043376542 HIT: 0.8553133596064325
Epoch: 448, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.5082772976161969 HIT: 0.6147012537029201

#### val Acc: 0, NDCG: 0.6984670628799714 HIT: 0.7658027070990266
Epoch: 480, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.6896140723336353 HIT: 0.776445295969107

#### val Acc: 0, NDCG: 0.8274558747736945 HIT: 0.8750132247143462
Epoch: 512, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.71297706032003 HIT: 0.7961947537558189

#### val Acc: 0, NDCG: 0.8100770267202471 HIT: 0.8675338222069403
Epoch: 544, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.6687824337479359 HIT: 0.7541451214028777

#### val Acc: 0, NDCG: 0.7885905752315618 HIT: 0.839977650232755
Epoch: 576, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.6887986420120994 HIT: 0.7699635328501904

#### val Acc: 0, NDCG: 0.8252821291753956 HIT: 0.8709383596064325
Epoch: 608, plus 0 steps train_loss: 0.6946

#### test Acc: 0, NDCG: 0.6912229793967826 HIT: 0.7722249590033856

#### val Acc: 0, NDCG: 0.8174403735935317 HIT: 0.8635796326174354
Epoch: 640, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.7090471433939912 HIT: 0.7874920651713924

#### val Acc: 0, NDCG: 0.8063847757806797 HIT: 0.8538503755818875
Epoch: 704, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.7135105324178855 HIT: 0.7869672093207787

#### val Acc: 0, NDCG: 0.8198753287704135 HIT: 0.8703754827020737
Epoch: 768, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.6966602466988109 HIT: 0.7811557739102836

#### val Acc: 0, NDCG: 0.8340391680619086 HIT: 0.8818950354422345
Epoch: 832, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.7155576718658937 HIT: 0.7916471051100296

#### val Acc: 0, NDCG: 0.8328754137011148 HIT: 0.8787987991959374
Epoch: 896, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.708570272074339 HIT: 0.7901956927105375

#### val Acc: 0, NDCG: 0.8206509659802563 HIT: 0.8708656236775285
Epoch: 960, plus 0 steps train_loss: 0.6949

#### test Acc: 0, NDCG: 0.7196721409877505 HIT: 0.7996050769678374

#### val Acc: 0, NDCG: 0.8308287516411164 HIT: 0.8769126243123149
Epoch: 1017, plus 0 steps train_loss: 0.6947
Done: it took 79550.8155040741
max value of NDCG: 0.7196721409877505
max value of HIT: 0.7996050769678374

After 20 validations
max value of NDCG: 0.7196721409877505
max value of HIT: 0.7996050769678374
