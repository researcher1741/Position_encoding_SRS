 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.0001
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12236347988277035 HIT: 0.27139676126745665

#### val Acc: 0, NDCG: 0.4688869424298421 HIT: 0.5661756440435886
Epoch: 1, plus 0 steps train_loss: 0.7732

#### test Acc: 0, NDCG: 0.12610170429134127 HIT: 0.27898526766821835

#### val Acc: 0, NDCG: 0.46564237928359936 HIT: 0.5553338579136691
Epoch: 2, plus 0 steps train_loss: 0.7925

#### test Acc: 0, NDCG: 0.11871901683329446 HIT: 0.2677450870186204

#### val Acc: 0, NDCG: 0.4761302563299039 HIT: 0.5655590417371984
Epoch: 3, plus 0 steps train_loss: 0.7907

#### test Acc: 0, NDCG: 0.12590202345644425 HIT: 0.28380484950275076

#### val Acc: 0, NDCG: 0.48232462866229053 HIT: 0.5745320104210749
Epoch: 4, plus 0 steps train_loss: 0.7885

#### test Acc: 0, NDCG: 0.12249306925873105 HIT: 0.2734226221963606

#### val Acc: 0, NDCG: 0.4683222877356372 HIT: 0.5592591184405417
Epoch: 5, plus 0 steps train_loss: 0.7902

#### test Acc: 0, NDCG: 0.12830534457447804 HIT: 0.2826733098815066

#### val Acc: 0, NDCG: 0.4705155554623555 HIT: 0.5641919368916631
Epoch: 6, plus 0 steps train_loss: 0.7797

#### test Acc: 0, NDCG: 0.12740852737160702 HIT: 0.2810227002221752

#### val Acc: 0, NDCG: 0.47570153653563735 HIT: 0.5690900404676259
Epoch: 7, plus 0 steps train_loss: 0.7962

#### test Acc: 0, NDCG: 0.12494269667370413 HIT: 0.2796803917160389

#### val Acc: 0, NDCG: 0.4704681202460004 HIT: 0.5630256823952603
Epoch: 8, plus 0 steps train_loss: 0.7791

#### test Acc: 0, NDCG: 0.13625260917030982 HIT: 0.2924926602835379

#### val Acc: 0, NDCG: 0.4760337958361725 HIT: 0.5602319614896318
Epoch: 9, plus 0 steps train_loss: 0.7793

#### test Acc: 0, NDCG: 0.1298325787866855 HIT: 0.2838527890922556

#### val Acc: 0, NDCG: 0.47114910994032105 HIT: 0.5637513885950063
Epoch: 10, plus 0 steps train_loss: 0.7809

#### test Acc: 0, NDCG: 0.12109833310691265 HIT: 0.2620121733495557

#### val Acc: 0, NDCG: 0.48399286943581415 HIT: 0.5718358217837495
Epoch: 12, plus 0 steps train_loss: 0.7577

#### test Acc: 0, NDCG: 0.13203432230727627 HIT: 0.28436028750528985

#### val Acc: 0, NDCG: 0.4763374654244763 HIT: 0.561869346434617
Epoch: 14, plus 0 steps train_loss: 0.7769

#### test Acc: 0, NDCG: 0.13158792023468696 HIT: 0.2852546088129497

#### val Acc: 0, NDCG: 0.4737126495912976 HIT: 0.5626008384468895
Epoch: 16, plus 0 steps train_loss: 0.7683

#### test Acc: 0, NDCG: 0.1302591666527887 HIT: 0.28397925042319083

#### val Acc: 0, NDCG: 0.468046156331234 HIT: 0.5629893144308082
Epoch: 18, plus 0 steps train_loss: 0.7769

#### test Acc: 0, NDCG: 0.13546565957559112 HIT: 0.2984305570249683

#### val Acc: 0, NDCG: 0.47635540234693097 HIT: 0.5656855030681338
Epoch: 20, plus 0 steps train_loss: 0.7506

#### test Acc: 0, NDCG: 0.12708537343588006 HIT: 0.2815359844477359

#### val Acc: 0, NDCG: 0.4833217530506628 HIT: 0.5845869260473974
Epoch: 22, plus 0 steps train_loss: 0.735

#### test Acc: 0, NDCG: 0.13566330285587092 HIT: 0.2946276251057977

#### val Acc: 0, NDCG: 0.48256355631092873 HIT: 0.5766727610558613
Epoch: 24, plus 0 steps train_loss: 0.7472

#### test Acc: 0, NDCG: 0.12765167017268272 HIT: 0.28277662796233605

#### val Acc: 0, NDCG: 0.4843787689629271 HIT: 0.5747560040203131
Epoch: 26, plus 0 steps train_loss: 0.7482

#### test Acc: 0, NDCG: 0.12914325696672121 HIT: 0.28649525232754974

#### val Acc: 0, NDCG: 0.47835261873037344 HIT: 0.5653656302898857
Epoch: 28, plus 0 steps train_loss: 0.7356

#### test Acc: 0, NDCG: 0.1186679315519869 HIT: 0.26660197577232336

#### val Acc: 0, NDCG: 0.47424172263669817 HIT: 0.5749973550571308
Epoch: 30, plus 0 steps train_loss: 0.7308

#### test Acc: 0, NDCG: 0.1270848067964399 HIT: 0.28546124497460856

#### val Acc: 0, NDCG: 0.48055311550232177 HIT: 0.5708919077972916
Epoch: 32, plus 0 steps train_loss: 0.7318

#### test Acc: 0, NDCG: 0.12542983314786693 HIT: 0.28229971170122725

#### val Acc: 0, NDCG: 0.48446047307722173 HIT: 0.5811724701121456
Epoch: 36, plus 0 steps train_loss: 0.72

#### test Acc: 0, NDCG: 0.14722364412473554 HIT: 0.29818920598815063

#### val Acc: 0, NDCG: 0.5043921989200646 HIT: 0.5974314298561151
Epoch: 40, plus 0 steps train_loss: 0.7232

#### test Acc: 0, NDCG: 0.17850117847684316 HIT: 0.33010374788404573

#### val Acc: 0, NDCG: 0.49944230089652375 HIT: 0.5980901859394837
Epoch: 44, plus 0 steps train_loss: 0.7151

#### test Acc: 0, NDCG: 0.2511085689791306 HIT: 0.4062334691070673

#### val Acc: 0, NDCG: 0.5650829355267162 HIT: 0.6622829493757935
Epoch: 48, plus 0 steps train_loss: 0.7172

#### test Acc: 0, NDCG: 0.290905448661012 HIT: 0.4518008754760897

#### val Acc: 0, NDCG: 0.5667283409246866 HIT: 0.6623730427422768
Epoch: 52, plus 0 steps train_loss: 0.7148

#### test Acc: 0, NDCG: 0.34470617181321045 HIT: 0.4894367594159966

#### val Acc: 0, NDCG: 0.6047269652663462 HIT: 0.6934238454824376
Epoch: 56, plus 0 steps train_loss: 0.7136

#### test Acc: 0, NDCG: 0.3990462234415989 HIT: 0.53577781157427

#### val Acc: 0, NDCG: 0.6566414969203025 HIT: 0.7402128848391875
Epoch: 60, plus 0 steps train_loss: 0.7149

#### test Acc: 0, NDCG: 0.4485334882402996 HIT: 0.5845579969847651

#### val Acc: 0, NDCG: 0.6604859310630842 HIT: 0.7446704401184934
Epoch: 64, plus 0 steps train_loss: 0.7086

#### test Acc: 0, NDCG: 0.43851421300779897 HIT: 0.5633397693609818

#### val Acc: 0, NDCG: 0.6827877914686048 HIT: 0.7614253266504444
Epoch: 68, plus 0 steps train_loss: 0.7108

#### test Acc: 0, NDCG: 0.47588747784279495 HIT: 0.6030246574798985

#### val Acc: 0, NDCG: 0.7086632001270687 HIT: 0.7833271066969953
Epoch: 72, plus 0 steps train_loss: 0.7083

#### test Acc: 0, NDCG: 0.5313393985168025 HIT: 0.6484118771159543

#### val Acc: 0, NDCG: 0.720753979531931 HIT: 0.7925298547926365
Epoch: 80, plus 0 steps train_loss: 0.7041

#### test Acc: 0, NDCG: 0.5834227249614377 HIT: 0.6912640843207787

#### val Acc: 0, NDCG: 0.7642143565315358 HIT: 0.8257503372302158
Epoch: 88, plus 0 steps train_loss: 0.7029

#### test Acc: 0, NDCG: 0.589056899203113 HIT: 0.6912773090351249

#### val Acc: 0, NDCG: 0.7706876576084755 HIT: 0.8356920162399492
Epoch: 96, plus 0 steps train_loss: 0.7065

#### test Acc: 0, NDCG: 0.6268351473323925 HIT: 0.7201799222386797

#### val Acc: 0, NDCG: 0.79094765124981 HIT: 0.849423402454507
Epoch: 104, plus 0 steps train_loss: 0.705

#### test Acc: 0, NDCG: 0.6403966394170487 HIT: 0.73552720323741

#### val Acc: 0, NDCG: 0.7775217165148598 HIT: 0.8334421617118071
Epoch: 112, plus 0 steps train_loss: 0.7022

#### test Acc: 0, NDCG: 0.651364114690095 HIT: 0.7432248135315277

#### val Acc: 0, NDCG: 0.7879385276558739 HIT: 0.8436309775708845
Epoch: 120, plus 0 steps train_loss: 0.7038

#### test Acc: 0, NDCG: 0.6539304231384263 HIT: 0.7490899743440542

#### val Acc: 0, NDCG: 0.7798255860892243 HIT: 0.8365078158061785
Epoch: 128, plus 0 steps train_loss: 0.704

#### test Acc: 0, NDCG: 0.623874052551697 HIT: 0.730096804909014

#### val Acc: 0, NDCG: 0.7755453444830669 HIT: 0.8385700446995346
Epoch: 136, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.6466902097966049 HIT: 0.7433570606749894

#### val Acc: 0, NDCG: 0.7906247545502166 HIT: 0.8437152851248414
Epoch: 144, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.6409644036165134 HIT: 0.7475906223550571

#### val Acc: 0, NDCG: 0.7871755242093632 HIT: 0.8522477055120609
Epoch: 160, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.6694637884012167 HIT: 0.7635354951333051

#### val Acc: 0, NDCG: 0.7950120570759183 HIT: 0.8571937486775285
Epoch: 176, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.6788811270433959 HIT: 0.7771404200169276

#### val Acc: 0, NDCG: 0.7979469954210197 HIT: 0.8543330776555226
Epoch: 192, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.6496300974003925 HIT: 0.7514968723550571

#### val Acc: 0, NDCG: 0.8013391234936647 HIT: 0.8571400232754973
Epoch: 208, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.6393263877356721 HIT: 0.7362471236246297

#### val Acc: 0, NDCG: 0.8070350520191679 HIT: 0.8611843062314853
Epoch: 224, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.6706684684070042 HIT: 0.767206179909014

#### val Acc: 0, NDCG: 0.8014023959231539 HIT: 0.8559299619128227
Epoch: 240, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.676746853363716 HIT: 0.7732647521688532

#### val Acc: 0, NDCG: 0.7943146631982677 HIT: 0.8558208580194668
Epoch: 256, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.6645529468418052 HIT: 0.757894327920017

#### val Acc: 0, NDCG: 0.7849247779435288 HIT: 0.8460552330194668
Epoch: 272, plus 0 steps train_loss: 0.694

#### test Acc: 0, NDCG: 0.6401144180167633 HIT: 0.7416279292742276

#### val Acc: 0, NDCG: 0.7902326347644502 HIT: 0.8503483059140923
Epoch: 288, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.6562462792585514 HIT: 0.745993738097757

#### val Acc: 0, NDCG: 0.8027835090866392 HIT: 0.8599089478417267
Epoch: 304, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.6345193158867597 HIT: 0.7280899545069827

#### val Acc: 0, NDCG: 0.7930506634166816 HIT: 0.8501796908061785
Epoch: 320, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.6674355012155925 HIT: 0.7583307434934405

#### val Acc: 0, NDCG: 0.7895770928166509 HIT: 0.8493944733918747
Epoch: 352, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.6802830373107381 HIT: 0.7755625462865002

#### val Acc: 0, NDCG: 0.7852648125979731 HIT: 0.8428994855586119
Epoch: 384, plus 0 steps train_loss: 0.6946

#### test Acc: 0, NDCG: 0.6528347964628765 HIT: 0.7559354171074905

#### val Acc: 0, NDCG: 0.7965392096763202 HIT: 0.8576954612780364
Epoch: 416, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.6426018518583599 HIT: 0.7292024836013542

#### val Acc: 0, NDCG: 0.7909693195178633 HIT: 0.8495862317498942
Epoch: 448, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.6826802176411055 HIT: 0.7764279385315277

#### val Acc: 0, NDCG: 0.7947128631089827 HIT: 0.8542066163245874
Epoch: 480, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.6808542215465306 HIT: 0.7698370715192552

#### val Acc: 0, NDCG: 0.8077401756940964 HIT: 0.8669172199005502
Epoch: 512, plus 0 steps train_loss: 0.6938

#### test Acc: 0, NDCG: 0.6741360535642738 HIT: 0.7664019519678374

#### val Acc: 0, NDCG: 0.7915604423902317 HIT: 0.8495688743123149
Epoch: 544, plus 0 steps train_loss: 0.6941

#### test Acc: 0, NDCG: 0.668328621737521 HIT: 0.7622965047079983

#### val Acc: 0, NDCG: 0.8085401612770149 HIT: 0.8646615795598815
Epoch: 576, plus 0 steps train_loss: 0.6938

#### test Acc: 0, NDCG: 0.677443078919532 HIT: 0.7716984500634786

#### val Acc: 0, NDCG: 0.7947496116030329 HIT: 0.8487952285230639
Epoch: 608, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.6641783886595858 HIT: 0.7616493202496826

#### val Acc: 0, NDCG: 0.7893070890835469 HIT: 0.8551373055966991
Epoch: 640, plus 0 steps train_loss: 0.6953

#### test Acc: 0, NDCG: 0.6453720177932158 HIT: 0.7522035680279306

#### val Acc: 0, NDCG: 0.7910099805175358 HIT: 0.8497928679115531
Epoch: 704, plus 0 steps train_loss: 0.693

#### test Acc: 0, NDCG: 0.6477602243571691 HIT: 0.7462293033220483

#### val Acc: 0, NDCG: 0.7895298584640236 HIT: 0.849115101301312
Epoch: 768, plus 0 steps train_loss: 0.6941

#### test Acc: 0, NDCG: 0.6498785720799544 HIT: 0.7508612595217943

#### val Acc: 0, NDCG: 0.7986066656130775 HIT: 0.8535288497143462
Epoch: 832, plus 0 steps train_loss: 0.6939

#### test Acc: 0, NDCG: 0.6523522593195301 HIT: 0.7437017297926365

#### val Acc: 0, NDCG: 0.7778197173064978 HIT: 0.8384130012166737
Epoch: 896, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.6494211966239345 HIT: 0.746066474026661

#### val Acc: 0, NDCG: 0.8013378422399507 HIT: 0.8583542173614049
Epoch: 960, plus 0 steps train_loss: 0.6935

#### test Acc: 0, NDCG: 0.6563305915391351 HIT: 0.752735862780364

#### val Acc: 0, NDCG: 0.7878810168933092 HIT: 0.8466602637008042
Epoch: 1017, plus 0 steps train_loss: 0.6947
Done: it took 83091.45235705376
max value of NDCG: 0.6826802176411055
max value of HIT: 0.7771404200169276

After 20 validations
max value of NDCG: 0.6826802176411055
max value of HIT: 0.7771404200169276
