 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13465260768255546 HIT: 0.2966477002221752

#### val Acc: 0, NDCG: 0.4896643883895654 HIT: 0.5886634442446044
Epoch: 1, plus 0 steps train_loss: 0.8044

#### test Acc: 0, NDCG: 0.1371711657109806 HIT: 0.29850907876639865

#### val Acc: 0, NDCG: 0.481905391184742 HIT: 0.5837595548561151
Epoch: 2, plus 0 steps train_loss: 0.7906

#### test Acc: 0, NDCG: 0.13014381232711875 HIT: 0.28771688531527717

#### val Acc: 0, NDCG: 0.4778492527154134 HIT: 0.5743923243757935
Epoch: 3, plus 0 steps train_loss: 0.7831

#### test Acc: 0, NDCG: 0.12759380600898224 HIT: 0.28274025999788405

#### val Acc: 0, NDCG: 0.47487620643790285 HIT: 0.5723433201967838
Epoch: 4, plus 0 steps train_loss: 0.7799

#### test Acc: 0, NDCG: 0.1350217171936976 HIT: 0.292088479951333

#### val Acc: 0, NDCG: 0.4870031528357181 HIT: 0.5857854157850191
Epoch: 5, plus 0 steps train_loss: 0.7817

#### test Acc: 0, NDCG: 0.13771738460295624 HIT: 0.29445900999788405

#### val Acc: 0, NDCG: 0.4750284701725448 HIT: 0.5719449256771054
Epoch: 6, plus 0 steps train_loss: 0.7792

#### test Acc: 0, NDCG: 0.12911998825036394 HIT: 0.28318246138383407

#### val Acc: 0, NDCG: 0.48900098220594934 HIT: 0.5902661143144308
Epoch: 7, plus 0 steps train_loss: 0.7652

#### test Acc: 0, NDCG: 0.13493200741588351 HIT: 0.29541449560939487

#### val Acc: 0, NDCG: 0.48803264734488666 HIT: 0.5886212904676259
Epoch: 8, plus 0 steps train_loss: 0.7744

#### test Acc: 0, NDCG: 0.13277084806790115 HIT: 0.29343657426999575

#### val Acc: 0, NDCG: 0.4831579399292262 HIT: 0.588022045598815
Epoch: 9, plus 0 steps train_loss: 0.7667

#### test Acc: 0, NDCG: 0.1354772781312475 HIT: 0.2984437817393144

#### val Acc: 0, NDCG: 0.48068391784821474 HIT: 0.5801194522323319
Epoch: 10, plus 0 steps train_loss: 0.7743

#### test Acc: 0, NDCG: 0.12981043344069043 HIT: 0.28768630316335164

#### val Acc: 0, NDCG: 0.4781514255671721 HIT: 0.5681287690435886
Epoch: 12, plus 0 steps train_loss: 0.7644

#### test Acc: 0, NDCG: 0.137829358664193 HIT: 0.296707211436733

#### val Acc: 0, NDCG: 0.4714952568058996 HIT: 0.5639026462653407
Epoch: 14, plus 0 steps train_loss: 0.771

#### test Acc: 0, NDCG: 0.13509899347058874 HIT: 0.2873416340457046

#### val Acc: 0, NDCG: 0.48160628780792 HIT: 0.573256652031316
Epoch: 16, plus 0 steps train_loss: 0.7664

#### test Acc: 0, NDCG: 0.13540958941868836 HIT: 0.29826772772958104

#### val Acc: 0, NDCG: 0.47840673148796725 HIT: 0.569264441388066
Epoch: 18, plus 0 steps train_loss: 0.7489

#### test Acc: 0, NDCG: 0.1245977122569207 HIT: 0.28382220694033006

#### val Acc: 0, NDCG: 0.4717730994791804 HIT: 0.5648697035019044
Epoch: 20, plus 0 steps train_loss: 0.7573

#### test Acc: 0, NDCG: 0.13507666281292605 HIT: 0.2983346778459585

#### val Acc: 0, NDCG: 0.4873316444989206 HIT: 0.5798111510791367
Epoch: 22, plus 0 steps train_loss: 0.7611

#### test Acc: 0, NDCG: 0.12654495303640823 HIT: 0.2749335458104105

#### val Acc: 0, NDCG: 0.4827534251388329 HIT: 0.5786068755289886
Epoch: 24, plus 0 steps train_loss: 0.7505

#### test Acc: 0, NDCG: 0.13183416327623104 HIT: 0.27960186997460856

#### val Acc: 0, NDCG: 0.4776381053407749 HIT: 0.5711349119234024
Epoch: 26, plus 0 steps train_loss: 0.7371

#### test Acc: 0, NDCG: 0.12717873955809864 HIT: 0.28082350296233605

#### val Acc: 0, NDCG: 0.4821697104651426 HIT: 0.5796598934088024
Epoch: 28, plus 0 steps train_loss: 0.7365

#### test Acc: 0, NDCG: 0.12287247427472903 HIT: 0.2721704070567076

#### val Acc: 0, NDCG: 0.4848243492076059 HIT: 0.5839165983389759
Epoch: 30, plus 0 steps train_loss: 0.7276

#### test Acc: 0, NDCG: 0.13375952364304095 HIT: 0.2886054208104105

#### val Acc: 0, NDCG: 0.48375653331717733 HIT: 0.5770959519149387
Epoch: 32, plus 0 steps train_loss: 0.7254

#### test Acc: 0, NDCG: 0.15477774951002596 HIT: 0.3126653089293271

#### val Acc: 0, NDCG: 0.4937207650023563 HIT: 0.5896131440435886
Epoch: 36, plus 0 steps train_loss: 0.7168

#### test Acc: 0, NDCG: 0.2017692463922539 HIT: 0.3558216845641134

#### val Acc: 0, NDCG: 0.5085175873628462 HIT: 0.6040107252433348
Epoch: 40, plus 0 steps train_loss: 0.7235

#### test Acc: 0, NDCG: 0.22061227447275053 HIT: 0.3769729620715192

#### val Acc: 0, NDCG: 0.5254866986022453 HIT: 0.6207904081146848
Epoch: 44, plus 0 steps train_loss: 0.715

#### test Acc: 0, NDCG: 0.2519011032820399 HIT: 0.4064078700275074

#### val Acc: 0, NDCG: 0.5440361142638261 HIT: 0.6395099912716885
Epoch: 48, plus 0 steps train_loss: 0.7141

#### test Acc: 0, NDCG: 0.2702431010368165 HIT: 0.4210468022640711

#### val Acc: 0, NDCG: 0.5633591725066943 HIT: 0.6537695395154465
Epoch: 52, plus 0 steps train_loss: 0.7139

#### test Acc: 0, NDCG: 0.29477587288471024 HIT: 0.45246707046127804

#### val Acc: 0, NDCG: 0.5652936508593281 HIT: 0.6594049209162083
Epoch: 56, plus 0 steps train_loss: 0.711

#### test Acc: 0, NDCG: 0.3162806251570467 HIT: 0.46598190197841727

#### val Acc: 0, NDCG: 0.5801725866362752 HIT: 0.6730941533537875
Epoch: 60, plus 0 steps train_loss: 0.7118

#### test Acc: 0, NDCG: 0.3211321602243232 HIT: 0.47880574217096905

#### val Acc: 0, NDCG: 0.5887061393530285 HIT: 0.6809008675412611
Epoch: 64, plus 0 steps train_loss: 0.7091

#### test Acc: 0, NDCG: 0.32057380005311914 HIT: 0.46867065171392297

#### val Acc: 0, NDCG: 0.5838977295887379 HIT: 0.675186964399069
Epoch: 68, plus 0 steps train_loss: 0.7083

#### test Acc: 0, NDCG: 0.34471686328313117 HIT: 0.4967649042530682

#### val Acc: 0, NDCG: 0.5954249551724091 HIT: 0.685163358283961
Epoch: 72, plus 0 steps train_loss: 0.7093

#### test Acc: 0, NDCG: 0.36466794065507524 HIT: 0.5132420717837495

#### val Acc: 0, NDCG: 0.6079591439635712 HIT: 0.6953042345535336
Epoch: 80, plus 0 steps train_loss: 0.7045

#### test Acc: 0, NDCG: 0.3587071619288958 HIT: 0.51003094583157

#### val Acc: 0, NDCG: 0.6142664843380721 HIT: 0.701562004073212
Epoch: 88, plus 0 steps train_loss: 0.7061

#### test Acc: 0, NDCG: 0.35973450592794287 HIT: 0.5118096699111299

#### val Acc: 0, NDCG: 0.6187352985437239 HIT: 0.711327629073212
Epoch: 96, plus 0 steps train_loss: 0.709

#### test Acc: 0, NDCG: 0.3910642046858655 HIT: 0.5416793403512484

#### val Acc: 0, NDCG: 0.6263522787973331 HIT: 0.7158810635315277
Epoch: 104, plus 0 steps train_loss: 0.7055

#### test Acc: 0, NDCG: 0.38988126512639854 HIT: 0.5312012338658485

#### val Acc: 0, NDCG: 0.6246471991588769 HIT: 0.7148106882141346
Epoch: 112, plus 0 steps train_loss: 0.7042

#### test Acc: 0, NDCG: 0.4275655079298011 HIT: 0.5686189100190435

#### val Acc: 0, NDCG: 0.6391855239712464 HIT: 0.726952629073212
Epoch: 120, plus 0 steps train_loss: 0.7024

#### test Acc: 0, NDCG: 0.4132960167526151 HIT: 0.557679591620821

#### val Acc: 0, NDCG: 0.6389005729209164 HIT: 0.729420691388066
Epoch: 128, plus 0 steps train_loss: 0.7

#### test Acc: 0, NDCG: 0.41298481903072215 HIT: 0.5492984289039358

#### val Acc: 0, NDCG: 0.6554149284750109 HIT: 0.744948159119763
Epoch: 136, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.39542470923135997 HIT: 0.5410379417054592

#### val Acc: 0, NDCG: 0.6319263374097699 HIT: 0.716388561944562
Epoch: 144, plus 0 steps train_loss: 0.7016

#### test Acc: 0, NDCG: 0.4500058627101404 HIT: 0.5773373029517562

#### val Acc: 0, NDCG: 0.6709849158882774 HIT: 0.7483526965192552
Epoch: 160, plus 0 steps train_loss: 0.7007

#### test Acc: 0, NDCG: 0.48218260017399217 HIT: 0.6180636373254337

#### val Acc: 0, NDCG: 0.6889456897199513 HIT: 0.7701933122619551
Epoch: 176, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.49499485466116927 HIT: 0.6312875251269573

#### val Acc: 0, NDCG: 0.6768456526773695 HIT: 0.7593267297926365
Epoch: 192, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.49855569666061994 HIT: 0.6321992038721964

#### val Acc: 0, NDCG: 0.7009777897249282 HIT: 0.7805449574164198
Epoch: 208, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.49843193790912904 HIT: 0.6222343816123572

#### val Acc: 0, NDCG: 0.6884720373943697 HIT: 0.7693163483918747
Epoch: 224, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.4839202791345696 HIT: 0.6160551338341091

#### val Acc: 0, NDCG: 0.6778567159287698 HIT: 0.763202397640711
Epoch: 240, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.4881147046647062 HIT: 0.6265158828819297

#### val Acc: 0, NDCG: 0.7034413203517915 HIT: 0.7849049804274228
Epoch: 256, plus 0 steps train_loss: 0.6943

#### test Acc: 0, NDCG: 0.4830531976916195 HIT: 0.6161336555755396

#### val Acc: 0, NDCG: 0.6893154948032092 HIT: 0.7689468829348286
Epoch: 272, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.5000904195644323 HIT: 0.6325496588023699

#### val Acc: 0, NDCG: 0.6980920845967172 HIT: 0.7812764494286923
Epoch: 288, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.49247157664481994 HIT: 0.6369634072154041

#### val Acc: 0, NDCG: 0.7055443838407809 HIT: 0.7862530747460855
Epoch: 304, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.49602244251298727 HIT: 0.6306940660706729

#### val Acc: 0, NDCG: 0.6876903116357153 HIT: 0.770313987780364
Epoch: 320, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.4706494174712796 HIT: 0.6064771344688955

#### val Acc: 0, NDCG: 0.6951197536899866 HIT: 0.7810656805438002
Epoch: 352, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.4976136055451992 HIT: 0.6377924314959796

#### val Acc: 0, NDCG: 0.6815314055868467 HIT: 0.7611707508992805
Epoch: 384, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.5551847949345387 HIT: 0.6684621971540414

#### val Acc: 0, NDCG: 0.7222378232291068 HIT: 0.7932861431443081
Epoch: 416, plus 0 steps train_loss: 0.6949

#### test Acc: 0, NDCG: 0.4895003936129421 HIT: 0.6195324071625052

#### val Acc: 0, NDCG: 0.6971644896594479 HIT: 0.7811863560622091
Epoch: 448, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.49688423635593504 HIT: 0.6289781593842573

#### val Acc: 0, NDCG: 0.6831235331889863 HIT: 0.7621146648857385
Epoch: 480, plus 0 steps train_loss: 0.6943

#### test Acc: 0, NDCG: 0.5401883329043731 HIT: 0.6593495424248835

#### val Acc: 0, NDCG: 0.717970641087039 HIT: 0.7879284807448159
Epoch: 512, plus 0 steps train_loss: 0.6948

#### test Acc: 0, NDCG: 0.4683750053791519 HIT: 0.6051406117752857

#### val Acc: 0, NDCG: 0.687579919527533 HIT: 0.7693890843207787
Epoch: 544, plus 0 steps train_loss: 0.6939

#### test Acc: 0, NDCG: 0.4413319211654037 HIT: 0.5836868189272112

#### val Acc: 0, NDCG: 0.6760032127867059 HIT: 0.7576397521688532
Epoch: 576, plus 0 steps train_loss: 0.6945

#### test Acc: 0, NDCG: 0.1938500327771827 HIT: 0.35401981723444775

#### val Acc: 0, NDCG: 0.5175315735811992 HIT: 0.6242007313267033
Epoch: 608, plus 0 steps train_loss: 0.6925

#### test Acc: 0, NDCG: 0.16215932440192857 HIT: 0.32891435013753706

#### val Acc: 0, NDCG: 0.49911930239253766 HIT: 0.6045297952814219
Epoch: 640, plus 0 steps train_loss: 0.6935

#### test Acc: 0, NDCG: 0.19417861884242196 HIT: 0.3683140803533643

#### val Acc: 0, NDCG: 0.5243168168200474 HIT: 0.6319578528353788
Epoch: 704, plus 0 steps train_loss: 0.691

#### test Acc: 0, NDCG: 0.21255262999434466 HIT: 0.3801708633093525

#### val Acc: 0, NDCG: 0.5307494156683882 HIT: 0.6319884349873043
Epoch: 768, plus 0 steps train_loss: 0.6781

#### test Acc: 0, NDCG: 0.22802858698523532 HIT: 0.3919449918006771

#### val Acc: 0, NDCG: 0.5346557556176795 HIT: 0.6345465906686416
Epoch: 832, plus 0 steps train_loss: 0.6775

#### test Acc: 0, NDCG: 0.2395865718856065 HIT: 0.4148006043694456

#### val Acc: 0, NDCG: 0.535707547526937 HIT: 0.638839663563267
Epoch: 896, plus 0 steps train_loss: 0.6715

#### test Acc: 0, NDCG: 0.24903655851436834 HIT: 0.42345370027507406

#### val Acc: 0, NDCG: 0.5309623531782616 HIT: 0.6335605229052053
Epoch: 960, plus 0 steps train_loss: 0.6721

#### test Acc: 0, NDCG: 0.24610374090129572 HIT: 0.41790841224079556

#### val Acc: 0, NDCG: 0.5356311051210856 HIT: 0.6352301430914092
Epoch: 1017, plus 0 steps train_loss: 0.6751
Done: it took 80924.53493642807
max value of NDCG: 0.5551847949345387
max value of HIT: 0.6684621971540414

After 20 validations
max value of NDCG: 0.5551847949345387
max value of HIT: 0.6684621971540414
