 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12813807638334368 HIT: 0.28131942975031743

#### val Acc: 0, NDCG: 0.4656102688068988 HIT: 0.551463975878121
Epoch: 1, plus 0 steps train_loss: 0.7991

#### test Acc: 0, NDCG: 0.13066216936957295 HIT: 0.28400983257511636

#### val Acc: 0, NDCG: 0.4749614875327881 HIT: 0.5620759825962759
Epoch: 2, plus 0 steps train_loss: 0.8127

#### test Acc: 0, NDCG: 0.1323095080941512 HIT: 0.28983862542319083

#### val Acc: 0, NDCG: 0.48844186939727124 HIT: 0.5763702457151926
Epoch: 3, plus 0 steps train_loss: 0.794

#### test Acc: 0, NDCG: 0.13620049499874728 HIT: 0.2993802568239526

#### val Acc: 0, NDCG: 0.4719383929737725 HIT: 0.5551156501269573
Epoch: 4, plus 0 steps train_loss: 0.8057

#### test Acc: 0, NDCG: 0.13086727604943676 HIT: 0.280158961066441

#### val Acc: 0, NDCG: 0.47745807464769474 HIT: 0.5679047754443504
Epoch: 5, plus 0 steps train_loss: 0.7955

#### test Acc: 0, NDCG: 0.12953088224341366 HIT: 0.28272868837283116

#### val Acc: 0, NDCG: 0.46716662897868716 HIT: 0.5480594384786288
Epoch: 6, plus 0 steps train_loss: 0.7969

#### test Acc: 0, NDCG: 0.13071428581348635 HIT: 0.2855571241536183

#### val Acc: 0, NDCG: 0.47976089769478525 HIT: 0.5690115187261955
Epoch: 7, plus 0 steps train_loss: 0.7827

#### test Acc: 0, NDCG: 0.13474869422794272 HIT: 0.2946945752221752

#### val Acc: 0, NDCG: 0.47189225638090826 HIT: 0.5599178745239103
Epoch: 8, plus 0 steps train_loss: 0.7704

#### test Acc: 0, NDCG: 0.13406383092259994 HIT: 0.2901047727994075

#### val Acc: 0, NDCG: 0.47464778802408447 HIT: 0.5634604448793906
Epoch: 9, plus 0 steps train_loss: 0.7865

#### test Acc: 0, NDCG: 0.1299339259710915 HIT: 0.2837378993863733

#### val Acc: 0, NDCG: 0.4783387119511468 HIT: 0.5661144797397376
Epoch: 10, plus 0 steps train_loss: 0.776

#### test Acc: 0, NDCG: 0.14060936691453577 HIT: 0.29906616985823103

#### val Acc: 0, NDCG: 0.47911305879226035 HIT: 0.5727913073952603
Epoch: 12, plus 0 steps train_loss: 0.776

#### test Acc: 0, NDCG: 0.13895534648539679 HIT: 0.30242276766821835

#### val Acc: 0, NDCG: 0.4797420554540732 HIT: 0.5739038364896318
Epoch: 14, plus 0 steps train_loss: 0.7664

#### test Acc: 0, NDCG: 0.13752878751625686 HIT: 0.29879423666948796

#### val Acc: 0, NDCG: 0.4772079708477284 HIT: 0.5745799500105797
Epoch: 16, plus 0 steps train_loss: 0.7721

#### test Acc: 0, NDCG: 0.13404313694529946 HIT: 0.29459869604316546

#### val Acc: 0, NDCG: 0.4746505867783852 HIT: 0.5660723259627592
Epoch: 18, plus 0 steps train_loss: 0.7655

#### test Acc: 0, NDCG: 0.1258249601822226 HIT: 0.27697676417689376

#### val Acc: 0, NDCG: 0.47005932118580857 HIT: 0.5622330260791367
Epoch: 20, plus 0 steps train_loss: 0.7602

#### test Acc: 0, NDCG: 0.13153340779954728 HIT: 0.2876499351988997

#### val Acc: 0, NDCG: 0.47665099725611065 HIT: 0.5717994538192975
Epoch: 22, plus 0 steps train_loss: 0.7475

#### test Acc: 0, NDCG: 0.1259483370017051 HIT: 0.28200876798561153

#### val Acc: 0, NDCG: 0.4833861137371677 HIT: 0.5731954877274651
Epoch: 24, plus 0 steps train_loss: 0.7444

#### test Acc: 0, NDCG: 0.13105901728288566 HIT: 0.29213063372831144

#### val Acc: 0, NDCG: 0.46815376113146845 HIT: 0.5610609857702074
Epoch: 26, plus 0 steps train_loss: 0.7384

#### test Acc: 0, NDCG: 0.12964704514584668 HIT: 0.2863191983178163

#### val Acc: 0, NDCG: 0.4846701728269424 HIT: 0.5756213962653407
Epoch: 28, plus 0 steps train_loss: 0.7492

#### test Acc: 0, NDCG: 0.1310080303296956 HIT: 0.2928679115531104

#### val Acc: 0, NDCG: 0.4912359954820754 HIT: 0.5885369829136691
Epoch: 30, plus 0 steps train_loss: 0.75

#### test Acc: 0, NDCG: 0.12730709401479015 HIT: 0.2822327615848498

#### val Acc: 0, NDCG: 0.48114392626421276 HIT: 0.5768182329136691
Epoch: 32, plus 0 steps train_loss: 0.7449

#### test Acc: 0, NDCG: 0.1276150711270348 HIT: 0.28361722386796445

#### val Acc: 0, NDCG: 0.4709982145394838 HIT: 0.5676692102200592
Epoch: 36, plus 0 steps train_loss: 0.7284

#### test Acc: 0, NDCG: 0.13516879946395877 HIT: 0.29610383384468897

#### val Acc: 0, NDCG: 0.48164099371212665 HIT: 0.5757536434088024
Epoch: 40, plus 0 steps train_loss: 0.7354

#### test Acc: 0, NDCG: 0.13737029342698276 HIT: 0.2899783114684723

#### val Acc: 0, NDCG: 0.4914605859379037 HIT: 0.5782506347862887
Epoch: 44, plus 0 steps train_loss: 0.7315

#### test Acc: 0, NDCG: 0.1322785060686292 HIT: 0.2892947590457046

#### val Acc: 0, NDCG: 0.47518083838597264 HIT: 0.5714126309246721
Epoch: 48, plus 0 steps train_loss: 0.7223

#### test Acc: 0, NDCG: 0.15229290531754816 HIT: 0.3103617289991536

#### val Acc: 0, NDCG: 0.4994243316322649 HIT: 0.5975463195619974
Epoch: 52, plus 0 steps train_loss: 0.7197

#### test Acc: 0, NDCG: 0.1883196744467675 HIT: 0.34534192498942023

#### val Acc: 0, NDCG: 0.5107430854704732 HIT: 0.6054373413034279
Epoch: 56, plus 0 steps train_loss: 0.7075

#### test Acc: 0, NDCG: 0.24770783075893021 HIT: 0.4006154451438849

#### val Acc: 0, NDCG: 0.5582113114787232 HIT: 0.6530975587177317
Epoch: 60, plus 0 steps train_loss: 0.7118

#### test Acc: 0, NDCG: 0.2811009423657878 HIT: 0.4242157744392721

#### val Acc: 0, NDCG: 0.5833438232026322 HIT: 0.6743215721540414
Epoch: 64, plus 0 steps train_loss: 0.7149

#### test Acc: 0, NDCG: 0.3714701828695282 HIT: 0.5138049486881083

#### val Acc: 0, NDCG: 0.6261151305054616 HIT: 0.7102341105057131
Epoch: 68, plus 0 steps train_loss: 0.7153

#### test Acc: 0, NDCG: 0.418282335318126 HIT: 0.5637265922556073

#### val Acc: 0, NDCG: 0.6473339514283476 HIT: 0.7320193477570884
Epoch: 72, plus 0 steps train_loss: 0.7135

#### test Acc: 0, NDCG: 0.4685229550582876 HIT: 0.6020633860558613

#### val Acc: 0, NDCG: 0.6841919781203079 HIT: 0.7605004231908591
Epoch: 80, plus 0 steps train_loss: 0.7108

#### test Acc: 0, NDCG: 0.4923622785500277 HIT: 0.6245511862568769

#### val Acc: 0, NDCG: 0.694152199683841 HIT: 0.7721770194138806
Epoch: 88, plus 0 steps train_loss: 0.7084

#### test Acc: 0, NDCG: 0.49287942332457163 HIT: 0.622488957363521

#### val Acc: 0, NDCG: 0.7036950360518199 HIT: 0.7773280456517139
Epoch: 96, plus 0 steps train_loss: 0.7053

#### test Acc: 0, NDCG: 0.4324061849037638 HIT: 0.5685403882776132

#### val Acc: 0, NDCG: 0.6770939710358741 HIT: 0.7520886783220483
Epoch: 104, plus 0 steps train_loss: 0.7049

#### test Acc: 0, NDCG: 0.5308276169492906 HIT: 0.6584915890816758

#### val Acc: 0, NDCG: 0.716297839489445 HIT: 0.7864712825327973
Epoch: 112, plus 0 steps train_loss: 0.7047

#### test Acc: 0, NDCG: 0.5388847528640788 HIT: 0.6645080075645365

#### val Acc: 0, NDCG: 0.7379092275713629 HIT: 0.8048114816969953
Epoch: 120, plus 0 steps train_loss: 0.7007

#### test Acc: 0, NDCG: 0.571928465977101 HIT: 0.6901763515658061

#### val Acc: 0, NDCG: 0.7392117382631573 HIT: 0.8103013912399492
Epoch: 128, plus 0 steps train_loss: 0.7015

#### test Acc: 0, NDCG: 0.527080061165651 HIT: 0.6474811878438426

#### val Acc: 0, NDCG: 0.7099951695601275 HIT: 0.7887864340880236
Epoch: 136, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.5518905418126286 HIT: 0.672362661341515

#### val Acc: 0, NDCG: 0.7277550525266644 HIT: 0.8015813452179432
Epoch: 144, plus 0 steps train_loss: 0.7042

#### test Acc: 0, NDCG: 0.5391039399486152 HIT: 0.6647799407532797

#### val Acc: 0, NDCG: 0.7231808691794808 HIT: 0.7960071281210326
Epoch: 160, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.5211241146007084 HIT: 0.6469546789039358

#### val Acc: 0, NDCG: 0.7238869384135626 HIT: 0.7982801258992805
Epoch: 176, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.6074958568342111 HIT: 0.7158446955670758

#### val Acc: 0, NDCG: 0.7569233178466138 HIT: 0.8189296908061785
Epoch: 192, plus 0 steps train_loss: 0.7016

#### test Acc: 0, NDCG: 0.5741018764616016 HIT: 0.6863618480215827

#### val Acc: 0, NDCG: 0.7544227988425238 HIT: 0.8199942803110453
Epoch: 208, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.5915828039023904 HIT: 0.7058013515658061

#### val Acc: 0, NDCG: 0.7594177443176615 HIT: 0.8300260526872619
Epoch: 224, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.5947550822725427 HIT: 0.7090430596699111

#### val Acc: 0, NDCG: 0.7446175244422396 HIT: 0.8101195514176894
Epoch: 240, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.5653026378541748 HIT: 0.6893299698476513

#### val Acc: 0, NDCG: 0.7375776637453274 HIT: 0.7995744948159119
Epoch: 256, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.5768665298883509 HIT: 0.6977706437790944

#### val Acc: 0, NDCG: 0.736534454741286 HIT: 0.8071514295916209
Epoch: 272, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.5771683351583247 HIT: 0.6944330564959796

#### val Acc: 0, NDCG: 0.7524366108215562 HIT: 0.8226483151713924
Epoch: 288, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.5822341624258592 HIT: 0.7052922000634786

#### val Acc: 0, NDCG: 0.7613440062082941 HIT: 0.8332487502644943
Epoch: 304, plus 0 steps train_loss: 0.6982

#### test Acc: 0, NDCG: 0.6046440618376235 HIT: 0.7191459148857385

#### val Acc: 0, NDCG: 0.7630944860874755 HIT: 0.8340281818662717
Epoch: 320, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.5769640764050397 HIT: 0.6921716303427846

#### val Acc: 0, NDCG: 0.75104255735577 HIT: 0.8236038007829031
Epoch: 352, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.5963482143700067 HIT: 0.7143453435780787

#### val Acc: 0, NDCG: 0.7388429686894151 HIT: 0.8082507339716463
Epoch: 384, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.6107570249740973 HIT: 0.728905754073212

#### val Acc: 0, NDCG: 0.7618243944008906 HIT: 0.8211258199322895
Epoch: 416, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.6118239481929292 HIT: 0.7233679049407533

#### val Acc: 0, NDCG: 0.7599792527217017 HIT: 0.826954612780364
Epoch: 448, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.5981360465668274 HIT: 0.7110672675095218

#### val Acc: 0, NDCG: 0.7641854359816339 HIT: 0.8293003464875158
Epoch: 480, plus 0 steps train_loss: 0.694

#### test Acc: 0, NDCG: 0.6027664039700644 HIT: 0.7173324759310199

#### val Acc: 0, NDCG: 0.761785756838613 HIT: 0.8332181681125688
Epoch: 512, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.5924749751761853 HIT: 0.7008916763647906

#### val Acc: 0, NDCG: 0.7594295683570024 HIT: 0.8271595958527296
Epoch: 544, plus 0 steps train_loss: 0.6946

#### test Acc: 0, NDCG: 0.6086899143730208 HIT: 0.719532737780364

#### val Acc: 0, NDCG: 0.7640754768351203 HIT: 0.8304186613944138
Epoch: 576, plus 0 steps train_loss: 0.6944

#### test Acc: 0, NDCG: 0.6022331629148737 HIT: 0.716388561944562

#### val Acc: 0, NDCG: 0.7630368709942696 HIT: 0.8350142496297079
Epoch: 608, plus 0 steps train_loss: 0.6942

#### test Acc: 0, NDCG: 0.5916474015434995 HIT: 0.6960125833157004

#### val Acc: 0, NDCG: 0.7735282071022435 HIT: 0.8373368400867541
Epoch: 640, plus 0 steps train_loss: 0.6948

#### test Acc: 0, NDCG: 0.5952419045833822 HIT: 0.7041928956834532

#### val Acc: 0, NDCG: 0.7620294514376937 HIT: 0.8261255884997883
Epoch: 704, plus 0 steps train_loss: 0.6941

#### test Acc: 0, NDCG: 0.6022088540002614 HIT: 0.7131600785548031

#### val Acc: 0, NDCG: 0.75338724739424 HIT: 0.8281688068662717
Epoch: 768, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.5876719552719688 HIT: 0.7029712626957257

#### val Acc: 0, NDCG: 0.7539120405536147 HIT: 0.8232169778882776
Epoch: 832, plus 0 steps train_loss: 0.6919

#### test Acc: 0, NDCG: 0.5998205488472985 HIT: 0.7108201306601777

#### val Acc: 0, NDCG: 0.7580808148954622 HIT: 0.8287432553956835
Epoch: 896, plus 0 steps train_loss: 0.6933

#### test Acc: 0, NDCG: 0.5819127044898682 HIT: 0.700443689166314

#### val Acc: 0, NDCG: 0.7642359950932387 HIT: 0.8302922000634786
Epoch: 960, plus 0 steps train_loss: 0.6921

#### test Acc: 0, NDCG: 0.58080389360215 HIT: 0.6990286447312738

#### val Acc: 0, NDCG: 0.7672574852782221 HIT: 0.8386064126639864
Epoch: 1017, plus 0 steps train_loss: 0.6947
Done: it took 82036.98614573479
max value of NDCG: 0.6118239481929292
max value of HIT: 0.728905754073212

After 20 validations
max value of NDCG: 0.6118239481929292
max value of HIT: 0.728905754073212
