 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13644746427477195 HIT: 0.30580250872831144

#### val Acc: 0, NDCG: 0.4704512698439287 HIT: 0.5584416657850191
Epoch: 1, plus 0 steps train_loss: 0.8064

#### test Acc: 0, NDCG: 0.129394170636225 HIT: 0.2915446135738468

#### val Acc: 0, NDCG: 0.47481554168874435 HIT: 0.5713208844688955
Epoch: 2, plus 0 steps train_loss: 0.7917

#### test Acc: 0, NDCG: 0.13339418697345623 HIT: 0.29909096619763015

#### val Acc: 0, NDCG: 0.4867102555336113 HIT: 0.576866172503174
Epoch: 3, plus 0 steps train_loss: 0.8042

#### test Acc: 0, NDCG: 0.125992868908628 HIT: 0.287837560833686

#### val Acc: 0, NDCG: 0.47151575272337304 HIT: 0.5625661235717309
Epoch: 4, plus 0 steps train_loss: 0.7893

#### test Acc: 0, NDCG: 0.13117559626800251 HIT: 0.29528059537663987

#### val Acc: 0, NDCG: 0.4804926789006353 HIT: 0.5774712031845112
Epoch: 5, plus 0 steps train_loss: 0.7759

#### test Acc: 0, NDCG: 0.12613546082460095 HIT: 0.2867671855162928

#### val Acc: 0, NDCG: 0.47635593506901197 HIT: 0.5757957971857808
Epoch: 6, plus 0 steps train_loss: 0.7742

#### test Acc: 0, NDCG: 0.12190174608760197 HIT: 0.27143891504443507

#### val Acc: 0, NDCG: 0.47726466150979213 HIT: 0.568490795598815
Epoch: 7, plus 0 steps train_loss: 0.7602

#### test Acc: 0, NDCG: 0.12751945337563303 HIT: 0.279324150973339

#### val Acc: 0, NDCG: 0.4854749247478503 HIT: 0.5791391702814219
Epoch: 8, plus 0 steps train_loss: 0.7685

#### test Acc: 0, NDCG: 0.12048549437678284 HIT: 0.2674235611510791

#### val Acc: 0, NDCG: 0.4742435731812207 HIT: 0.5662368083474396
Epoch: 9, plus 0 steps train_loss: 0.7615

#### test Acc: 0, NDCG: 0.120278220238518 HIT: 0.2641892919487939

#### val Acc: 0, NDCG: 0.47362020127363624 HIT: 0.5682742409013964
Epoch: 10, plus 0 steps train_loss: 0.7743

#### test Acc: 0, NDCG: 0.1314372268587176 HIT: 0.28117974370503596

#### val Acc: 0, NDCG: 0.47588007150415296 HIT: 0.5671732834320778
Epoch: 12, plus 0 steps train_loss: 0.7681

#### test Acc: 0, NDCG: 0.13592557648709497 HIT: 0.2957095720482438

#### val Acc: 0, NDCG: 0.4721420574209842 HIT: 0.5656086344159966
Epoch: 14, plus 0 steps train_loss: 0.7583

#### test Acc: 0, NDCG: 0.13447470494407818 HIT: 0.29274723603470165

#### val Acc: 0, NDCG: 0.4912412638329289 HIT: 0.5828825909860347
Epoch: 16, plus 0 steps train_loss: 0.7555

#### test Acc: 0, NDCG: 0.13666399906794102 HIT: 0.29520207363520945

#### val Acc: 0, NDCG: 0.4760961820551614 HIT: 0.5680750436415574
Epoch: 18, plus 0 steps train_loss: 0.753

#### test Acc: 0, NDCG: 0.1302618845187094 HIT: 0.29450116377486246

#### val Acc: 0, NDCG: 0.4773828822882291 HIT: 0.5677303745239103
Epoch: 20, plus 0 steps train_loss: 0.7569

#### test Acc: 0, NDCG: 0.12734736173359607 HIT: 0.284028843101989

#### val Acc: 0, NDCG: 0.4753766235938061 HIT: 0.5643506334638172
Epoch: 22, plus 0 steps train_loss: 0.7395

#### test Acc: 0, NDCG: 0.12554424113861049 HIT: 0.2780603642086331

#### val Acc: 0, NDCG: 0.4752629996827788 HIT: 0.5644886664198053
Epoch: 24, plus 0 steps train_loss: 0.734

#### test Acc: 0, NDCG: 0.12529973221462778 HIT: 0.2765610122196361

#### val Acc: 0, NDCG: 0.47212758727044435 HIT: 0.5653540586648329
Epoch: 26, plus 0 steps train_loss: 0.7378

#### test Acc: 0, NDCG: 0.13689085672569912 HIT: 0.29811068424672027

#### val Acc: 0, NDCG: 0.4901392761408975 HIT: 0.5827313333157004
Epoch: 28, plus 0 steps train_loss: 0.7433

#### test Acc: 0, NDCG: 0.1262443432047087 HIT: 0.275061660230639

#### val Acc: 0, NDCG: 0.47925286505580106 HIT: 0.5774769889970377
Epoch: 30, plus 0 steps train_loss: 0.7395

#### test Acc: 0, NDCG: 0.1414953595432613 HIT: 0.30760437605797714

#### val Acc: 0, NDCG: 0.4850074745108991 HIT: 0.5895825618916631
Epoch: 32, plus 0 steps train_loss: 0.7276

#### test Acc: 0, NDCG: 0.12851175635131615 HIT: 0.28651839557765557

#### val Acc: 0, NDCG: 0.4898771596922639 HIT: 0.587884012642827
Epoch: 36, plus 0 steps train_loss: 0.7225

#### test Acc: 0, NDCG: 0.13828370164005968 HIT: 0.30051179644519677

#### val Acc: 0, NDCG: 0.48481226395636956 HIT: 0.5788978192446044
Epoch: 40, plus 0 steps train_loss: 0.7207

#### test Acc: 0, NDCG: 0.14567626513945553 HIT: 0.3147812632247144

#### val Acc: 0, NDCG: 0.4843599974659136 HIT: 0.5790011373254337
Epoch: 44, plus 0 steps train_loss: 0.7221

#### test Acc: 0, NDCG: 0.15736217919184375 HIT: 0.3263313981168007

#### val Acc: 0, NDCG: 0.48523603619196054 HIT: 0.5806459611722387
Epoch: 48, plus 0 steps train_loss: 0.7154

#### test Acc: 0, NDCG: 0.1728811901520212 HIT: 0.32960947418535763

#### val Acc: 0, NDCG: 0.4900728941119096 HIT: 0.5806765433241642
Epoch: 52, plus 0 steps train_loss: 0.7115

#### test Acc: 0, NDCG: 0.1865153557087414 HIT: 0.3399974873042742

#### val Acc: 0, NDCG: 0.49741925955147215 HIT: 0.5883915110558613
Epoch: 56, plus 0 steps train_loss: 0.7156

#### test Acc: 0, NDCG: 0.18652660869401086 HIT: 0.3417439761426153

#### val Acc: 0, NDCG: 0.508209512065699 HIT: 0.6019790785019044
Epoch: 60, plus 0 steps train_loss: 0.7083

#### test Acc: 0, NDCG: 0.19237738157850923 HIT: 0.3481472175201016

#### val Acc: 0, NDCG: 0.5080825424385675 HIT: 0.5997961740901396
Epoch: 64, plus 0 steps train_loss: 0.7122

#### test Acc: 0, NDCG: 0.204732881113692 HIT: 0.34764550491959373

#### val Acc: 0, NDCG: 0.527856862863789 HIT: 0.6175429141980534
Epoch: 68, plus 0 steps train_loss: 0.704

#### test Acc: 0, NDCG: 0.21463147579767353 HIT: 0.3675214240372408

#### val Acc: 0, NDCG: 0.5349450211860581 HIT: 0.6304337045069827
Epoch: 72, plus 0 steps train_loss: 0.7084

#### test Acc: 0, NDCG: 0.23228344067975595 HIT: 0.3772564668853153

#### val Acc: 0, NDCG: 0.5281559236257583 HIT: 0.6134068847862887
Epoch: 80, plus 0 steps train_loss: 0.7076

#### test Acc: 0, NDCG: 0.22706241538728722 HIT: 0.37687542980321626

#### val Acc: 0, NDCG: 0.5287090308487523 HIT: 0.6131465232225984
Epoch: 88, plus 0 steps train_loss: 0.7022

#### test Acc: 0, NDCG: 0.2268669610888697 HIT: 0.36911252248201437

#### val Acc: 0, NDCG: 0.5210700250576131 HIT: 0.6084550558082945
Epoch: 96, plus 0 steps train_loss: 0.706

#### test Acc: 0, NDCG: 0.22797933844174556 HIT: 0.37390730797714766

#### val Acc: 0, NDCG: 0.5258454154753769 HIT: 0.6140656408696572
Epoch: 104, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.23158629053160787 HIT: 0.37595052634363096

#### val Acc: 0, NDCG: 0.5255638054212335 HIT: 0.6150153406686416
Epoch: 112, plus 0 steps train_loss: 0.7038

#### test Acc: 0, NDCG: 0.24872743591663415 HIT: 0.3952635685569192

#### val Acc: 0, NDCG: 0.5561523847736612 HIT: 0.6461620225878121
Epoch: 120, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.24205718407073817 HIT: 0.39092255607278886

#### val Acc: 0, NDCG: 0.5424276895733612 HIT: 0.6295931086013542
Epoch: 128, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.26583999089093324 HIT: 0.4050597757088447

#### val Acc: 0, NDCG: 0.5458020279352079 HIT: 0.6374783445302581
Epoch: 136, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.2765672121650116 HIT: 0.42339997487304276

#### val Acc: 0, NDCG: 0.559765029583158 HIT: 0.6374799976195513
Epoch: 144, plus 0 steps train_loss: 0.7021

#### test Acc: 0, NDCG: 0.2852115834566063 HIT: 0.42414303851036816

#### val Acc: 0, NDCG: 0.5714278358373345 HIT: 0.6592404385315277
Epoch: 160, plus 0 steps train_loss: 0.7024

#### test Acc: 0, NDCG: 0.3404335782280195 HIT: 0.47561941255818874

#### val Acc: 0, NDCG: 0.6062792487990709 HIT: 0.6875702562949639
Epoch: 176, plus 0 steps train_loss: 0.7013

#### test Acc: 0, NDCG: 0.33253543870487723 HIT: 0.46916079268937794

#### val Acc: 0, NDCG: 0.5990039766622908 HIT: 0.6847343816123572
Epoch: 192, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.34202737681941664 HIT: 0.47911404332416424

#### val Acc: 0, NDCG: 0.6051800938352383 HIT: 0.6884893739420228
Epoch: 208, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.387269288693736 HIT: 0.5248880858548455

#### val Acc: 0, NDCG: 0.62611119261088 HIT: 0.7081355136479052
Epoch: 224, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.5122459928062106 HIT: 0.6334398473867965

#### val Acc: 0, NDCG: 0.6937921797086152 HIT: 0.7673326412399492
Epoch: 240, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.44194278103987106 HIT: 0.5751064589504867

#### val Acc: 0, NDCG: 0.6801535512759349 HIT: 0.7527970270842149
Epoch: 256, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.4669099155021191 HIT: 0.6015864697947525

#### val Acc: 0, NDCG: 0.6638149082987288 HIT: 0.7384052316969953
Epoch: 272, plus 0 steps train_loss: 0.6942

#### test Acc: 0, NDCG: 0.4736294146576048 HIT: 0.5993845548561151

#### val Acc: 0, NDCG: 0.6813309388617468 HIT: 0.7567454308611934
Epoch: 288, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.4942103775623347 HIT: 0.6199440263965298

#### val Acc: 0, NDCG: 0.6985484680085108 HIT: 0.7701511584849767
Epoch: 304, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.5628441194920923 HIT: 0.6774351658379179

#### val Acc: 0, NDCG: 0.7436930996767347 HIT: 0.8124842956517139
Epoch: 320, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.6044367465748206 HIT: 0.7096712336013542

#### val Acc: 0, NDCG: 0.7544389734069362 HIT: 0.8173823992276766
Epoch: 352, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.5934147824332309 HIT: 0.7051120133305121

#### val Acc: 0, NDCG: 0.7526966635589711 HIT: 0.8159425584532374
Epoch: 384, plus 0 steps train_loss: 0.6949

#### test Acc: 0, NDCG: 0.563339441078199 HIT: 0.668776284119763

#### val Acc: 0, NDCG: 0.7508403356613377 HIT: 0.821476274862463
Epoch: 416, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.6023474993891469 HIT: 0.7097613269678374

#### val Acc: 0, NDCG: 0.7580759049773492 HIT: 0.8193470958527296
Epoch: 448, plus 0 steps train_loss: 0.6942

#### test Acc: 0, NDCG: 0.6027369652968425 HIT: 0.7161414250952179

#### val Acc: 0, NDCG: 0.7667981259533042 HIT: 0.8308955776555226
Epoch: 480, plus 0 steps train_loss: 0.6932

#### test Acc: 0, NDCG: 0.6340098543898058 HIT: 0.7366703144837071

#### val Acc: 0, NDCG: 0.7729288550230728 HIT: 0.8320576994286923
Epoch: 512, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.6254652511918126 HIT: 0.7217520101565806

#### val Acc: 0, NDCG: 0.7768042993945137 HIT: 0.8344455869128227
Epoch: 544, plus 0 steps train_loss: 0.6939

#### test Acc: 0, NDCG: 0.6346067643659898 HIT: 0.7259971434617013

#### val Acc: 0, NDCG: 0.7783984964978187 HIT: 0.8363929261002961
Epoch: 576, plus 0 steps train_loss: 0.6936

#### test Acc: 0, NDCG: 0.6557883035323004 HIT: 0.7575075050253914

#### val Acc: 0, NDCG: 0.77656314218441 HIT: 0.8350869855586119
Epoch: 608, plus 0 steps train_loss: 0.6938

#### test Acc: 0, NDCG: 0.663254795993544 HIT: 0.7566611233072366

#### val Acc: 0, NDCG: 0.7839559583117853 HIT: 0.8433590443821413
Epoch: 640, plus 0 steps train_loss: 0.6946

#### test Acc: 0, NDCG: 0.6343564485019781 HIT: 0.7373290705670758

#### val Acc: 0, NDCG: 0.7724421539817478 HIT: 0.8310964280046551
Epoch: 704, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.6374069757996542 HIT: 0.7298918218366482

#### val Acc: 0, NDCG: 0.7771792855976276 HIT: 0.8309393845217943
Epoch: 768, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.6452205703412057 HIT: 0.7378919474714346

#### val Acc: 0, NDCG: 0.7826298942245382 HIT: 0.8389990213711384
Epoch: 832, plus 0 steps train_loss: 0.6935

#### test Acc: 0, NDCG: 0.6430510694142055 HIT: 0.7448812090033856

#### val Acc: 0, NDCG: 0.7687320185888729 HIT: 0.827226545969107
Epoch: 896, plus 0 steps train_loss: 0.6939

#### test Acc: 0, NDCG: 0.642519690653484 HIT: 0.7395119749788405

#### val Acc: 0, NDCG: 0.7873880789038833 HIT: 0.8439392787240796
Epoch: 960, plus 0 steps train_loss: 0.6938

#### test Acc: 0, NDCG: 0.6159897028028325 HIT: 0.7113160574481592

#### val Acc: 0, NDCG: 0.7831058226693676 HIT: 0.8371550002644943
Epoch: 1017, plus 0 steps train_loss: 0.6944
Done: it took 81085.00475263596
max value of NDCG: 0.663254795993544
max value of HIT: 0.7575075050253914

After 20 validations
max value of NDCG: 0.663254795993544
max value of HIT: 0.7575075050253914
