 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.0001
max_norm:             	0.1
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12681394350513198 HIT: 0.2862828303533643

#### val Acc: 0, NDCG: 0.496743515116756 HIT: 0.5907620411024121
Epoch: 1, plus 0 steps train_loss: 0.7691

#### test Acc: 0, NDCG: 0.12740327496810913 HIT: 0.28098633225772324

#### val Acc: 0, NDCG: 0.4868484367138253 HIT: 0.5770480123254337
Epoch: 2, plus 0 steps train_loss: 0.766

#### test Acc: 0, NDCG: 0.1295761719216228 HIT: 0.2867671855162928

#### val Acc: 0, NDCG: 0.487215719287122 HIT: 0.5796235254443504
Epoch: 3, plus 0 steps train_loss: 0.7766

#### test Acc: 0, NDCG: 0.13046064202125604 HIT: 0.2855877063055438

#### val Acc: 0, NDCG: 0.48235347989239524 HIT: 0.5754759244075328
Epoch: 4, plus 0 steps train_loss: 0.7721

#### test Acc: 0, NDCG: 0.13206195835999135 HIT: 0.2912057302687262

#### val Acc: 0, NDCG: 0.4774474909502453 HIT: 0.5731533339504867
Epoch: 5, plus 0 steps train_loss: 0.7731

#### test Acc: 0, NDCG: 0.1272230198087927 HIT: 0.2758105096804909

#### val Acc: 0, NDCG: 0.47969776526204566 HIT: 0.5770595839504867
Epoch: 6, plus 0 steps train_loss: 0.7833

#### test Acc: 0, NDCG: 0.1272975569769115 HIT: 0.27954814457257726

#### val Acc: 0, NDCG: 0.48168578480484425 HIT: 0.5735285852200592
Epoch: 7, plus 0 steps train_loss: 0.7637

#### test Acc: 0, NDCG: 0.12805281562704907 HIT: 0.2771412465615743

#### val Acc: 0, NDCG: 0.4822125364294925 HIT: 0.5715754602200592
Epoch: 8, plus 0 steps train_loss: 0.7598

#### test Acc: 0, NDCG: 0.1272285955986493 HIT: 0.281597148751587

#### val Acc: 0, NDCG: 0.4766929792667037 HIT: 0.568304823053322
Epoch: 9, plus 0 steps train_loss: 0.7569

#### test Acc: 0, NDCG: 0.12203818612310882 HIT: 0.277334658008887

#### val Acc: 0, NDCG: 0.47284170989675334 HIT: 0.5596938809246721
Epoch: 10, plus 0 steps train_loss: 0.7765

#### test Acc: 0, NDCG: 0.1310170905370184 HIT: 0.2915619710114261

#### val Acc: 0, NDCG: 0.49352230571300854 HIT: 0.590072702867118
Epoch: 12, plus 0 steps train_loss: 0.7572

#### test Acc: 0, NDCG: 0.12929404604215342 HIT: 0.28381642112780364

#### val Acc: 0, NDCG: 0.4806669400044566 HIT: 0.5763586740901396
Epoch: 14, plus 0 steps train_loss: 0.7444

#### test Acc: 0, NDCG: 0.13249473975179543 HIT: 0.28859963499788405

#### val Acc: 0, NDCG: 0.4796191674861192 HIT: 0.5682130765975455
Epoch: 16, plus 0 steps train_loss: 0.7484

#### test Acc: 0, NDCG: 0.13908308324888266 HIT: 0.2998894083262802

#### val Acc: 0, NDCG: 0.47582264791090395 HIT: 0.5654499378438426
Epoch: 18, plus 0 steps train_loss: 0.7526

#### test Acc: 0, NDCG: 0.12831797108559329 HIT: 0.2814401052687262

#### val Acc: 0, NDCG: 0.4764936568268978 HIT: 0.5704571453131612
Epoch: 20, plus 0 steps train_loss: 0.7492

#### test Acc: 0, NDCG: 0.12342236070167312 HIT: 0.2766453197735929

#### val Acc: 0, NDCG: 0.486887932488017 HIT: 0.58069968657427
Epoch: 22, plus 0 steps train_loss: 0.7382

#### test Acc: 0, NDCG: 0.127035151108295 HIT: 0.2765172053533643

#### val Acc: 0, NDCG: 0.4830269104810608 HIT: 0.5817584902666102
Epoch: 24, plus 0 steps train_loss: 0.7327

#### test Acc: 0, NDCG: 0.126166032968583 HIT: 0.28186164303851036

#### val Acc: 0, NDCG: 0.4862676813270042 HIT: 0.5748419646635633
Epoch: 26, plus 0 steps train_loss: 0.7378

#### test Acc: 0, NDCG: 0.12188784924619579 HIT: 0.27374249497460856

#### val Acc: 0, NDCG: 0.485179945461343 HIT: 0.5836330935251799
Epoch: 28, plus 0 steps train_loss: 0.7316

#### test Acc: 0, NDCG: 0.12713062654137747 HIT: 0.28601089716462125

#### val Acc: 0, NDCG: 0.4752434668790702 HIT: 0.5708439682077867
Epoch: 30, plus 0 steps train_loss: 0.7214

#### test Acc: 0, NDCG: 0.12613891019005607 HIT: 0.27633123280787136

#### val Acc: 0, NDCG: 0.47067923886484453 HIT: 0.5595120411024121
Epoch: 32, plus 0 steps train_loss: 0.7192

#### test Acc: 0, NDCG: 0.14301972423695083 HIT: 0.2932084479475243

#### val Acc: 0, NDCG: 0.4903774498864678 HIT: 0.5814981287029201
Epoch: 36, plus 0 steps train_loss: 0.7137

#### test Acc: 0, NDCG: 0.1851390966205728 HIT: 0.33652599978840453

#### val Acc: 0, NDCG: 0.49686771377000044 HIT: 0.589346996667372
Epoch: 40, plus 0 steps train_loss: 0.708

#### test Acc: 0, NDCG: 0.2304854365576958 HIT: 0.3780243268620398

#### val Acc: 0, NDCG: 0.5302092714908916 HIT: 0.6238734196466357
Epoch: 44, plus 0 steps train_loss: 0.7091

#### test Acc: 0, NDCG: 0.24582248529259257 HIT: 0.3941336820249683

#### val Acc: 0, NDCG: 0.5400162233348619 HIT: 0.6300485347016505
Epoch: 48, plus 0 steps train_loss: 0.7057

#### test Acc: 0, NDCG: 0.2669802572333735 HIT: 0.4180175161341515

#### val Acc: 0, NDCG: 0.5485093959947047 HIT: 0.6404844874100719
Epoch: 52, plus 0 steps train_loss: 0.7094

#### test Acc: 0, NDCG: 0.3161781613462195 HIT: 0.46336258199322894

#### val Acc: 0, NDCG: 0.5856612523295999 HIT: 0.6762457680914092
Epoch: 56, plus 0 steps train_loss: 0.7101

#### test Acc: 0, NDCG: 0.36568820626731124 HIT: 0.5057205154993651

#### val Acc: 0, NDCG: 0.6076696006770592 HIT: 0.700026284119763
Epoch: 60, plus 0 steps train_loss: 0.7066

#### test Acc: 0, NDCG: 0.3470854033952569 HIT: 0.48626200142826914

#### val Acc: 0, NDCG: 0.6038404084913418 HIT: 0.6911012550253914
Epoch: 64, plus 0 steps train_loss: 0.7078

#### test Acc: 0, NDCG: 0.3844369649617801 HIT: 0.5261998122090563

#### val Acc: 0, NDCG: 0.6292988151381503 HIT: 0.7166067697312738
Epoch: 68, plus 0 steps train_loss: 0.709

#### test Acc: 0, NDCG: 0.3748984253127207 HIT: 0.5073826967837495

#### val Acc: 0, NDCG: 0.6283302197995565 HIT: 0.7075974330829454
Epoch: 72, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.39081411049079107 HIT: 0.5308623505607278

#### val Acc: 0, NDCG: 0.6364313022966657 HIT: 0.7194600018514601
Epoch: 80, plus 0 steps train_loss: 0.7044

#### test Acc: 0, NDCG: 0.42091794924801734 HIT: 0.5546139375264495

#### val Acc: 0, NDCG: 0.6495187026978909 HIT: 0.7355214174248835
Epoch: 88, plus 0 steps train_loss: 0.7024

#### test Acc: 0, NDCG: 0.44983906083798947 HIT: 0.5852952748095641

#### val Acc: 0, NDCG: 0.667804690004612 HIT: 0.7480311706517139
Epoch: 96, plus 0 steps train_loss: 0.7062

#### test Acc: 0, NDCG: 0.35089004049277905 HIT: 0.49086337547608977

#### val Acc: 0, NDCG: 0.6037599075970688 HIT: 0.6872983231062209
Epoch: 104, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.2780424380818071 HIT: 0.4140575407321202

#### val Acc: 0, NDCG: 0.581175216262572 HIT: 0.6684985651184934
Epoch: 112, plus 0 steps train_loss: 0.7044

#### test Acc: 0, NDCG: 0.2487226433062395 HIT: 0.3914490650126957

#### val Acc: 0, NDCG: 0.5474992706122908 HIT: 0.640411751481168
Epoch: 120, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.22611786155258443 HIT: 0.3657980784490055

#### val Acc: 0, NDCG: 0.5236992712640948 HIT: 0.6122637735399915
Epoch: 128, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.2330885288167968 HIT: 0.38103625555438003

#### val Acc: 0, NDCG: 0.5356131645449574 HIT: 0.6221385024333475
Epoch: 136, plus 0 steps train_loss: 0.7

#### test Acc: 0, NDCG: 0.3149846557661484 HIT: 0.4595770075116377

#### val Acc: 0, NDCG: 0.5769043932698669 HIT: 0.6662983032691494
Epoch: 144, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.3632692405927956 HIT: 0.5046732834320778

#### val Acc: 0, NDCG: 0.6042885684569625 HIT: 0.6926196175412611
Epoch: 160, plus 0 steps train_loss: 0.701

#### test Acc: 0, NDCG: 0.4584492892068126 HIT: 0.5965296696466357

#### val Acc: 0, NDCG: 0.6680686515056453 HIT: 0.7545509548243757
Epoch: 176, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.5043394036120535 HIT: 0.6317586555755396

#### val Acc: 0, NDCG: 0.6953571744037386 HIT: 0.7756352822154041
Epoch: 192, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.3833233767039216 HIT: 0.5258377856538299

#### val Acc: 0, NDCG: 0.6185717993990991 HIT: 0.7080321955670758
Epoch: 208, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.38267706672738305 HIT: 0.5275189774650867

#### val Acc: 0, NDCG: 0.6248769327468213 HIT: 0.7127790414727042
Epoch: 224, plus 0 steps train_loss: 0.6948

#### test Acc: 0, NDCG: 0.4628304538256977 HIT: 0.5938276951967838

#### val Acc: 0, NDCG: 0.6691094525583737 HIT: 0.7472765353893356
Epoch: 240, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.3862347387211969 HIT: 0.5237945672873466

#### val Acc: 0, NDCG: 0.6386803233615693 HIT: 0.7247391425095218
Epoch: 256, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.4563937660272597 HIT: 0.5758015829983072

#### val Acc: 0, NDCG: 0.6876904083408473 HIT: 0.7583290904041472
Epoch: 272, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.42542338500068533 HIT: 0.5623900695619974

#### val Acc: 0, NDCG: 0.6653825139972375 HIT: 0.7429528803427846
Epoch: 288, plus 0 steps train_loss: 0.6934

#### test Acc: 0, NDCG: 0.5018493897917828 HIT: 0.6322967361404993

#### val Acc: 0, NDCG: 0.6929962479036675 HIT: 0.7733796418747355
Epoch: 304, plus 0 steps train_loss: 0.6944

#### test Acc: 0, NDCG: 0.41590416189608903 HIT: 0.556427376481168

#### val Acc: 0, NDCG: 0.6483028490824626 HIT: 0.7377464756136267
Epoch: 320, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.3231643857099319 HIT: 0.47899336780575535

#### val Acc: 0, NDCG: 0.5806278523846605 HIT: 0.6750357067287346
Epoch: 352, plus 0 steps train_loss: 0.6941

#### test Acc: 0, NDCG: 0.3525563117387137 HIT: 0.4969277335484553

#### val Acc: 0, NDCG: 0.6093867607790655 HIT: 0.7002982173085062
Epoch: 384, plus 0 steps train_loss: 0.6929

#### test Acc: 0, NDCG: 0.4714833585826054 HIT: 0.6010293787029201

#### val Acc: 0, NDCG: 0.6659844067584308 HIT: 0.7512422966038934
Epoch: 416, plus 0 steps train_loss: 0.6887

#### test Acc: 0, NDCG: 0.4982103667116348 HIT: 0.6317950235399915

#### val Acc: 0, NDCG: 0.7025500637790842 HIT: 0.7821591991112992
Epoch: 448, plus 0 steps train_loss: 0.6829

#### test Acc: 0, NDCG: 0.49251874747467606 HIT: 0.627477154305967

#### val Acc: 0, NDCG: 0.7062977915297175 HIT: 0.7867432157215405
Epoch: 480, plus 0 steps train_loss: 0.6887

#### test Acc: 0, NDCG: 0.45558891160982506 HIT: 0.5967363058082945

#### val Acc: 0, NDCG: 0.6752679309156994 HIT: 0.7706280747460855
Epoch: 512, plus 0 steps train_loss: 0.6873

#### test Acc: 0, NDCG: 0.4132203205961849 HIT: 0.5697620212653407

#### val Acc: 0, NDCG: 0.6419355032001571 HIT: 0.73748032823741
Epoch: 544, plus 0 steps train_loss: 0.6774

#### test Acc: 0, NDCG: 0.4149999530711008 HIT: 0.5613866443609818

#### val Acc: 0, NDCG: 0.6507588077969654 HIT: 0.7435810542742276
Epoch: 576, plus 0 steps train_loss: 0.6692

#### test Acc: 0, NDCG: 0.3830575321543671 HIT: 0.5451814100190435

#### val Acc: 0, NDCG: 0.6270539218970989 HIT: 0.7214552806284384
Epoch: 608, plus 0 steps train_loss: 0.6706

#### test Acc: 0, NDCG: 0.2989482012472947 HIT: 0.4748151846170123

#### val Acc: 0, NDCG: 0.5747593853364286 HIT: 0.6746662412716885
Epoch: 640, plus 0 steps train_loss: 0.6792

#### test Acc: 0, NDCG: 0.21584430872909371 HIT: 0.3972720720482438

#### val Acc: 0, NDCG: 0.5310954727277065 HIT: 0.6410341396000847
Epoch: 704, plus 0 steps train_loss: 0.6499

#### test Acc: 0, NDCG: 0.22636783171948147 HIT: 0.4187547939589505

#### val Acc: 0, NDCG: 0.5215973195810911 HIT: 0.6254645180914092
Epoch: 768, plus 0 steps train_loss: 0.6477

#### test Acc: 0, NDCG: 0.23021740616709777 HIT: 0.41538827761320357

#### val Acc: 0, NDCG: 0.5368916195691458 HIT: 0.6421103007300042
Epoch: 832, plus 0 steps train_loss: 0.6474

#### test Acc: 0, NDCG: 0.23518005572859793 HIT: 0.4237446439906898

#### val Acc: 0, NDCG: 0.5347318377903522 HIT: 0.6427211172238679
Epoch: 896, plus 0 steps train_loss: 0.6441

#### test Acc: 0, NDCG: 0.23348222229846316 HIT: 0.43145382590986037

#### val Acc: 0, NDCG: 0.5372930432187024 HIT: 0.6407679922238679
Epoch: 960, plus 0 steps train_loss: 0.6488

#### test Acc: 0, NDCG: 0.23613083378041622 HIT: 0.4256440435886585

#### val Acc: 0, NDCG: 0.5319522073451443 HIT: 0.6405572233389759
Epoch: 1017, plus 0 steps train_loss: 0.6476
Done: it took 83755.16536593437
max value of NDCG: 0.5043394036120535
max value of HIT: 0.6322967361404993

After 20 validations
max value of NDCG: 0.5043394036120535
max value of HIT: 0.6322967361404993
