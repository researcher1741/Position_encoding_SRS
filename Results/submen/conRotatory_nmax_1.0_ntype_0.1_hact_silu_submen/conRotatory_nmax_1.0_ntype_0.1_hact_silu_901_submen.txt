 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	1.0
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	rotatory
position_concatenation: 	True
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11889541
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12932057538536063 HIT: 0.2808656567393144

#### val Acc: 0, NDCG: 0.47792470558296024 HIT: 0.5702753054909014
Epoch: 1, plus 0 steps train_loss: 0.838

#### test Acc: 0, NDCG: 0.1375152210824946 HIT: 0.3023616033643673

#### val Acc: 0, NDCG: 0.47418682752296476 HIT: 0.5686131242065171
Epoch: 2, plus 0 steps train_loss: 0.8263

#### test Acc: 0, NDCG: 0.12803845864934468 HIT: 0.29094536870503596

#### val Acc: 0, NDCG: 0.4843137956591593 HIT: 0.575881757829031
Epoch: 3, plus 0 steps train_loss: 0.8228

#### test Acc: 0, NDCG: 0.1312123793528166 HIT: 0.28541909119763015

#### val Acc: 0, NDCG: 0.49106366212921926 HIT: 0.5909785957998307
Epoch: 4, plus 0 steps train_loss: 0.809

#### test Acc: 0, NDCG: 0.1268145545979791 HIT: 0.28435450169276344

#### val Acc: 0, NDCG: 0.4801015126698038 HIT: 0.5769562658696572
Epoch: 5, plus 0 steps train_loss: 0.8066

#### test Acc: 0, NDCG: 0.13497189233474594 HIT: 0.2984917213288193

#### val Acc: 0, NDCG: 0.4819693221732731 HIT: 0.580736054538722
Epoch: 6, plus 0 steps train_loss: 0.7872

#### test Acc: 0, NDCG: 0.13735389781038107 HIT: 0.3014614962441811

#### val Acc: 0, NDCG: 0.48365246171009274 HIT: 0.5744055490901396
Epoch: 7, plus 0 steps train_loss: 0.7698

#### test Acc: 0, NDCG: 0.13120976029735745 HIT: 0.291743810833686

#### val Acc: 0, NDCG: 0.4641200525389384 HIT: 0.5540890816758358
Epoch: 8, plus 0 steps train_loss: 0.7751

#### test Acc: 0, NDCG: 0.13511014571200222 HIT: 0.2971188306707575

#### val Acc: 0, NDCG: 0.4791177496695705 HIT: 0.5685040203131612
Epoch: 9, plus 0 steps train_loss: 0.7665

#### test Acc: 0, NDCG: 0.13432210395194505 HIT: 0.29700394096487515

#### val Acc: 0, NDCG: 0.4766163908493604 HIT: 0.5660607543377063
Epoch: 10, plus 0 steps train_loss: 0.7577

#### test Acc: 0, NDCG: 0.13290070514160993 HIT: 0.2906792213288193

#### val Acc: 0, NDCG: 0.4783963334845423 HIT: 0.5701967837494709
Epoch: 12, plus 0 steps train_loss: 0.765

#### test Acc: 0, NDCG: 0.1335490051522275 HIT: 0.29260176417689376

#### val Acc: 0, NDCG: 0.4855156156777068 HIT: 0.5808145762801523
Epoch: 14, plus 0 steps train_loss: 0.7548

#### test Acc: 0, NDCG: 0.12696289720465181 HIT: 0.285848067869234

#### val Acc: 0, NDCG: 0.4728728463084541 HIT: 0.5636480705141769
Epoch: 16, plus 0 steps train_loss: 0.7397

#### test Acc: 0, NDCG: 0.13289902892189862 HIT: 0.2945854713288193

#### val Acc: 0, NDCG: 0.4784577192577783 HIT: 0.5660607543377063
Epoch: 18, plus 0 steps train_loss: 0.7553

#### test Acc: 0, NDCG: 0.12448453327097914 HIT: 0.2751633252221752

#### val Acc: 0, NDCG: 0.47577168436625206 HIT: 0.5733351737727466
Epoch: 20, plus 0 steps train_loss: 0.75

#### test Acc: 0, NDCG: 0.12597135083121008 HIT: 0.28605883675412613

#### val Acc: 0, NDCG: 0.4896005393504725 HIT: 0.5884394506453661
Epoch: 22, plus 0 steps train_loss: 0.7357

#### test Acc: 0, NDCG: 0.1346682330211857 HIT: 0.29751887827972917

#### val Acc: 0, NDCG: 0.4813877128231243 HIT: 0.5859482450804063
Epoch: 24, plus 0 steps train_loss: 0.734

#### test Acc: 0, NDCG: 0.13213117556399326 HIT: 0.2908304789991536

#### val Acc: 0, NDCG: 0.4793845422316977 HIT: 0.570099251481168
Epoch: 26, plus 0 steps train_loss: 0.7419

#### test Acc: 0, NDCG: 0.12841631435542472 HIT: 0.2860051113520948

#### val Acc: 0, NDCG: 0.4896930223087826 HIT: 0.5900958461172239
Epoch: 28, plus 0 steps train_loss: 0.7389

#### test Acc: 0, NDCG: 0.13221450775849045 HIT: 0.2908668469636056

#### val Acc: 0, NDCG: 0.47841582744317723 HIT: 0.5677361603364367
Epoch: 30, plus 0 steps train_loss: 0.7312

#### test Acc: 0, NDCG: 0.13591926454244185 HIT: 0.2949780800359712

#### val Acc: 0, NDCG: 0.48035353568134886 HIT: 0.5694884349873043
Epoch: 32, plus 0 steps train_loss: 0.7279

#### test Acc: 0, NDCG: 0.14408126228158402 HIT: 0.3123032823741007

#### val Acc: 0, NDCG: 0.47967087409468356 HIT: 0.5787523473867965
Epoch: 36, plus 0 steps train_loss: 0.7254

#### test Acc: 0, NDCG: 0.13200947928964765 HIT: 0.2966361285971223

#### val Acc: 0, NDCG: 0.4769386056210692 HIT: 0.5710373796550995
Epoch: 40, plus 0 steps train_loss: 0.7258

#### test Acc: 0, NDCG: 0.1390520851139864 HIT: 0.306116595694033

#### val Acc: 0, NDCG: 0.48120128860943284 HIT: 0.581153459585273
Epoch: 44, plus 0 steps train_loss: 0.7259

#### test Acc: 0, NDCG: 0.13436703847218087 HIT: 0.2971246164832839

#### val Acc: 0, NDCG: 0.4730950152493917 HIT: 0.5651168403512484
Epoch: 48, plus 0 steps train_loss: 0.7236

#### test Acc: 0, NDCG: 0.1433196041901354 HIT: 0.31219996429327124

#### val Acc: 0, NDCG: 0.4761169832731622 HIT: 0.5745683783855269
Epoch: 52, plus 0 steps train_loss: 0.7236

#### test Acc: 0, NDCG: 0.12635140051084173 HIT: 0.280859870926788

#### val Acc: 0, NDCG: 0.48158800867481716 HIT: 0.5775497249259416
Epoch: 56, plus 0 steps train_loss: 0.7185

#### test Acc: 0, NDCG: 0.12833040909323737 HIT: 0.2854554591620821

#### val Acc: 0, NDCG: 0.4828882841617975 HIT: 0.5745741641980534
Epoch: 60, plus 0 steps train_loss: 0.7229

#### test Acc: 0, NDCG: 0.12678020028010334 HIT: 0.28592080379813795

#### val Acc: 0, NDCG: 0.4779019573787065 HIT: 0.5688776184934405
Epoch: 64, plus 0 steps train_loss: 0.7176

#### test Acc: 0, NDCG: 0.13479349374897515 HIT: 0.293696935833686

#### val Acc: 0, NDCG: 0.4838693511769381 HIT: 0.5731839161024121
Epoch: 68, plus 0 steps train_loss: 0.7176

#### test Acc: 0, NDCG: 0.1274975382109 HIT: 0.28077556337283116

#### val Acc: 0, NDCG: 0.48718993268594396 HIT: 0.5798590906686416
Epoch: 72, plus 0 steps train_loss: 0.7124

#### test Acc: 0, NDCG: 0.12965393244604673 HIT: 0.2883814272111722

#### val Acc: 0, NDCG: 0.4828178727331955 HIT: 0.5755486603364367
Epoch: 80, plus 0 steps train_loss: 0.7127

#### test Acc: 0, NDCG: 0.1332286886869285 HIT: 0.2979594265763859

#### val Acc: 0, NDCG: 0.4950978666095898 HIT: 0.5955510407850191
Epoch: 88, plus 0 steps train_loss: 0.7126

#### test Acc: 0, NDCG: 0.12874463764964994 HIT: 0.28801940065594583

#### val Acc: 0, NDCG: 0.4806430191974177 HIT: 0.5674088486563691
Epoch: 96, plus 0 steps train_loss: 0.7112

#### test Acc: 0, NDCG: 0.13901111577334851 HIT: 0.3002282916314008

#### val Acc: 0, NDCG: 0.48114012501294234 HIT: 0.5709820011637748
Epoch: 104, plus 0 steps train_loss: 0.7096

#### test Acc: 0, NDCG: 0.12782185571059632 HIT: 0.28703333289250954

#### val Acc: 0, NDCG: 0.47900268061711015 HIT: 0.5712613732543377
Epoch: 112, plus 0 steps train_loss: 0.7063

#### test Acc: 0, NDCG: 0.1246487496365915 HIT: 0.27312589266821835

#### val Acc: 0, NDCG: 0.4755315810630742 HIT: 0.5644770947947525
Epoch: 120, plus 0 steps train_loss: 0.7072

#### test Acc: 0, NDCG: 0.12874900304962034 HIT: 0.2849653181866272

#### val Acc: 0, NDCG: 0.4699809616788051 HIT: 0.5598930781845112
Epoch: 128, plus 0 steps train_loss: 0.701

#### test Acc: 0, NDCG: 0.12989949369343828 HIT: 0.28344860876005074

#### val Acc: 0, NDCG: 0.47492733077264865 HIT: 0.566326901713923
Epoch: 136, plus 0 steps train_loss: 0.7078

#### test Acc: 0, NDCG: 0.13832162989891908 HIT: 0.29958110717308506

#### val Acc: 0, NDCG: 0.4790980060629053 HIT: 0.5720217943292425
Epoch: 144, plus 0 steps train_loss: 0.7057

#### test Acc: 0, NDCG: 0.1370485831347927 HIT: 0.2888236285971223

#### val Acc: 0, NDCG: 0.4860811236293799 HIT: 0.5738311005607278
Epoch: 160, plus 0 steps train_loss: 0.7029

#### test Acc: 0, NDCG: 0.2976482672294205 HIT: 0.4417517456622937

#### val Acc: 0, NDCG: 0.5725873309846453 HIT: 0.6649981485399915
Epoch: 176, plus 0 steps train_loss: 0.7044

#### test Acc: 0, NDCG: 0.30904322664504036 HIT: 0.45686759415996614

#### val Acc: 0, NDCG: 0.5909261334768648 HIT: 0.6823332694138806
Epoch: 192, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.40533271198671034 HIT: 0.5369630765975455

#### val Acc: 0, NDCG: 0.6522160454171344 HIT: 0.7338765935780787
Epoch: 208, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.3542861889694433 HIT: 0.5014638105691918

#### val Acc: 0, NDCG: 0.5917470876693354 HIT: 0.6814025801417689
Epoch: 224, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.3535498689083538 HIT: 0.4937356181231486

#### val Acc: 0, NDCG: 0.6070902228819772 HIT: 0.6828308492911553
Epoch: 240, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.27509345063136614 HIT: 0.4136649320249683

#### val Acc: 0, NDCG: 0.560398307152287 HIT: 0.6512899055755396
Epoch: 256, plus 0 steps train_loss: 0.701

#### test Acc: 0, NDCG: 0.3888133958818108 HIT: 0.5271991046868388

#### val Acc: 0, NDCG: 0.6375565271064583 HIT: 0.7283081622936944
Epoch: 272, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.3350113152348967 HIT: 0.47964633807659757

#### val Acc: 0, NDCG: 0.5996846628271318 HIT: 0.6839723074481592
Epoch: 288, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.3974722525784848 HIT: 0.5287100283008886

#### val Acc: 0, NDCG: 0.6260352690529348 HIT: 0.7130278314113415
Epoch: 304, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.4062827597768013 HIT: 0.540936276713923

#### val Acc: 0, NDCG: 0.6351174427353234 HIT: 0.7209725785548031
Epoch: 320, plus 0 steps train_loss: 0.7003

#### test Acc: 0, NDCG: 0.5558627318598915 HIT: 0.6833557051417689

#### val Acc: 0, NDCG: 0.7269677506316612 HIT: 0.8032567512166737
Epoch: 352, plus 0 steps train_loss: 0.6984

#### test Acc: 0, NDCG: 0.5154107689780576 HIT: 0.6380048534701651

#### val Acc: 0, NDCG: 0.695320617440024 HIT: 0.7782835312632247
Epoch: 384, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.582070087122189 HIT: 0.6951339663563267

#### val Acc: 0, NDCG: 0.7506813534754533 HIT: 0.8170129337706306
Epoch: 416, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.5853197262523606 HIT: 0.699608879073212

#### val Acc: 0, NDCG: 0.7426241681706623 HIT: 0.8205150034384258
Epoch: 448, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.5310116356389477 HIT: 0.6566839359394837

#### val Acc: 0, NDCG: 0.7199050244715517 HIT: 0.7902990107913669
Epoch: 480, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.5674045046840028 HIT: 0.6928188148011003

#### val Acc: 0, NDCG: 0.7390567541374731 HIT: 0.8092847413245874
Epoch: 512, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.5691185187169036 HIT: 0.692286520048667

#### val Acc: 0, NDCG: 0.7482880332448719 HIT: 0.8146002499471011
Epoch: 544, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.5774377519030907 HIT: 0.6910417438108337

#### val Acc: 0, NDCG: 0.7433010010747312 HIT: 0.812375191758358
Epoch: 576, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.5575455835877869 HIT: 0.6677612872936944

#### val Acc: 0, NDCG: 0.744027829415184 HIT: 0.8158640367118071
Epoch: 608, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.43823460651838725 HIT: 0.5804393250105797

#### val Acc: 0, NDCG: 0.661214636433422 HIT: 0.7363314311785866
Epoch: 640, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.575466919258265 HIT: 0.6918575433770631

#### val Acc: 0, NDCG: 0.7445780197601817 HIT: 0.8160996019360982
Epoch: 704, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.5431593435405291 HIT: 0.6646898473867965

#### val Acc: 0, NDCG: 0.7243337591158514 HIT: 0.8019260143355903
Epoch: 768, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.534307005262524 HIT: 0.6566591396000847

#### val Acc: 0, NDCG: 0.7164358416383236 HIT: 0.7887748624629708
Epoch: 832, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.5589375112895949 HIT: 0.6762994934934405

#### val Acc: 0, NDCG: 0.7345314287586178 HIT: 0.8043271265340668
Epoch: 896, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.5617541097658204 HIT: 0.6771574468366482

#### val Acc: 0, NDCG: 0.7315776654233007 HIT: 0.798038774862463
Epoch: 960, plus 0 steps train_loss: 0.6945

#### test Acc: 0, NDCG: 0.559268429896293 HIT: 0.6757671987410072

#### val Acc: 0, NDCG: 0.7335437584340062 HIT: 0.79989436759416
Epoch: 1017, plus 0 steps train_loss: 0.6983
Done: it took 88069.75372314453
max value of NDCG: 0.5853197262523606
max value of HIT: 0.699608879073212

After 20 validations
max value of NDCG: 0.5853197262523606
max value of HIT: 0.699608879073212
