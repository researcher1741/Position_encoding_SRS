 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2.0
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.14043416147974583 HIT: 0.3098352200592467

#### val Acc: 0, NDCG: 0.4884844125369694 HIT: 0.5802649240901396
Epoch: 1, plus 0 steps train_loss: 0.7953

#### test Acc: 0, NDCG: 0.13994516360244033 HIT: 0.31086344159966145

#### val Acc: 0, NDCG: 0.4835971539157683 HIT: 0.5767149148328397
Epoch: 2, plus 0 steps train_loss: 0.8004

#### test Acc: 0, NDCG: 0.13778771585473165 HIT: 0.3059173984341938

#### val Acc: 0, NDCG: 0.48357777757800674 HIT: 0.5791275986563691
Epoch: 3, plus 0 steps train_loss: 0.8044

#### test Acc: 0, NDCG: 0.13247967904896119 HIT: 0.2924331490689801

#### val Acc: 0, NDCG: 0.47743873756378613 HIT: 0.5759412690435886
Epoch: 4, plus 0 steps train_loss: 0.7779

#### test Acc: 0, NDCG: 0.13550006858006888 HIT: 0.29890334056284384

#### val Acc: 0, NDCG: 0.47365506938218555 HIT: 0.563219093842573
Epoch: 5, plus 0 steps train_loss: 0.7969

#### test Acc: 0, NDCG: 0.13255876553214907 HIT: 0.29058912796233605

#### val Acc: 0, NDCG: 0.479532180544503 HIT: 0.5762189880448583
Epoch: 6, plus 0 steps train_loss: 0.7891

#### test Acc: 0, NDCG: 0.1337009750328721 HIT: 0.2969981551523487

#### val Acc: 0, NDCG: 0.4860632375877581 HIT: 0.5784688425730004
Epoch: 7, plus 0 steps train_loss: 0.7864

#### test Acc: 0, NDCG: 0.13021603527479023 HIT: 0.28366516345746934

#### val Acc: 0, NDCG: 0.4887379813689872 HIT: 0.5847266120926788
Epoch: 8, plus 0 steps train_loss: 0.7799

#### test Acc: 0, NDCG: 0.13375394114248865 HIT: 0.292825757776132

#### val Acc: 0, NDCG: 0.47512029778266 HIT: 0.5678452642297926
Epoch: 9, plus 0 steps train_loss: 0.7828

#### test Acc: 0, NDCG: 0.1358379445507953 HIT: 0.29315306945619973

#### val Acc: 0, NDCG: 0.480126717002256 HIT: 0.5755296498095641
Epoch: 10, plus 0 steps train_loss: 0.7776

#### test Acc: 0, NDCG: 0.1352920469859239 HIT: 0.29883639044646637

#### val Acc: 0, NDCG: 0.48343762853966177 HIT: 0.5688602610558613
Epoch: 12, plus 0 steps train_loss: 0.7652

#### test Acc: 0, NDCG: 0.13370218627790223 HIT: 0.29630303110452816

#### val Acc: 0, NDCG: 0.4811202905122439 HIT: 0.5759776370080406
Epoch: 14, plus 0 steps train_loss: 0.7643

#### test Acc: 0, NDCG: 0.1450716267945091 HIT: 0.318350283008887

#### val Acc: 0, NDCG: 0.48788562213231884 HIT: 0.5867218908696572
Epoch: 16, plus 0 steps train_loss: 0.7616

#### test Acc: 0, NDCG: 0.1418735315405507 HIT: 0.31404977121244176

#### val Acc: 0, NDCG: 0.4811116471432265 HIT: 0.5767876507617435
Epoch: 18, plus 0 steps train_loss: 0.7645

#### test Acc: 0, NDCG: 0.12964794612892194 HIT: 0.2830849291155311

#### val Acc: 0, NDCG: 0.4752797236567311 HIT: 0.570614188796022
Epoch: 20, plus 0 steps train_loss: 0.7539

#### test Acc: 0, NDCG: 0.13527103137843333 HIT: 0.29327374497460856

#### val Acc: 0, NDCG: 0.48357419835171017 HIT: 0.5685825420545916
Epoch: 22, plus 0 steps train_loss: 0.7435

#### test Acc: 0, NDCG: 0.14170882033997734 HIT: 0.30457508992805754

#### val Acc: 0, NDCG: 0.4736747020490247 HIT: 0.5676386280681338
Epoch: 24, plus 0 steps train_loss: 0.7484

#### test Acc: 0, NDCG: 0.13737181533376672 HIT: 0.29079411103470165

#### val Acc: 0, NDCG: 0.48826796927552807 HIT: 0.5777563610876005
Epoch: 26, plus 0 steps train_loss: 0.7441

#### test Acc: 0, NDCG: 0.1324540475808186 HIT: 0.28595717176258995

#### val Acc: 0, NDCG: 0.47834822545246436 HIT: 0.5704819416525604
Epoch: 28, plus 0 steps train_loss: 0.7318

#### test Acc: 0, NDCG: 0.1445674624063221 HIT: 0.3063885288827761

#### val Acc: 0, NDCG: 0.4769046032476858 HIT: 0.5702637338658485
Epoch: 30, plus 0 steps train_loss: 0.7381

#### test Acc: 0, NDCG: 0.12954194450731196 HIT: 0.2913685595641134

#### val Acc: 0, NDCG: 0.473722841363686 HIT: 0.5701967837494709
Epoch: 32, plus 0 steps train_loss: 0.7266

#### test Acc: 0, NDCG: 0.1317828787790673 HIT: 0.28431813372831144

#### val Acc: 0, NDCG: 0.48316433285098853 HIT: 0.5838686587494709
Epoch: 36, plus 0 steps train_loss: 0.7288

#### test Acc: 0, NDCG: 0.12841194840629333 HIT: 0.27534516504443507

#### val Acc: 0, NDCG: 0.4752003876124715 HIT: 0.5708381823952603
Epoch: 40, plus 0 steps train_loss: 0.7251

#### test Acc: 0, NDCG: 0.13462392733439943 HIT: 0.28738378782268303

#### val Acc: 0, NDCG: 0.4821937076970947 HIT: 0.5808261479052053
Epoch: 44, plus 0 steps train_loss: 0.722

#### test Acc: 0, NDCG: 0.13032431469223307 HIT: 0.2790770141239949

#### val Acc: 0, NDCG: 0.4718603536588127 HIT: 0.5702695196783749
Epoch: 48, plus 0 steps train_loss: 0.7133

#### test Acc: 0, NDCG: 0.14220689361822086 HIT: 0.3043031567393144

#### val Acc: 0, NDCG: 0.47378380508026924 HIT: 0.5641861510791367
Epoch: 52, plus 0 steps train_loss: 0.71

#### test Acc: 0, NDCG: 0.14119541974987534 HIT: 0.29777180094159966

#### val Acc: 0, NDCG: 0.48439806576896877 HIT: 0.5797937936415574
Epoch: 56, plus 0 steps train_loss: 0.7163

#### test Acc: 0, NDCG: 0.14459826007089138 HIT: 0.29514256242065173

#### val Acc: 0, NDCG: 0.4848715182230297 HIT: 0.5770728086648329
Epoch: 60, plus 0 steps train_loss: 0.7118

#### test Acc: 0, NDCG: 0.1572651334409212 HIT: 0.3134579652454507

#### val Acc: 0, NDCG: 0.4971412680421512 HIT: 0.59632468657427
Epoch: 64, plus 0 steps train_loss: 0.707

#### test Acc: 0, NDCG: 0.1745335922795494 HIT: 0.3272926695408379

#### val Acc: 0, NDCG: 0.5065359541823635 HIT: 0.6023295334320778
Epoch: 68, plus 0 steps train_loss: 0.7119

#### test Acc: 0, NDCG: 0.1972401466089744 HIT: 0.35041608257511636

#### val Acc: 0, NDCG: 0.5181890147941051 HIT: 0.6089261862568769
Epoch: 72, plus 0 steps train_loss: 0.7114

#### test Acc: 0, NDCG: 0.19242517587095606 HIT: 0.3504755937896742

#### val Acc: 0, NDCG: 0.5231745723516332 HIT: 0.6160972876110876
Epoch: 80, plus 0 steps train_loss: 0.7063

#### test Acc: 0, NDCG: 0.23546718799085534 HIT: 0.38733039303851036

#### val Acc: 0, NDCG: 0.5591021449421253 HIT: 0.6529884548243757
Epoch: 88, plus 0 steps train_loss: 0.7082

#### test Acc: 0, NDCG: 0.24854900869282548 HIT: 0.39935744419170544

#### val Acc: 0, NDCG: 0.5547636167429006 HIT: 0.6442932051417689
Epoch: 96, plus 0 steps train_loss: 0.7058

#### test Acc: 0, NDCG: 0.27110022599794015 HIT: 0.4302743466991113

#### val Acc: 0, NDCG: 0.5651577920342005 HIT: 0.6597074362568769
Epoch: 104, plus 0 steps train_loss: 0.7021

#### test Acc: 0, NDCG: 0.278378048910164 HIT: 0.4354022296868387

#### val Acc: 0, NDCG: 0.5759203796015102 HIT: 0.6626813438954718
Epoch: 112, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.24040232207231912 HIT: 0.40259915229581045

#### val Acc: 0, NDCG: 0.5486398252119996 HIT: 0.6376543985399915
Epoch: 120, plus 0 steps train_loss: 0.7026

#### test Acc: 0, NDCG: 0.26922678231314195 HIT: 0.4225593789674143

#### val Acc: 0, NDCG: 0.5526745199256425 HIT: 0.6409977716356327
Epoch: 128, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.2579935509275012 HIT: 0.41417243043800256

#### val Acc: 0, NDCG: 0.5650378950188643 HIT: 0.6577237291049514
Epoch: 136, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.23865030350230831 HIT: 0.3995508556390182

#### val Acc: 0, NDCG: 0.5358834042161691 HIT: 0.6246181363732544
Epoch: 144, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.2599414061426864 HIT: 0.41573873254337707

#### val Acc: 0, NDCG: 0.5406995850750052 HIT: 0.6323388899174778
Epoch: 160, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.26386277444288564 HIT: 0.4154056350507829

#### val Acc: 0, NDCG: 0.5523462860803885 HIT: 0.6422747831146848
Epoch: 176, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.29862918113951037 HIT: 0.44311885050782907

#### val Acc: 0, NDCG: 0.58091674710704 HIT: 0.6724775510473974
Epoch: 192, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.40626270639471374 HIT: 0.5365109566758358

#### val Acc: 0, NDCG: 0.6344829658448884 HIT: 0.7202716686944561
Epoch: 208, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.44175482008005235 HIT: 0.5800351446783749

#### val Acc: 0, NDCG: 0.6630378552288766 HIT: 0.7429032876639864
Epoch: 224, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.43148956061332966 HIT: 0.5676080459162083

#### val Acc: 0, NDCG: 0.6589832078716222 HIT: 0.7439141517668219
Epoch: 240, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.4144524088051694 HIT: 0.5541485928903935

#### val Acc: 0, NDCG: 0.6289770230078792 HIT: 0.709399300412611
Epoch: 256, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.4069525359597974 HIT: 0.5297919752433348

#### val Acc: 0, NDCG: 0.6428317410059872 HIT: 0.7196666380131189
Epoch: 272, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.35447152750463207 HIT: 0.49021040520524756

#### val Acc: 0, NDCG: 0.6160655720504843 HIT: 0.7028927409542953
Epoch: 288, plus 0 steps train_loss: 0.6954

#### test Acc: 0, NDCG: 0.46844327716106243 HIT: 0.5981149822788827

#### val Acc: 0, NDCG: 0.6826317112512186 HIT: 0.7627312671921287
Epoch: 304, plus 0 steps train_loss: 0.6948

#### test Acc: 0, NDCG: 0.4432930052288961 HIT: 0.5708745503597122

#### val Acc: 0, NDCG: 0.6581094503554339 HIT: 0.7443125462865002
Epoch: 320, plus 0 steps train_loss: 0.6954

#### test Acc: 0, NDCG: 0.48507611649149557 HIT: 0.612882028935675

#### val Acc: 0, NDCG: 0.6866297505195745 HIT: 0.7701263621455777
Epoch: 352, plus 0 steps train_loss: 0.6939

#### test Acc: 0, NDCG: 0.5184877494755318 HIT: 0.6431401753597122

#### val Acc: 0, NDCG: 0.7105554875152101 HIT: 0.7823352531210326
Epoch: 384, plus 0 steps train_loss: 0.6921

#### test Acc: 0, NDCG: 0.501713583722104 HIT: 0.6278887735399915

#### val Acc: 0, NDCG: 0.711263034529245 HIT: 0.7891311032056707
Epoch: 416, plus 0 steps train_loss: 0.6835

#### test Acc: 0, NDCG: 0.601777060671319 HIT: 0.7112069535548031

#### val Acc: 0, NDCG: 0.7606295989422479 HIT: 0.8273893752644943
Epoch: 448, plus 0 steps train_loss: 0.6859

#### test Acc: 0, NDCG: 0.4872786216553285 HIT: 0.6184868281845112

#### val Acc: 0, NDCG: 0.6807449350819796 HIT: 0.7631544580512061
Epoch: 480, plus 0 steps train_loss: 0.6842

#### test Acc: 0, NDCG: 0.4775966507425971 HIT: 0.6109826293377063

#### val Acc: 0, NDCG: 0.6783346674425541 HIT: 0.7577488560622091
Epoch: 512, plus 0 steps train_loss: 0.682

#### test Acc: 0, NDCG: 0.470240469980594 HIT: 0.6102742805755396

#### val Acc: 0, NDCG: 0.677688134214127 HIT: 0.759368883569615
Epoch: 544, plus 0 steps train_loss: 0.6775

#### test Acc: 0, NDCG: 0.4444403082594402 HIT: 0.5860094093842573

#### val Acc: 0, NDCG: 0.6545961398583099 HIT: 0.7371530165573423
Epoch: 576, plus 0 steps train_loss: 0.6655

#### test Acc: 0, NDCG: 0.430629517941357 HIT: 0.5818122156686416

#### val Acc: 0, NDCG: 0.6511677090555064 HIT: 0.7384168033220483
Epoch: 608, plus 0 steps train_loss: 0.6658

#### test Acc: 0, NDCG: 0.3709782783851225 HIT: 0.5376408432077867

#### val Acc: 0, NDCG: 0.6220820389471289 HIT: 0.715724020048667
Epoch: 640, plus 0 steps train_loss: 0.6687

#### test Acc: 0, NDCG: 0.27354489723243125 HIT: 0.4676366443609818

#### val Acc: 0, NDCG: 0.5613661122965288 HIT: 0.6685407188954718
Epoch: 704, plus 0 steps train_loss: 0.6565

#### test Acc: 0, NDCG: 0.26732673031997406 HIT: 0.4529861404993652

#### val Acc: 0, NDCG: 0.5504129562525534 HIT: 0.6550754800571308
Epoch: 768, plus 0 steps train_loss: 0.6473

#### test Acc: 0, NDCG: 0.2768539939705615 HIT: 0.46140367118070247

#### val Acc: 0, NDCG: 0.5620979122005609 HIT: 0.6670529385315277
Epoch: 832, plus 0 steps train_loss: 0.6511

#### test Acc: 0, NDCG: 0.27388961251145266 HIT: 0.4568560225349132

#### val Acc: 0, NDCG: 0.5582281159617011 HIT: 0.661515089399069
Epoch: 896, plus 0 steps train_loss: 0.6448

#### test Acc: 0, NDCG: 0.2794195035351528 HIT: 0.46925253914515447

#### val Acc: 0, NDCG: 0.5649310744929401 HIT: 0.671491483283961
Epoch: 960, plus 0 steps train_loss: 0.6474

#### test Acc: 0, NDCG: 0.28217087190576695 HIT: 0.4689921775814642

#### val Acc: 0, NDCG: 0.5555022528982994 HIT: 0.6574939496931866
Epoch: 1017, plus 0 steps train_loss: 0.6547
Done: it took 80876.26895356178
max value of NDCG: 0.601777060671319
max value of HIT: 0.7112069535548031

After 20 validations
max value of NDCG: 0.601777060671319
max value of HIT: 0.7112069535548031
