 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2.0
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12068732569449626 HIT: 0.27224892879813795

#### val Acc: 0, NDCG: 0.4784360782659421 HIT: 0.5770116443609818
Epoch: 1, plus 0 steps train_loss: 0.7953

#### test Acc: 0, NDCG: 0.12415669859709891 HIT: 0.27195219926999575

#### val Acc: 0, NDCG: 0.48401294460068817 HIT: 0.585023341620821
Epoch: 2, plus 0 steps train_loss: 0.8069

#### test Acc: 0, NDCG: 0.12491551497153071 HIT: 0.27815045757511636

#### val Acc: 0, NDCG: 0.49615835889912885 HIT: 0.5952658828819297
Epoch: 3, plus 0 steps train_loss: 0.7888

#### test Acc: 0, NDCG: 0.12323927632594668 HIT: 0.27350114393779096

#### val Acc: 0, NDCG: 0.48271643425720184 HIT: 0.5799318265975455
Epoch: 4, plus 0 steps train_loss: 0.7971

#### test Acc: 0, NDCG: 0.12361495531355271 HIT: 0.27736524016081254

#### val Acc: 0, NDCG: 0.48917967616430974 HIT: 0.5925027441282268
Epoch: 5, plus 0 steps train_loss: 0.7843

#### test Acc: 0, NDCG: 0.12488657105796556 HIT: 0.27365240160812526

#### val Acc: 0, NDCG: 0.47359612262076095 HIT: 0.5718531792213288
Epoch: 6, plus 0 steps train_loss: 0.7681

#### test Acc: 0, NDCG: 0.12691239025216602 HIT: 0.2796803917160389

#### val Acc: 0, NDCG: 0.48404694521699637 HIT: 0.5714489988891239
Epoch: 7, plus 0 steps train_loss: 0.7742

#### test Acc: 0, NDCG: 0.1270151241700552 HIT: 0.280859870926788

#### val Acc: 0, NDCG: 0.477551694849434 HIT: 0.5721920625264495
Epoch: 8, plus 0 steps train_loss: 0.7806

#### test Acc: 0, NDCG: 0.1313279250430983 HIT: 0.28934269863520945

#### val Acc: 0, NDCG: 0.47791164493285193 HIT: 0.5648754893144308
Epoch: 9, plus 0 steps train_loss: 0.7703

#### test Acc: 0, NDCG: 0.13230055505489896 HIT: 0.2945433175518409

#### val Acc: 0, NDCG: 0.48342988909216444 HIT: 0.5753478099873043
Epoch: 10, plus 0 steps train_loss: 0.7787

#### test Acc: 0, NDCG: 0.1296265020601274 HIT: 0.284312347915785

#### val Acc: 0, NDCG: 0.47582147634149824 HIT: 0.5703538272323319
Epoch: 12, plus 0 steps train_loss: 0.7792

#### test Acc: 0, NDCG: 0.12958492329046892 HIT: 0.2820988613520948

#### val Acc: 0, NDCG: 0.4765458796873717 HIT: 0.5682015049724926
Epoch: 14, plus 0 steps train_loss: 0.7858

#### test Acc: 0, NDCG: 0.12953362543368147 HIT: 0.2919851618705036

#### val Acc: 0, NDCG: 0.4711096808517967 HIT: 0.5675485347016505
Epoch: 16, plus 0 steps train_loss: 0.7687

#### test Acc: 0, NDCG: 0.12563786814070238 HIT: 0.27282337732754974

#### val Acc: 0, NDCG: 0.47335428757633585 HIT: 0.5595120411024121
Epoch: 18, plus 0 steps train_loss: 0.7559

#### test Acc: 0, NDCG: 0.1287605613710623 HIT: 0.2787439166314008

#### val Acc: 0, NDCG: 0.47534339174581675 HIT: 0.5691743480215827
Epoch: 20, plus 0 steps train_loss: 0.7578

#### test Acc: 0, NDCG: 0.13241798811507444 HIT: 0.28381642112780364

#### val Acc: 0, NDCG: 0.47437853511561306 HIT: 0.5667021529834956
Epoch: 22, plus 0 steps train_loss: 0.736

#### test Acc: 0, NDCG: 0.13639606857976672 HIT: 0.2958550439060516

#### val Acc: 0, NDCG: 0.47847006125940394 HIT: 0.5629165785019044
Epoch: 24, plus 0 steps train_loss: 0.744

#### test Acc: 0, NDCG: 0.1282087007148552 HIT: 0.27799919990478206

#### val Acc: 0, NDCG: 0.47047035985202607 HIT: 0.5643679909013964
Epoch: 26, plus 0 steps train_loss: 0.7416

#### test Acc: 0, NDCG: 0.1319551268845493 HIT: 0.28807312605797714

#### val Acc: 0, NDCG: 0.4751135206752646 HIT: 0.5662062261955141
Epoch: 28, plus 0 steps train_loss: 0.7352

#### test Acc: 0, NDCG: 0.1258971336544532 HIT: 0.27584687764494287

#### val Acc: 0, NDCG: 0.4801999819708539 HIT: 0.5735343710325856
Epoch: 30, plus 0 steps train_loss: 0.7366

#### test Acc: 0, NDCG: 0.1283257631574376 HIT: 0.28337421974185356

#### val Acc: 0, NDCG: 0.47475286021531354 HIT: 0.5660913364896318
Epoch: 32, plus 0 steps train_loss: 0.7293

#### test Acc: 0, NDCG: 0.13142222141672444 HIT: 0.2869605969636056

#### val Acc: 0, NDCG: 0.4779010653913133 HIT: 0.5779902732225984
Epoch: 36, plus 0 steps train_loss: 0.7196

#### test Acc: 0, NDCG: 0.16037794659475038 HIT: 0.3213489869868811

#### val Acc: 0, NDCG: 0.49525980910270434 HIT: 0.5928300558082945
Epoch: 40, plus 0 steps train_loss: 0.7149

#### test Acc: 0, NDCG: 0.20012191412955688 HIT: 0.35446615134363096

#### val Acc: 0, NDCG: 0.5263252689521619 HIT: 0.61736686018832
Epoch: 44, plus 0 steps train_loss: 0.7144

#### test Acc: 0, NDCG: 0.2757203513967089 HIT: 0.41882174407532796

#### val Acc: 0, NDCG: 0.5801341552607278 HIT: 0.6715047079983072
Epoch: 48, plus 0 steps train_loss: 0.7218

#### test Acc: 0, NDCG: 0.3357423753162646 HIT: 0.4715445474502751

#### val Acc: 0, NDCG: 0.6098557888190218 HIT: 0.6971482556601777
Epoch: 52, plus 0 steps train_loss: 0.7068

#### test Acc: 0, NDCG: 0.41408218770043176 HIT: 0.5430406593842573

#### val Acc: 0, NDCG: 0.6626186626563905 HIT: 0.74795843472281
Epoch: 56, plus 0 steps train_loss: 0.7116

#### test Acc: 0, NDCG: 0.44768216553694307 HIT: 0.5723185238573847

#### val Acc: 0, NDCG: 0.6922697884898579 HIT: 0.7674301735082523
Epoch: 60, plus 0 steps train_loss: 0.7147

#### test Acc: 0, NDCG: 0.487644814665391 HIT: 0.6111090906686416

#### val Acc: 0, NDCG: 0.6927353051107931 HIT: 0.767169811944562
Epoch: 64, plus 0 steps train_loss: 0.7109

#### test Acc: 0, NDCG: 0.5028187553581933 HIT: 0.6264009931760475

#### val Acc: 0, NDCG: 0.7108288810236228 HIT: 0.7846388330512061
Epoch: 68, plus 0 steps train_loss: 0.7071

#### test Acc: 0, NDCG: 0.5449135143522147 HIT: 0.6579766517668219

#### val Acc: 0, NDCG: 0.7028176282501716 HIT: 0.7740152547079983
Epoch: 72, plus 0 steps train_loss: 0.707

#### test Acc: 0, NDCG: 0.5686843982652684 HIT: 0.6800296894837071

#### val Acc: 0, NDCG: 0.7465819251907215 HIT: 0.8111535587706306
Epoch: 80, plus 0 steps train_loss: 0.7072

#### test Acc: 0, NDCG: 0.5574794943552138 HIT: 0.6759548243757935

#### val Acc: 0, NDCG: 0.7300386911946348 HIT: 0.7997199666737198
Epoch: 88, plus 0 steps train_loss: 0.7092

#### test Acc: 0, NDCG: 0.5674830528843462 HIT: 0.6832523870609395

#### val Acc: 0, NDCG: 0.7383157915327406 HIT: 0.807314258887008
Epoch: 96, plus 0 steps train_loss: 0.7078

#### test Acc: 0, NDCG: 0.5853149251431103 HIT: 0.6935023672238679

#### val Acc: 0, NDCG: 0.7629107723323105 HIT: 0.8319006559458315
Epoch: 104, plus 0 steps train_loss: 0.7037

#### test Acc: 0, NDCG: 0.6181805942058878 HIT: 0.7275460881294964

#### val Acc: 0, NDCG: 0.7651695040622994 HIT: 0.830370721804909
Epoch: 112, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.5982251018675054 HIT: 0.7108564986246297

#### val Acc: 0, NDCG: 0.7658900647885569 HIT: 0.8369367924777825
Epoch: 120, plus 0 steps train_loss: 0.7043

#### test Acc: 0, NDCG: 0.5877749634082157 HIT: 0.7023662320143885

#### val Acc: 0, NDCG: 0.7717967432496609 HIT: 0.8391924328184511
Epoch: 128, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.6224635611005207 HIT: 0.7232034225560727

#### val Acc: 0, NDCG: 0.7662711617221687 HIT: 0.8301293707680915
Epoch: 136, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.6147040018423875 HIT: 0.7234695699322895

#### val Acc: 0, NDCG: 0.7695465335538344 HIT: 0.8307881268514601
Epoch: 144, plus 0 steps train_loss: 0.7

#### test Acc: 0, NDCG: 0.6353035065347872 HIT: 0.7403277745450698

#### val Acc: 0, NDCG: 0.7835943218040736 HIT: 0.8447377208527296
Epoch: 160, plus 0 steps train_loss: 0.7018

#### test Acc: 0, NDCG: 0.6383325023454431 HIT: 0.7454746680596699

#### val Acc: 0, NDCG: 0.8005075430355709 HIT: 0.8544975600402032
Epoch: 176, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.6345534091949205 HIT: 0.7372927026026238

#### val Acc: 0, NDCG: 0.775239199356272 HIT: 0.8421431972069403
Epoch: 192, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.6342645336124475 HIT: 0.7285305028036394

#### val Acc: 0, NDCG: 0.7806570438816038 HIT: 0.8414117051946678
Epoch: 208, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.6527842496337126 HIT: 0.7554204797926365

#### val Acc: 0, NDCG: 0.7844679076436721 HIT: 0.8436309775708845
Epoch: 224, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.6558899020049929 HIT: 0.7537392879813796

#### val Acc: 0, NDCG: 0.797831512386737 HIT: 0.8560142694667795
Epoch: 240, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.6948783318749685 HIT: 0.7778603404041472

#### val Acc: 0, NDCG: 0.7981083362775646 HIT: 0.8520237119128227
Epoch: 256, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.6600173949248217 HIT: 0.7622353404041472

#### val Acc: 0, NDCG: 0.7990480564350885 HIT: 0.855772918429962
Epoch: 272, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.6545371651873424 HIT: 0.7564007617435464

#### val Acc: 0, NDCG: 0.7993257221997618 HIT: 0.8569639692657639
Epoch: 288, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.6768711326891768 HIT: 0.7708099145683454

#### val Acc: 0, NDCG: 0.799990339091984 HIT: 0.8605197643355903
Epoch: 304, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.6430671901667288 HIT: 0.7395904967202709

#### val Acc: 0, NDCG: 0.7887015808229909 HIT: 0.8503003663245874
Epoch: 320, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.6463866689079989 HIT: 0.7428801444138806

#### val Acc: 0, NDCG: 0.7894982167545243 HIT: 0.8524832707363521
Epoch: 352, plus 0 steps train_loss: 0.6938

#### test Acc: 0, NDCG: 0.698900046028624 HIT: 0.7817608045916209

#### val Acc: 0, NDCG: 0.8188185226183723 HIT: 0.8675817617964452
Epoch: 384, plus 0 steps train_loss: 0.6941

#### test Acc: 0, NDCG: 0.6507883235368441 HIT: 0.7509587917900973

#### val Acc: 0, NDCG: 0.8045037397153726 HIT: 0.8635432646529835
Epoch: 416, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.6603965599250725 HIT: 0.7570958857913669

#### val Acc: 0, NDCG: 0.8021943532747566 HIT: 0.8638995053956835
Epoch: 448, plus 0 steps train_loss: 0.694

#### test Acc: 0, NDCG: 0.6390884084834799 HIT: 0.7468649161553111

#### val Acc: 0, NDCG: 0.8046351362581402 HIT: 0.8646615795598815
Epoch: 480, plus 0 steps train_loss: 0.6933

#### test Acc: 0, NDCG: 0.6821700145150087 HIT: 0.7705379813796022

#### val Acc: 0, NDCG: 0.8186775150211633 HIT: 0.8719054168429963
Epoch: 512, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.6379635018766076 HIT: 0.7405939219212865

#### val Acc: 0, NDCG: 0.7948593848309061 HIT: 0.8543215060304697
Epoch: 544, plus 0 steps train_loss: 0.6934

#### test Acc: 0, NDCG: 0.6436970777550429 HIT: 0.7451167742276766

#### val Acc: 0, NDCG: 0.7906184691122035 HIT: 0.845505580829454
Epoch: 576, plus 0 steps train_loss: 0.6896

#### test Acc: 0, NDCG: 0.6231812471134361 HIT: 0.7277816533537875

#### val Acc: 0, NDCG: 0.7705095162223883 HIT: 0.8376203449005502
Epoch: 608, plus 0 steps train_loss: 0.6892

#### test Acc: 0, NDCG: 0.6111230525600351 HIT: 0.7292330657532797

#### val Acc: 0, NDCG: 0.7686020257481266 HIT: 0.8419018461701228
Epoch: 640, plus 0 steps train_loss: 0.6834

#### test Acc: 0, NDCG: 0.45659422589416804 HIT: 0.5953328329983072

#### val Acc: 0, NDCG: 0.6719454092727047 HIT: 0.7509091991112992
Epoch: 704, plus 0 steps train_loss: 0.6827

#### test Acc: 0, NDCG: 0.35201470754966085 HIT: 0.5069652917371984

#### val Acc: 0, NDCG: 0.60923974931733 HIT: 0.7044590430596699
Epoch: 768, plus 0 steps train_loss: 0.6805

#### test Acc: 0, NDCG: 0.3113461513797685 HIT: 0.4696087798878544

#### val Acc: 0, NDCG: 0.5855140108864759 HIT: 0.6863734196466357
Epoch: 832, plus 0 steps train_loss: 0.6671

#### test Acc: 0, NDCG: 0.26871363694810374 HIT: 0.44455125238044857

#### val Acc: 0, NDCG: 0.5664580452818179 HIT: 0.6750472783537875
Epoch: 896, plus 0 steps train_loss: 0.676

#### test Acc: 0, NDCG: 0.24382632112949956 HIT: 0.4232545030152349

#### val Acc: 0, NDCG: 0.5464054864435754 HIT: 0.6573121098709267
Epoch: 960, plus 0 steps train_loss: 0.668

#### test Acc: 0, NDCG: 0.22895785419951487 HIT: 0.40769645313161235

#### val Acc: 0, NDCG: 0.5353424826333341 HIT: 0.6475406990584004
Epoch: 1017, plus 0 steps train_loss: 0.6777
Done: it took 81519.39792060852
max value of NDCG: 0.698900046028624
max value of HIT: 0.7817608045916209

After 20 validations
max value of NDCG: 0.698900046028624
max value of HIT: 0.7817608045916209
