 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.0001
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11571301
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12506570191313257 HIT: 0.2796803917160389

#### val Acc: 0, NDCG: 0.47175964063155684 HIT: 0.562554551946678
Epoch: 1, plus 0 steps train_loss: 0.861

#### test Acc: 0, NDCG: 0.12350094553095865 HIT: 0.2748913920334321

#### val Acc: 0, NDCG: 0.4773499642786934 HIT: 0.5725367316440966
Epoch: 2, plus 0 steps train_loss: 0.8756

#### test Acc: 0, NDCG: 0.1244495582904771 HIT: 0.28156656659966145

#### val Acc: 0, NDCG: 0.4856395501736203 HIT: 0.5784630567604739
Epoch: 3, plus 0 steps train_loss: 0.8748

#### test Acc: 0, NDCG: 0.12966007692863848 HIT: 0.288574838658485

#### val Acc: 0, NDCG: 0.4879510370593608 HIT: 0.5823924500105797
Epoch: 4, plus 0 steps train_loss: 0.837

#### test Acc: 0, NDCG: 0.1262141329950952 HIT: 0.28133100137537026

#### val Acc: 0, NDCG: 0.47546116837900454 HIT: 0.5652871085484553
Epoch: 5, plus 0 steps train_loss: 0.8433

#### test Acc: 0, NDCG: 0.1272423986450568 HIT: 0.290491595694033

#### val Acc: 0, NDCG: 0.4705012141924165 HIT: 0.5650267469847651
Epoch: 6, plus 0 steps train_loss: 0.8216

#### test Acc: 0, NDCG: 0.12742563615271796 HIT: 0.28149548376005074

#### val Acc: 0, NDCG: 0.4771548595067333 HIT: 0.5688429036182818
Epoch: 7, plus 0 steps train_loss: 0.8169

#### test Acc: 0, NDCG: 0.13348938696613877 HIT: 0.29684111166948796

#### val Acc: 0, NDCG: 0.473159089672811 HIT: 0.5716597677740162
Epoch: 8, plus 0 steps train_loss: 0.8054

#### test Acc: 0, NDCG: 0.13071740679272958 HIT: 0.2897427462441811

#### val Acc: 0, NDCG: 0.4824103477153957 HIT: 0.5764909212336013
Epoch: 9, plus 0 steps train_loss: 0.7923

#### test Acc: 0, NDCG: 0.13464798264117475 HIT: 0.29968855797714766

#### val Acc: 0, NDCG: 0.47832962876509283 HIT: 0.5732988058082945
Epoch: 10, plus 0 steps train_loss: 0.7755

#### test Acc: 0, NDCG: 0.12845607363437947 HIT: 0.2879466647270419

#### val Acc: 0, NDCG: 0.4868969840104691 HIT: 0.5701430583474396
Epoch: 12, plus 0 steps train_loss: 0.7816

#### test Acc: 0, NDCG: 0.1403318049477386 HIT: 0.31619630765975454

#### val Acc: 0, NDCG: 0.48438292338370426 HIT: 0.5794111034701651
Epoch: 14, plus 0 steps train_loss: 0.7684

#### test Acc: 0, NDCG: 0.12762719009146828 HIT: 0.2831882471963606

#### val Acc: 0, NDCG: 0.47961453432758744 HIT: 0.5718473934088024
Epoch: 16, plus 0 steps train_loss: 0.7649

#### test Acc: 0, NDCG: 0.12904070793069675 HIT: 0.28772845694033006

#### val Acc: 0, NDCG: 0.4753322911307331 HIT: 0.5708861219847651
Epoch: 18, plus 0 steps train_loss: 0.7755

#### test Acc: 0, NDCG: 0.13027951964081752 HIT: 0.2935514639758781

#### val Acc: 0, NDCG: 0.4804721795080247 HIT: 0.5746849211807025
Epoch: 20, plus 0 steps train_loss: 0.7585

#### test Acc: 0, NDCG: 0.12404885650407034 HIT: 0.2739664885738468

#### val Acc: 0, NDCG: 0.48815581649757467 HIT: 0.592393640234871
Epoch: 22, plus 0 steps train_loss: 0.753

#### test Acc: 0, NDCG: 0.12707577100127465 HIT: 0.27825377565594583

#### val Acc: 0, NDCG: 0.4803020178358453 HIT: 0.5707770180914092
Epoch: 24, plus 0 steps train_loss: 0.7488

#### test Acc: 0, NDCG: 0.12607771237314291 HIT: 0.2816814563055438

#### val Acc: 0, NDCG: 0.47968486060948323 HIT: 0.5711696267985612
Epoch: 26, plus 0 steps train_loss: 0.7524

#### test Acc: 0, NDCG: 0.128993107579236 HIT: 0.292825757776132

#### val Acc: 0, NDCG: 0.4821237691767473 HIT: 0.5697066427740162
Epoch: 28, plus 0 steps train_loss: 0.7483

#### test Acc: 0, NDCG: 0.12849414050344107 HIT: 0.2831634508569615

#### val Acc: 0, NDCG: 0.47101202625704797 HIT: 0.5657276568451122
Epoch: 30, plus 0 steps train_loss: 0.7476

#### test Acc: 0, NDCG: 0.13378368157505877 HIT: 0.2939077047185781

#### val Acc: 0, NDCG: 0.48098276435407383 HIT: 0.5740666657850191
Epoch: 32, plus 0 steps train_loss: 0.7488

#### test Acc: 0, NDCG: 0.13547899269750038 HIT: 0.29787511902242914

#### val Acc: 0, NDCG: 0.48032741007159485 HIT: 0.574913047503174
Epoch: 36, plus 0 steps train_loss: 0.7334

#### test Acc: 0, NDCG: 0.13064475132407674 HIT: 0.2835560595641134

#### val Acc: 0, NDCG: 0.49251242300684683 HIT: 0.5821816811256877
Epoch: 40, plus 0 steps train_loss: 0.7432

#### test Acc: 0, NDCG: 0.12899500583339565 HIT: 0.28074498122090563

#### val Acc: 0, NDCG: 0.4791572729059743 HIT: 0.5796888224714346
Epoch: 44, plus 0 steps train_loss: 0.7406

#### test Acc: 0, NDCG: 0.12173066626421285 HIT: 0.27229108257511636

#### val Acc: 0, NDCG: 0.48513562894271944 HIT: 0.5755965999259416
Epoch: 48, plus 0 steps train_loss: 0.7359

#### test Acc: 0, NDCG: 0.1372377288743014 HIT: 0.30003322709479474

#### val Acc: 0, NDCG: 0.47681955573909046 HIT: 0.5746469001269573
Epoch: 52, plus 0 steps train_loss: 0.7318

#### test Acc: 0, NDCG: 0.13178337874284163 HIT: 0.28967001031527717

#### val Acc: 0, NDCG: 0.47990105184415804 HIT: 0.5729425650655946
Epoch: 56, plus 0 steps train_loss: 0.7343

#### test Acc: 0, NDCG: 0.1313027469388879 HIT: 0.2858059140922556

#### val Acc: 0, NDCG: 0.4798300076394797 HIT: 0.5690115187261955
Epoch: 60, plus 0 steps train_loss: 0.7317

#### test Acc: 0, NDCG: 0.1181879970194364 HIT: 0.25661235717308506

#### val Acc: 0, NDCG: 0.47814900054547993 HIT: 0.5696107635950063
Epoch: 64, plus 0 steps train_loss: 0.7139

#### test Acc: 0, NDCG: 0.13288642010445212 HIT: 0.28829133384468897

#### val Acc: 0, NDCG: 0.47782237461757343 HIT: 0.5713093128438426
Epoch: 68, plus 0 steps train_loss: 0.7232

#### test Acc: 0, NDCG: 0.13371174858417548 HIT: 0.2810954361510791

#### val Acc: 0, NDCG: 0.49197595591989135 HIT: 0.5878650021159543
Epoch: 72, plus 0 steps train_loss: 0.7216

#### test Acc: 0, NDCG: 0.16981752763108393 HIT: 0.327920843472281

#### val Acc: 0, NDCG: 0.5005477784930559 HIT: 0.5918439880448583
Epoch: 80, plus 0 steps train_loss: 0.7153

#### test Acc: 0, NDCG: 0.2334741196800858 HIT: 0.3851664991536183

#### val Acc: 0, NDCG: 0.5521969547959867 HIT: 0.6397645670228522
Epoch: 88, plus 0 steps train_loss: 0.7182

#### test Acc: 0, NDCG: 0.3554650618975336 HIT: 0.5022680385103682

#### val Acc: 0, NDCG: 0.6180231219389716 HIT: 0.7018645194138806
Epoch: 96, plus 0 steps train_loss: 0.7065

#### test Acc: 0, NDCG: 0.41827959421816374 HIT: 0.5561265142297926

#### val Acc: 0, NDCG: 0.664196405442758 HIT: 0.7477708090880236
Epoch: 104, plus 0 steps train_loss: 0.7139

#### test Acc: 0, NDCG: 0.48704543270273803 HIT: 0.6193753636796445

#### val Acc: 0, NDCG: 0.6981785743738025 HIT: 0.7752484593207787
Epoch: 112, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.483979702668154 HIT: 0.612759700327973

#### val Acc: 0, NDCG: 0.7093148703656778 HIT: 0.7802556667900973
Epoch: 120, plus 0 steps train_loss: 0.7117

#### test Acc: 0, NDCG: 0.5293894196316171 HIT: 0.6516709426576386

#### val Acc: 0, NDCG: 0.7203858235176195 HIT: 0.7918347307448159
Epoch: 128, plus 0 steps train_loss: 0.712

#### test Acc: 0, NDCG: 0.504708376283624 HIT: 0.6277433016821836

#### val Acc: 0, NDCG: 0.7221372615133931 HIT: 0.7945672873465933
Epoch: 136, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.4860594528037173 HIT: 0.6130200618916631

#### val Acc: 0, NDCG: 0.7078213094639999 HIT: 0.7785133106749894
Epoch: 144, plus 0 steps train_loss: 0.7065

#### test Acc: 0, NDCG: 0.5139458094474223 HIT: 0.6398620992911553

#### val Acc: 0, NDCG: 0.7047188112040399 HIT: 0.7802366562632247
Epoch: 160, plus 0 steps train_loss: 0.7098

#### test Acc: 0, NDCG: 0.4288549909213082 HIT: 0.5462691427740162

#### val Acc: 0, NDCG: 0.6601052198774012 HIT: 0.7343303665890817
Epoch: 176, plus 0 steps train_loss: 0.7033

#### test Acc: 0, NDCG: 0.42399498927245377 HIT: 0.5505316335167161

#### val Acc: 0, NDCG: 0.6320705402561365 HIT: 0.7130741179115531
Epoch: 192, plus 0 steps train_loss: 0.7095

#### test Acc: 0, NDCG: 0.5516876416321921 HIT: 0.6642840139652983

#### val Acc: 0, NDCG: 0.7337582555232154 HIT: 0.8047808995450698
Epoch: 208, plus 0 steps train_loss: 0.7046

#### test Acc: 0, NDCG: 0.5727702885823038 HIT: 0.679794124259416

#### val Acc: 0, NDCG: 0.7378796149878678 HIT: 0.803026971804909
Epoch: 224, plus 0 steps train_loss: 0.7003

#### test Acc: 0, NDCG: 0.6458812425811651 HIT: 0.7426197828501904

#### val Acc: 0, NDCG: 0.7847770442745163 HIT: 0.8422159331358443
Epoch: 240, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.6380109454953403 HIT: 0.7456069152031316

#### val Acc: 0, NDCG: 0.7791009450360804 HIT: 0.8407587349238256
Epoch: 256, plus 0 steps train_loss: 0.7024

#### test Acc: 0, NDCG: 0.6641317701371782 HIT: 0.757785224026661

#### val Acc: 0, NDCG: 0.7782105342329764 HIT: 0.8392040044435041
Epoch: 272, plus 0 steps train_loss: 0.7028

#### test Acc: 0, NDCG: 0.6506579225414401 HIT: 0.7458730625793484

#### val Acc: 0, NDCG: 0.8030024962148669 HIT: 0.8663543429961913
Epoch: 288, plus 0 steps train_loss: 0.7015

#### test Acc: 0, NDCG: 0.669403745160672 HIT: 0.7591333183453237

#### val Acc: 0, NDCG: 0.8051708075453973 HIT: 0.8611115703025815
Epoch: 304, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.6631256849210201 HIT: 0.7553725402031316

#### val Acc: 0, NDCG: 0.8180739512040381 HIT: 0.8690637563478629
Epoch: 320, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.6944235784874405 HIT: 0.7779082799936522

#### val Acc: 0, NDCG: 0.8162781394876836 HIT: 0.8668866377486246
Epoch: 352, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.6935717587146029 HIT: 0.7766998717202709

#### val Acc: 0, NDCG: 0.8188644244661204 HIT: 0.8751892787240796
Epoch: 384, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.6913421030307056 HIT: 0.7733738560622091

#### val Acc: 0, NDCG: 0.793760710354279 HIT: 0.8466181099238256
Epoch: 416, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.6792873912530716 HIT: 0.7695519136161659

#### val Acc: 0, NDCG: 0.8053637468619625 HIT: 0.8595221249471011
Epoch: 448, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.6705399093019903 HIT: 0.7595449375793484

#### val Acc: 0, NDCG: 0.8190832134521199 HIT: 0.8681082707363521
Epoch: 480, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.68157028133297 HIT: 0.7733912134997883

#### val Acc: 0, NDCG: 0.8062725301894128 HIT: 0.8573144241959374
Epoch: 512, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.6775726691108291 HIT: 0.7658332892509522

#### val Acc: 0, NDCG: 0.820808955524285 HIT: 0.8660766239949218
Epoch: 544, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.6836154250039153 HIT: 0.7706165031210326

#### val Acc: 0, NDCG: 0.8170409756530929 HIT: 0.8683744181125688
Epoch: 576, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.667846741383768 HIT: 0.7574099727570884

#### val Acc: 0, NDCG: 0.8198503601170457 HIT: 0.873253511161659
Epoch: 608, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.678083280370973 HIT: 0.7627081239420228

#### val Acc: 0, NDCG: 0.7954695450922145 HIT: 0.8483530271371139
Epoch: 640, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.6416099273110384 HIT: 0.7300620900338552

#### val Acc: 0, NDCG: 0.7870645180502926 HIT: 0.8434433519360982
Epoch: 704, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.6751204091482301 HIT: 0.7611360360241219

#### val Acc: 0, NDCG: 0.8165683396502253 HIT: 0.8665419686309775
Epoch: 768, plus 0 steps train_loss: 0.6944

#### test Acc: 0, NDCG: 0.6666162996810917 HIT: 0.7572835114261531

#### val Acc: 0, NDCG: 0.8042552427111413 HIT: 0.8609908947841727
Epoch: 832, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.661420554697862 HIT: 0.7478567697312738

#### val Acc: 0, NDCG: 0.7983637028518258 HIT: 0.8563167848074481
Epoch: 896, plus 0 steps train_loss: 0.6954

#### test Acc: 0, NDCG: 0.6496573971094973 HIT: 0.7453961463182396

#### val Acc: 0, NDCG: 0.8003527659952708 HIT: 0.854484335325857
Epoch: 960, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.6698557611868122 HIT: 0.7607839280046551

#### val Acc: 0, NDCG: 0.7967694745106602 HIT: 0.8517269823846805
Epoch: 1017, plus 0 steps train_loss: 0.6942
Done: it took 79125.7117471695
max value of NDCG: 0.6944235784874405
max value of HIT: 0.7779082799936522

After 20 validations
max value of NDCG: 0.6944235784874405
max value of HIT: 0.7779082799936522
