 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	None
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	rotatory
position_concatenation: 	True
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11889541
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12603648968327819 HIT: 0.27603450327972917

#### val Acc: 0, NDCG: 0.4794516273664491 HIT: 0.5700281686415574
Epoch: 1, plus 0 steps train_loss: 0.7599

#### test Acc: 0, NDCG: 0.1283239381193478 HIT: 0.2845115451756242

#### val Acc: 0, NDCG: 0.47180270423384546 HIT: 0.5663938518303004
Epoch: 2, plus 0 steps train_loss: 0.7605

#### test Acc: 0, NDCG: 0.13179026688747889 HIT: 0.2855761346804909

#### val Acc: 0, NDCG: 0.4840714594841171 HIT: 0.5786680398328397
Epoch: 3, plus 0 steps train_loss: 0.7459

#### test Acc: 0, NDCG: 0.1317861207700335 HIT: 0.29006261902242914

#### val Acc: 0, NDCG: 0.464041155855395 HIT: 0.5532410468683876
Epoch: 4, plus 0 steps train_loss: 0.7523

#### test Acc: 0, NDCG: 0.13022080238101974 HIT: 0.2877590390922556

#### val Acc: 0, NDCG: 0.4804953730429962 HIT: 0.5677956715509945
Epoch: 5, plus 0 steps train_loss: 0.7527

#### test Acc: 0, NDCG: 0.12727932402633704 HIT: 0.2801821043165468

#### val Acc: 0, NDCG: 0.4806052419868494 HIT: 0.5692660944773592
Epoch: 6, plus 0 steps train_loss: 0.7573

#### test Acc: 0, NDCG: 0.1305119716886883 HIT: 0.28915507300042315

#### val Acc: 0, NDCG: 0.47476624481515406 HIT: 0.5619553070778671
Epoch: 7, plus 0 steps train_loss: 0.749

#### test Acc: 0, NDCG: 0.1263562882713947 HIT: 0.276082442869234

#### val Acc: 0, NDCG: 0.48415522295590124 HIT: 0.5811650312103259
Epoch: 8, plus 0 steps train_loss: 0.736

#### test Acc: 0, NDCG: 0.12425015270501676 HIT: 0.2803639441388066

#### val Acc: 0, NDCG: 0.48373364383183826 HIT: 0.5793210101036818
Epoch: 9, plus 0 steps train_loss: 0.7476

#### test Acc: 0, NDCG: 0.12751346873059743 HIT: 0.29002625105797714

#### val Acc: 0, NDCG: 0.4625191856475487 HIT: 0.5518144308082945
Epoch: 10, plus 0 steps train_loss: 0.7471

#### test Acc: 0, NDCG: 0.13407354044146566 HIT: 0.29567320408379183

#### val Acc: 0, NDCG: 0.48257752159153405 HIT: 0.5759412690435886
Epoch: 12, plus 0 steps train_loss: 0.7426

#### test Acc: 0, NDCG: 0.13369220112651825 HIT: 0.2911941586436733

#### val Acc: 0, NDCG: 0.48329134048572786 HIT: 0.5752039912187897
Epoch: 14, plus 0 steps train_loss: 0.7422

#### test Acc: 0, NDCG: 0.13616982674515996 HIT: 0.30101929485823103

#### val Acc: 0, NDCG: 0.4834081696775771 HIT: 0.5747923719847651
Epoch: 16, plus 0 steps train_loss: 0.7385

#### test Acc: 0, NDCG: 0.14283143128424877 HIT: 0.30997490610452816

#### val Acc: 0, NDCG: 0.47104429849449414 HIT: 0.5512094001269573
Epoch: 18, plus 0 steps train_loss: 0.736

#### test Acc: 0, NDCG: 0.12720441040472194 HIT: 0.2805209876216674

#### val Acc: 0, NDCG: 0.4795795441895516 HIT: 0.5769389084320778
Epoch: 20, plus 0 steps train_loss: 0.7335

#### test Acc: 0, NDCG: 0.13151031578795044 HIT: 0.2852678335272958

#### val Acc: 0, NDCG: 0.48544169561373046 HIT: 0.5800045625264495
Epoch: 22, plus 0 steps train_loss: 0.7374

#### test Acc: 0, NDCG: 0.12411727547408118 HIT: 0.2696734156792213

#### val Acc: 0, NDCG: 0.4714693730868111 HIT: 0.563085193609818
Epoch: 24, plus 0 steps train_loss: 0.7306

#### test Acc: 0, NDCG: 0.13195219527320304 HIT: 0.2905585458104105

#### val Acc: 0, NDCG: 0.4694917137928914 HIT: 0.5634546590668642
Epoch: 26, plus 0 steps train_loss: 0.7217

#### test Acc: 0, NDCG: 0.13734500496628718 HIT: 0.29132061997460856

#### val Acc: 0, NDCG: 0.4664474952718672 HIT: 0.5553338579136691
Epoch: 28, plus 0 steps train_loss: 0.7284

#### test Acc: 0, NDCG: 0.13348075100916704 HIT: 0.29041307395260263

#### val Acc: 0, NDCG: 0.47728677768502137 HIT: 0.5674336449957681
Epoch: 30, plus 0 steps train_loss: 0.7214

#### test Acc: 0, NDCG: 0.12073429475471113 HIT: 0.2732407823741007

#### val Acc: 0, NDCG: 0.48474586888312166 HIT: 0.5747808003597122
Epoch: 32, plus 0 steps train_loss: 0.7268

#### test Acc: 0, NDCG: 0.12806964394146625 HIT: 0.2819360320567076

#### val Acc: 0, NDCG: 0.47614195818467653 HIT: 0.5689024148328397
Epoch: 36, plus 0 steps train_loss: 0.7257

#### test Acc: 0, NDCG: 0.13190408512714655 HIT: 0.2888657823741007

#### val Acc: 0, NDCG: 0.48129726513835475 HIT: 0.5779729157850191
Epoch: 40, plus 0 steps train_loss: 0.7207

#### test Acc: 0, NDCG: 0.16864405842793712 HIT: 0.3221052753385527

#### val Acc: 0, NDCG: 0.4871259337979852 HIT: 0.5825800756453661
Epoch: 44, plus 0 steps train_loss: 0.7165

#### test Acc: 0, NDCG: 0.22943578290911032 HIT: 0.3797782546022006

#### val Acc: 0, NDCG: 0.5367351105176622 HIT: 0.6277259442446044
Epoch: 48, plus 0 steps train_loss: 0.7135

#### test Acc: 0, NDCG: 0.28626401786544176 HIT: 0.42980900206305545

#### val Acc: 0, NDCG: 0.5855527175774436 HIT: 0.6723320791895895
Epoch: 52, plus 0 steps train_loss: 0.7139

#### test Acc: 0, NDCG: 0.3324975042736647 HIT: 0.47000138859500634

#### val Acc: 0, NDCG: 0.5957640845969733 HIT: 0.682545691388066
Epoch: 56, plus 0 steps train_loss: 0.7123

#### test Acc: 0, NDCG: 0.3766706537979052 HIT: 0.5150381533008886

#### val Acc: 0, NDCG: 0.6216373958618444 HIT: 0.7065997936944561
Epoch: 60, plus 0 steps train_loss: 0.7105

#### test Acc: 0, NDCG: 0.3912545615748404 HIT: 0.5341519982543377

#### val Acc: 0, NDCG: 0.6233509880723683 HIT: 0.7110556958844689
Epoch: 64, plus 0 steps train_loss: 0.7068

#### test Acc: 0, NDCG: 0.40465339679191326 HIT: 0.5392740954295387

#### val Acc: 0, NDCG: 0.6386380994737977 HIT: 0.7190500357067287
Epoch: 68, plus 0 steps train_loss: 0.7065

#### test Acc: 0, NDCG: 0.4237173554045479 HIT: 0.5565728483389759

#### val Acc: 0, NDCG: 0.6420994427921558 HIT: 0.7210626719212865
Epoch: 72, plus 0 steps train_loss: 0.7108

#### test Acc: 0, NDCG: 0.344579527407049 HIT: 0.48459238124206516

#### val Acc: 0, NDCG: 0.615013432160409 HIT: 0.6986360360241219
Epoch: 80, plus 0 steps train_loss: 0.7033

#### test Acc: 0, NDCG: 0.3276998522934526 HIT: 0.47284304909013963

#### val Acc: 0, NDCG: 0.5907859449021088 HIT: 0.6783906514494288
Epoch: 88, plus 0 steps train_loss: 0.7028

#### test Acc: 0, NDCG: 0.5221784411553821 HIT: 0.6388454493757935

#### val Acc: 0, NDCG: 0.7173890335768965 HIT: 0.7850256559458315
Epoch: 96, plus 0 steps train_loss: 0.7042

#### test Acc: 0, NDCG: 0.4868730993082462 HIT: 0.6197564007617435

#### val Acc: 0, NDCG: 0.6867570045191758 HIT: 0.7653737304274228
Epoch: 104, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.5461501929403283 HIT: 0.6639335590351249

#### val Acc: 0, NDCG: 0.734760225266915 HIT: 0.8058744181125688
Epoch: 112, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.5574763642968669 HIT: 0.66779186944562

#### val Acc: 0, NDCG: 0.7410679385843756 HIT: 0.8108088896529835
Epoch: 120, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.5104108183051088 HIT: 0.6424913378121032

#### val Acc: 0, NDCG: 0.7135844746944142 HIT: 0.7893129430279306
Epoch: 128, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.506205872406566 HIT: 0.6330645961172239

#### val Acc: 0, NDCG: 0.6994127079906037 HIT: 0.7832907387325434
Epoch: 136, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.5054332257938532 HIT: 0.6323579004443504

#### val Acc: 0, NDCG: 0.6978596444516958 HIT: 0.7761369948159119
Epoch: 144, plus 0 steps train_loss: 0.7065

#### test Acc: 0, NDCG: 0.5073060490732099 HIT: 0.6416697524333475

#### val Acc: 0, NDCG: 0.7095434568305582 HIT: 0.7885087150867541
Epoch: 160, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.46760547057838897 HIT: 0.6013608231062209

#### val Acc: 0, NDCG: 0.695119777197462 HIT: 0.7675202668747355
Epoch: 176, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.44850590906262033 HIT: 0.5870070487727466

#### val Acc: 0, NDCG: 0.6828325408870124 HIT: 0.7605062090033856
Epoch: 192, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.5372184164124804 HIT: 0.6632078528353788

#### val Acc: 0, NDCG: 0.720817473871041 HIT: 0.7988066348391875
Epoch: 208, plus 0 steps train_loss: 0.7012

#### test Acc: 0, NDCG: 0.47706336904808355 HIT: 0.6146343035865425

#### val Acc: 0, NDCG: 0.6934000711495796 HIT: 0.7726903036394414
Epoch: 224, plus 0 steps train_loss: 0.7022

#### test Acc: 0, NDCG: 0.5173253692127135 HIT: 0.649034265234871

#### val Acc: 0, NDCG: 0.7215159678090929 HIT: 0.7996166485928904
Epoch: 240, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.5457317762820832 HIT: 0.669635890552264

#### val Acc: 0, NDCG: 0.7313392940526473 HIT: 0.8038733535230639
Epoch: 256, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.572837013141864 HIT: 0.7007577761320355

#### val Acc: 0, NDCG: 0.7467925782590903 HIT: 0.8145638819826492
Epoch: 272, plus 0 steps train_loss: 0.6989

#### test Acc: 0, NDCG: 0.5743794270883982 HIT: 0.6931998518831993

#### val Acc: 0, NDCG: 0.732595141229198 HIT: 0.8067703925095218
Epoch: 288, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.5720325959969554 HIT: 0.6927882326491748

#### val Acc: 0, NDCG: 0.7335316280122323 HIT: 0.8015755594054168
Epoch: 304, plus 0 steps train_loss: 0.6982

#### test Acc: 0, NDCG: 0.5626655381083604 HIT: 0.6815596236246297

#### val Acc: 0, NDCG: 0.727550549853235 HIT: 0.8004936124629708
Epoch: 320, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.5714795768871274 HIT: 0.6899102041895895

#### val Acc: 0, NDCG: 0.7482409772158218 HIT: 0.8188148011002961
Epoch: 352, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.5804091165879665 HIT: 0.7017264864578925

#### val Acc: 0, NDCG: 0.7282542153371723 HIT: 0.7960608535230639
Epoch: 384, plus 0 steps train_loss: 0.6954

#### test Acc: 0, NDCG: 0.5774821972216541 HIT: 0.6924377777190012

#### val Acc: 0, NDCG: 0.7481863636947734 HIT: 0.8220928771688532
Epoch: 416, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.5848988823856167 HIT: 0.700885890552264

#### val Acc: 0, NDCG: 0.7369576439202009 HIT: 0.807423362780364
Epoch: 448, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.5851669668748877 HIT: 0.7081412994604317

#### val Acc: 0, NDCG: 0.737823383756864 HIT: 0.8158045254972492
Epoch: 480, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.6088047911550661 HIT: 0.7288636002962336

#### val Acc: 0, NDCG: 0.7573265980557672 HIT: 0.8290284132987727
Epoch: 512, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.5778917907845985 HIT: 0.6938412505289886

#### val Acc: 0, NDCG: 0.739355733368428 HIT: 0.8073564126639864
Epoch: 544, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.4947116473786178 HIT: 0.6199250158696572

#### val Acc: 0, NDCG: 0.6965744155563611 HIT: 0.7770007339716463
Epoch: 576, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.5420534293628079 HIT: 0.6678761769995768

#### val Acc: 0, NDCG: 0.73484674454533 HIT: 0.8069638039568345
Epoch: 608, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.5389946741743411 HIT: 0.6649791380131189

#### val Acc: 0, NDCG: 0.7199295589696499 HIT: 0.7993331437790944
Epoch: 640, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.4589225691661203 HIT: 0.5930962031845112

#### val Acc: 0, NDCG: 0.652524618041972 HIT: 0.7345295638489208
Epoch: 704, plus 0 steps train_loss: 0.6946

#### test Acc: 0, NDCG: 0.5691588170908055 HIT: 0.6887861034701651

#### val Acc: 0, NDCG: 0.7409811645176504 HIT: 0.8161301840880236
Epoch: 768, plus 0 steps train_loss: 0.6954

#### test Acc: 0, NDCG: 0.5757859822443887 HIT: 0.6883860558611934

#### val Acc: 0, NDCG: 0.738021823888693 HIT: 0.8105005884997883
Epoch: 832, plus 0 steps train_loss: 0.6938

#### test Acc: 0, NDCG: 0.6041170553226161 HIT: 0.7166431376957257

#### val Acc: 0, NDCG: 0.7384055245574164 HIT: 0.8104526489102836
Epoch: 896, plus 0 steps train_loss: 0.693

#### test Acc: 0, NDCG: 0.5787737527583093 HIT: 0.696501071201862

#### val Acc: 0, NDCG: 0.7478279686973751 HIT: 0.8163599634997883
Epoch: 960, plus 0 steps train_loss: 0.6931

#### test Acc: 0, NDCG: 0.5816681177237677 HIT: 0.7023488745768091

#### val Acc: 0, NDCG: 0.7364673615857038 HIT: 0.8107130104739738
Epoch: 1017, plus 0 steps train_loss: 0.6965
Done: it took 88864.56859326363
max value of NDCG: 0.6088047911550661
max value of HIT: 0.7288636002962336

After 20 validations
max value of NDCG: 0.6088047911550661
max value of HIT: 0.7288636002962336
