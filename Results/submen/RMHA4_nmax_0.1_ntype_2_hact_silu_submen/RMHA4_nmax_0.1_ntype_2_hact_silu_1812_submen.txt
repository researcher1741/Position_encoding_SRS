 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2
max_norm:             	0.1
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.11667952377784807 HIT: 0.260493810833686

#### val Acc: 0, NDCG: 0.4776543531197966 HIT: 0.5745873889123995
Epoch: 1, plus 0 steps train_loss: 0.7503

#### test Acc: 0, NDCG: 0.12054342453138173 HIT: 0.27206130316335164

#### val Acc: 0, NDCG: 0.4714616892934608 HIT: 0.5691090509944985
Epoch: 2, plus 0 steps train_loss: 0.7529

#### test Acc: 0, NDCG: 0.12503497911305286 HIT: 0.2768023632564537

#### val Acc: 0, NDCG: 0.4790053222754758 HIT: 0.5724160561256877
Epoch: 3, plus 0 steps train_loss: 0.7428

#### test Acc: 0, NDCG: 0.12739883199465696 HIT: 0.28615058320990266

#### val Acc: 0, NDCG: 0.4701409374760234 HIT: 0.5670335973867965
Epoch: 4, plus 0 steps train_loss: 0.7518

#### test Acc: 0, NDCG: 0.12031767960342415 HIT: 0.2690204454083792

#### val Acc: 0, NDCG: 0.48477981141243176 HIT: 0.572161480374524
Epoch: 5, plus 0 steps train_loss: 0.7386

#### test Acc: 0, NDCG: 0.12534345495011695 HIT: 0.2704892152454507

#### val Acc: 0, NDCG: 0.48254343161806107 HIT: 0.5720118757934829
Epoch: 6, plus 0 steps train_loss: 0.7373

#### test Acc: 0, NDCG: 0.12161846319490965 HIT: 0.2673392535971223

#### val Acc: 0, NDCG: 0.4754891009632754 HIT: 0.5738253147482014
Epoch: 7, plus 0 steps train_loss: 0.7374

#### test Acc: 0, NDCG: 0.13219605203784102 HIT: 0.2838527890922556

#### val Acc: 0, NDCG: 0.47766016280020396 HIT: 0.5691685622090563
Epoch: 8, plus 0 steps train_loss: 0.7275

#### test Acc: 0, NDCG: 0.13561972520430707 HIT: 0.29396886902242914

#### val Acc: 0, NDCG: 0.48582671030011076 HIT: 0.5817700618916631
Epoch: 9, plus 0 steps train_loss: 0.7265

#### test Acc: 0, NDCG: 0.13022571939350652 HIT: 0.2863977200592467

#### val Acc: 0, NDCG: 0.47370025641141106 HIT: 0.5719507114896318
Epoch: 10, plus 0 steps train_loss: 0.7172

#### test Acc: 0, NDCG: 0.13594924404746112 HIT: 0.2929654438214135

#### val Acc: 0, NDCG: 0.49204091297090224 HIT: 0.5910091779517562
Epoch: 12, plus 0 steps train_loss: 0.7217

#### test Acc: 0, NDCG: 0.13090772788291255 HIT: 0.2868035534807448

#### val Acc: 0, NDCG: 0.48683648164377474 HIT: 0.5767876507617435
Epoch: 14, plus 0 steps train_loss: 0.7151

#### test Acc: 0, NDCG: 0.13715239363128878 HIT: 0.2910123188214135

#### val Acc: 0, NDCG: 0.4831312712175208 HIT: 0.5713820487727466
Epoch: 16, plus 0 steps train_loss: 0.7119

#### test Acc: 0, NDCG: 0.13655723890541918 HIT: 0.30035475296233605

#### val Acc: 0, NDCG: 0.48421870268390077 HIT: 0.5775439391134152
Epoch: 18, plus 0 steps train_loss: 0.7079

#### test Acc: 0, NDCG: 0.12588671907997895 HIT: 0.27565346619763015

#### val Acc: 0, NDCG: 0.4825388728492953 HIT: 0.5746353285019044
Epoch: 20, plus 0 steps train_loss: 0.7102

#### test Acc: 0, NDCG: 0.1394688173178304 HIT: 0.29495493678586543

#### val Acc: 0, NDCG: 0.488920668239699 HIT: 0.58380749444562
Epoch: 22, plus 0 steps train_loss: 0.7059

#### test Acc: 0, NDCG: 0.13719797769317163 HIT: 0.29415070884468897

#### val Acc: 0, NDCG: 0.4755050724090985 HIT: 0.5682742409013964
Epoch: 24, plus 0 steps train_loss: 0.7082

#### test Acc: 0, NDCG: 0.1402793540867546 HIT: 0.2977412187896742

#### val Acc: 0, NDCG: 0.47638813054145335 HIT: 0.5731591197630131
Epoch: 26, plus 0 steps train_loss: 0.7083

#### test Acc: 0, NDCG: 0.13809119082690097 HIT: 0.2997612939060516

#### val Acc: 0, NDCG: 0.47198430278380304 HIT: 0.5637935423719848
Epoch: 28, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.13794594076051298 HIT: 0.29226453396106644

#### val Acc: 0, NDCG: 0.47405373289551445 HIT: 0.562862853099873
Epoch: 30, plus 0 steps train_loss: 0.7058

#### test Acc: 0, NDCG: 0.1383357669426564 HIT: 0.2996769863520948

#### val Acc: 0, NDCG: 0.48414926972171524 HIT: 0.5719928652666102
Epoch: 32, plus 0 steps train_loss: 0.7075

#### test Acc: 0, NDCG: 0.13577611548368812 HIT: 0.29213063372831144

#### val Acc: 0, NDCG: 0.4814114734357313 HIT: 0.5796293112568769
Epoch: 36, plus 0 steps train_loss: 0.7063

#### test Acc: 0, NDCG: 0.144126832581123 HIT: 0.2954202814219213

#### val Acc: 0, NDCG: 0.4822909600864497 HIT: 0.578329156527719
Epoch: 40, plus 0 steps train_loss: 0.7023

#### test Acc: 0, NDCG: 0.14876143292411845 HIT: 0.299937347915785

#### val Acc: 0, NDCG: 0.485190182350959 HIT: 0.5846480903512484
Epoch: 44, plus 0 steps train_loss: 0.7013

#### test Acc: 0, NDCG: 0.13822106564854938 HIT: 0.2994108389758781

#### val Acc: 0, NDCG: 0.4744033442726948 HIT: 0.5621850864896318
Epoch: 48, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.13938504259567605 HIT: 0.3070720813055438

#### val Acc: 0, NDCG: 0.48237750807743124 HIT: 0.5721441229369446
Epoch: 52, plus 0 steps train_loss: 0.7018

#### test Acc: 0, NDCG: 0.13765732778193082 HIT: 0.30754321175412613

#### val Acc: 0, NDCG: 0.4673957162833313 HIT: 0.5566819522323319
Epoch: 56, plus 0 steps train_loss: 0.7022

#### test Acc: 0, NDCG: 0.16038682466366047 HIT: 0.31135936838764283

#### val Acc: 0, NDCG: 0.49559249591184873 HIT: 0.5949575817287346
Epoch: 60, plus 0 steps train_loss: 0.7009

#### test Acc: 0, NDCG: 0.13467925603861425 HIT: 0.28664072418535763

#### val Acc: 0, NDCG: 0.4695032088858643 HIT: 0.5606857345006349
Epoch: 64, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.1316478062853925 HIT: 0.2851529438214135

#### val Acc: 0, NDCG: 0.4816621963150945 HIT: 0.5712671590668642
Epoch: 68, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.136287767609901 HIT: 0.2919735902454507

#### val Acc: 0, NDCG: 0.4778017273032874 HIT: 0.5665013026343632
Epoch: 72, plus 0 steps train_loss: 0.7037

#### test Acc: 0, NDCG: 0.3030625377729705 HIT: 0.45094870794540837

#### val Acc: 0, NDCG: 0.5765775182273883 HIT: 0.6665454401184934
Epoch: 80, plus 0 steps train_loss: 0.7007

#### test Acc: 0, NDCG: 0.1517637152848402 HIT: 0.3031236775285654

#### val Acc: 0, NDCG: 0.48444054152677957 HIT: 0.5748287399492171
Epoch: 88, plus 0 steps train_loss: 0.7013

#### test Acc: 0, NDCG: 0.2942213390596291 HIT: 0.440723524121879

#### val Acc: 0, NDCG: 0.576308103357487 HIT: 0.6624036248942023
Epoch: 96, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.45858830932142464 HIT: 0.5739211939272112

#### val Acc: 0, NDCG: 0.672468859382076 HIT: 0.7472037994604317
Epoch: 104, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.5084181725010531 HIT: 0.6216979541366906

#### val Acc: 0, NDCG: 0.6881971018153287 HIT: 0.763571863097757
Epoch: 112, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.3186955085598382 HIT: 0.45353744577867117

#### val Acc: 0, NDCG: 0.5974397663407266 HIT: 0.6800908537875582
Epoch: 120, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.35853725411588 HIT: 0.4907600573952603

#### val Acc: 0, NDCG: 0.6163460880676025 HIT: 0.7043193570143885
Epoch: 128, plus 0 steps train_loss: 0.7009

#### test Acc: 0, NDCG: 0.23655432165948215 HIT: 0.3811875132247144

#### val Acc: 0, NDCG: 0.5333039070719651 HIT: 0.6221558598709267
Epoch: 136, plus 0 steps train_loss: 0.6942

#### test Acc: 0, NDCG: 0.2820669003231752 HIT: 0.4220328700275074

#### val Acc: 0, NDCG: 0.562916050285955 HIT: 0.6531397124947101
Epoch: 144, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.6329773865678614 HIT: 0.7349163867435464

#### val Acc: 0, NDCG: 0.7820366869064439 HIT: 0.8366169196995346
Epoch: 160, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.5751103510743796 HIT: 0.6899044183770631

#### val Acc: 0, NDCG: 0.7510214164859923 HIT: 0.8249766914409649
Epoch: 176, plus 0 steps train_loss: 0.6863

#### test Acc: 0, NDCG: 0.5304396566825534 HIT: 0.6543613454824376

#### val Acc: 0, NDCG: 0.7231929506638333 HIT: 0.7950458566969953
Epoch: 192, plus 0 steps train_loss: 0.6848

#### test Acc: 0, NDCG: 0.573754456624555 HIT: 0.6840202470376641

#### val Acc: 0, NDCG: 0.7512105106921376 HIT: 0.8244022429115531
Epoch: 208, plus 0 steps train_loss: 0.682

#### test Acc: 0, NDCG: 0.535658000414229 HIT: 0.6585643250105797

#### val Acc: 0, NDCG: 0.7226875178593231 HIT: 0.7945672873465933
Epoch: 224, plus 0 steps train_loss: 0.6867

#### test Acc: 0, NDCG: 0.5692376580101075 HIT: 0.6883381162716885

#### val Acc: 0, NDCG: 0.7486944435113495 HIT: 0.8204290427951756
Epoch: 240, plus 0 steps train_loss: 0.6669

#### test Acc: 0, NDCG: 0.573864098686734 HIT: 0.6951529768831993

#### val Acc: 0, NDCG: 0.7492491207863399 HIT: 0.8219895590880236
Epoch: 256, plus 0 steps train_loss: 0.6766

#### test Acc: 0, NDCG: 0.46512993637019323 HIT: 0.5989977319614896

#### val Acc: 0, NDCG: 0.6930824230406796 HIT: 0.7747641041578502
Epoch: 272, plus 0 steps train_loss: 0.6658

#### test Acc: 0, NDCG: 0.5100192505729635 HIT: 0.6457272601036818

#### val Acc: 0, NDCG: 0.7070429059621332 HIT: 0.787438339769361
Epoch: 288, plus 0 steps train_loss: 0.6477

#### test Acc: 0, NDCG: 0.31845985577979197 HIT: 0.4828153102517985

#### val Acc: 0, NDCG: 0.6079042496734381 HIT: 0.7001717559775709
Epoch: 304, plus 0 steps train_loss: 0.6129

#### test Acc: 0, NDCG: 0.2304957635812016 HIT: 0.4048415679221329

#### val Acc: 0, NDCG: 0.527666250590044 HIT: 0.6351689787875582
Epoch: 320, plus 0 steps train_loss: 0.6283

#### test Acc: 0, NDCG: 0.2776424717078482 HIT: 0.4886308783855269

#### val Acc: 0, NDCG: 0.5557630298364999 HIT: 0.668873816388066
Epoch: 352, plus 0 steps train_loss: 0.5837

#### test Acc: 0, NDCG: 0.2781712861916557 HIT: 0.49155271371138387

#### val Acc: 0, NDCG: 0.5570234166925807 HIT: 0.6821167147164621
Epoch: 384, plus 0 steps train_loss: 0.5606

#### test Acc: 0, NDCG: 0.2826292152102379 HIT: 0.4936570963817181

#### val Acc: 0, NDCG: 0.5541368824439413 HIT: 0.6720237780363945
Epoch: 416, plus 0 steps train_loss: 0.5454

#### test Acc: 0, NDCG: 0.28546158368162594 HIT: 0.49955862515869653

#### val Acc: 0, NDCG: 0.5619338145752006 HIT: 0.6832350296233601
Epoch: 448, plus 0 steps train_loss: 0.556

#### test Acc: 0, NDCG: 0.28085411501271756 HIT: 0.49997603020524756

#### val Acc: 0, NDCG: 0.5517331444832086 HIT: 0.6695210008463817
Epoch: 480, plus 0 steps train_loss: 0.5662

#### test Acc: 0, NDCG: 0.2892236969828472 HIT: 0.5005678361722387

#### val Acc: 0, NDCG: 0.5612227243688366 HIT: 0.6766441626110876
Epoch: 512, plus 0 steps train_loss: 0.5411

#### test Acc: 0, NDCG: 0.2841057397582331 HIT: 0.49977683294540837

#### val Acc: 0, NDCG: 0.56838269240371 HIT: 0.6864692988256453
Epoch: 544, plus 0 steps train_loss: 0.5297

#### test Acc: 0, NDCG: 0.2756663647971465 HIT: 0.4866430385103682

#### val Acc: 0, NDCG: 0.5568451173686564 HIT: 0.6761598074481592
Epoch: 576, plus 0 steps train_loss: 0.5315

#### test Acc: 0, NDCG: 0.2779960950352069 HIT: 0.4860322220165044

#### val Acc: 0, NDCG: 0.5623121136147564 HIT: 0.6824919659860347
Epoch: 608, plus 0 steps train_loss: 0.5234

#### test Acc: 0, NDCG: 0.27729516948601746 HIT: 0.49212137642826914

#### val Acc: 0, NDCG: 0.5575543417040644 HIT: 0.6776533736246297
Epoch: 640, plus 0 steps train_loss: 0.5244

#### test Acc: 0, NDCG: 0.28560208873336024 HIT: 0.4961003623571731

#### val Acc: 0, NDCG: 0.5585165217118362 HIT: 0.6769582495768091
Epoch: 704, plus 0 steps train_loss: 0.5245

#### test Acc: 0, NDCG: 0.2834421183780764 HIT: 0.48672734606432505

#### val Acc: 0, NDCG: 0.5639548708125643 HIT: 0.6841235651184934
Epoch: 768, plus 0 steps train_loss: 0.5028

#### test Acc: 0, NDCG: 0.28234600417782707 HIT: 0.4916254496402878

#### val Acc: 0, NDCG: 0.560439961305991 HIT: 0.6750299209162083
Epoch: 832, plus 0 steps train_loss: 0.5366

#### test Acc: 0, NDCG: 0.27014307781769753 HIT: 0.4819937248730427

#### val Acc: 0, NDCG: 0.563865121103248 HIT: 0.6780286248942023
Epoch: 896, plus 0 steps train_loss: 0.5148

#### test Acc: 0, NDCG: 0.2787794080836863 HIT: 0.49072368943080824

#### val Acc: 0, NDCG: 0.5649789632601072 HIT: 0.6855939880448583
Epoch: 960, plus 0 steps train_loss: 0.4928

#### test Acc: 0, NDCG: 0.28345659780219806 HIT: 0.4898599502750741

#### val Acc: 0, NDCG: 0.5650372267971371 HIT: 0.685260890552264
Epoch: 1017, plus 0 steps train_loss: 0.5082
Done: it took 142093.48807549477
max value of NDCG: 0.6329773865678614
max value of HIT: 0.7349163867435464

After 20 validations
max value of NDCG: 0.6329773865678614
max value of HIT: 0.7349163867435464
