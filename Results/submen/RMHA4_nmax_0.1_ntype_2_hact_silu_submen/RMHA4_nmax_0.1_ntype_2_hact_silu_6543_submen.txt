 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2
max_norm:             	0.1
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13010522551824466 HIT: 0.2916652890922556

#### val Acc: 0, NDCG: 0.48420746786172514 HIT: 0.5754759244075328
Epoch: 1, plus 0 steps train_loss: 0.743

#### test Acc: 0, NDCG: 0.1262826175549841 HIT: 0.2824741126216674

#### val Acc: 0, NDCG: 0.4713920886105353 HIT: 0.5630504787346593
Epoch: 2, plus 0 steps train_loss: 0.7374

#### test Acc: 0, NDCG: 0.12377891062018437 HIT: 0.2809020247037664

#### val Acc: 0, NDCG: 0.47882655984189315 HIT: 0.5734136955141769
Epoch: 3, plus 0 steps train_loss: 0.7444

#### test Acc: 0, NDCG: 0.12798779785982828 HIT: 0.2828725071413457

#### val Acc: 0, NDCG: 0.4855795979906728 HIT: 0.5877922661870504
Epoch: 4, plus 0 steps train_loss: 0.7471

#### test Acc: 0, NDCG: 0.12767551336279556 HIT: 0.287703660600931

#### val Acc: 0, NDCG: 0.4887722315071381 HIT: 0.5755470072471435
Epoch: 5, plus 0 steps train_loss: 0.7367

#### test Acc: 0, NDCG: 0.13451869002922492 HIT: 0.2987272865531104

#### val Acc: 0, NDCG: 0.4732711446554591 HIT: 0.5669377182077867
Epoch: 6, plus 0 steps train_loss: 0.7416

#### test Acc: 0, NDCG: 0.1364576369414679 HIT: 0.3059595522111722

#### val Acc: 0, NDCG: 0.4810480801282016 HIT: 0.569078468842573
Epoch: 7, plus 0 steps train_loss: 0.7274

#### test Acc: 0, NDCG: 0.12992947246317438 HIT: 0.28128306178586543

#### val Acc: 0, NDCG: 0.4802236181217663 HIT: 0.5718184643461701
Epoch: 8, plus 0 steps train_loss: 0.7254

#### test Acc: 0, NDCG: 0.12739283684684424 HIT: 0.28328412637537026

#### val Acc: 0, NDCG: 0.4815879428116228 HIT: 0.5734079097016505
Epoch: 9, plus 0 steps train_loss: 0.7189

#### test Acc: 0, NDCG: 0.12770140985442802 HIT: 0.28631341250528985

#### val Acc: 0, NDCG: 0.4830440262547332 HIT: 0.5766479647164621
Epoch: 10, plus 0 steps train_loss: 0.7165

#### test Acc: 0, NDCG: 0.13596422816834314 HIT: 0.29133219159966145

#### val Acc: 0, NDCG: 0.4832057217307793 HIT: 0.5817642760791367
Epoch: 12, plus 0 steps train_loss: 0.7202

#### test Acc: 0, NDCG: 0.13156355715434737 HIT: 0.28151862701015656

#### val Acc: 0, NDCG: 0.4895031558776961 HIT: 0.5832520564430808
Epoch: 14, plus 0 steps train_loss: 0.7156

#### test Acc: 0, NDCG: 0.13067330301208374 HIT: 0.2823054975137537

#### val Acc: 0, NDCG: 0.4739415022416676 HIT: 0.565848332363521
Epoch: 16, plus 0 steps train_loss: 0.7081

#### test Acc: 0, NDCG: 0.12828367307591493 HIT: 0.2834122407955988

#### val Acc: 0, NDCG: 0.47034701538203766 HIT: 0.5648754893144308
Epoch: 18, plus 0 steps train_loss: 0.7097

#### test Acc: 0, NDCG: 0.12698341803807955 HIT: 0.27480708447947527

#### val Acc: 0, NDCG: 0.4759076793668111 HIT: 0.5692660944773592
Epoch: 20, plus 0 steps train_loss: 0.704

#### test Acc: 0, NDCG: 0.133912475611921 HIT: 0.29075195725772324

#### val Acc: 0, NDCG: 0.47369658256003494 HIT: 0.5745799500105797
Epoch: 22, plus 0 steps train_loss: 0.703

#### test Acc: 0, NDCG: 0.13156388313455036 HIT: 0.28876246429327124

#### val Acc: 0, NDCG: 0.46847464762224833 HIT: 0.5519235347016505
Epoch: 24, plus 0 steps train_loss: 0.7055

#### test Acc: 0, NDCG: 0.13855453837403994 HIT: 0.2947730969636056

#### val Acc: 0, NDCG: 0.4765499867928687 HIT: 0.568551959902666
Epoch: 26, plus 0 steps train_loss: 0.7081

#### test Acc: 0, NDCG: 0.13998163055664806 HIT: 0.29940505316335164

#### val Acc: 0, NDCG: 0.48337904726468395 HIT: 0.5799681945619974
Epoch: 28, plus 0 steps train_loss: 0.7078

#### test Acc: 0, NDCG: 0.14172941026294184 HIT: 0.2997612939060516

#### val Acc: 0, NDCG: 0.49884199013320407 HIT: 0.5985018051735083
Epoch: 30, plus 0 steps train_loss: 0.7085

#### test Acc: 0, NDCG: 0.14953409485699756 HIT: 0.30695719159966145

#### val Acc: 0, NDCG: 0.5095492937235562 HIT: 0.6102684947630131
Epoch: 32, plus 0 steps train_loss: 0.7084

#### test Acc: 0, NDCG: 0.16139273229495807 HIT: 0.3190206107173085

#### val Acc: 0, NDCG: 0.4984381764428543 HIT: 0.6015616734553533
Epoch: 36, plus 0 steps train_loss: 0.7069

#### test Acc: 0, NDCG: 0.11533027529762858 HIT: 0.2649802951756242

#### val Acc: 0, NDCG: 0.47045755472881956 HIT: 0.556241403935675
Epoch: 40, plus 0 steps train_loss: 0.7025

#### test Acc: 0, NDCG: 0.15728626279210303 HIT: 0.3135249153618282

#### val Acc: 0, NDCG: 0.5056851238355526 HIT: 0.6011136862568769
Epoch: 44, plus 0 steps train_loss: 0.7043

#### test Acc: 0, NDCG: 0.1529694501685329 HIT: 0.3134158114684723

#### val Acc: 0, NDCG: 0.5075460064960992 HIT: 0.6019063425730004
Epoch: 48, plus 0 steps train_loss: 0.7046

#### test Acc: 0, NDCG: 0.17496079200873654 HIT: 0.32204989684722807

#### val Acc: 0, NDCG: 0.5036883285374577 HIT: 0.59872001296022
Epoch: 52, plus 0 steps train_loss: 0.7028

#### test Acc: 0, NDCG: 0.168593142743472 HIT: 0.32160769546127804

#### val Acc: 0, NDCG: 0.5130178080166496 HIT: 0.6067854356220906
Epoch: 56, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.1523927426324525 HIT: 0.3174485227994075

#### val Acc: 0, NDCG: 0.4939241573629624 HIT: 0.5970198106220906
Epoch: 60, plus 0 steps train_loss: 0.7044

#### test Acc: 0, NDCG: 0.17181700848966022 HIT: 0.3359209691070673

#### val Acc: 0, NDCG: 0.49979712754627087 HIT: 0.603302376481168
Epoch: 64, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.41588374472344913 HIT: 0.5476246759944985

#### val Acc: 0, NDCG: 0.649144333090646 HIT: 0.7292198410389336
Epoch: 68, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.3699138059481673 HIT: 0.4999280906157427

#### val Acc: 0, NDCG: 0.6168651704946797 HIT: 0.6953348167054592
Epoch: 72, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.3534582691998951 HIT: 0.4828690356538298

#### val Acc: 0, NDCG: 0.6048742758407794 HIT: 0.6841483614578925
Epoch: 80, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.397448279967728 HIT: 0.5296291459479475

#### val Acc: 0, NDCG: 0.6243272762822409 HIT: 0.7107473947312738
Epoch: 88, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.3747340629741182 HIT: 0.5082423032162505

#### val Acc: 0, NDCG: 0.6239978364708044 HIT: 0.706684101248413
Epoch: 96, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.34519393389513253 HIT: 0.48263347042953875

#### val Acc: 0, NDCG: 0.5978582135792584 HIT: 0.6855865491430384
Epoch: 104, plus 0 steps train_loss: 0.6984

#### test Acc: 0, NDCG: 0.2516630146678269 HIT: 0.41125224820143885

#### val Acc: 0, NDCG: 0.5297361851592647 HIT: 0.6253554141980534
Epoch: 112, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.3298876893129831 HIT: 0.47127840007405847

#### val Acc: 0, NDCG: 0.6023206365645617 HIT: 0.6900135222704189
Epoch: 120, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.4835418576901366 HIT: 0.6033271728205671

#### val Acc: 0, NDCG: 0.6995581883531871 HIT: 0.7692436124629708
Epoch: 128, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.5066059664377693 HIT: 0.6293459717520102

#### val Acc: 0, NDCG: 0.715184869963126 HIT: 0.7821897812632247
Epoch: 136, plus 0 steps train_loss: 0.6972

#### test Acc: 0, NDCG: 0.3837949332326323 HIT: 0.5231399439272112

#### val Acc: 0, NDCG: 0.6209887803794486 HIT: 0.7041201597545493
Epoch: 144, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.46700943109321613 HIT: 0.5878228483389759

#### val Acc: 0, NDCG: 0.6769704889197089 HIT: 0.7542120715192552
Epoch: 160, plus 0 steps train_loss: 0.6953

#### test Acc: 0, NDCG: 0.5212014725214257 HIT: 0.6462405443292425

#### val Acc: 0, NDCG: 0.7172354974044379 HIT: 0.7874441255818875
Epoch: 176, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.49273419158276316 HIT: 0.6186248611404993

#### val Acc: 0, NDCG: 0.696192993035607 HIT: 0.7624171802264071
Epoch: 192, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.5376404452245577 HIT: 0.6564235743757935

#### val Acc: 0, NDCG: 0.7460401468612823 HIT: 0.8157127790414727
Epoch: 208, plus 0 steps train_loss: 0.6953

#### test Acc: 0, NDCG: 0.6145880747500557 HIT: 0.7193699084849767

#### val Acc: 0, NDCG: 0.7533241756712623 HIT: 0.8151631268514601
Epoch: 224, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.5436967399130815 HIT: 0.6542886095535336

#### val Acc: 0, NDCG: 0.7330386995161424 HIT: 0.8010622751798562
Epoch: 240, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.5833362231354667 HIT: 0.6988236616589082

#### val Acc: 0, NDCG: 0.7528920713531287 HIT: 0.8233012854422345
Epoch: 256, plus 0 steps train_loss: 0.6943

#### test Acc: 0, NDCG: 0.6086258527378893 HIT: 0.7163769903195091

#### val Acc: 0, NDCG: 0.7640560820005621 HIT: 0.8333578541578502
Epoch: 272, plus 0 steps train_loss: 0.694

#### test Acc: 0, NDCG: 0.5890022718159497 HIT: 0.6993195884468895

#### val Acc: 0, NDCG: 0.7514885379353222 HIT: 0.8247469120292001
Epoch: 288, plus 0 steps train_loss: 0.6942

#### test Acc: 0, NDCG: 0.5926273623366745 HIT: 0.7081718816123572

#### val Acc: 0, NDCG: 0.7475563940811085 HIT: 0.8133248915573423
Epoch: 304, plus 0 steps train_loss: 0.6895

#### test Acc: 0, NDCG: 0.6275550745544932 HIT: 0.7318623042742276

#### val Acc: 0, NDCG: 0.7819788802039138 HIT: 0.8426027560304697
Epoch: 320, plus 0 steps train_loss: 0.6868

#### test Acc: 0, NDCG: 0.5964217280726936 HIT: 0.7142668218366482

#### val Acc: 0, NDCG: 0.7531779771654378 HIT: 0.8271538100402032
Epoch: 352, plus 0 steps train_loss: 0.6646

#### test Acc: 0, NDCG: 0.2528503683805732 HIT: 0.44204682210114266

#### val Acc: 0, NDCG: 0.5484099586619289 HIT: 0.6651361814959796
Epoch: 384, plus 0 steps train_loss: 0.602

#### test Acc: 0, NDCG: 0.2784094035754181 HIT: 0.4909055292530682

#### val Acc: 0, NDCG: 0.5620433992613227 HIT: 0.6837962534384258
Epoch: 416, plus 0 steps train_loss: 0.6046

#### test Acc: 0, NDCG: 0.27459745205004993 HIT: 0.48306244710114266

#### val Acc: 0, NDCG: 0.558492403098207 HIT: 0.6783790798243757
Epoch: 448, plus 0 steps train_loss: 0.5711

#### test Acc: 0, NDCG: 0.27325558691385055 HIT: 0.4899500436415573

#### val Acc: 0, NDCG: 0.5509843346916669 HIT: 0.6663040890816758
Epoch: 480, plus 0 steps train_loss: 0.556

#### test Acc: 0, NDCG: 0.28134122613200846 HIT: 0.4920850084638172

#### val Acc: 0, NDCG: 0.555908619984997 HIT: 0.6739537597862887
Epoch: 512, plus 0 steps train_loss: 0.5746

#### test Acc: 0, NDCG: 0.2616319205534692 HIT: 0.47058327602623784

#### val Acc: 0, NDCG: 0.5550371794403607 HIT: 0.6743827364578925
Epoch: 544, plus 0 steps train_loss: 0.5512

#### test Acc: 0, NDCG: 0.27118992982484097 HIT: 0.48891025047608977

#### val Acc: 0, NDCG: 0.5587637936605726 HIT: 0.6737892774016081
Epoch: 576, plus 0 steps train_loss: 0.5429

#### test Acc: 0, NDCG: 0.27554136556429465 HIT: 0.48546355929961915

#### val Acc: 0, NDCG: 0.5527200227981507 HIT: 0.6701070210008463
Epoch: 608, plus 0 steps train_loss: 0.5537

#### test Acc: 0, NDCG: 0.2675379118405056 HIT: 0.4862140618387643

#### val Acc: 0, NDCG: 0.5580202104371392 HIT: 0.6729734778353788
Epoch: 640, plus 0 steps train_loss: 0.5258

#### test Acc: 0, NDCG: 0.28245076761968907 HIT: 0.4923263595006348

#### val Acc: 0, NDCG: 0.5575807366526288 HIT: 0.6687589266821836
Epoch: 704, plus 0 steps train_loss: 0.5549

#### test Acc: 0, NDCG: 0.2729332578071504 HIT: 0.48236732305332203

#### val Acc: 0, NDCG: 0.5597080312026118 HIT: 0.6750778605057131
Epoch: 768, plus 0 steps train_loss: 0.5309

#### test Acc: 0, NDCG: 0.27325737665610295 HIT: 0.4842245688743123

#### val Acc: 0, NDCG: 0.5508420139596795 HIT: 0.6703004324481592
Epoch: 832, plus 0 steps train_loss: 0.5187

#### test Acc: 0, NDCG: 0.2760493731272273 HIT: 0.48071258067075756

#### val Acc: 0, NDCG: 0.5516614733047008 HIT: 0.6678224515975455
Epoch: 896, plus 0 steps train_loss: 0.5525

#### test Acc: 0, NDCG: 0.27522868320745 HIT: 0.4857487172027084

#### val Acc: 0, NDCG: 0.5455920403143161 HIT: 0.6657775801417689
Epoch: 960, plus 0 steps train_loss: 0.5371

#### test Acc: 0, NDCG: 0.27877759021874493 HIT: 0.4854999272640711

#### val Acc: 0, NDCG: 0.5481510104964903 HIT: 0.6648948304591621
Epoch: 1017, plus 0 steps train_loss: 0.5565
Done: it took 141503.6959388256
max value of NDCG: 0.6275550745544932
max value of HIT: 0.7318623042742276

After 20 validations
max value of NDCG: 0.6275550745544932
max value of HIT: 0.7318623042742276
