 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2
max_norm:             	0.1
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11571301
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.1266474291191203 HIT: 0.28228070117435466

#### val Acc: 0, NDCG: 0.489192527947406 HIT: 0.5857490478205671
Epoch: 1, plus 0 steps train_loss: 0.7793

#### test Acc: 0, NDCG: 0.12737777097102124 HIT: 0.278416604951333

#### val Acc: 0, NDCG: 0.481786926511072 HIT: 0.580071512642827
Epoch: 2, plus 0 steps train_loss: 0.7606

#### test Acc: 0, NDCG: 0.12424840375478631 HIT: 0.27212825327972917

#### val Acc: 0, NDCG: 0.47658880853102387 HIT: 0.5723623307236564
Epoch: 3, plus 0 steps train_loss: 0.7558

#### test Acc: 0, NDCG: 0.13347857531160123 HIT: 0.2919314364684723

#### val Acc: 0, NDCG: 0.48673437416377446 HIT: 0.5872178176576386
Epoch: 4, plus 0 steps train_loss: 0.7704

#### test Acc: 0, NDCG: 0.13157874400325628 HIT: 0.28660435622090563

#### val Acc: 0, NDCG: 0.49694008965430486 HIT: 0.588414654305967
Epoch: 5, plus 0 steps train_loss: 0.7507

#### test Acc: 0, NDCG: 0.11685862981553989 HIT: 0.27013876031527717

#### val Acc: 0, NDCG: 0.475419839312557 HIT: 0.568352762642827
Epoch: 6, plus 0 steps train_loss: 0.7607

#### test Acc: 0, NDCG: 0.12266636444413237 HIT: 0.2775338552687262

#### val Acc: 0, NDCG: 0.4748607659797833 HIT: 0.5671922939589505
Epoch: 7, plus 0 steps train_loss: 0.7616

#### test Acc: 0, NDCG: 0.12421196176830743 HIT: 0.27922083289250954

#### val Acc: 0, NDCG: 0.47534888317073865 HIT: 0.566007028935675
Epoch: 8, plus 0 steps train_loss: 0.7467

#### test Acc: 0, NDCG: 0.12774969424499272 HIT: 0.2820376970482438

#### val Acc: 0, NDCG: 0.4849799636220892 HIT: 0.5784572709479475
Epoch: 9, plus 0 steps train_loss: 0.7456

#### test Acc: 0, NDCG: 0.12989668271621818 HIT: 0.2924753028459585

#### val Acc: 0, NDCG: 0.4829772016247644 HIT: 0.5743080168218366
Epoch: 10, plus 0 steps train_loss: 0.7419

#### test Acc: 0, NDCG: 0.12093545360348541 HIT: 0.272593597915785

#### val Acc: 0, NDCG: 0.46742721416614935 HIT: 0.5532294752433348
Epoch: 12, plus 0 steps train_loss: 0.7375

#### test Acc: 0, NDCG: 0.12762193387062132 HIT: 0.2858728642086331

#### val Acc: 0, NDCG: 0.483507458999224 HIT: 0.5738005184088024
Epoch: 14, plus 0 steps train_loss: 0.7364

#### test Acc: 0, NDCG: 0.1159188121643317 HIT: 0.2598044725983919

#### val Acc: 0, NDCG: 0.4796972753180261 HIT: 0.571707707363521
Epoch: 16, plus 0 steps train_loss: 0.7275

#### test Acc: 0, NDCG: 0.12114048840576223 HIT: 0.2707189946572154

#### val Acc: 0, NDCG: 0.47213912685384485 HIT: 0.5727665110558613
Epoch: 18, plus 0 steps train_loss: 0.7354

#### test Acc: 0, NDCG: 0.12446012683948447 HIT: 0.2723638185040203

#### val Acc: 0, NDCG: 0.477830992073244 HIT: 0.572494577867118
Epoch: 20, plus 0 steps train_loss: 0.7309

#### test Acc: 0, NDCG: 0.12583065882908745 HIT: 0.28122355057130766

#### val Acc: 0, NDCG: 0.472445642550262 HIT: 0.5678146820778671
Epoch: 22, plus 0 steps train_loss: 0.7286

#### test Acc: 0, NDCG: 0.12472969127168447 HIT: 0.27438967943292425

#### val Acc: 0, NDCG: 0.4776620104537564 HIT: 0.5726152533855269
Epoch: 24, plus 0 steps train_loss: 0.731

#### test Acc: 0, NDCG: 0.12565386516832866 HIT: 0.27869432395260263

#### val Acc: 0, NDCG: 0.474753248200118 HIT: 0.568944568609818
Epoch: 26, plus 0 steps train_loss: 0.728

#### test Acc: 0, NDCG: 0.12546624931064895 HIT: 0.27515753940964877

#### val Acc: 0, NDCG: 0.47106289219120895 HIT: 0.5673187552898857
Epoch: 28, plus 0 steps train_loss: 0.7257

#### test Acc: 0, NDCG: 0.11590276060555682 HIT: 0.2647083619868811

#### val Acc: 0, NDCG: 0.4718427595805319 HIT: 0.5572448291366906
Epoch: 30, plus 0 steps train_loss: 0.7232

#### test Acc: 0, NDCG: 0.11578016910383038 HIT: 0.2637776727147694

#### val Acc: 0, NDCG: 0.4808030763080481 HIT: 0.5688486894308082
Epoch: 32, plus 0 steps train_loss: 0.7167

#### test Acc: 0, NDCG: 0.12902713186042924 HIT: 0.2810954361510791

#### val Acc: 0, NDCG: 0.47775289916841845 HIT: 0.5729004112886161
Epoch: 36, plus 0 steps train_loss: 0.7178

#### test Acc: 0, NDCG: 0.1309178764224778 HIT: 0.29196780443292425

#### val Acc: 0, NDCG: 0.47070234070391187 HIT: 0.563981168006771
Epoch: 40, plus 0 steps train_loss: 0.7124

#### test Acc: 0, NDCG: 0.12854558026719 HIT: 0.28914350137537026

#### val Acc: 0, NDCG: 0.48222165811642115 HIT: 0.5837901370080406
Epoch: 44, plus 0 steps train_loss: 0.7122

#### test Acc: 0, NDCG: 0.12938032646892972 HIT: 0.28113758992805754

#### val Acc: 0, NDCG: 0.4738103292085165 HIT: 0.5598930781845112
Epoch: 48, plus 0 steps train_loss: 0.7092

#### test Acc: 0, NDCG: 0.12866500036019485 HIT: 0.28849053110452816

#### val Acc: 0, NDCG: 0.47557945992141293 HIT: 0.5671369154676259
Epoch: 52, plus 0 steps train_loss: 0.7088

#### test Acc: 0, NDCG: 0.13207449231762855 HIT: 0.29288692207998307

#### val Acc: 0, NDCG: 0.47673231769926117 HIT: 0.5719564973021583
Epoch: 56, plus 0 steps train_loss: 0.7088

#### test Acc: 0, NDCG: 0.1349851317722281 HIT: 0.3008374550359712

#### val Acc: 0, NDCG: 0.47924411748066453 HIT: 0.5731781302898857
Epoch: 60, plus 0 steps train_loss: 0.7114

#### test Acc: 0, NDCG: 0.13810867118543013 HIT: 0.30407916314007616

#### val Acc: 0, NDCG: 0.46753949516288157 HIT: 0.5626024915361828
Epoch: 64, plus 0 steps train_loss: 0.7057

#### test Acc: 0, NDCG: 0.13879882411648548 HIT: 0.28928897323317815

#### val Acc: 0, NDCG: 0.4790585480258092 HIT: 0.5727780826809141
Epoch: 68, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.12783575991452364 HIT: 0.2838891570567076

#### val Acc: 0, NDCG: 0.4714239170601104 HIT: 0.5646705062420652
Epoch: 72, plus 0 steps train_loss: 0.7089

#### test Acc: 0, NDCG: 0.13360916642673207 HIT: 0.29220915546974185

#### val Acc: 0, NDCG: 0.47415162420085316 HIT: 0.5725193742065171
Epoch: 80, plus 0 steps train_loss: 0.7036

#### test Acc: 0, NDCG: 0.13339325242125366 HIT: 0.28440244128226827

#### val Acc: 0, NDCG: 0.46920005366941026 HIT: 0.5668344001269573
Epoch: 88, plus 0 steps train_loss: 0.7017

#### test Acc: 0, NDCG: 0.3871750313182812 HIT: 0.5228084995239103

#### val Acc: 0, NDCG: 0.614875974913569 HIT: 0.6973780350719424
Epoch: 96, plus 0 steps train_loss: 0.7038

#### test Acc: 0, NDCG: 0.5131573019163761 HIT: 0.6341655535865425

#### val Acc: 0, NDCG: 0.7129630081856791 HIT: 0.7885145008992805
Epoch: 104, plus 0 steps train_loss: 0.7036

#### test Acc: 0, NDCG: 0.3936022798136421 HIT: 0.5345751891134152

#### val Acc: 0, NDCG: 0.6327429618678817 HIT: 0.7223570408379179
Epoch: 112, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.5763063904554435 HIT: 0.7015504324481592

#### val Acc: 0, NDCG: 0.7514389911782272 HIT: 0.8184585603575962
Epoch: 120, plus 0 steps train_loss: 0.7028

#### test Acc: 0, NDCG: 0.5796012967706791 HIT: 0.6981285376110876

#### val Acc: 0, NDCG: 0.7460275262853129 HIT: 0.8200000661235718
Epoch: 128, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.48629413599523624 HIT: 0.622488957363521

#### val Acc: 0, NDCG: 0.6889142868678849 HIT: 0.7665226274862463
Epoch: 136, plus 0 steps train_loss: 0.7037

#### test Acc: 0, NDCG: 0.580264577833256 HIT: 0.6935808889652983

#### val Acc: 0, NDCG: 0.7618169040847544 HIT: 0.834585272958104
Epoch: 144, plus 0 steps train_loss: 0.7024

#### test Acc: 0, NDCG: 0.5330514752890023 HIT: 0.65740220323741

#### val Acc: 0, NDCG: 0.7225461049675116 HIT: 0.799501758887008
Epoch: 160, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.14740355431832164 HIT: 0.29895871905416843

#### val Acc: 0, NDCG: 0.4838535930101629 HIT: 0.5752213486563691
Epoch: 176, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.5188618725755263 HIT: 0.6422251904358866

#### val Acc: 0, NDCG: 0.7039283518210724 HIT: 0.7794324283220483
Epoch: 192, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.5766640960753958 HIT: 0.68536999444562

#### val Acc: 0, NDCG: 0.7444825630879821 HIT: 0.8168253081358443
Epoch: 208, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.20369001714964566 HIT: 0.3565895445408379

#### val Acc: 0, NDCG: 0.5232127522960587 HIT: 0.6160435622090563
Epoch: 224, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.5543474866980004 HIT: 0.6748786632458739

#### val Acc: 0, NDCG: 0.7222795301077206 HIT: 0.7962426933453237
Epoch: 240, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.15603445012411696 HIT: 0.3121214425518409

#### val Acc: 0, NDCG: 0.4940560152982673 HIT: 0.5787349899492171
Epoch: 256, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.14769127279280206 HIT: 0.2952748095641134

#### val Acc: 0, NDCG: 0.4964147104173235 HIT: 0.5873269215509945
Epoch: 272, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.29144148982247503 HIT: 0.43738593683876426

#### val Acc: 0, NDCG: 0.5890499964525736 HIT: 0.6745149836013542
Epoch: 288, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.6666549177640143 HIT: 0.7631544580512061

#### val Acc: 0, NDCG: 0.7832249714504046 HIT: 0.8408678388171815
Epoch: 304, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.6513525241925373 HIT: 0.750807534119763

#### val Acc: 0, NDCG: 0.8005980434897667 HIT: 0.8581913880660178
Epoch: 320, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.6322591048582858 HIT: 0.7273642483072366

#### val Acc: 0, NDCG: 0.7742253699489963 HIT: 0.8335818477570884
Epoch: 352, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.5078777427919325 HIT: 0.634244075327973

#### val Acc: 0, NDCG: 0.7007803811326037 HIT: 0.7736342176258993
Epoch: 384, plus 0 steps train_loss: 0.6954

#### test Acc: 0, NDCG: 0.31491181573038957 HIT: 0.4506825605691917

#### val Acc: 0, NDCG: 0.6051374214523667 HIT: 0.6890505977570884
Epoch: 416, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.38107249861116393 HIT: 0.5086001970482438

#### val Acc: 0, NDCG: 0.6190798342802443 HIT: 0.6989980625793484
Epoch: 448, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.5205011399667345 HIT: 0.6347515737410072

#### val Acc: 0, NDCG: 0.7102963395415277 HIT: 0.7819542160389336
Epoch: 480, plus 0 steps train_loss: 0.6937

#### test Acc: 0, NDCG: 0.6141982072440194 HIT: 0.7141329216038934

#### val Acc: 0, NDCG: 0.767645455284842 HIT: 0.8262710603575962
Epoch: 512, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.5945558651498835 HIT: 0.7014529001798562

#### val Acc: 0, NDCG: 0.7647542548243237 HIT: 0.8290821387008042
Epoch: 544, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.5198935128389661 HIT: 0.6358161632458739

#### val Acc: 0, NDCG: 0.7112382388888038 HIT: 0.7790265949005502
Epoch: 576, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.5694647738866754 HIT: 0.6797098167054592

#### val Acc: 0, NDCG: 0.7315883362023574 HIT: 0.7942532003808718
Epoch: 608, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.4554280365521295 HIT: 0.5679295717837495

#### val Acc: 0, NDCG: 0.6793292260112125 HIT: 0.7503959148857385
Epoch: 640, plus 0 steps train_loss: 0.6941

#### test Acc: 0, NDCG: 0.486744884151416 HIT: 0.6157468326809141

#### val Acc: 0, NDCG: 0.6889844281263388 HIT: 0.7637057633305121
Epoch: 704, plus 0 steps train_loss: 0.6946

#### test Acc: 0, NDCG: 0.4358319813365491 HIT: 0.5774521926576386

#### val Acc: 0, NDCG: 0.6684711332695518 HIT: 0.7417734011320355
Epoch: 768, plus 0 steps train_loss: 0.6937

#### test Acc: 0, NDCG: 0.5685757620629159 HIT: 0.6791353681760475

#### val Acc: 0, NDCG: 0.7455158605552603 HIT: 0.8080936904887854
Epoch: 832, plus 0 steps train_loss: 0.6916

#### test Acc: 0, NDCG: 0.4595342198091594 HIT: 0.5946129126110876

#### val Acc: 0, NDCG: 0.6786159692148236 HIT: 0.761383172873466
Epoch: 896, plus 0 steps train_loss: 0.6916

#### test Acc: 0, NDCG: 0.4889949007643443 HIT: 0.6202217453977994

#### val Acc: 0, NDCG: 0.6793740559882306 HIT: 0.755759363097757
Epoch: 960, plus 0 steps train_loss: 0.6931

#### test Acc: 0, NDCG: 0.4625953351644669 HIT: 0.6061861907532797

#### val Acc: 0, NDCG: 0.6711317008462435 HIT: 0.748854409119763
Epoch: 1017, plus 0 steps train_loss: 0.6965
Done: it took 133775.71848249435
max value of NDCG: 0.6666549177640143
max value of HIT: 0.7631544580512061

After 20 validations
max value of NDCG: 0.6666549177640143
max value of HIT: 0.7631544580512061
