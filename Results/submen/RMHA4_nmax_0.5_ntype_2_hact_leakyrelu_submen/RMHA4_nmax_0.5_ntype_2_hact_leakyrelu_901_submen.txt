 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2
max_norm:             	0.5
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13562844148440859 HIT: 0.2965807501057977

#### val Acc: 0, NDCG: 0.4830969416858333 HIT: 0.5773373029517562
Epoch: 1, plus 0 steps train_loss: 0.7688

#### test Acc: 0, NDCG: 0.1358095594646065 HIT: 0.2924695170334321

#### val Acc: 0, NDCG: 0.4795365755654016 HIT: 0.5764314100190435
Epoch: 2, plus 0 steps train_loss: 0.7579

#### test Acc: 0, NDCG: 0.13239354866751954 HIT: 0.2823286407638595

#### val Acc: 0, NDCG: 0.4840501110212549 HIT: 0.5754279848180279
Epoch: 3, plus 0 steps train_loss: 0.7504

#### test Acc: 0, NDCG: 0.13080119556654224 HIT: 0.28196082839610664

#### val Acc: 0, NDCG: 0.49311321521908846 HIT: 0.5853547860241219
Epoch: 4, plus 0 steps train_loss: 0.7608

#### test Acc: 0, NDCG: 0.1350996310864532 HIT: 0.29069823185569194

#### val Acc: 0, NDCG: 0.48356813352417316 HIT: 0.5750700909860347
Epoch: 5, plus 0 steps train_loss: 0.7554

#### test Acc: 0, NDCG: 0.132094919444536 HIT: 0.2913512021265341

#### val Acc: 0, NDCG: 0.4788571743961365 HIT: 0.5613254800571308
Epoch: 6, plus 0 steps train_loss: 0.7563

#### test Acc: 0, NDCG: 0.1294311187176663 HIT: 0.2853463552687262

#### val Acc: 0, NDCG: 0.48165020381586826 HIT: 0.5730268726195513
Epoch: 7, plus 0 steps train_loss: 0.758

#### test Acc: 0, NDCG: 0.12170182189603113 HIT: 0.26730867144519677

#### val Acc: 0, NDCG: 0.46990166965680974 HIT: 0.5712613732543377
Epoch: 8, plus 0 steps train_loss: 0.7499

#### test Acc: 0, NDCG: 0.12253858713815505 HIT: 0.2716629086436733

#### val Acc: 0, NDCG: 0.4822438747108747 HIT: 0.5753783921392298
Epoch: 9, plus 0 steps train_loss: 0.7551

#### test Acc: 0, NDCG: 0.12377074949508501 HIT: 0.27106366377486246

#### val Acc: 0, NDCG: 0.4777560059409063 HIT: 0.57057782083157
Epoch: 10, plus 0 steps train_loss: 0.7401

#### test Acc: 0, NDCG: 0.12915267562890895 HIT: 0.28260057395260263

#### val Acc: 0, NDCG: 0.481277233822627 HIT: 0.5776340324798985
Epoch: 12, plus 0 steps train_loss: 0.7367

#### test Acc: 0, NDCG: 0.1251906324067225 HIT: 0.2786100163986458

#### val Acc: 0, NDCG: 0.48412531075366483 HIT: 0.5795507895154465
Epoch: 14, plus 0 steps train_loss: 0.7349

#### test Acc: 0, NDCG: 0.12529381666860842 HIT: 0.2763733865848498

#### val Acc: 0, NDCG: 0.4753766905997935 HIT: 0.5657524531845112
Epoch: 16, plus 0 steps train_loss: 0.7245

#### test Acc: 0, NDCG: 0.13189924205068063 HIT: 0.29813548058611933

#### val Acc: 0, NDCG: 0.48533180108326496 HIT: 0.5885791366906474
Epoch: 18, plus 0 steps train_loss: 0.726

#### test Acc: 0, NDCG: 0.13439242932326417 HIT: 0.28561250264494287

#### val Acc: 0, NDCG: 0.48273174290497556 HIT: 0.5776472571942446
Epoch: 20, plus 0 steps train_loss: 0.7244

#### test Acc: 0, NDCG: 0.14611654718263628 HIT: 0.30672162637537026

#### val Acc: 0, NDCG: 0.4862350830616915 HIT: 0.5843034212336013
Epoch: 22, plus 0 steps train_loss: 0.7182

#### test Acc: 0, NDCG: 0.13497470923304955 HIT: 0.2931340589293271

#### val Acc: 0, NDCG: 0.4820228044736448 HIT: 0.5791523949957681
Epoch: 24, plus 0 steps train_loss: 0.7165

#### test Acc: 0, NDCG: 0.13044943362837502 HIT: 0.29127846619763015

#### val Acc: 0, NDCG: 0.4751609985878207 HIT: 0.5735401568451122
Epoch: 26, plus 0 steps train_loss: 0.7227

#### test Acc: 0, NDCG: 0.13976389463582908 HIT: 0.3004564179538722

#### val Acc: 0, NDCG: 0.485104234397089 HIT: 0.5719928652666102
Epoch: 28, plus 0 steps train_loss: 0.7157

#### test Acc: 0, NDCG: 0.1329335563002375 HIT: 0.2885268990689801

#### val Acc: 0, NDCG: 0.4737617223425707 HIT: 0.5620701967837495
Epoch: 30, plus 0 steps train_loss: 0.712

#### test Acc: 0, NDCG: 0.1320574180046718 HIT: 0.2880367580935252

#### val Acc: 0, NDCG: 0.48169899135725286 HIT: 0.5727780826809141
Epoch: 32, plus 0 steps train_loss: 0.711

#### test Acc: 0, NDCG: 0.13120807534566414 HIT: 0.28561828845746934

#### val Acc: 0, NDCG: 0.477636745200105 HIT: 0.5673303269149387
Epoch: 36, plus 0 steps train_loss: 0.7111

#### test Acc: 0, NDCG: 0.15251599094670523 HIT: 0.3064554789991536

#### val Acc: 0, NDCG: 0.4840158605466396 HIT: 0.5758801047397376
Epoch: 40, plus 0 steps train_loss: 0.7098

#### test Acc: 0, NDCG: 0.1537626707324152 HIT: 0.3115164118705036

#### val Acc: 0, NDCG: 0.47888385173424314 HIT: 0.5659648751586965
Epoch: 44, plus 0 steps train_loss: 0.7061

#### test Acc: 0, NDCG: 0.1525193693317886 HIT: 0.30391633384468897

#### val Acc: 0, NDCG: 0.477054302263747 HIT: 0.565049890234871
Epoch: 48, plus 0 steps train_loss: 0.7041

#### test Acc: 0, NDCG: 0.168072230666806 HIT: 0.31955869128226827

#### val Acc: 0, NDCG: 0.48668592335262106 HIT: 0.5711332588341091
Epoch: 52, plus 0 steps train_loss: 0.7101

#### test Acc: 0, NDCG: 0.2435189260958218 HIT: 0.39548177634363096

#### val Acc: 0, NDCG: 0.5301919003713536 HIT: 0.6202275312103259
Epoch: 56, plus 0 steps train_loss: 0.7016

#### test Acc: 0, NDCG: 0.29388168136074033 HIT: 0.44417021529834955

#### val Acc: 0, NDCG: 0.5833837090859618 HIT: 0.6739942604739738
Epoch: 60, plus 0 steps train_loss: 0.7025

#### test Acc: 0, NDCG: 0.21323252550798455 HIT: 0.36719576544646637

#### val Acc: 0, NDCG: 0.5355670898109846 HIT: 0.625905066388066
Epoch: 64, plus 0 steps train_loss: 0.703

#### test Acc: 0, NDCG: 0.3310521681691768 HIT: 0.4721421392297926

#### val Acc: 0, NDCG: 0.6214514200263936 HIT: 0.7025960114261531
Epoch: 68, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.30730877801535866 HIT: 0.4655702827443927

#### val Acc: 0, NDCG: 0.5800040759319058 HIT: 0.6665148579665678
Epoch: 72, plus 0 steps train_loss: 0.7035

#### test Acc: 0, NDCG: 0.2097738039677636 HIT: 0.3630539502221752

#### val Acc: 0, NDCG: 0.5240214249050699 HIT: 0.616618010738468
Epoch: 80, plus 0 steps train_loss: 0.7021

#### test Acc: 0, NDCG: 0.33942073850513343 HIT: 0.48706044355691924

#### val Acc: 0, NDCG: 0.5989699343501235 HIT: 0.6856171312949639
Epoch: 88, plus 0 steps train_loss: 0.703

#### test Acc: 0, NDCG: 0.45845620901414597 HIT: 0.5959800174566229

#### val Acc: 0, NDCG: 0.6668008394534791 HIT: 0.7494040613097758
Epoch: 96, plus 0 steps train_loss: 0.7009

#### test Acc: 0, NDCG: 0.35526718564320103 HIT: 0.5036525007934829

#### val Acc: 0, NDCG: 0.6193225209684878 HIT: 0.7048574375793484
Epoch: 104, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.35891679428989265 HIT: 0.5041773566440966

#### val Acc: 0, NDCG: 0.6099953742548175 HIT: 0.6992890062949639
Epoch: 112, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.47310521855087917 HIT: 0.60919811944562

#### val Acc: 0, NDCG: 0.6878405029458632 HIT: 0.7763246204506983
Epoch: 120, plus 0 steps train_loss: 0.7002

#### test Acc: 0, NDCG: 0.47740007100825416 HIT: 0.6052497156686416

#### val Acc: 0, NDCG: 0.6798692139397814 HIT: 0.7538004522852306
Epoch: 128, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.41026124442089573 HIT: 0.5547709810093102

#### val Acc: 0, NDCG: 0.6383029009798541 HIT: 0.7267112780363945
Epoch: 136, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.4590133532331024 HIT: 0.5973644797397376

#### val Acc: 0, NDCG: 0.6698666248017415 HIT: 0.7540302316969953
Epoch: 144, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.4194719819503316 HIT: 0.5639448000423191

#### val Acc: 0, NDCG: 0.6554202691479208 HIT: 0.7377158934617013
Epoch: 160, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.39423376263241083 HIT: 0.5397394400655946

#### val Acc: 0, NDCG: 0.6215244989443169 HIT: 0.7108507128121032
Epoch: 176, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.4115583177159811 HIT: 0.5486586833474396

#### val Acc: 0, NDCG: 0.6331951906443593 HIT: 0.7166737198476513
Epoch: 192, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.44953739312447927 HIT: 0.5878228483389759

#### val Acc: 0, NDCG: 0.6695584798479101 HIT: 0.7544534225560727
Epoch: 208, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.44559233359646816 HIT: 0.5853200711489631

#### val Acc: 0, NDCG: 0.6585876350772046 HIT: 0.7363983812949639
Epoch: 224, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.5243228708032999 HIT: 0.6620705274016081

#### val Acc: 0, NDCG: 0.7223013630981354 HIT: 0.7957409807448159
Epoch: 240, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.555537902550765 HIT: 0.6831201399174778

#### val Acc: 0, NDCG: 0.7254253142329424 HIT: 0.8005969305438002
Epoch: 256, plus 0 steps train_loss: 0.6948

#### test Acc: 0, NDCG: 0.5504193053698528 HIT: 0.6821340721540414

#### val Acc: 0, NDCG: 0.7265307884883997 HIT: 0.8028145498307238
Epoch: 272, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.5664164987486673 HIT: 0.6852303084003385

#### val Acc: 0, NDCG: 0.7477098134830311 HIT: 0.816710418429962
Epoch: 288, plus 0 steps train_loss: 0.694

#### test Acc: 0, NDCG: 0.5931951173986042 HIT: 0.6969126904358866

#### val Acc: 0, NDCG: 0.755441471048918 HIT: 0.8224433320990266
Epoch: 304, plus 0 steps train_loss: 0.6889

#### test Acc: 0, NDCG: 0.5887968547454236 HIT: 0.6976689787875582

#### val Acc: 0, NDCG: 0.7533953495380947 HIT: 0.8194561997460855
Epoch: 320, plus 0 steps train_loss: 0.6901

#### test Acc: 0, NDCG: 0.611534103142533 HIT: 0.7131542927422768

#### val Acc: 0, NDCG: 0.7519649011078875 HIT: 0.8152722307448159
Epoch: 352, plus 0 steps train_loss: 0.6845

#### test Acc: 0, NDCG: 0.5040768423099484 HIT: 0.63183717731697

#### val Acc: 0, NDCG: 0.7032249841852835 HIT: 0.7824980824164198
Epoch: 384, plus 0 steps train_loss: 0.682

#### test Acc: 0, NDCG: 0.44652848201487044 HIT: 0.5883014176893779

#### val Acc: 0, NDCG: 0.6778355480294319 HIT: 0.7649199574164198
Epoch: 416, plus 0 steps train_loss: 0.687

#### test Acc: 0, NDCG: 0.4138610138207812 HIT: 0.5652871085484553

#### val Acc: 0, NDCG: 0.6384861169304625 HIT: 0.7340700050253914
Epoch: 448, plus 0 steps train_loss: 0.6723

#### test Acc: 0, NDCG: 0.34866544231838215 HIT: 0.5321988732543377

#### val Acc: 0, NDCG: 0.5995969181534925 HIT: 0.7007462045069827
Epoch: 480, plus 0 steps train_loss: 0.6291

#### test Acc: 0, NDCG: 0.26667660333191306 HIT: 0.458399181390182

#### val Acc: 0, NDCG: 0.5466860435765063 HIT: 0.6632500066123572
Epoch: 512, plus 0 steps train_loss: 0.612

#### test Acc: 0, NDCG: 0.27596446666508695 HIT: 0.47655010183030044

#### val Acc: 0, NDCG: 0.5623137204735095 HIT: 0.672265129073212
Epoch: 544, plus 0 steps train_loss: 0.5882

#### test Acc: 0, NDCG: 0.27869046416952076 HIT: 0.4811399042530682

#### val Acc: 0, NDCG: 0.5614645249280704 HIT: 0.6733181469530258
Epoch: 576, plus 0 steps train_loss: 0.5751

#### test Acc: 0, NDCG: 0.28623872928814437 HIT: 0.48105559669911135

#### val Acc: 0, NDCG: 0.5591497798840681 HIT: 0.6697144122936944
Epoch: 608, plus 0 steps train_loss: 0.5835

#### test Acc: 0, NDCG: 0.289617432731026 HIT: 0.4886862568768514

#### val Acc: 0, NDCG: 0.5747805824163165 HIT: 0.6819464465192552
Epoch: 640, plus 0 steps train_loss: 0.5872

#### test Acc: 0, NDCG: 0.29382305986797347 HIT: 0.4881845442763436

#### val Acc: 0, NDCG: 0.5711598881329388 HIT: 0.6824729554591621
Epoch: 704, plus 0 steps train_loss: 0.5672

#### test Acc: 0, NDCG: 0.30126932422885716 HIT: 0.4985973537346593

#### val Acc: 0, NDCG: 0.5750213741437051 HIT: 0.6917542252962336
Epoch: 768, plus 0 steps train_loss: 0.5629

#### test Acc: 0, NDCG: 0.3108365752749493 HIT: 0.5097226446783749

#### val Acc: 0, NDCG: 0.5709765571512739 HIT: 0.6843591303427846
Epoch: 832, plus 0 steps train_loss: 0.5416

#### test Acc: 0, NDCG: 0.3064029706231783 HIT: 0.5031565740055015

#### val Acc: 0, NDCG: 0.5664250964727966 HIT: 0.6809736034701651
Epoch: 896, plus 0 steps train_loss: 0.5682

#### test Acc: 0, NDCG: 0.3093041037206312 HIT: 0.508102617170969

#### val Acc: 0, NDCG: 0.5711169232250904 HIT: 0.679794124259416
Epoch: 960, plus 0 steps train_loss: 0.5519

#### test Acc: 0, NDCG: 0.3090919760996938 HIT: 0.5027102398963182

#### val Acc: 0, NDCG: 0.5754738688403764 HIT: 0.6855939880448583
Epoch: 1017, plus 0 steps train_loss: 0.5778
Done: it took 86068.0264992714
max value of NDCG: 0.611534103142533
max value of HIT: 0.7131542927422768

After 20 validations
max value of NDCG: 0.611534103142533
max value of HIT: 0.7131542927422768
