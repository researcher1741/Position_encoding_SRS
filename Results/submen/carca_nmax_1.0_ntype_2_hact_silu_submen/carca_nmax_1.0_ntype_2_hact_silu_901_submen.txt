 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2
max_norm:             	1.0
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11571301
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.1321067737176275 HIT: 0.2886227782479898

#### val Acc: 0, NDCG: 0.4817304199328589 HIT: 0.577664614631824
Epoch: 1, plus 0 steps train_loss: 0.7686

#### test Acc: 0, NDCG: 0.11997163804105447 HIT: 0.2711058175518409

#### val Acc: 0, NDCG: 0.46978816439141025 HIT: 0.5573845151819721
Epoch: 2, plus 0 steps train_loss: 0.765

#### test Acc: 0, NDCG: 0.1216954585613446 HIT: 0.2720670889758781

#### val Acc: 0, NDCG: 0.483284594023637 HIT: 0.5744898566440966
Epoch: 3, plus 0 steps train_loss: 0.7522

#### test Acc: 0, NDCG: 0.12922479259923972 HIT: 0.28029699402242914

#### val Acc: 0, NDCG: 0.4883041706030448 HIT: 0.5788366549407533
Epoch: 4, plus 0 steps train_loss: 0.7642

#### test Acc: 0, NDCG: 0.126968088124476 HIT: 0.2841247222809987

#### val Acc: 0, NDCG: 0.484041723103514 HIT: 0.576339663563267
Epoch: 5, plus 0 steps train_loss: 0.7557

#### test Acc: 0, NDCG: 0.12708614375382313 HIT: 0.28755405601989

#### val Acc: 0, NDCG: 0.4849778029147978 HIT: 0.5827734870926788
Epoch: 6, plus 0 steps train_loss: 0.7532

#### test Acc: 0, NDCG: 0.13248968555392743 HIT: 0.28699696492805754

#### val Acc: 0, NDCG: 0.48305953884667946 HIT: 0.5782084810093102
Epoch: 7, plus 0 steps train_loss: 0.7556

#### test Acc: 0, NDCG: 0.1280450923142464 HIT: 0.28492316440964877

#### val Acc: 0, NDCG: 0.4629278503001716 HIT: 0.5572638396635633
Epoch: 8, plus 0 steps train_loss: 0.7519

#### test Acc: 0, NDCG: 0.1301576303907548 HIT: 0.2875044633410918

#### val Acc: 0, NDCG: 0.48832271550164885 HIT: 0.5882518250105797
Epoch: 9, plus 0 steps train_loss: 0.7476

#### test Acc: 0, NDCG: 0.1288733425949434 HIT: 0.2849595323741007

#### val Acc: 0, NDCG: 0.4780488545553826 HIT: 0.5724218419382142
Epoch: 10, plus 0 steps train_loss: 0.7462

#### test Acc: 0, NDCG: 0.13535965386270107 HIT: 0.29610383384468897

#### val Acc: 0, NDCG: 0.4746177692298601 HIT: 0.5657524531845112
Epoch: 12, plus 0 steps train_loss: 0.7436

#### test Acc: 0, NDCG: 0.12862455922033003 HIT: 0.28788550042319083

#### val Acc: 0, NDCG: 0.48435446330191767 HIT: 0.5795218604528142
Epoch: 14, plus 0 steps train_loss: 0.7393

#### test Acc: 0, NDCG: 0.13149534662267892 HIT: 0.2935341065382988

#### val Acc: 0, NDCG: 0.4765383494400421 HIT: 0.5684676523487093
Epoch: 16, plus 0 steps train_loss: 0.7285

#### test Acc: 0, NDCG: 0.13008614455590048 HIT: 0.282322854951333

#### val Acc: 0, NDCG: 0.4782220139026131 HIT: 0.5646399240901396
Epoch: 18, plus 0 steps train_loss: 0.74

#### test Acc: 0, NDCG: 0.12927623402172364 HIT: 0.28344116985823103

#### val Acc: 0, NDCG: 0.470393474940367 HIT: 0.5604981088658485
Epoch: 20, plus 0 steps train_loss: 0.7303

#### test Acc: 0, NDCG: 0.12688809119205186 HIT: 0.28361143805543804

#### val Acc: 0, NDCG: 0.48377420860122283 HIT: 0.5724639957151926
Epoch: 22, plus 0 steps train_loss: 0.7317

#### test Acc: 0, NDCG: 0.14272151341691303 HIT: 0.308389593472281

#### val Acc: 0, NDCG: 0.4813339671569088 HIT: 0.5758743189272112
Epoch: 24, plus 0 steps train_loss: 0.7185

#### test Acc: 0, NDCG: 0.14277843118447986 HIT: 0.30238061389123994

#### val Acc: 0, NDCG: 0.48791549143387997 HIT: 0.5827619154676259
Epoch: 26, plus 0 steps train_loss: 0.7257

#### test Acc: 0, NDCG: 0.14526446811613503 HIT: 0.3006324719636056

#### val Acc: 0, NDCG: 0.4954696755237632 HIT: 0.5883129893144308
Epoch: 28, plus 0 steps train_loss: 0.7171

#### test Acc: 0, NDCG: 0.14568704733519477 HIT: 0.3055785151290732

#### val Acc: 0, NDCG: 0.49105748091720686 HIT: 0.5833247923719848
Epoch: 30, plus 0 steps train_loss: 0.7174

#### test Acc: 0, NDCG: 0.13426735218493824 HIT: 0.2923240451756242

#### val Acc: 0, NDCG: 0.48404959849033263 HIT: 0.5721077549724926
Epoch: 32, plus 0 steps train_loss: 0.7196

#### test Acc: 0, NDCG: 0.1500584184352538 HIT: 0.30836066440964877

#### val Acc: 0, NDCG: 0.49641303516149216 HIT: 0.5936516411870504
Epoch: 36, plus 0 steps train_loss: 0.7198

#### test Acc: 0, NDCG: 0.18151861031998617 HIT: 0.3363268025285654

#### val Acc: 0, NDCG: 0.5064869529247575 HIT: 0.6053282374100719
Epoch: 40, plus 0 steps train_loss: 0.7114

#### test Acc: 0, NDCG: 0.15803115974669288 HIT: 0.31844616218789673

#### val Acc: 0, NDCG: 0.49942560177957274 HIT: 0.5981091964663563
Epoch: 44, plus 0 steps train_loss: 0.7125

#### test Acc: 0, NDCG: 0.19431707761085737 HIT: 0.35837240134363096

#### val Acc: 0, NDCG: 0.5067887372484112 HIT: 0.6054373413034279
Epoch: 48, plus 0 steps train_loss: 0.7157

#### test Acc: 0, NDCG: 0.195281600751947 HIT: 0.3520361100825222

#### val Acc: 0, NDCG: 0.5064068757980978 HIT: 0.5987968816123572
Epoch: 52, plus 0 steps train_loss: 0.7058

#### test Acc: 0, NDCG: 0.15263166920964685 HIT: 0.3163665758569615

#### val Acc: 0, NDCG: 0.48691997416002586 HIT: 0.578317584902666
Epoch: 56, plus 0 steps train_loss: 0.7103

#### test Acc: 0, NDCG: 0.14019055554804416 HIT: 0.297566817869234

#### val Acc: 0, NDCG: 0.49314955973279284 HIT: 0.5860209810093102
Epoch: 60, plus 0 steps train_loss: 0.7088

#### test Acc: 0, NDCG: 0.21116203127044694 HIT: 0.3677148354845535

#### val Acc: 0, NDCG: 0.5372844353060899 HIT: 0.6277185053427846
Epoch: 64, plus 0 steps train_loss: 0.7076

#### test Acc: 0, NDCG: 0.18805198981959195 HIT: 0.34675118361193397

#### val Acc: 0, NDCG: 0.5120699210408204 HIT: 0.5994630765975455
Epoch: 68, plus 0 steps train_loss: 0.7077

#### test Acc: 0, NDCG: 0.13868333842221078 HIT: 0.29070401766821835

#### val Acc: 0, NDCG: 0.4893851098281246 HIT: 0.5770480123254337
Epoch: 72, plus 0 steps train_loss: 0.7106

#### test Acc: 0, NDCG: 0.13668524277915045 HIT: 0.29319522323317815

#### val Acc: 0, NDCG: 0.48369902816392774 HIT: 0.5749799976195513
Epoch: 80, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.282192381473246 HIT: 0.4360551999576809

#### val Acc: 0, NDCG: 0.5776173764591724 HIT: 0.6663710391980534
Epoch: 88, plus 0 steps train_loss: 0.7074

#### test Acc: 0, NDCG: 0.239176918398709 HIT: 0.38098831596487515

#### val Acc: 0, NDCG: 0.5387989821534541 HIT: 0.6295393831993229
Epoch: 96, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.16521411584143256 HIT: 0.31701954612780364

#### val Acc: 0, NDCG: 0.5005738912957951 HIT: 0.5958519030363945
Epoch: 104, plus 0 steps train_loss: 0.7029

#### test Acc: 0, NDCG: 0.15781809224193796 HIT: 0.30803335272958104

#### val Acc: 0, NDCG: 0.49510077742818953 HIT: 0.5909918205141769
Epoch: 112, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.15877718506303307 HIT: 0.3070605096804909

#### val Acc: 0, NDCG: 0.500708820672439 HIT: 0.5919778882776132
Epoch: 120, plus 0 steps train_loss: 0.7009

#### test Acc: 0, NDCG: 0.1949389364484182 HIT: 0.34630898222598394

#### val Acc: 0, NDCG: 0.513182290348061 HIT: 0.6118769506453661
Epoch: 128, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.14814612994606577 HIT: 0.2997497222809987

#### val Acc: 0, NDCG: 0.48199094293304 HIT: 0.5737889467837495
Epoch: 136, plus 0 steps train_loss: 0.703

#### test Acc: 0, NDCG: 0.23889542266294558 HIT: 0.3902695858019467

#### val Acc: 0, NDCG: 0.5427277052753987 HIT: 0.6357012735399915
Epoch: 144, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.13487225179639686 HIT: 0.2956616324587389

#### val Acc: 0, NDCG: 0.4815883468712336 HIT: 0.5762189880448583
Epoch: 160, plus 0 steps train_loss: 0.7003

#### test Acc: 0, NDCG: 0.13160046493608485 HIT: 0.2823286407638595

#### val Acc: 0, NDCG: 0.4704016752511251 HIT: 0.5597839742911553
Epoch: 176, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.12874239191702921 HIT: 0.288919507776132

#### val Acc: 0, NDCG: 0.47325734399666713 HIT: 0.5617007313267033
Epoch: 192, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.482153207019538 HIT: 0.6122827840668642

#### val Acc: 0, NDCG: 0.6971905838598073 HIT: 0.7790819733918747
Epoch: 208, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.5923151186658377 HIT: 0.7064906898011003

#### val Acc: 0, NDCG: 0.7490519135912317 HIT: 0.8221350309458315
Epoch: 224, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.5174634612329188 HIT: 0.6481573013647906

#### val Acc: 0, NDCG: 0.7156220975052452 HIT: 0.7911090245450698
Epoch: 240, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.6104503047463529 HIT: 0.7188202562949639

#### val Acc: 0, NDCG: 0.7675317832298127 HIT: 0.8355886981591197
Epoch: 256, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.5986407680135004 HIT: 0.7178036063796022

#### val Acc: 0, NDCG: 0.7614341071420979 HIT: 0.83309749259416
Epoch: 272, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.6292381092598374 HIT: 0.732430966991113

#### val Acc: 0, NDCG: 0.7645058192970973 HIT: 0.8325172582522217
Epoch: 288, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.6143324973853019 HIT: 0.7302174804274228

#### val Acc: 0, NDCG: 0.7553026923710072 HIT: 0.8217482080512061
Epoch: 304, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.6181091846609885 HIT: 0.7235728880131189

#### val Acc: 0, NDCG: 0.7579332158654535 HIT: 0.827963823793906
Epoch: 320, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.6202441590887053 HIT: 0.7270617329665678

#### val Acc: 0, NDCG: 0.7803956349279058 HIT: 0.8515583672767668
Epoch: 352, plus 0 steps train_loss: 0.6939

#### test Acc: 0, NDCG: 0.6245586272122856 HIT: 0.7285495133305121

#### val Acc: 0, NDCG: 0.779725660099477 HIT: 0.8474644916419806
Epoch: 384, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.626285068439181 HIT: 0.7348800187790944

#### val Acc: 0, NDCG: 0.764489911370965 HIT: 0.8279696096064325
Epoch: 416, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.6073679466627533 HIT: 0.7144908154358866

#### val Acc: 0, NDCG: 0.757473623640716 HIT: 0.8284060251798562
Epoch: 448, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.5794647922734352 HIT: 0.6917600111087601

#### val Acc: 0, NDCG: 0.753636126526729 HIT: 0.8231326703343208
Epoch: 480, plus 0 steps train_loss: 0.6953

#### test Acc: 0, NDCG: 0.3602189516046341 HIT: 0.5055138793377063

#### val Acc: 0, NDCG: 0.6001981280365658 HIT: 0.6847533921392298
Epoch: 512, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.6056209217568141 HIT: 0.718366483283961

#### val Acc: 0, NDCG: 0.7550477069279316 HIT: 0.8202777851248414
Epoch: 544, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.5377101244437804 HIT: 0.659525596434617

#### val Acc: 0, NDCG: 0.725430608934308 HIT: 0.7988851565806179
Epoch: 576, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.4257858273945154 HIT: 0.5628686389123995

#### val Acc: 0, NDCG: 0.6631310237937899 HIT: 0.7503537611087601
Epoch: 608, plus 0 steps train_loss: 0.6942

#### test Acc: 0, NDCG: 0.4807593688876931 HIT: 0.6086484672556073

#### val Acc: 0, NDCG: 0.6833885145697176 HIT: 0.7606748241112992
Epoch: 640, plus 0 steps train_loss: 0.6946

#### test Acc: 0, NDCG: 0.37042662711709984 HIT: 0.5151224608548455

#### val Acc: 0, NDCG: 0.6340463349890321 HIT: 0.7217098563796022
Epoch: 704, plus 0 steps train_loss: 0.6925

#### test Acc: 0, NDCG: 0.15923484675343128 HIT: 0.3333512418006771

#### val Acc: 0, NDCG: 0.5001239982514099 HIT: 0.6106437460325856
Epoch: 768, plus 0 steps train_loss: 0.6905

#### test Acc: 0, NDCG: 0.23456245271594106 HIT: 0.39459902666102414

#### val Acc: 0, NDCG: 0.5411084004238561 HIT: 0.6420317789885738
Epoch: 832, plus 0 steps train_loss: 0.69

#### test Acc: 0, NDCG: 0.2670034984530647 HIT: 0.4325126296022006

#### val Acc: 0, NDCG: 0.5560047052048251 HIT: 0.6576931469530258
Epoch: 896, plus 0 steps train_loss: 0.6913

#### test Acc: 0, NDCG: 0.2404660926503193 HIT: 0.40719474053110455

#### val Acc: 0, NDCG: 0.5521091446806237 HIT: 0.6536298534701651
Epoch: 960, plus 0 steps train_loss: 0.6873

#### test Acc: 0, NDCG: 0.25330639824049195 HIT: 0.4143542702602624

#### val Acc: 0, NDCG: 0.5531445805657764 HIT: 0.6505468419382142
Epoch: 1017, plus 0 steps train_loss: 0.6846
Done: it took 132580.38519501686
max value of NDCG: 0.6292381092598374
max value of HIT: 0.7348800187790944

After 20 validations
max value of NDCG: 0.6292381092598374
max value of HIT: 0.7348800187790944
