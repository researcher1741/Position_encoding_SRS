 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2
max_norm:             	0.1
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11571301
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12956774298255463 HIT: 0.28469338499788405

#### val Acc: 0, NDCG: 0.4711746223179964 HIT: 0.5643969199640287
Epoch: 1, plus 0 steps train_loss: 0.7468

#### test Acc: 0, NDCG: 0.12328616616650512 HIT: 0.27549063690224296

#### val Acc: 0, NDCG: 0.4792477880661907 HIT: 0.5743212415361828
Epoch: 2, plus 0 steps train_loss: 0.7679

#### test Acc: 0, NDCG: 0.13342334103932404 HIT: 0.29768170757511636

#### val Acc: 0, NDCG: 0.4770396381584221 HIT: 0.5667616641980534
Epoch: 3, plus 0 steps train_loss: 0.7415

#### test Acc: 0, NDCG: 0.12126653623233533 HIT: 0.26839805728946253

#### val Acc: 0, NDCG: 0.4799811184362126 HIT: 0.5727780826809141
Epoch: 4, plus 0 steps train_loss: 0.7516

#### test Acc: 0, NDCG: 0.1253176545835674 HIT: 0.2812888475983919

#### val Acc: 0, NDCG: 0.47749804556562814 HIT: 0.5745625925730004
Epoch: 5, plus 0 steps train_loss: 0.7614

#### test Acc: 0, NDCG: 0.12448311735738737 HIT: 0.27829014362039783

#### val Acc: 0, NDCG: 0.47371689722039934 HIT: 0.571278730691917
Epoch: 6, plus 0 steps train_loss: 0.7446

#### test Acc: 0, NDCG: 0.13182697026329457 HIT: 0.28771688531527717

#### val Acc: 0, NDCG: 0.47390152110599193 HIT: 0.570516656527719
Epoch: 7, plus 0 steps train_loss: 0.7465

#### test Acc: 0, NDCG: 0.12492363274004005 HIT: 0.27511538563267035

#### val Acc: 0, NDCG: 0.4679269340104416 HIT: 0.5650689007617435
Epoch: 8, plus 0 steps train_loss: 0.7461

#### test Acc: 0, NDCG: 0.12265819743248713 HIT: 0.2792935688214135

#### val Acc: 0, NDCG: 0.4738604696092281 HIT: 0.563575334585273
Epoch: 9, plus 0 steps train_loss: 0.7485

#### test Acc: 0, NDCG: 0.12900711293140493 HIT: 0.28289151766821835

#### val Acc: 0, NDCG: 0.47991318562712165 HIT: 0.5719201293377063
Epoch: 10, plus 0 steps train_loss: 0.7444

#### test Acc: 0, NDCG: 0.12321964702979378 HIT: 0.27088760976512904

#### val Acc: 0, NDCG: 0.4799819556386436 HIT: 0.5779001798561151
Epoch: 12, plus 0 steps train_loss: 0.736

#### test Acc: 0, NDCG: 0.127063352181799 HIT: 0.2757683559035125

#### val Acc: 0, NDCG: 0.47948364251170417 HIT: 0.5768603866906474
Epoch: 14, plus 0 steps train_loss: 0.734

#### test Acc: 0, NDCG: 0.13074424139663696 HIT: 0.2838775854316547

#### val Acc: 0, NDCG: 0.47820317980822996 HIT: 0.5742790877592043
Epoch: 16, plus 0 steps train_loss: 0.7359

#### test Acc: 0, NDCG: 0.14041322062298303 HIT: 0.29840162796233605

#### val Acc: 0, NDCG: 0.47809418332034553 HIT: 0.5785167821625052
Epoch: 18, plus 0 steps train_loss: 0.7431

#### test Acc: 0, NDCG: 0.1369028016385061 HIT: 0.2986793469636056

#### val Acc: 0, NDCG: 0.4612413647425018 HIT: 0.552752558982226
Epoch: 20, plus 0 steps train_loss: 0.7289

#### test Acc: 0, NDCG: 0.13235063785012227 HIT: 0.28277662796233605

#### val Acc: 0, NDCG: 0.4845276171083268 HIT: 0.5818006440435886
Epoch: 22, plus 0 steps train_loss: 0.7264

#### test Acc: 0, NDCG: 0.12989696870401457 HIT: 0.2839370966462124

#### val Acc: 0, NDCG: 0.47722979535895715 HIT: 0.567898989631824
Epoch: 24, plus 0 steps train_loss: 0.7297

#### test Acc: 0, NDCG: 0.1308541381524364 HIT: 0.2787554882564537

#### val Acc: 0, NDCG: 0.46903776821637777 HIT: 0.5622272402666102
Epoch: 26, plus 0 steps train_loss: 0.7233

#### test Acc: 0, NDCG: 0.13567970158493045 HIT: 0.2889137219636056

#### val Acc: 0, NDCG: 0.47331775335313386 HIT: 0.5647358032691494
Epoch: 28, plus 0 steps train_loss: 0.7214

#### test Acc: 0, NDCG: 0.13325471784810203 HIT: 0.2893980771265341

#### val Acc: 0, NDCG: 0.47234827422931075 HIT: 0.5583689298561151
Epoch: 30, plus 0 steps train_loss: 0.7195

#### test Acc: 0, NDCG: 0.13268930746660773 HIT: 0.30086225137537026

#### val Acc: 0, NDCG: 0.4852302764605901 HIT: 0.5809046696466357
Epoch: 32, plus 0 steps train_loss: 0.726

#### test Acc: 0, NDCG: 0.14757159953460536 HIT: 0.3048280125899281

#### val Acc: 0, NDCG: 0.4790293202263043 HIT: 0.5649308678057554
Epoch: 36, plus 0 steps train_loss: 0.7143

#### test Acc: 0, NDCG: 0.1479232699471679 HIT: 0.30968974820143885

#### val Acc: 0, NDCG: 0.4992047699354892 HIT: 0.5933433400338552
Epoch: 40, plus 0 steps train_loss: 0.721

#### test Acc: 0, NDCG: 0.21617131230354117 HIT: 0.37439166314007616

#### val Acc: 0, NDCG: 0.5242470743993983 HIT: 0.6184140922556073
Epoch: 44, plus 0 steps train_loss: 0.7153

#### test Acc: 0, NDCG: 0.24264982890345976 HIT: 0.40129899756665255

#### val Acc: 0, NDCG: 0.5617780884990689 HIT: 0.6586048256982648
Epoch: 48, plus 0 steps train_loss: 0.7178

#### test Acc: 0, NDCG: 0.3168824727352012 HIT: 0.4672861894308083

#### val Acc: 0, NDCG: 0.5770885300974623 HIT: 0.6709302594688955
Epoch: 52, plus 0 steps train_loss: 0.7101

#### test Acc: 0, NDCG: 0.1793017903760412 HIT: 0.3308658220482438

#### val Acc: 0, NDCG: 0.49587210385811403 HIT: 0.5883857252433348
Epoch: 56, plus 0 steps train_loss: 0.7142

#### test Acc: 0, NDCG: 0.5841982063735252 HIT: 0.7083462825327973

#### val Acc: 0, NDCG: 0.759442249648707 HIT: 0.8288713698159119
Epoch: 60, plus 0 steps train_loss: 0.7172

#### test Acc: 0, NDCG: 0.4908532902516549 HIT: 0.6210375449640287

#### val Acc: 0, NDCG: 0.6816017099619203 HIT: 0.7601615398857385
Epoch: 64, plus 0 steps train_loss: 0.7089

#### test Acc: 0, NDCG: 0.526310656405196 HIT: 0.6505278314113415

#### val Acc: 0, NDCG: 0.7311954636023374 HIT: 0.8050644043588658
Epoch: 68, plus 0 steps train_loss: 0.7116

#### test Acc: 0, NDCG: 0.5083244048424187 HIT: 0.6400918787029201

#### val Acc: 0, NDCG: 0.7009408467491252 HIT: 0.7763246204506983
Epoch: 72, plus 0 steps train_loss: 0.709

#### test Acc: 0, NDCG: 0.37237540172410727 HIT: 0.5105938227359289

#### val Acc: 0, NDCG: 0.6172465997436418 HIT: 0.696882108283961
Epoch: 80, plus 0 steps train_loss: 0.7062

#### test Acc: 0, NDCG: 0.40289640143405836 HIT: 0.5469469093842573

#### val Acc: 0, NDCG: 0.6348797898001135 HIT: 0.71990220323741
Epoch: 88, plus 0 steps train_loss: 0.7074

#### test Acc: 0, NDCG: 0.16488187377413888 HIT: 0.31043446492805754

#### val Acc: 0, NDCG: 0.5014574089205882 HIT: 0.597848834902666
Epoch: 96, plus 0 steps train_loss: 0.7025

#### test Acc: 0, NDCG: 0.5476443155394917 HIT: 0.6703731683770631

#### val Acc: 0, NDCG: 0.7455932011684209 HIT: 0.8133901885844266
Epoch: 104, plus 0 steps train_loss: 0.7043

#### test Acc: 0, NDCG: 0.6096807303622698 HIT: 0.7182210114261531

#### val Acc: 0, NDCG: 0.7770614265300202 HIT: 0.8434185555966991
Epoch: 112, plus 0 steps train_loss: 0.704

#### test Acc: 0, NDCG: 0.531288904727287 HIT: 0.6559582297397376

#### val Acc: 0, NDCG: 0.7319418308005625 HIT: 0.8016003557448159
Epoch: 120, plus 0 steps train_loss: 0.7036

#### test Acc: 0, NDCG: 0.5826252519041378 HIT: 0.6961869842361404

#### val Acc: 0, NDCG: 0.7320160222890038 HIT: 0.8010374788404571
Epoch: 128, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.6317490294976559 HIT: 0.7378671511320355

#### val Acc: 0, NDCG: 0.7720691770359678 HIT: 0.8379955961701228
Epoch: 136, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.637497587901844 HIT: 0.7412295347545493

#### val Acc: 0, NDCG: 0.7854277091561919 HIT: 0.8454865703025815
Epoch: 144, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.19112045653043103 HIT: 0.33866675042319083

#### val Acc: 0, NDCG: 0.5105875615089918 HIT: 0.597576901713923
Epoch: 160, plus 0 steps train_loss: 0.7017

#### test Acc: 0, NDCG: 0.27440473470711235 HIT: 0.42144684987304276

#### val Acc: 0, NDCG: 0.5535775235536778 HIT: 0.633470429538722
Epoch: 176, plus 0 steps train_loss: 0.7012

#### test Acc: 0, NDCG: 0.46829452985594183 HIT: 0.5987125740584004

#### val Acc: 0, NDCG: 0.6819395054692048 HIT: 0.7587580670757511
Epoch: 192, plus 0 steps train_loss: 0.7013

#### test Acc: 0, NDCG: 0.6355398041364732 HIT: 0.7389317406369023

#### val Acc: 0, NDCG: 0.7785325040539564 HIT: 0.8396346342044012
Epoch: 208, plus 0 steps train_loss: 0.7002

#### test Acc: 0, NDCG: 0.6291621210240949 HIT: 0.7336699574164198

#### val Acc: 0, NDCG: 0.7927634433148574 HIT: 0.8508442327020737
Epoch: 224, plus 0 steps train_loss: 0.703

#### test Acc: 0, NDCG: 0.6447074450438248 HIT: 0.7473360466038934

#### val Acc: 0, NDCG: 0.7912492082166419 HIT: 0.8530519334532374
Epoch: 240, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.6349116792462369 HIT: 0.7388647905205248

#### val Acc: 0, NDCG: 0.7890699465826928 HIT: 0.8477727927951756
Epoch: 256, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.6751047865618005 HIT: 0.7666317313796022

#### val Acc: 0, NDCG: 0.8059022163723073 HIT: 0.8610520590880236
Epoch: 272, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.5491135570926987 HIT: 0.6672769321307659

#### val Acc: 0, NDCG: 0.7334081317525329 HIT: 0.8027186706517139
Epoch: 288, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.16440889978171186 HIT: 0.3316890605162928

#### val Acc: 0, NDCG: 0.48945058701996613 HIT: 0.5856341581146848
Epoch: 304, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.6572935857254248 HIT: 0.7567933704506983

#### val Acc: 0, NDCG: 0.7990580337259248 HIT: 0.8593824389018198
Epoch: 320, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.6526759231802206 HIT: 0.7506562764494288

#### val Acc: 0, NDCG: 0.7946123717200946 HIT: 0.8541280945831571
Epoch: 352, plus 0 steps train_loss: 0.7016

#### test Acc: 0, NDCG: 0.6785792221869924 HIT: 0.7696668033220483

#### val Acc: 0, NDCG: 0.8016182105518239 HIT: 0.8603627208527296
Epoch: 384, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.66766966046562 HIT: 0.7662085405205248

#### val Acc: 0, NDCG: 0.7959606941979658 HIT: 0.8562630594054168
Epoch: 416, plus 0 steps train_loss: 0.701

#### test Acc: 0, NDCG: 0.6721472364930605 HIT: 0.7631065184617013

#### val Acc: 0, NDCG: 0.8026129592058165 HIT: 0.8578103509839188
Epoch: 448, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.6631896343802955 HIT: 0.7585225018514601

#### val Acc: 0, NDCG: 0.8019831753758233 HIT: 0.8594245926787982
Epoch: 480, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.6609005976683243 HIT: 0.7528085987092679

#### val Acc: 0, NDCG: 0.807735616177705 HIT: 0.8641772243969531
Epoch: 512, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.6641444097931467 HIT: 0.7631123042742276

#### val Acc: 0, NDCG: 0.7971533658956611 HIT: 0.8538503755818875
Epoch: 544, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.6564120825887698 HIT: 0.7602342758146424

#### val Acc: 0, NDCG: 0.8077119462394561 HIT: 0.8657798944667795
Epoch: 576, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.6543373088751913 HIT: 0.757894327920017

#### val Acc: 0, NDCG: 0.8059206795003537 HIT: 0.8618736444667795
Epoch: 608, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.671376994068801 HIT: 0.7668672966038934

#### val Acc: 0, NDCG: 0.8123093287114829 HIT: 0.8766101089716463
Epoch: 640, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.6886991619841584 HIT: 0.7823104567816335

#### val Acc: 0, NDCG: 0.8027448821978576 HIT: 0.8622431099238256
Epoch: 704, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.6809667442473789 HIT: 0.7791125555438002

#### val Acc: 0, NDCG: 0.7948241703637288 HIT: 0.8507905073000424
Epoch: 768, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.6671360730503018 HIT: 0.7624766914409649

#### val Acc: 0, NDCG: 0.8013757189191015 HIT: 0.8580649267350825
Epoch: 832, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.6814560120773772 HIT: 0.7747219503808718

#### val Acc: 0, NDCG: 0.8120015935975625 HIT: 0.8673519823846805
Epoch: 896, plus 0 steps train_loss: 0.6944

#### test Acc: 0, NDCG: 0.6765585551475825 HIT: 0.7727688253808718

#### val Acc: 0, NDCG: 0.8086316237670789 HIT: 0.8668386981591197
Epoch: 960, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.6802661398652369 HIT: 0.765917596804909

#### val Acc: 0, NDCG: 0.8090662561996061 HIT: 0.863573846804909
Epoch: 1017, plus 0 steps train_loss: 0.6955
Done: it took 132397.50140476227
max value of NDCG: 0.6886991619841584
max value of HIT: 0.7823104567816335

After 20 validations
max value of NDCG: 0.6886991619841584
max value of HIT: 0.7823104567816335
