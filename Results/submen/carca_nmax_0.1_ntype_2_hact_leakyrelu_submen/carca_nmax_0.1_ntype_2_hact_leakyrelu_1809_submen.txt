 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2
max_norm:             	0.1
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11571301
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12399729951929729 HIT: 0.2712570752221752

#### val Acc: 0, NDCG: 0.4724645165044944 HIT: 0.5655474701121456
Epoch: 1, plus 0 steps train_loss: 0.7494

#### test Acc: 0, NDCG: 0.1296497850302154 HIT: 0.2830849291155311

#### val Acc: 0, NDCG: 0.4801494774599496 HIT: 0.572052376481168
Epoch: 2, plus 0 steps train_loss: 0.7559

#### test Acc: 0, NDCG: 0.13077966707238892 HIT: 0.2883756413986458

#### val Acc: 0, NDCG: 0.4787629991827326 HIT: 0.571696135738468
Epoch: 3, plus 0 steps train_loss: 0.7513

#### test Acc: 0, NDCG: 0.12463124023352956 HIT: 0.2741235320567076

#### val Acc: 0, NDCG: 0.48611434729192216 HIT: 0.5737451399174778
Epoch: 4, plus 0 steps train_loss: 0.7467

#### test Acc: 0, NDCG: 0.12454584641858973 HIT: 0.27674698476512904

#### val Acc: 0, NDCG: 0.47634880061145485 HIT: 0.569815746667372
Epoch: 5, plus 0 steps train_loss: 0.7477

#### test Acc: 0, NDCG: 0.1343871865160694 HIT: 0.2920942657638595

#### val Acc: 0, NDCG: 0.47140402142220156 HIT: 0.5635100375581887
Epoch: 6, plus 0 steps train_loss: 0.744

#### test Acc: 0, NDCG: 0.1326534211259764 HIT: 0.28919144096487515

#### val Acc: 0, NDCG: 0.47238047634540514 HIT: 0.5668170426893779
Epoch: 7, plus 0 steps train_loss: 0.7505

#### test Acc: 0, NDCG: 0.12481672601124076 HIT: 0.2737672913140076

#### val Acc: 0, NDCG: 0.48039577956797774 HIT: 0.569754582363521
Epoch: 8, plus 0 steps train_loss: 0.7461

#### test Acc: 0, NDCG: 0.12893018398682973 HIT: 0.27871333447947527

#### val Acc: 0, NDCG: 0.47576498934884237 HIT: 0.5731591197630131
Epoch: 9, plus 0 steps train_loss: 0.7393

#### test Acc: 0, NDCG: 0.13489945848962956 HIT: 0.2914528671180702

#### val Acc: 0, NDCG: 0.4726640893461762 HIT: 0.56471844583157
Epoch: 10, plus 0 steps train_loss: 0.7419

#### test Acc: 0, NDCG: 0.1298485722525577 HIT: 0.2941564946572154

#### val Acc: 0, NDCG: 0.4842467230081244 HIT: 0.5731475481379602
Epoch: 12, plus 0 steps train_loss: 0.7352

#### test Acc: 0, NDCG: 0.12833410103831303 HIT: 0.27898526766821835

#### val Acc: 0, NDCG: 0.47743556846748847 HIT: 0.5667558783855269
Epoch: 14, plus 0 steps train_loss: 0.7381

#### test Acc: 0, NDCG: 0.12545300903624718 HIT: 0.28575797450275076

#### val Acc: 0, NDCG: 0.4678246660037094 HIT: 0.5513854541366906
Epoch: 16, plus 0 steps train_loss: 0.7459

#### test Acc: 0, NDCG: 0.13148502907744344 HIT: 0.2925538245873889

#### val Acc: 0, NDCG: 0.4801205712822886 HIT: 0.5718473934088024
Epoch: 18, plus 0 steps train_loss: 0.7405

#### test Acc: 0, NDCG: 0.13510058914436684 HIT: 0.2944821532479898

#### val Acc: 0, NDCG: 0.4764896233761115 HIT: 0.5711944231379602
Epoch: 20, plus 0 steps train_loss: 0.7367

#### test Acc: 0, NDCG: 0.13142224460732294 HIT: 0.2819839716462124

#### val Acc: 0, NDCG: 0.47579091120185796 HIT: 0.5715812460325856
Epoch: 22, plus 0 steps train_loss: 0.7287

#### test Acc: 0, NDCG: 0.12990310897142254 HIT: 0.28258900232754974

#### val Acc: 0, NDCG: 0.46702279713129907 HIT: 0.5551652428057554
Epoch: 24, plus 0 steps train_loss: 0.7248

#### test Acc: 0, NDCG: 0.12127851309076325 HIT: 0.2744202615848498

#### val Acc: 0, NDCG: 0.46961765149492635 HIT: 0.5580069033008886
Epoch: 26, plus 0 steps train_loss: 0.7293

#### test Acc: 0, NDCG: 0.13125857793977375 HIT: 0.28137894096487515

#### val Acc: 0, NDCG: 0.48202625603763327 HIT: 0.5762189880448583
Epoch: 28, plus 0 steps train_loss: 0.7222

#### test Acc: 0, NDCG: 0.1263578509209497 HIT: 0.28219639362039783

#### val Acc: 0, NDCG: 0.47846178609225065 HIT: 0.568649492170969
Epoch: 30, plus 0 steps train_loss: 0.723

#### test Acc: 0, NDCG: 0.13035625762019598 HIT: 0.2887203105162928

#### val Acc: 0, NDCG: 0.4825463621197327 HIT: 0.5794053176576386
Epoch: 32, plus 0 steps train_loss: 0.7231

#### test Acc: 0, NDCG: 0.138083870295986 HIT: 0.3020227200592467

#### val Acc: 0, NDCG: 0.4698451055059691 HIT: 0.5607816136796445
Epoch: 36, plus 0 steps train_loss: 0.7187

#### test Acc: 0, NDCG: 0.13344649015694063 HIT: 0.2825046947735929

#### val Acc: 0, NDCG: 0.48018513773667176 HIT: 0.5730822511108761
Epoch: 40, plus 0 steps train_loss: 0.7152

#### test Acc: 0, NDCG: 0.14207564888557855 HIT: 0.3084929115531104

#### val Acc: 0, NDCG: 0.46849876255707373 HIT: 0.5615684841832416
Epoch: 44, plus 0 steps train_loss: 0.7192

#### test Acc: 0, NDCG: 0.15132389044692515 HIT: 0.2982503702920017

#### val Acc: 0, NDCG: 0.4873190279794761 HIT: 0.5762132022323319
Epoch: 48, plus 0 steps train_loss: 0.7115

#### test Acc: 0, NDCG: 0.16971967607573588 HIT: 0.3208952139758781

#### val Acc: 0, NDCG: 0.4957337178768199 HIT: 0.5928664237727466
Epoch: 52, plus 0 steps train_loss: 0.7177

#### test Acc: 0, NDCG: 0.21082920783781844 HIT: 0.36620969768303

#### val Acc: 0, NDCG: 0.5394675924300846 HIT: 0.6307362198476513
Epoch: 56, plus 0 steps train_loss: 0.7172

#### test Acc: 0, NDCG: 0.1973831993712971 HIT: 0.3428391477994075

#### val Acc: 0, NDCG: 0.5166512839013991 HIT: 0.6119554723867965
Epoch: 60, plus 0 steps train_loss: 0.716

#### test Acc: 0, NDCG: 0.26859293184432187 HIT: 0.4271549672027084

#### val Acc: 0, NDCG: 0.5458635734081205 HIT: 0.6363120900338552
Epoch: 64, plus 0 steps train_loss: 0.7095

#### test Acc: 0, NDCG: 0.3252660171483393 HIT: 0.48046957654464667

#### val Acc: 0, NDCG: 0.5948514656293622 HIT: 0.6838094781527718
Epoch: 68, plus 0 steps train_loss: 0.7081

#### test Acc: 0, NDCG: 0.2626846254315251 HIT: 0.4172686666842996

#### val Acc: 0, NDCG: 0.5564429965110813 HIT: 0.6519122936944561
Epoch: 72, plus 0 steps train_loss: 0.7075

#### test Acc: 0, NDCG: 0.15270663344660107 HIT: 0.3129736100825222

#### val Acc: 0, NDCG: 0.4839136295625535 HIT: 0.576092526713923
Epoch: 80, plus 0 steps train_loss: 0.7073

#### test Acc: 0, NDCG: 0.4532379885142377 HIT: 0.5934582297397376

#### val Acc: 0, NDCG: 0.6710646134992247 HIT: 0.754786520048667
Epoch: 88, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.503201493299971 HIT: 0.6328174592678798

#### val Acc: 0, NDCG: 0.691698088464918 HIT: 0.7741532876639864
Epoch: 96, plus 0 steps train_loss: 0.7067

#### test Acc: 0, NDCG: 0.4311905343947119 HIT: 0.576890968842573

#### val Acc: 0, NDCG: 0.6539522034913956 HIT: 0.7467136584849767
Epoch: 104, plus 0 steps train_loss: 0.7017

#### test Acc: 0, NDCG: 0.3687956355352684 HIT: 0.5184426907003808

#### val Acc: 0, NDCG: 0.6254533013439678 HIT: 0.7138072630131189
Epoch: 112, plus 0 steps train_loss: 0.7049

#### test Acc: 0, NDCG: 0.47347565749565185 HIT: 0.6128514467837495

#### val Acc: 0, NDCG: 0.691205248248289 HIT: 0.769431238097757
Epoch: 120, plus 0 steps train_loss: 0.7049

#### test Acc: 0, NDCG: 0.36942802671421004 HIT: 0.5109575023804487

#### val Acc: 0, NDCG: 0.6240869840593196 HIT: 0.7129187275179856
Epoch: 128, plus 0 steps train_loss: 0.7053

#### test Acc: 0, NDCG: 0.1490817050653773 HIT: 0.309419468101989

#### val Acc: 0, NDCG: 0.49102801111871425 HIT: 0.5823445104210749
Epoch: 136, plus 0 steps train_loss: 0.7025

#### test Acc: 0, NDCG: 0.4104724721219779 HIT: 0.5576738058082945

#### val Acc: 0, NDCG: 0.6424271469619791 HIT: 0.7210874682606855
Epoch: 144, plus 0 steps train_loss: 0.7018

#### test Acc: 0, NDCG: 0.5690460247626924 HIT: 0.6870991258463817

#### val Acc: 0, NDCG: 0.7367331784151572 HIT: 0.8068910680279306
Epoch: 160, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.594367313801624 HIT: 0.7088364235082523

#### val Acc: 0, NDCG: 0.7561454172880379 HIT: 0.8268512946995346
Epoch: 176, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.533579191141035 HIT: 0.6550754800571308

#### val Acc: 0, NDCG: 0.7244868660254001 HIT: 0.7998406421921287
Epoch: 192, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.5208047386803636 HIT: 0.6501583659542953

#### val Acc: 0, NDCG: 0.7280945860811024 HIT: 0.8047561032056707
Epoch: 208, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.6066894709733942 HIT: 0.7186863560622091

#### val Acc: 0, NDCG: 0.7460333342871267 HIT: 0.8154408458527296
Epoch: 224, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.5667173940988187 HIT: 0.6862221619763013

#### val Acc: 0, NDCG: 0.7398295665013038 HIT: 0.8191057448159119
Epoch: 240, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.5776769114888971 HIT: 0.6881447048243757

#### val Acc: 0, NDCG: 0.7516372848129781 HIT: 0.8234409714875158
Epoch: 256, plus 0 steps train_loss: 0.6995

#### test Acc: 0, NDCG: 0.5889636654081445 HIT: 0.7059410376110876

#### val Acc: 0, NDCG: 0.7317021872000957 HIT: 0.8042601764176894
Epoch: 272, plus 0 steps train_loss: 0.7002

#### test Acc: 0, NDCG: 0.5723449330383517 HIT: 0.6895118096699111

#### val Acc: 0, NDCG: 0.7585855285626081 HIT: 0.8303880792424884
Epoch: 288, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.5664389931111462 HIT: 0.6882959624947101

#### val Acc: 0, NDCG: 0.7263248745107189 HIT: 0.7962542649703765
Epoch: 304, plus 0 steps train_loss: 0.6989

#### test Acc: 0, NDCG: 0.5307367661985868 HIT: 0.6638186693292425

#### val Acc: 0, NDCG: 0.7295472907972808 HIT: 0.8010680609923826
Epoch: 320, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.5861810314980929 HIT: 0.7010908736246297

#### val Acc: 0, NDCG: 0.7541052002263327 HIT: 0.8256544580512061
Epoch: 352, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.5973903812875444 HIT: 0.7071436600719424

#### val Acc: 0, NDCG: 0.7734276952957769 HIT: 0.8403355440647482
Epoch: 384, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.60147305962193 HIT: 0.7130394030363945

#### val Acc: 0, NDCG: 0.7654110382024406 HIT: 0.8360961965721541
Epoch: 416, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.618013451043047 HIT: 0.7300009257300042

#### val Acc: 0, NDCG: 0.7474801628922443 HIT: 0.8192991562632247
Epoch: 448, plus 0 steps train_loss: 0.6982

#### test Acc: 0, NDCG: 0.6019710253854194 HIT: 0.7124285865425306

#### val Acc: 0, NDCG: 0.7642030262696061 HIT: 0.8291011492276766
Epoch: 480, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.5855725273749673 HIT: 0.6981764772005925

#### val Acc: 0, NDCG: 0.7614661965412646 HIT: 0.8285076901713924
Epoch: 512, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.5984555304755474 HIT: 0.7153487687790944

#### val Acc: 0, NDCG: 0.7621560204613007 HIT: 0.8292102531210326
Epoch: 544, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.5956113857187172 HIT: 0.708256189166314

#### val Acc: 0, NDCG: 0.7542779650931771 HIT: 0.8217118400867541
Epoch: 576, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.6036475899726291 HIT: 0.7106077086859923

#### val Acc: 0, NDCG: 0.7467513874435108 HIT: 0.8136331927105375
Epoch: 608, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.6132255889526605 HIT: 0.7253747553427846

#### val Acc: 0, NDCG: 0.7516368109686394 HIT: 0.8193470958527296
Epoch: 640, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.6008824019605958 HIT: 0.7130815568133728

#### val Acc: 0, NDCG: 0.7608090229005976 HIT: 0.8297904874629708
Epoch: 704, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.5908349562438956 HIT: 0.7018413761637748

#### val Acc: 0, NDCG: 0.7532599078663044 HIT: 0.8240881559458315
Epoch: 768, plus 0 steps train_loss: 0.6942

#### test Acc: 0, NDCG: 0.6184313967414564 HIT: 0.7232397905205248

#### val Acc: 0, NDCG: 0.7512141527528504 HIT: 0.8222557064642404
Epoch: 832, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.5863419771743542 HIT: 0.7040589954506983

#### val Acc: 0, NDCG: 0.7611564538885622 HIT: 0.8224243215721541
Epoch: 896, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.6064539257745866 HIT: 0.7216429062632247

#### val Acc: 0, NDCG: 0.7665317656192923 HIT: 0.835468022640711
Epoch: 960, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.595414887176113 HIT: 0.7117392483072366

#### val Acc: 0, NDCG: 0.7663547323220511 HIT: 0.8331760143355903
Epoch: 1017, plus 0 steps train_loss: 0.6964
Done: it took 131813.8566119671
max value of NDCG: 0.6184313967414564
max value of HIT: 0.7300009257300042

After 20 validations
max value of NDCG: 0.6184313967414564
max value of HIT: 0.7300009257300042
