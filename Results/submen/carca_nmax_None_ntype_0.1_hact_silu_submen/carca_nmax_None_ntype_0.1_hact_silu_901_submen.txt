 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	None
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11571301
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12713323638500315 HIT: 0.2844445950592467

#### val Acc: 0, NDCG: 0.48059144117400326 HIT: 0.5704629311256877
Epoch: 1, plus 0 steps train_loss: 0.7944

#### test Acc: 0, NDCG: 0.126682947290304 HIT: 0.2807681244710114

#### val Acc: 0, NDCG: 0.4720793688231049 HIT: 0.5625123981696996
Epoch: 2, plus 0 steps train_loss: 0.7972

#### test Acc: 0, NDCG: 0.12593176533028752 HIT: 0.28332049433982226

#### val Acc: 0, NDCG: 0.4881252260960393 HIT: 0.578118387642827
Epoch: 3, plus 0 steps train_loss: 0.785

#### test Acc: 0, NDCG: 0.11637313186759199 HIT: 0.27003544223444775

#### val Acc: 0, NDCG: 0.4901863033760794 HIT: 0.5801731776343632
Epoch: 4, plus 0 steps train_loss: 0.7856

#### test Acc: 0, NDCG: 0.13028433765409472 HIT: 0.2876441493863733

#### val Acc: 0, NDCG: 0.4804550326904875 HIT: 0.5712481485399915
Epoch: 5, plus 0 steps train_loss: 0.7783

#### test Acc: 0, NDCG: 0.12727538386697457 HIT: 0.28768630316335164

#### val Acc: 0, NDCG: 0.4801590336927891 HIT: 0.5706315462336013
Epoch: 6, plus 0 steps train_loss: 0.7744

#### test Acc: 0, NDCG: 0.12840539330015407 HIT: 0.28273447418535763

#### val Acc: 0, NDCG: 0.4866025178235644 HIT: 0.5777241258463817
Epoch: 7, plus 0 steps train_loss: 0.7803

#### test Acc: 0, NDCG: 0.13040006252634115 HIT: 0.289790685833686

#### val Acc: 0, NDCG: 0.4698846599717066 HIT: 0.5689156395471858
Epoch: 8, plus 0 steps train_loss: 0.768

#### test Acc: 0, NDCG: 0.1262161747758908 HIT: 0.2780049857173085

#### val Acc: 0, NDCG: 0.48211563776903077 HIT: 0.5686784212336013
Epoch: 9, plus 0 steps train_loss: 0.7763

#### test Acc: 0, NDCG: 0.13239789717257877 HIT: 0.29011055861193397

#### val Acc: 0, NDCG: 0.4786676565560076 HIT: 0.569350402031316
Epoch: 10, plus 0 steps train_loss: 0.759

#### test Acc: 0, NDCG: 0.12595871671031675 HIT: 0.2842280403618282

#### val Acc: 0, NDCG: 0.4810537554930801 HIT: 0.575184980691917
Epoch: 12, plus 0 steps train_loss: 0.7572

#### test Acc: 0, NDCG: 0.12738522957051554 HIT: 0.28523725137537026

#### val Acc: 0, NDCG: 0.4856467754405884 HIT: 0.5759354832310623
Epoch: 14, plus 0 steps train_loss: 0.7654

#### test Acc: 0, NDCG: 0.13134969615369385 HIT: 0.2896278565382988

#### val Acc: 0, NDCG: 0.4761445285192154 HIT: 0.5655111021476936
Epoch: 16, plus 0 steps train_loss: 0.7613

#### test Acc: 0, NDCG: 0.12494052948106582 HIT: 0.2782289793165468

#### val Acc: 0, NDCG: 0.47708241134778834 HIT: 0.5662310225349133
Epoch: 18, plus 0 steps train_loss: 0.7495

#### test Acc: 0, NDCG: 0.1313569738528706 HIT: 0.2865795598815066

#### val Acc: 0, NDCG: 0.4801376530991875 HIT: 0.5776108892297926
Epoch: 20, plus 0 steps train_loss: 0.7545

#### test Acc: 0, NDCG: 0.13219427546112558 HIT: 0.29362419990478206

#### val Acc: 0, NDCG: 0.4872807883969227 HIT: 0.5845274148328397
Epoch: 22, plus 0 steps train_loss: 0.7435

#### test Acc: 0, NDCG: 0.12883357286112285 HIT: 0.28520666922344473

#### val Acc: 0, NDCG: 0.4728547029813663 HIT: 0.5624148659013964
Epoch: 24, plus 0 steps train_loss: 0.7501

#### test Acc: 0, NDCG: 0.12443624795955668 HIT: 0.2746078872196361

#### val Acc: 0, NDCG: 0.4869477007944174 HIT: 0.5870244062103259
Epoch: 26, plus 0 steps train_loss: 0.7434

#### test Acc: 0, NDCG: 0.12910773542039616 HIT: 0.28259478814007616

#### val Acc: 0, NDCG: 0.49632205674488394 HIT: 0.5957866060093102
Epoch: 28, plus 0 steps train_loss: 0.7388

#### test Acc: 0, NDCG: 0.13210859286616652 HIT: 0.2874085841620821

#### val Acc: 0, NDCG: 0.48539087973513384 HIT: 0.5802533524650867
Epoch: 30, plus 0 steps train_loss: 0.734

#### test Acc: 0, NDCG: 0.13697537811234156 HIT: 0.3004390605162928

#### val Acc: 0, NDCG: 0.4869431406681289 HIT: 0.5775497249259416
Epoch: 32, plus 0 steps train_loss: 0.7394

#### test Acc: 0, NDCG: 0.13070773839997668 HIT: 0.28225011902242914

#### val Acc: 0, NDCG: 0.48356856044417684 HIT: 0.5779307620080406
Epoch: 36, plus 0 steps train_loss: 0.7424

#### test Acc: 0, NDCG: 0.13234133047350732 HIT: 0.300257220694033

#### val Acc: 0, NDCG: 0.4826235681195872 HIT: 0.5770711555755396
Epoch: 40, plus 0 steps train_loss: 0.7392

#### test Acc: 0, NDCG: 0.13001579861715062 HIT: 0.2915024597968684

#### val Acc: 0, NDCG: 0.4808175079969632 HIT: 0.5712498016292847
Epoch: 44, plus 0 steps train_loss: 0.7282

#### test Acc: 0, NDCG: 0.13117157583184286 HIT: 0.2859935397270419

#### val Acc: 0, NDCG: 0.47848157480234466 HIT: 0.5740782374100719
Epoch: 48, plus 0 steps train_loss: 0.7298

#### test Acc: 0, NDCG: 0.13312013495320532 HIT: 0.2927836039991536

#### val Acc: 0, NDCG: 0.48150980723450765 HIT: 0.5803360069297503
Epoch: 52, plus 0 steps train_loss: 0.7302

#### test Acc: 0, NDCG: 0.1253804671984325 HIT: 0.28148804485823103

#### val Acc: 0, NDCG: 0.480552485454614 HIT: 0.5788920334320778
Epoch: 56, plus 0 steps train_loss: 0.7308

#### test Acc: 0, NDCG: 0.13475606785260633 HIT: 0.2918644863520948

#### val Acc: 0, NDCG: 0.4939830966795878 HIT: 0.5941227716356327
Epoch: 60, plus 0 steps train_loss: 0.7309

#### test Acc: 0, NDCG: 0.13028738644788684 HIT: 0.2847413245873889

#### val Acc: 0, NDCG: 0.4863109369892197 HIT: 0.5778943940435886
Epoch: 64, plus 0 steps train_loss: 0.725

#### test Acc: 0, NDCG: 0.13205731370605603 HIT: 0.29079989684722807

#### val Acc: 0, NDCG: 0.4895727811049953 HIT: 0.581745265552264
Epoch: 68, plus 0 steps train_loss: 0.716

#### test Acc: 0, NDCG: 0.12251546234790797 HIT: 0.2720497315382988

#### val Acc: 0, NDCG: 0.4801194172169962 HIT: 0.5681403406686416
Epoch: 72, plus 0 steps train_loss: 0.7195

#### test Acc: 0, NDCG: 0.12753596194425423 HIT: 0.27815045757511636

#### val Acc: 0, NDCG: 0.4833699092068714 HIT: 0.578317584902666
Epoch: 80, plus 0 steps train_loss: 0.7251

#### test Acc: 0, NDCG: 0.12670759608473678 HIT: 0.27598656369022434

#### val Acc: 0, NDCG: 0.49450865096412194 HIT: 0.5925217546550995
Epoch: 88, plus 0 steps train_loss: 0.7172

#### test Acc: 0, NDCG: 0.1318951770080184 HIT: 0.28683413563267035

#### val Acc: 0, NDCG: 0.48544247253703027 HIT: 0.580833586807025
Epoch: 96, plus 0 steps train_loss: 0.7165

#### test Acc: 0, NDCG: 0.14007084439193432 HIT: 0.3043320858019467

#### val Acc: 0, NDCG: 0.47482999715222673 HIT: 0.5679700724714346
Epoch: 104, plus 0 steps train_loss: 0.7157

#### test Acc: 0, NDCG: 0.12912977616566915 HIT: 0.2835866417160389

#### val Acc: 0, NDCG: 0.4705969928651749 HIT: 0.5649672357702074
Epoch: 112, plus 0 steps train_loss: 0.7122

#### test Acc: 0, NDCG: 0.14089251213044873 HIT: 0.3018235227994075

#### val Acc: 0, NDCG: 0.47516571181422457 HIT: 0.5686974317604739
Epoch: 120, plus 0 steps train_loss: 0.7125

#### test Acc: 0, NDCG: 0.1307332351245427 HIT: 0.28653740610452816

#### val Acc: 0, NDCG: 0.471902824504245 HIT: 0.5630794077972916
Epoch: 128, plus 0 steps train_loss: 0.7072

#### test Acc: 0, NDCG: 0.1324291517911556 HIT: 0.28379162478840453

#### val Acc: 0, NDCG: 0.4719538772528326 HIT: 0.567161711807025
Epoch: 136, plus 0 steps train_loss: 0.71

#### test Acc: 0, NDCG: 0.12161341443908347 HIT: 0.2684459968789674

#### val Acc: 0, NDCG: 0.4715651189816464 HIT: 0.5589260209479475
Epoch: 144, plus 0 steps train_loss: 0.7027

#### test Acc: 0, NDCG: 0.13663102905568422 HIT: 0.297603185833686

#### val Acc: 0, NDCG: 0.48288086147487663 HIT: 0.5701182620080406
Epoch: 160, plus 0 steps train_loss: 0.708

#### test Acc: 0, NDCG: 0.12563186301765822 HIT: 0.2734341938214135

#### val Acc: 0, NDCG: 0.4737761243144333 HIT: 0.5676270564430808
Epoch: 176, plus 0 steps train_loss: 0.7061

#### test Acc: 0, NDCG: 0.12828544303542197 HIT: 0.28024905443292425

#### val Acc: 0, NDCG: 0.4810459215752894 HIT: 0.576854600878121
Epoch: 192, plus 0 steps train_loss: 0.7061

#### test Acc: 0, NDCG: 0.14021407733246574 HIT: 0.2968105295175624

#### val Acc: 0, NDCG: 0.4855665905244939 HIT: 0.5770000727359289
Epoch: 208, plus 0 steps train_loss: 0.7054

#### test Acc: 0, NDCG: 0.1476614868015197 HIT: 0.3047073370715192

#### val Acc: 0, NDCG: 0.4854453539460218 HIT: 0.568661063796022
Epoch: 224, plus 0 steps train_loss: 0.7021

#### test Acc: 0, NDCG: 0.22325973151071268 HIT: 0.369451405787135

#### val Acc: 0, NDCG: 0.5417307837395412 HIT: 0.6363963975878121
Epoch: 240, plus 0 steps train_loss: 0.7025

#### test Acc: 0, NDCG: 0.27661909628974835 HIT: 0.42077486907532796

#### val Acc: 0, NDCG: 0.5690639307327883 HIT: 0.6645807434934405
Epoch: 256, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.4671041942502969 HIT: 0.5907810516292847

#### val Acc: 0, NDCG: 0.6836855399027388 HIT: 0.7566726949322895
Epoch: 272, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.5657515774459079 HIT: 0.6753861616589082

#### val Acc: 0, NDCG: 0.7361669832627236 HIT: 0.7984008014176894
Epoch: 288, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.5903001426718728 HIT: 0.6878421894837071

#### val Acc: 0, NDCG: 0.7605820065374246 HIT: 0.8171584056284384
Epoch: 304, plus 0 steps train_loss: 0.6982

#### test Acc: 0, NDCG: 0.5872143767354733 HIT: 0.687828964769361

#### val Acc: 0, NDCG: 0.7516364239278284 HIT: 0.8105311706517139
Epoch: 320, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.5867822158959279 HIT: 0.6881926444138806

#### val Acc: 0, NDCG: 0.7608033866119516 HIT: 0.8201397521688532
Epoch: 352, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.4993286162966142 HIT: 0.611223980374524

#### val Acc: 0, NDCG: 0.6950949805339492 HIT: 0.7645695024862463
Epoch: 384, plus 0 steps train_loss: 0.7029

#### test Acc: 0, NDCG: 0.5063861409685668 HIT: 0.6198101261637748

#### val Acc: 0, NDCG: 0.7148180071809304 HIT: 0.7828485373465933
Epoch: 416, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.601454246410686 HIT: 0.6990707985082523

#### val Acc: 0, NDCG: 0.7626730673569516 HIT: 0.8222193384997883
Epoch: 448, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.5632319839816169 HIT: 0.6641021741430384

#### val Acc: 0, NDCG: 0.7450025221547856 HIT: 0.8036377882987727
Epoch: 480, plus 0 steps train_loss: 0.6982

#### test Acc: 0, NDCG: 0.38919092602832306 HIT: 0.5297919752433348

#### val Acc: 0, NDCG: 0.6276000693751197 HIT: 0.7065270577655522
Epoch: 512, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.6149128812688419 HIT: 0.7134435833685993

#### val Acc: 0, NDCG: 0.7651517200829749 HIT: 0.8278968736775285
Epoch: 544, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.6366533857490979 HIT: 0.7320267866589082

#### val Acc: 0, NDCG: 0.801925066899776 HIT: 0.8541702483601354
Epoch: 576, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.6696111413725622 HIT: 0.7530499497460855

#### val Acc: 0, NDCG: 0.8029801805276513 HIT: 0.8579558228417267
Epoch: 608, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.6813318458852234 HIT: 0.7704710312632247

#### val Acc: 0, NDCG: 0.8115810741050425 HIT: 0.8613239922767668
Epoch: 640, plus 0 steps train_loss: 0.6949

#### test Acc: 0, NDCG: 0.6594610078737173 HIT: 0.7428495622619551

#### val Acc: 0, NDCG: 0.810164138835497 HIT: 0.8658526303956835
Epoch: 704, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.6319676764268645 HIT: 0.7221942115425306

#### val Acc: 0, NDCG: 0.7864731323890417 HIT: 0.8415935450169276
Epoch: 768, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.5917374870693884 HIT: 0.6924319919064749

#### val Acc: 0, NDCG: 0.766894830679038 HIT: 0.8250552131823953
Epoch: 832, plus 0 steps train_loss: 0.6953

#### test Acc: 0, NDCG: 0.6606014094842938 HIT: 0.749689219212865

#### val Acc: 0, NDCG: 0.7858978045138196 HIT: 0.8412604475243335
Epoch: 896, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.660907027078144 HIT: 0.7497065766504444

#### val Acc: 0, NDCG: 0.7997874024916616 HIT: 0.8540859408061785
Epoch: 960, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.6588344122906385 HIT: 0.749875191758358

#### val Acc: 0, NDCG: 0.7909284180652206 HIT: 0.8449790718895472
Epoch: 1017, plus 0 steps train_loss: 0.6949
Done: it took 79989.63581633568
max value of NDCG: 0.6813318458852234
max value of HIT: 0.7704710312632247

After 20 validations
max value of NDCG: 0.6813318458852234
max value of HIT: 0.7704710312632247
