 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.11845619814397701 HIT: 0.264363692869234

#### val Acc: 0, NDCG: 0.47728905836429014 HIT: 0.5725730996085484
Epoch: 1, plus 0 steps train_loss: 0.8167

#### test Acc: 0, NDCG: 0.12239484394202833 HIT: 0.26958166922344473

#### val Acc: 0, NDCG: 0.4776558614176998 HIT: 0.5711101155840034
Epoch: 2, plus 0 steps train_loss: 0.8193

#### test Acc: 0, NDCG: 0.12347094135585202 HIT: 0.2731986285971223

#### val Acc: 0, NDCG: 0.4873801532502743 HIT: 0.5764429816440966
Epoch: 3, plus 0 steps train_loss: 0.8142

#### test Acc: 0, NDCG: 0.12215055924364272 HIT: 0.2720670889758781

#### val Acc: 0, NDCG: 0.4717750559071389 HIT: 0.5615263304062632
Epoch: 4, plus 0 steps train_loss: 0.7963

#### test Acc: 0, NDCG: 0.11862414120297039 HIT: 0.2651447775603047

#### val Acc: 0, NDCG: 0.47821000766681293 HIT: 0.5692412981379602
Epoch: 5, plus 0 steps train_loss: 0.7901

#### test Acc: 0, NDCG: 0.11642036263347545 HIT: 0.2667953872196361

#### val Acc: 0, NDCG: 0.47724186730998946 HIT: 0.5775612965509945
Epoch: 6, plus 0 steps train_loss: 0.7644

#### test Acc: 0, NDCG: 0.12076460872621159 HIT: 0.2720497315382988

#### val Acc: 0, NDCG: 0.48149787285483514 HIT: 0.5753593816123572
Epoch: 7, plus 0 steps train_loss: 0.7766

#### test Acc: 0, NDCG: 0.11979284218116021 HIT: 0.26606968101989

#### val Acc: 0, NDCG: 0.4745730839047775 HIT: 0.5577523275497249
Epoch: 8, plus 0 steps train_loss: 0.7671

#### test Acc: 0, NDCG: 0.11828435071999491 HIT: 0.2619758053851037

#### val Acc: 0, NDCG: 0.4687861068779656 HIT: 0.5582118863732544
Epoch: 9, plus 0 steps train_loss: 0.7545

#### test Acc: 0, NDCG: 0.12051930064176913 HIT: 0.2654167107490478

#### val Acc: 0, NDCG: 0.47524598192487877 HIT: 0.569042100878121
Epoch: 10, plus 0 steps train_loss: 0.7682

#### test Acc: 0, NDCG: 0.12375976422359951 HIT: 0.2687542980321625

#### val Acc: 0, NDCG: 0.47758313760108057 HIT: 0.5693446162187897
Epoch: 12, plus 0 steps train_loss: 0.7682

#### test Acc: 0, NDCG: 0.12242406265284156 HIT: 0.2713298111510791

#### val Acc: 0, NDCG: 0.474176740138503 HIT: 0.5661946545704613
Epoch: 14, plus 0 steps train_loss: 0.7675

#### test Acc: 0, NDCG: 0.12501232632690074 HIT: 0.28458428110452816

#### val Acc: 0, NDCG: 0.49066477248823487 HIT: 0.5761826200804063
Epoch: 16, plus 0 steps train_loss: 0.7407

#### test Acc: 0, NDCG: 0.126561386450552 HIT: 0.2755443623042742

#### val Acc: 0, NDCG: 0.4731896537909522 HIT: 0.5574514652983495
Epoch: 18, plus 0 steps train_loss: 0.7386

#### test Acc: 0, NDCG: 0.12856384189700373 HIT: 0.29021387669276344

#### val Acc: 0, NDCG: 0.48662597026328375 HIT: 0.5813832389970377
Epoch: 20, plus 0 steps train_loss: 0.7383

#### test Acc: 0, NDCG: 0.12456281461394501 HIT: 0.27389375264494287

#### val Acc: 0, NDCG: 0.4797695388306472 HIT: 0.576165262642827
Epoch: 22, plus 0 steps train_loss: 0.732

#### test Acc: 0, NDCG: 0.12841117536434593 HIT: 0.2805209876216674

#### val Acc: 0, NDCG: 0.47458916736035806 HIT: 0.5690900404676259
Epoch: 24, plus 0 steps train_loss: 0.7252

#### test Acc: 0, NDCG: 0.1248317321090626 HIT: 0.2736333910812526

#### val Acc: 0, NDCG: 0.47252306157998164 HIT: 0.5641324256771054
Epoch: 26, plus 0 steps train_loss: 0.7183

#### test Acc: 0, NDCG: 0.1251469767266229 HIT: 0.2756898341620821

#### val Acc: 0, NDCG: 0.48794220027313767 HIT: 0.5748824653512484
Epoch: 28, plus 0 steps train_loss: 0.7284

#### test Acc: 0, NDCG: 0.12730972311358585 HIT: 0.27918446492805754

#### val Acc: 0, NDCG: 0.47486925200952124 HIT: 0.5696892853364367
Epoch: 30, plus 0 steps train_loss: 0.7186

#### test Acc: 0, NDCG: 0.13131110104064558 HIT: 0.28356184537663987

#### val Acc: 0, NDCG: 0.47405763449050786 HIT: 0.5653350481379602
Epoch: 32, plus 0 steps train_loss: 0.7145

#### test Acc: 0, NDCG: 0.1316221395683395 HIT: 0.2908246931866272

#### val Acc: 0, NDCG: 0.47955792246451473 HIT: 0.5701852121244181
Epoch: 36, plus 0 steps train_loss: 0.7135

#### test Acc: 0, NDCG: 0.128162035461873 HIT: 0.2791001573741007

#### val Acc: 0, NDCG: 0.4802130819527123 HIT: 0.5721672661870504
Epoch: 40, plus 0 steps train_loss: 0.7132

#### test Acc: 0, NDCG: 0.13114440301487504 HIT: 0.28443880924672027

#### val Acc: 0, NDCG: 0.4791720766681608 HIT: 0.576473563796022
Epoch: 44, plus 0 steps train_loss: 0.7105

#### test Acc: 0, NDCG: 0.13494977671040165 HIT: 0.28650103814007616

#### val Acc: 0, NDCG: 0.4712646891128523 HIT: 0.5641861510791367
Epoch: 48, plus 0 steps train_loss: 0.7125

#### test Acc: 0, NDCG: 0.12991464796395086 HIT: 0.27693461039991535

#### val Acc: 0, NDCG: 0.4678194763020232 HIT: 0.5594698873254337
Epoch: 52, plus 0 steps train_loss: 0.7146

#### test Acc: 0, NDCG: 0.13016931862803718 HIT: 0.2814458910812526

#### val Acc: 0, NDCG: 0.47758103260151913 HIT: 0.56356376296022
Epoch: 56, plus 0 steps train_loss: 0.7077

#### test Acc: 0, NDCG: 0.1314297608312289 HIT: 0.2773578012589928

#### val Acc: 0, NDCG: 0.4781496404070895 HIT: 0.5732219371561574
Epoch: 60, plus 0 steps train_loss: 0.7065

#### test Acc: 0, NDCG: 0.13077501531850413 HIT: 0.28634978046974185

#### val Acc: 0, NDCG: 0.479560181000285 HIT: 0.5744667133939907
Epoch: 64, plus 0 steps train_loss: 0.7075

#### test Acc: 0, NDCG: 0.15231350141809885 HIT: 0.30046385685569194

#### val Acc: 0, NDCG: 0.49803448098704556 HIT: 0.5936516411870504
Epoch: 68, plus 0 steps train_loss: 0.7093

#### test Acc: 0, NDCG: 0.14545424624571007 HIT: 0.2936663536817605

#### val Acc: 0, NDCG: 0.5025502614382011 HIT: 0.5923093326809141
Epoch: 72, plus 0 steps train_loss: 0.7063

#### test Acc: 0, NDCG: 0.20224332980899146 HIT: 0.34129020313161235

#### val Acc: 0, NDCG: 0.527974668784853 HIT: 0.6148756546233601
Epoch: 80, plus 0 steps train_loss: 0.7083

#### test Acc: 0, NDCG: 0.22503817726077813 HIT: 0.3733502168853153

#### val Acc: 0, NDCG: 0.5277381165960096 HIT: 0.6184736034701651
Epoch: 88, plus 0 steps train_loss: 0.7031

#### test Acc: 0, NDCG: 0.20425439214044624 HIT: 0.3465941401290732

#### val Acc: 0, NDCG: 0.5217279346859127 HIT: 0.6095370027507405
Epoch: 96, plus 0 steps train_loss: 0.7089

#### test Acc: 0, NDCG: 0.24421818586009328 HIT: 0.3809635196254761

#### val Acc: 0, NDCG: 0.5518289680888491 HIT: 0.6427037597862887
Epoch: 104, plus 0 steps train_loss: 0.7054

#### test Acc: 0, NDCG: 0.32185497871506313 HIT: 0.4486261174883623

#### val Acc: 0, NDCG: 0.581932103797639 HIT: 0.6704574759310199
Epoch: 112, plus 0 steps train_loss: 0.7037

#### test Acc: 0, NDCG: 0.34035965171944565 HIT: 0.47937440488785443

#### val Acc: 0, NDCG: 0.6157153721319005 HIT: 0.6951166089187474
Epoch: 120, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.3147259926910612 HIT: 0.4513297450275074

#### val Acc: 0, NDCG: 0.5917935101579489 HIT: 0.6765408445302581
Epoch: 128, plus 0 steps train_loss: 0.7009

#### test Acc: 0, NDCG: 0.4039125167220399 HIT: 0.5305598352200592

#### val Acc: 0, NDCG: 0.629189249602651 HIT: 0.700885890552264
Epoch: 136, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.46685690095881316 HIT: 0.5837901370080406

#### val Acc: 0, NDCG: 0.6805222431021396 HIT: 0.7533772614261531
Epoch: 144, plus 0 steps train_loss: 0.7015

#### test Acc: 0, NDCG: 0.4697031553212194 HIT: 0.5898908630448583

#### val Acc: 0, NDCG: 0.6660683647207889 HIT: 0.7377274650867541
Epoch: 160, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.5513358108330129 HIT: 0.6642360743757935

#### val Acc: 0, NDCG: 0.7523816602833001 HIT: 0.814425849026661
Epoch: 176, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.45823553621249097 HIT: 0.584115795598815

#### val Acc: 0, NDCG: 0.6657412455834051 HIT: 0.7403889388489208
Epoch: 192, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.38027814844382135 HIT: 0.5068024624418113

#### val Acc: 0, NDCG: 0.6260507419814308 HIT: 0.7082140353893356
Epoch: 208, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.4865135040265715 HIT: 0.5962345932077867

#### val Acc: 0, NDCG: 0.7073524451126578 HIT: 0.7780347413245874
Epoch: 224, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.4637864916562847 HIT: 0.5898735056072788

#### val Acc: 0, NDCG: 0.6742913673952252 HIT: 0.7441439311785866
Epoch: 240, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.5789453016897793 HIT: 0.6874057739102836

#### val Acc: 0, NDCG: 0.7475168226579161 HIT: 0.8077738177105375
Epoch: 256, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.6157996390299042 HIT: 0.7090066917054592

#### val Acc: 0, NDCG: 0.7582115779250843 HIT: 0.8166624788404571
Epoch: 272, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.6164954264357899 HIT: 0.7134857371455777

#### val Acc: 0, NDCG: 0.7620359346235502 HIT: 0.8203753173931443
Epoch: 288, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.5713302840111117 HIT: 0.6723816718683876

#### val Acc: 0, NDCG: 0.746832244073568 HIT: 0.8044478020524757
Epoch: 304, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.4721220810811617 HIT: 0.5878592163034279

#### val Acc: 0, NDCG: 0.6774015387974146 HIT: 0.748829612780364
Epoch: 320, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.49829706963794856 HIT: 0.6153905919382142

#### val Acc: 0, NDCG: 0.691847084077075 HIT: 0.7589283352729581
Epoch: 352, plus 0 steps train_loss: 0.6972

#### test Acc: 0, NDCG: 0.6261219725499602 HIT: 0.7252598656369023

#### val Acc: 0, NDCG: 0.7598871361169159 HIT: 0.8189660587706306
Epoch: 384, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.6998551026470681 HIT: 0.785938987780364

#### val Acc: 0, NDCG: 0.8050416891848274 HIT: 0.8565887179961913
Epoch: 416, plus 0 steps train_loss: 0.6934

#### test Acc: 0, NDCG: 0.6141882970530874 HIT: 0.7082082495768091

#### val Acc: 0, NDCG: 0.7672788645487632 HIT: 0.8222862886161659
Epoch: 448, plus 0 steps train_loss: 0.692

#### test Acc: 0, NDCG: 0.6086985569088336 HIT: 0.7122045929432924

#### val Acc: 0, NDCG: 0.7433138771734802 HIT: 0.8070175293588658
Epoch: 480, plus 0 steps train_loss: 0.6902

#### test Acc: 0, NDCG: 0.6994430177664266 HIT: 0.7861745530046551

#### val Acc: 0, NDCG: 0.8220937034543638 HIT: 0.8713367541261109
Epoch: 512, plus 0 steps train_loss: 0.6822

#### test Acc: 0, NDCG: 0.6811207429275641 HIT: 0.7673690092044012

#### val Acc: 0, NDCG: 0.793520504091248 HIT: 0.843588823793906
Epoch: 544, plus 0 steps train_loss: 0.6726

#### test Acc: 0, NDCG: 0.5906660374270624 HIT: 0.6894564311785866

#### val Acc: 0, NDCG: 0.7724412617484145 HIT: 0.8356920162399492
Epoch: 576, plus 0 steps train_loss: 0.6775

#### test Acc: 0, NDCG: 0.4237990340330785 HIT: 0.5632670334320778

#### val Acc: 0, NDCG: 0.648639155578089 HIT: 0.7316019427105375
Epoch: 608, plus 0 steps train_loss: 0.6799

#### test Acc: 0, NDCG: 0.3528876849457644 HIT: 0.5137016306072788

#### val Acc: 0, NDCG: 0.5935858525274144 HIT: 0.6862816731908591
Epoch: 640, plus 0 steps train_loss: 0.6653

#### test Acc: 0, NDCG: 0.23730196871145826 HIT: 0.4266226724502751

#### val Acc: 0, NDCG: 0.5321298108760113 HIT: 0.6414399730215827
Epoch: 704, plus 0 steps train_loss: 0.6572

#### test Acc: 0, NDCG: 0.2489201884377754 HIT: 0.44632253755818874

#### val Acc: 0, NDCG: 0.5395490663688939 HIT: 0.6487317498942023
Epoch: 768, plus 0 steps train_loss: 0.6637

#### test Acc: 0, NDCG: 0.2607295096880319 HIT: 0.45247864208633093

#### val Acc: 0, NDCG: 0.544621250194606 HIT: 0.6481093617752857
Epoch: 832, plus 0 steps train_loss: 0.6427

#### test Acc: 0, NDCG: 0.2541511347689825 HIT: 0.4449686574269996

#### val Acc: 0, NDCG: 0.5425731125183441 HIT: 0.6515618387642828
Epoch: 896, plus 0 steps train_loss: 0.6476

#### test Acc: 0, NDCG: 0.26634409656248076 HIT: 0.4623707284172662

#### val Acc: 0, NDCG: 0.5458554021249538 HIT: 0.6511328620926788
Epoch: 960, plus 0 steps train_loss: 0.6501

#### test Acc: 0, NDCG: 0.2671156608279239 HIT: 0.46724982146635635

#### val Acc: 0, NDCG: 0.5471716025010156 HIT: 0.6552515340668642
Epoch: 1017, plus 0 steps train_loss: 0.6392
Done: it took 81922.61475586891
max value of NDCG: 0.6998551026470681
max value of HIT: 0.7861745530046551

After 20 validations
max value of NDCG: 0.6998551026470681
max value of HIT: 0.7861745530046551
