 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12085668372246108 HIT: 0.26976929485823103

#### val Acc: 0, NDCG: 0.46822256615357977 HIT: 0.5572026753597122
Epoch: 1, plus 0 steps train_loss: 0.8304

#### test Acc: 0, NDCG: 0.1230870783721163 HIT: 0.27913073952602624

#### val Acc: 0, NDCG: 0.47542560601219924 HIT: 0.5665451095006349
Epoch: 2, plus 0 steps train_loss: 0.8303

#### test Acc: 0, NDCG: 0.11593242555757828 HIT: 0.2628891372196361

#### val Acc: 0, NDCG: 0.4806854570751404 HIT: 0.566635202867118
Epoch: 3, plus 0 steps train_loss: 0.8065

#### test Acc: 0, NDCG: 0.12147996352431659 HIT: 0.27293248122090563

#### val Acc: 0, NDCG: 0.48680555525658586 HIT: 0.5828040692446044
Epoch: 4, plus 0 steps train_loss: 0.7999

#### test Acc: 0, NDCG: 0.12355525756660718 HIT: 0.2787075486669488

#### val Acc: 0, NDCG: 0.47790408830512043 HIT: 0.5729541366906474
Epoch: 5, plus 0 steps train_loss: 0.7821

#### test Acc: 0, NDCG: 0.12846714794786016 HIT: 0.28026062605797714

#### val Acc: 0, NDCG: 0.4790860822656699 HIT: 0.5790127089504867
Epoch: 6, plus 0 steps train_loss: 0.7773

#### test Acc: 0, NDCG: 0.1301355189122824 HIT: 0.27991017112780364

#### val Acc: 0, NDCG: 0.4792549148550363 HIT: 0.5736682712653407
Epoch: 7, plus 0 steps train_loss: 0.7723

#### test Acc: 0, NDCG: 0.12343089147797626 HIT: 0.27507901766821835

#### val Acc: 0, NDCG: 0.4760838991203216 HIT: 0.5732260698793906
Epoch: 8, plus 0 steps train_loss: 0.751

#### test Acc: 0, NDCG: 0.12500041711623974 HIT: 0.27975312764494287

#### val Acc: 0, NDCG: 0.4810871902197184 HIT: 0.5695495992911553
Epoch: 9, plus 0 steps train_loss: 0.7638

#### test Acc: 0, NDCG: 0.12664649095800784 HIT: 0.2817847743863733

#### val Acc: 0, NDCG: 0.47331861919342955 HIT: 0.5642894691599661
Epoch: 10, plus 0 steps train_loss: 0.771

#### test Acc: 0, NDCG: 0.13457104341074083 HIT: 0.29836525999788405

#### val Acc: 0, NDCG: 0.4898556356094505 HIT: 0.5845274148328397
Epoch: 12, plus 0 steps train_loss: 0.7656

#### test Acc: 0, NDCG: 0.13512529301305123 HIT: 0.29782717943292425

#### val Acc: 0, NDCG: 0.4825952140453866 HIT: 0.5725846712336013
Epoch: 14, plus 0 steps train_loss: 0.7592

#### test Acc: 0, NDCG: 0.1358525756258702 HIT: 0.2937027216462124

#### val Acc: 0, NDCG: 0.4754471731152587 HIT: 0.5601765829983072
Epoch: 16, plus 0 steps train_loss: 0.753

#### test Acc: 0, NDCG: 0.13624056667539403 HIT: 0.2919487939060516

#### val Acc: 0, NDCG: 0.47246286462295933 HIT: 0.5691206226195513
Epoch: 18, plus 0 steps train_loss: 0.7517

#### test Acc: 0, NDCG: 0.12074031515967946 HIT: 0.26267092943292425

#### val Acc: 0, NDCG: 0.4744893756139496 HIT: 0.557396086807025
Epoch: 20, plus 0 steps train_loss: 0.7299

#### test Acc: 0, NDCG: 0.12923348250273295 HIT: 0.28591501798561153

#### val Acc: 0, NDCG: 0.4777170030597748 HIT: 0.5638530535865425
Epoch: 22, plus 0 steps train_loss: 0.7214

#### test Acc: 0, NDCG: 0.12789960742378265 HIT: 0.27150586516081254

#### val Acc: 0, NDCG: 0.47647070570964667 HIT: 0.5559926139970377
Epoch: 24, plus 0 steps train_loss: 0.7289

#### test Acc: 0, NDCG: 0.12516164912798472 HIT: 0.26780459823317815

#### val Acc: 0, NDCG: 0.4908779036602343 HIT: 0.5766727610558613
Epoch: 26, plus 0 steps train_loss: 0.7206

#### test Acc: 0, NDCG: 0.14762936636163593 HIT: 0.2872151727147694

#### val Acc: 0, NDCG: 0.49870031592914627 HIT: 0.5867714835484553
Epoch: 28, plus 0 steps train_loss: 0.7234

#### test Acc: 0, NDCG: 0.1540310177058733 HIT: 0.2958376864684723

#### val Acc: 0, NDCG: 0.500971401599649 HIT: 0.5883187751269573
Epoch: 30, plus 0 steps train_loss: 0.7184

#### test Acc: 0, NDCG: 0.1796922064923745 HIT: 0.3251519189060516

#### val Acc: 0, NDCG: 0.5126228914803899 HIT: 0.5973223259627592
Epoch: 32, plus 0 steps train_loss: 0.7149

#### test Acc: 0, NDCG: 0.18979953224222898 HIT: 0.34120589557765557

#### val Acc: 0, NDCG: 0.5182837989756535 HIT: 0.6062779372090563
Epoch: 36, plus 0 steps train_loss: 0.7111

#### test Acc: 0, NDCG: 0.2000191680162098 HIT: 0.3513104038827761

#### val Acc: 0, NDCG: 0.5336754503250777 HIT: 0.6188852227041896
Epoch: 40, plus 0 steps train_loss: 0.7141

#### test Acc: 0, NDCG: 0.20703337910557718 HIT: 0.3547455234341938

#### val Acc: 0, NDCG: 0.5179006804511799 HIT: 0.6111991840351249
Epoch: 44, plus 0 steps train_loss: 0.7188

#### test Acc: 0, NDCG: 0.2524399711957524 HIT: 0.3947370596170123

#### val Acc: 0, NDCG: 0.5561386565708195 HIT: 0.6393223656369023
Epoch: 48, plus 0 steps train_loss: 0.7174

#### test Acc: 0, NDCG: 0.2514127946577458 HIT: 0.39571734156792215

#### val Acc: 0, NDCG: 0.54792957697483 HIT: 0.6331679141980534
Epoch: 52, plus 0 steps train_loss: 0.7093

#### test Acc: 0, NDCG: 0.279723025412064 HIT: 0.41751001772111723

#### val Acc: 0, NDCG: 0.5679589197900954 HIT: 0.6524693847862887
Epoch: 56, plus 0 steps train_loss: 0.7101

#### test Acc: 0, NDCG: 0.3250928780022486 HIT: 0.4660529848180279

#### val Acc: 0, NDCG: 0.590895493190691 HIT: 0.679376719212865
Epoch: 60, plus 0 steps train_loss: 0.7067

#### test Acc: 0, NDCG: 0.29490433958500123 HIT: 0.43253742594159966

#### val Acc: 0, NDCG: 0.5918446765888674 HIT: 0.6797519704824376
Epoch: 64, plus 0 steps train_loss: 0.7083

#### test Acc: 0, NDCG: 0.3099767770849701 HIT: 0.4504354237198477

#### val Acc: 0, NDCG: 0.5880944908868725 HIT: 0.6674587719530258
Epoch: 68, plus 0 steps train_loss: 0.7065

#### test Acc: 0, NDCG: 0.362767913408488 HIT: 0.5019655231696996

#### val Acc: 0, NDCG: 0.6225337397585233 HIT: 0.7063873717202709
Epoch: 72, plus 0 steps train_loss: 0.7084

#### test Acc: 0, NDCG: 0.3645806256559293 HIT: 0.5009488732543377

#### val Acc: 0, NDCG: 0.6139202384126263 HIT: 0.691537670598815
Epoch: 80, plus 0 steps train_loss: 0.709

#### test Acc: 0, NDCG: 0.31771834538898885 HIT: 0.45515168747355056

#### val Acc: 0, NDCG: 0.590311517638964 HIT: 0.666147045598815
Epoch: 88, plus 0 steps train_loss: 0.7081

#### test Acc: 0, NDCG: 0.3741248929003731 HIT: 0.5073289713817182

#### val Acc: 0, NDCG: 0.6268043502664442 HIT: 0.7094050862251375
Epoch: 96, plus 0 steps train_loss: 0.701

#### test Acc: 0, NDCG: 0.38183262980924326 HIT: 0.514942274121879

#### val Acc: 0, NDCG: 0.6405992345667643 HIT: 0.7185772521688532
Epoch: 104, plus 0 steps train_loss: 0.702

#### test Acc: 0, NDCG: 0.41692862849646417 HIT: 0.5476494723338976

#### val Acc: 0, NDCG: 0.659985287555197 HIT: 0.7358950156051629
Epoch: 112, plus 0 steps train_loss: 0.7042

#### test Acc: 0, NDCG: 0.42273975588620666 HIT: 0.5550850679750318

#### val Acc: 0, NDCG: 0.6566692945100845 HIT: 0.7345237780363945
Epoch: 120, plus 0 steps train_loss: 0.6995

#### test Acc: 0, NDCG: 0.4191247190591955 HIT: 0.5497769982543377

#### val Acc: 0, NDCG: 0.6461465309447316 HIT: 0.7208940568133728
Epoch: 128, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.4311168107865101 HIT: 0.5709530721011427

#### val Acc: 0, NDCG: 0.6598276982316043 HIT: 0.7393243493440542
Epoch: 136, plus 0 steps train_loss: 0.7037

#### test Acc: 0, NDCG: 0.41919425624843293 HIT: 0.5586044950804063

#### val Acc: 0, NDCG: 0.6664840927967027 HIT: 0.7414824574164198
Epoch: 144, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.35245721568970434 HIT: 0.5013737172027084

#### val Acc: 0, NDCG: 0.6173652288538315 HIT: 0.7025960114261531
Epoch: 160, plus 0 steps train_loss: 0.701

#### test Acc: 0, NDCG: 0.31004231993837034 HIT: 0.45095449375793484

#### val Acc: 0, NDCG: 0.5875968727106473 HIT: 0.6711236709162083
Epoch: 176, plus 0 steps train_loss: 0.7002

#### test Acc: 0, NDCG: 0.362024157471425 HIT: 0.5084836542530682

#### val Acc: 0, NDCG: 0.620042989400669 HIT: 0.7050392774016081
Epoch: 192, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.3724660958083341 HIT: 0.5134296974185357

#### val Acc: 0, NDCG: 0.634413906278228 HIT: 0.7184450050253914
Epoch: 208, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.4403631045762055 HIT: 0.5729714941282268

#### val Acc: 0, NDCG: 0.6484061152667341 HIT: 0.7314217559775709
Epoch: 224, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.43758721931158623 HIT: 0.5791218128438426

#### val Acc: 0, NDCG: 0.6727784960552626 HIT: 0.7546774161553111
Epoch: 240, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.4448097179703079 HIT: 0.5872483998095641

#### val Acc: 0, NDCG: 0.6725280218291749 HIT: 0.7579844212865002
Epoch: 256, plus 0 steps train_loss: 0.6935

#### test Acc: 0, NDCG: 0.4197339283575583 HIT: 0.5579936785865425

#### val Acc: 0, NDCG: 0.6311396873235054 HIT: 0.7194062764494288
Epoch: 272, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.3596266196141575 HIT: 0.498827133146424

#### val Acc: 0, NDCG: 0.6138497883834613 HIT: 0.7015446466356327
Epoch: 288, plus 0 steps train_loss: 0.6937

#### test Acc: 0, NDCG: 0.38764741934396807 HIT: 0.5444788470694033

#### val Acc: 0, NDCG: 0.6345238447549699 HIT: 0.7223934088023699
Epoch: 304, plus 0 steps train_loss: 0.6928

#### test Acc: 0, NDCG: 0.24747164737973448 HIT: 0.4151089055226407

#### val Acc: 0, NDCG: 0.5646581478347654 HIT: 0.6565268924566229
Epoch: 320, plus 0 steps train_loss: 0.6914

#### test Acc: 0, NDCG: 0.28656882028769964 HIT: 0.4505850283008887

#### val Acc: 0, NDCG: 0.5573330959946129 HIT: 0.6597859579983072
Epoch: 352, plus 0 steps train_loss: 0.6854

#### test Acc: 0, NDCG: 0.2571829255307719 HIT: 0.4178736973656369

#### val Acc: 0, NDCG: 0.5580209455651278 HIT: 0.6600025126957257
Epoch: 384, plus 0 steps train_loss: 0.6877

#### test Acc: 0, NDCG: 0.2139123666709879 HIT: 0.39299635659119764

#### val Acc: 0, NDCG: 0.5286004021459307 HIT: 0.6365302978205671
Epoch: 416, plus 0 steps train_loss: 0.6848

#### test Acc: 0, NDCG: 0.2028883465475307 HIT: 0.3872402996720271

#### val Acc: 0, NDCG: 0.5223627323864448 HIT: 0.6325934656686416
Epoch: 448, plus 0 steps train_loss: 0.6788

#### test Acc: 0, NDCG: 0.2044934206608344 HIT: 0.39210782109606435

#### val Acc: 0, NDCG: 0.5233914646164368 HIT: 0.6357740094688955
Epoch: 480, plus 0 steps train_loss: 0.6738

#### test Acc: 0, NDCG: 0.2545392954801311 HIT: 0.42730622487304276

#### val Acc: 0, NDCG: 0.5399927950334987 HIT: 0.6466273672238679
Epoch: 512, plus 0 steps train_loss: 0.6667

#### test Acc: 0, NDCG: 0.26812531697911735 HIT: 0.44146658775920444

#### val Acc: 0, NDCG: 0.547561991043767 HIT: 0.6460471328819297
Epoch: 544, plus 0 steps train_loss: 0.6559

#### test Acc: 0, NDCG: 0.268919263678994 HIT: 0.43833563663774866

#### val Acc: 0, NDCG: 0.5569564995994092 HIT: 0.6583155350719424
Epoch: 576, plus 0 steps train_loss: 0.6637

#### test Acc: 0, NDCG: 0.28522925123807147 HIT: 0.46208722360347015

#### val Acc: 0, NDCG: 0.5468144601428893 HIT: 0.647008404305967
Epoch: 608, plus 0 steps train_loss: 0.6474

#### test Acc: 0, NDCG: 0.2749307068408159 HIT: 0.4451562830617859

#### val Acc: 0, NDCG: 0.5449050246753964 HIT: 0.6478853681760475
Epoch: 640, plus 0 steps train_loss: 0.6452

#### test Acc: 0, NDCG: 0.2780072774468185 HIT: 0.44914105480321626

#### val Acc: 0, NDCG: 0.562367932297668 HIT: 0.6621680596699111
Epoch: 704, plus 0 steps train_loss: 0.6408

#### test Acc: 0, NDCG: 0.2878117608991471 HIT: 0.4625104144625476

#### val Acc: 0, NDCG: 0.5652403222894502 HIT: 0.6625185146000847
Epoch: 768, plus 0 steps train_loss: 0.6347

#### test Acc: 0, NDCG: 0.2893728465593543 HIT: 0.4684061574269996

#### val Acc: 0, NDCG: 0.5708809197049861 HIT: 0.6672711463182396
Epoch: 832, plus 0 steps train_loss: 0.6403

#### test Acc: 0, NDCG: 0.28895754223786785 HIT: 0.4619533233707152

#### val Acc: 0, NDCG: 0.5544535417605565 HIT: 0.6502079586330936
Epoch: 896, plus 0 steps train_loss: 0.6362

#### test Acc: 0, NDCG: 0.2897782592478726 HIT: 0.46276333712441814

#### val Acc: 0, NDCG: 0.5659086246240799 HIT: 0.6621126811785866
Epoch: 960, plus 0 steps train_loss: 0.6326

#### test Acc: 0, NDCG: 0.29665303158038714 HIT: 0.47415642853364365

#### val Acc: 0, NDCG: 0.5613238890037541 HIT: 0.6628326015658061
Epoch: 1017, plus 0 steps train_loss: 0.6381
Done: it took 82347.98897147179
max value of NDCG: 0.4448097179703079
max value of HIT: 0.5872483998095641

After 20 validations
max value of NDCG: 0.4448097179703079
max value of HIT: 0.5872483998095641
