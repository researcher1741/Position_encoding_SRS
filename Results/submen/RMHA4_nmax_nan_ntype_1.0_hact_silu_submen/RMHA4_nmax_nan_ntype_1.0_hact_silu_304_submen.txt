 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12761527687229732 HIT: 0.2794084585272958

#### val Acc: 0, NDCG: 0.4743924217957313 HIT: 0.5648944998413035
Epoch: 1, plus 0 steps train_loss: 0.7977

#### test Acc: 0, NDCG: 0.12951009446866624 HIT: 0.2821236576914939

#### val Acc: 0, NDCG: 0.48366188187194437 HIT: 0.5805847968683876
Epoch: 2, plus 0 steps train_loss: 0.8035

#### test Acc: 0, NDCG: 0.12877617093769841 HIT: 0.2822327615848498

#### val Acc: 0, NDCG: 0.4956658651304796 HIT: 0.5847323979052053
Epoch: 3, plus 0 steps train_loss: 0.7955

#### test Acc: 0, NDCG: 0.13142522020274028 HIT: 0.2858902216462124

#### val Acc: 0, NDCG: 0.4804157758356444 HIT: 0.5700397402666102
Epoch: 4, plus 0 steps train_loss: 0.7964

#### test Acc: 0, NDCG: 0.13165774762932414 HIT: 0.29144129549301734

#### val Acc: 0, NDCG: 0.4776628066806371 HIT: 0.5699248505607278
Epoch: 5, plus 0 steps train_loss: 0.7931

#### test Acc: 0, NDCG: 0.13357295817315115 HIT: 0.2969981551523487

#### val Acc: 0, NDCG: 0.4701432072414671 HIT: 0.565038318609818
Epoch: 6, plus 0 steps train_loss: 0.7807

#### test Acc: 0, NDCG: 0.13139367112661904 HIT: 0.29591042239737625

#### val Acc: 0, NDCG: 0.4874458186413225 HIT: 0.5809716197630131
Epoch: 7, plus 0 steps train_loss: 0.7649

#### test Acc: 0, NDCG: 0.13398076628977562 HIT: 0.29759740002115953

#### val Acc: 0, NDCG: 0.47399723884888256 HIT: 0.5660855506771054
Epoch: 8, plus 0 steps train_loss: 0.7776

#### test Acc: 0, NDCG: 0.13352124050743308 HIT: 0.29892069800042315

#### val Acc: 0, NDCG: 0.4775511199891806 HIT: 0.567064179538722
Epoch: 9, plus 0 steps train_loss: 0.7583

#### test Acc: 0, NDCG: 0.13972524127239033 HIT: 0.3096550333262802

#### val Acc: 0, NDCG: 0.4781771521662152 HIT: 0.5657698106220906
Epoch: 10, plus 0 steps train_loss: 0.7712

#### test Acc: 0, NDCG: 0.13274273831486288 HIT: 0.29488798666948796

#### val Acc: 0, NDCG: 0.48063802726364685 HIT: 0.5730268726195513
Epoch: 12, plus 0 steps train_loss: 0.7651

#### test Acc: 0, NDCG: 0.1303746926107004 HIT: 0.2911809339293271

#### val Acc: 0, NDCG: 0.4730844391158448 HIT: 0.5677361603364367
Epoch: 14, plus 0 steps train_loss: 0.7637

#### test Acc: 0, NDCG: 0.12657818005469476 HIT: 0.27970518805543804

#### val Acc: 0, NDCG: 0.4735002477456123 HIT: 0.5702389375264495
Epoch: 16, plus 0 steps train_loss: 0.7553

#### test Acc: 0, NDCG: 0.13062508607686427 HIT: 0.2923909952920017

#### val Acc: 0, NDCG: 0.4764178095066406 HIT: 0.5690842546550995
Epoch: 18, plus 0 steps train_loss: 0.7388

#### test Acc: 0, NDCG: 0.13045217922382224 HIT: 0.2851529438214135

#### val Acc: 0, NDCG: 0.4779017335220543 HIT: 0.5754626996931866
Epoch: 20, plus 0 steps train_loss: 0.7435

#### test Acc: 0, NDCG: 0.12719545062718438 HIT: 0.27799919990478206

#### val Acc: 0, NDCG: 0.4731530541194553 HIT: 0.5710258080300465
Epoch: 22, plus 0 steps train_loss: 0.7352

#### test Acc: 0, NDCG: 0.13268698735062198 HIT: 0.29289270789250954

#### val Acc: 0, NDCG: 0.47869368536829465 HIT: 0.5708861219847651
Epoch: 24, plus 0 steps train_loss: 0.7327

#### test Acc: 0, NDCG: 0.12773743089846082 HIT: 0.28670602121244176

#### val Acc: 0, NDCG: 0.47585796665060276 HIT: 0.5773563134786288
Epoch: 26, plus 0 steps train_loss: 0.7349

#### test Acc: 0, NDCG: 0.12716190893980903 HIT: 0.28049040546974185

#### val Acc: 0, NDCG: 0.4809297500924115 HIT: 0.57918876296022
Epoch: 28, plus 0 steps train_loss: 0.7204

#### test Acc: 0, NDCG: 0.13170040975606043 HIT: 0.2908800716779517

#### val Acc: 0, NDCG: 0.48268098929885483 HIT: 0.5747617898328397
Epoch: 30, plus 0 steps train_loss: 0.7266

#### test Acc: 0, NDCG: 0.13434022466374243 HIT: 0.29162892112780364

#### val Acc: 0, NDCG: 0.47586378565034465 HIT: 0.5731839161024121
Epoch: 32, plus 0 steps train_loss: 0.7253

#### test Acc: 0, NDCG: 0.1286941182740067 HIT: 0.28947081305543804

#### val Acc: 0, NDCG: 0.47396672326484685 HIT: 0.568661063796022
Epoch: 36, plus 0 steps train_loss: 0.7213

#### test Acc: 0, NDCG: 0.15095198313320876 HIT: 0.31988600296233605

#### val Acc: 0, NDCG: 0.486203041643052 HIT: 0.5838322907850191
Epoch: 40, plus 0 steps train_loss: 0.7123

#### test Acc: 0, NDCG: 0.17946789717308062 HIT: 0.34311108098815063

#### val Acc: 0, NDCG: 0.5206868372162576 HIT: 0.612196823423614
Epoch: 44, plus 0 steps train_loss: 0.7132

#### test Acc: 0, NDCG: 0.17428595791504445 HIT: 0.33902299116589085

#### val Acc: 0, NDCG: 0.5020858904491113 HIT: 0.5984232834320778
Epoch: 48, plus 0 steps train_loss: 0.7097

#### test Acc: 0, NDCG: 0.1848051663357137 HIT: 0.3453725071413457

#### val Acc: 0, NDCG: 0.512469974348848 HIT: 0.5998920532691494
Epoch: 52, plus 0 steps train_loss: 0.7121

#### test Acc: 0, NDCG: 0.19533854312296683 HIT: 0.36404580379813795

#### val Acc: 0, NDCG: 0.49962543906947693 HIT: 0.5879683201967838
Epoch: 56, plus 0 steps train_loss: 0.7118

#### test Acc: 0, NDCG: 0.22786843805391876 HIT: 0.3840233879073212

#### val Acc: 0, NDCG: 0.5429944194473679 HIT: 0.629774948423614
Epoch: 60, plus 0 steps train_loss: 0.7089

#### test Acc: 0, NDCG: 0.21574978244909387 HIT: 0.3758488613520948

#### val Acc: 0, NDCG: 0.5295207426406914 HIT: 0.6194538854210749
Epoch: 64, plus 0 steps train_loss: 0.7053

#### test Acc: 0, NDCG: 0.2044068085863459 HIT: 0.3573383939906898

#### val Acc: 0, NDCG: 0.517120570204871 HIT: 0.6050563042213288
Epoch: 68, plus 0 steps train_loss: 0.7079

#### test Acc: 0, NDCG: 0.2887983301462432 HIT: 0.4416484275814642

#### val Acc: 0, NDCG: 0.5622959563980853 HIT: 0.6476671603893356
Epoch: 72, plus 0 steps train_loss: 0.7085

#### test Acc: 0, NDCG: 0.2563149359448835 HIT: 0.4009353179221329

#### val Acc: 0, NDCG: 0.5515478399158366 HIT: 0.6335720945302581
Epoch: 80, plus 0 steps train_loss: 0.7085

#### test Acc: 0, NDCG: 0.28006942323872724 HIT: 0.4234958540520525

#### val Acc: 0, NDCG: 0.5652925467092542 HIT: 0.6523966488573847
Epoch: 88, plus 0 steps train_loss: 0.7054

#### test Acc: 0, NDCG: 0.314658407481577 HIT: 0.45305309061574267

#### val Acc: 0, NDCG: 0.592701859342608 HIT: 0.675568001481168
Epoch: 96, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.22882324892049163 HIT: 0.37157314589504864

#### val Acc: 0, NDCG: 0.5342167081837316 HIT: 0.6196225005289886
Epoch: 104, plus 0 steps train_loss: 0.7042

#### test Acc: 0, NDCG: 0.3228788665647772 HIT: 0.4612945672873466

#### val Acc: 0, NDCG: 0.5896273282617952 HIT: 0.6750968710325856
Epoch: 112, plus 0 steps train_loss: 0.704

#### test Acc: 0, NDCG: 0.34127027836671564 HIT: 0.48324428692340243

#### val Acc: 0, NDCG: 0.6150995936949619 HIT: 0.6971308982225984
Epoch: 120, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.41923843454847043 HIT: 0.5495703620926788

#### val Acc: 0, NDCG: 0.6520502469565082 HIT: 0.7315118493440542
Epoch: 128, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.4523696681407802 HIT: 0.5828577946466357

#### val Acc: 0, NDCG: 0.6715352173846552 HIT: 0.7533582508992805
Epoch: 136, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.41771069501941194 HIT: 0.5580664145154465

#### val Acc: 0, NDCG: 0.6398294060828987 HIT: 0.7233736907532797
Epoch: 144, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.517879869968095 HIT: 0.6389661248942023

#### val Acc: 0, NDCG: 0.7198198106446669 HIT: 0.7875780258146424
Epoch: 160, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.5623504086532826 HIT: 0.6766251520842149

#### val Acc: 0, NDCG: 0.7285552669328327 HIT: 0.8011887365107914
Epoch: 176, plus 0 steps train_loss: 0.7012

#### test Acc: 0, NDCG: 0.5056939147105377 HIT: 0.6303568358548455

#### val Acc: 0, NDCG: 0.7004930152960562 HIT: 0.7785802607913669
Epoch: 192, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.5644136933880659 HIT: 0.67791373518832

#### val Acc: 0, NDCG: 0.7342891998529767 HIT: 0.8016367237092679
Epoch: 208, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.5919923249621957 HIT: 0.70232407823741

#### val Acc: 0, NDCG: 0.7485862503724396 HIT: 0.8138993400867541
Epoch: 224, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.5895153514134233 HIT: 0.7004379033537875

#### val Acc: 0, NDCG: 0.7531746143299997 HIT: 0.8198488084532374
Epoch: 240, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.5919106299216574 HIT: 0.698170691388066

#### val Acc: 0, NDCG: 0.7425925745149486 HIT: 0.8071687870292001
Epoch: 256, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.6212198687542957 HIT: 0.7239770683453237

#### val Acc: 0, NDCG: 0.7670289656279815 HIT: 0.8205745146529835
Epoch: 272, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.5521659229656413 HIT: 0.6639087626957257

#### val Acc: 0, NDCG: 0.7270266816911679 HIT: 0.7970584929115531
Epoch: 288, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.5571469677523598 HIT: 0.6702392681443081

#### val Acc: 0, NDCG: 0.7375964359618041 HIT: 0.8045684775708845
Epoch: 304, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.5728396872535589 HIT: 0.6916699177422768

#### val Acc: 0, NDCG: 0.7542907054493645 HIT: 0.822594589769361
Epoch: 320, plus 0 steps train_loss: 0.6944

#### test Acc: 0, NDCG: 0.6147478763642179 HIT: 0.7151495715192552

#### val Acc: 0, NDCG: 0.7544667401247837 HIT: 0.8157739433453237
Epoch: 352, plus 0 steps train_loss: 0.6943

#### test Acc: 0, NDCG: 0.6394006394124392 HIT: 0.734740332733813

#### val Acc: 0, NDCG: 0.7796522585813094 HIT: 0.8361383503491324
Epoch: 384, plus 0 steps train_loss: 0.6919

#### test Acc: 0, NDCG: 0.6340086854238368 HIT: 0.7322854951333051

#### val Acc: 0, NDCG: 0.777937270473953 HIT: 0.8359275814642404
Epoch: 416, plus 0 steps train_loss: 0.6915

#### test Acc: 0, NDCG: 0.5903764904690574 HIT: 0.7035936508146424

#### val Acc: 0, NDCG: 0.7426473660286322 HIT: 0.8065042451333051
Epoch: 448, plus 0 steps train_loss: 0.6937

#### test Acc: 0, NDCG: 0.6475488608006165 HIT: 0.7424321572154041

#### val Acc: 0, NDCG: 0.781812262428206 HIT: 0.8414059193821413
Epoch: 480, plus 0 steps train_loss: 0.6881

#### test Acc: 0, NDCG: 0.6271443553197843 HIT: 0.7270981009310199

#### val Acc: 0, NDCG: 0.7648829879377881 HIT: 0.8316039264176894
Epoch: 512, plus 0 steps train_loss: 0.6837

#### test Acc: 0, NDCG: 0.5318181605882166 HIT: 0.6557763899174778

#### val Acc: 0, NDCG: 0.7290922893537106 HIT: 0.8028219887325434
Epoch: 544, plus 0 steps train_loss: 0.6805

#### test Acc: 0, NDCG: 0.4718886719495662 HIT: 0.6090220654358866

#### val Acc: 0, NDCG: 0.6841472344127197 HIT: 0.7643397230744816
Epoch: 576, plus 0 steps train_loss: 0.6801

#### test Acc: 0, NDCG: 0.2762411000876253 HIT: 0.4538573185569192

#### val Acc: 0, NDCG: 0.5610072156696762 HIT: 0.6666487581993229
Epoch: 608, plus 0 steps train_loss: 0.6751

#### test Acc: 0, NDCG: 0.2559197773746825 HIT: 0.4539110439589505

#### val Acc: 0, NDCG: 0.5502778231766018 HIT: 0.6596884257300042
Epoch: 640, plus 0 steps train_loss: 0.6514

#### test Acc: 0, NDCG: 0.27204350074388356 HIT: 0.47083619868810833

#### val Acc: 0, NDCG: 0.5645058460085799 HIT: 0.6783848656369023
Epoch: 704, plus 0 steps train_loss: 0.6586

#### test Acc: 0, NDCG: 0.26637176952470626 HIT: 0.4640155522640711

#### val Acc: 0, NDCG: 0.5498023548960326 HIT: 0.6662925174566229
Epoch: 768, plus 0 steps train_loss: 0.6655

#### test Acc: 0, NDCG: 0.27370618669733293 HIT: 0.4663133463817181

#### val Acc: 0, NDCG: 0.5562636325038146 HIT: 0.6674777824798985
Epoch: 832, plus 0 steps train_loss: 0.6367

#### test Acc: 0, NDCG: 0.2759288855973325 HIT: 0.47135692181548877

#### val Acc: 0, NDCG: 0.5643222280489204 HIT: 0.6693697431760475
Epoch: 896, plus 0 steps train_loss: 0.6507

#### test Acc: 0, NDCG: 0.27994794900505593 HIT: 0.47338112965509943

#### val Acc: 0, NDCG: 0.5662896959691966 HIT: 0.674243050412611
Epoch: 960, plus 0 steps train_loss: 0.6252

#### test Acc: 0, NDCG: 0.27842814126902526 HIT: 0.4715387616377486

#### val Acc: 0, NDCG: 0.5671015528472801 HIT: 0.6791833077655522
Epoch: 1017, plus 0 steps train_loss: 0.6497
Done: it took 81192.80553746223
max value of NDCG: 0.6475488608006165
max value of HIT: 0.7424321572154041

After 20 validations
max value of NDCG: 0.6475488608006165
max value of HIT: 0.7424321572154041
