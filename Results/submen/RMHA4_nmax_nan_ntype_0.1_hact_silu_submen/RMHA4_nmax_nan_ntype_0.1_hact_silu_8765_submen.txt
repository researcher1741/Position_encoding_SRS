 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12287348512429602 HIT: 0.26802859183241645

#### val Acc: 0, NDCG: 0.47792664315028377 HIT: 0.5740856763118917
Epoch: 1, plus 0 steps train_loss: 0.812

#### test Acc: 0, NDCG: 0.12444437302460021 HIT: 0.2783860227994075

#### val Acc: 0, NDCG: 0.4781318764888269 HIT: 0.5734442776661024
Epoch: 2, plus 0 steps train_loss: 0.8149

#### test Acc: 0, NDCG: 0.12616436739917092 HIT: 0.28082928877486246

#### val Acc: 0, NDCG: 0.48317218227388803 HIT: 0.5726879893144308
Epoch: 3, plus 0 steps train_loss: 0.8171

#### test Acc: 0, NDCG: 0.13026862613659523 HIT: 0.28520666922344473

#### val Acc: 0, NDCG: 0.488797627712502 HIT: 0.5861895961172239
Epoch: 4, plus 0 steps train_loss: 0.7898

#### test Acc: 0, NDCG: 0.1334920194203991 HIT: 0.28613322577232336

#### val Acc: 0, NDCG: 0.4738695862160327 HIT: 0.5701546299724926
Epoch: 5, plus 0 steps train_loss: 0.7756

#### test Acc: 0, NDCG: 0.1351824582967721 HIT: 0.2953591171180702

#### val Acc: 0, NDCG: 0.47442809539155006 HIT: 0.5687032175730004
Epoch: 6, plus 0 steps train_loss: 0.7819

#### test Acc: 0, NDCG: 0.1324398476826217 HIT: 0.2906428533643673

#### val Acc: 0, NDCG: 0.4760460423370489 HIT: 0.5723739023487093
Epoch: 7, plus 0 steps train_loss: 0.7763

#### test Acc: 0, NDCG: 0.12860806423732307 HIT: 0.28185172450275076

#### val Acc: 0, NDCG: 0.4729450091791282 HIT: 0.5697256533008886
Epoch: 8, plus 0 steps train_loss: 0.7604

#### test Acc: 0, NDCG: 0.12801621052588155 HIT: 0.2809689748201439

#### val Acc: 0, NDCG: 0.4866495572797085 HIT: 0.5806575327972916
Epoch: 9, plus 0 steps train_loss: 0.7827

#### test Acc: 0, NDCG: 0.12950647435530596 HIT: 0.28679776766821835

#### val Acc: 0, NDCG: 0.47646235387291247 HIT: 0.570208355374524
Epoch: 10, plus 0 steps train_loss: 0.7715

#### test Acc: 0, NDCG: 0.12931763506909497 HIT: 0.2862233191388066

#### val Acc: 0, NDCG: 0.48752683971908134 HIT: 0.581570864631824
Epoch: 12, plus 0 steps train_loss: 0.7609

#### test Acc: 0, NDCG: 0.13580067491253836 HIT: 0.3007647191070673

#### val Acc: 0, NDCG: 0.48160007662292964 HIT: 0.5757710008463817
Epoch: 14, plus 0 steps train_loss: 0.7738

#### test Acc: 0, NDCG: 0.1348950050562634 HIT: 0.29502188690224296

#### val Acc: 0, NDCG: 0.4762228072649479 HIT: 0.5711274730215827
Epoch: 16, plus 0 steps train_loss: 0.7607

#### test Acc: 0, NDCG: 0.1324698800627577 HIT: 0.2982619419170546

#### val Acc: 0, NDCG: 0.4714636125009201 HIT: 0.5650631149492171
Epoch: 18, plus 0 steps train_loss: 0.7617

#### test Acc: 0, NDCG: 0.13779152428393576 HIT: 0.29538969926999575

#### val Acc: 0, NDCG: 0.4717753474539588 HIT: 0.5582482543377063
Epoch: 20, plus 0 steps train_loss: 0.753

#### test Acc: 0, NDCG: 0.12769436842112217 HIT: 0.2816393025285654

#### val Acc: 0, NDCG: 0.4742944458889673 HIT: 0.5653408339504867
Epoch: 22, plus 0 steps train_loss: 0.7444

#### test Acc: 0, NDCG: 0.1314000776355908 HIT: 0.28561250264494287

#### val Acc: 0, NDCG: 0.4754697715334646 HIT: 0.5657582389970377
Epoch: 24, plus 0 steps train_loss: 0.7356

#### test Acc: 0, NDCG: 0.12793619822670296 HIT: 0.2764576941388066

#### val Acc: 0, NDCG: 0.4864234277276137 HIT: 0.5775860928903935
Epoch: 26, plus 0 steps train_loss: 0.7383

#### test Acc: 0, NDCG: 0.13744505101751317 HIT: 0.29200995820990266

#### val Acc: 0, NDCG: 0.491028963884244 HIT: 0.5931383569614896
Epoch: 28, plus 0 steps train_loss: 0.725

#### test Acc: 0, NDCG: 0.1475467778499746 HIT: 0.30319641345746934

#### val Acc: 0, NDCG: 0.47918335341362567 HIT: 0.5719317009627592
Epoch: 30, plus 0 steps train_loss: 0.7252

#### test Acc: 0, NDCG: 0.15657459564567833 HIT: 0.31539786553110455

#### val Acc: 0, NDCG: 0.48933111600492807 HIT: 0.5805542147164621
Epoch: 32, plus 0 steps train_loss: 0.7241

#### test Acc: 0, NDCG: 0.1581457170644892 HIT: 0.3145093300359712

#### val Acc: 0, NDCG: 0.4965764396052619 HIT: 0.5853564391134152
Epoch: 36, plus 0 steps train_loss: 0.7188

#### test Acc: 0, NDCG: 0.20174713115021187 HIT: 0.3503549182712653

#### val Acc: 0, NDCG: 0.5239135470584247 HIT: 0.6113810238573847
Epoch: 40, plus 0 steps train_loss: 0.7194

#### test Acc: 0, NDCG: 0.2264156270525483 HIT: 0.3723104237198477

#### val Acc: 0, NDCG: 0.522213991739716 HIT: 0.6087691427740162
Epoch: 44, plus 0 steps train_loss: 0.71

#### test Acc: 0, NDCG: 0.2430833836906342 HIT: 0.3822347452920017

#### val Acc: 0, NDCG: 0.5455121989692875 HIT: 0.629981584585273
Epoch: 48, plus 0 steps train_loss: 0.7068

#### test Acc: 0, NDCG: 0.2608641467200826 HIT: 0.40720052634363096

#### val Acc: 0, NDCG: 0.5328548545323096 HIT: 0.617391656527719
Epoch: 52, plus 0 steps train_loss: 0.7086

#### test Acc: 0, NDCG: 0.2619393897956279 HIT: 0.4023387907321202

#### val Acc: 0, NDCG: 0.5487313017788182 HIT: 0.6341233998095641
Epoch: 56, plus 0 steps train_loss: 0.71

#### test Acc: 0, NDCG: 0.265872162666486 HIT: 0.40046418747355056

#### val Acc: 0, NDCG: 0.559562233469845 HIT: 0.6393050081993229
Epoch: 60, plus 0 steps train_loss: 0.7191

#### test Acc: 0, NDCG: 0.28971521619243734 HIT: 0.4268102980850614

#### val Acc: 0, NDCG: 0.5660699040671252 HIT: 0.6522759733389759
Epoch: 64, plus 0 steps train_loss: 0.7072

#### test Acc: 0, NDCG: 0.24141365856488192 HIT: 0.3864840113203555

#### val Acc: 0, NDCG: 0.5394667877485696 HIT: 0.6255356009310199
Epoch: 68, plus 0 steps train_loss: 0.7052

#### test Acc: 0, NDCG: 0.23269288471514943 HIT: 0.37815822709479474

#### val Acc: 0, NDCG: 0.5353838306861969 HIT: 0.622477385738468
Epoch: 72, plus 0 steps train_loss: 0.7123

#### test Acc: 0, NDCG: 0.21432809725398153 HIT: 0.35597872804697417

#### val Acc: 0, NDCG: 0.5316305704965376 HIT: 0.6150095548561151
Epoch: 80, plus 0 steps train_loss: 0.7049

#### test Acc: 0, NDCG: 0.24131258812832707 HIT: 0.3874394969318663

#### val Acc: 0, NDCG: 0.5392304391120941 HIT: 0.6262208064430808
Epoch: 88, plus 0 steps train_loss: 0.7046

#### test Acc: 0, NDCG: 0.22308830353042944 HIT: 0.36363997037663987

#### val Acc: 0, NDCG: 0.5383670732820527 HIT: 0.6206143541049514
Epoch: 96, plus 0 steps train_loss: 0.7054

#### test Acc: 0, NDCG: 0.2424134330363565 HIT: 0.3872039317075751

#### val Acc: 0, NDCG: 0.5340526747053536 HIT: 0.6109999867752857
Epoch: 104, plus 0 steps train_loss: 0.7037

#### test Acc: 0, NDCG: 0.24133084487866505 HIT: 0.3871063994392721

#### val Acc: 0, NDCG: 0.5472150903994456 HIT: 0.629393911341515
Epoch: 112, plus 0 steps train_loss: 0.7031

#### test Acc: 0, NDCG: 0.2334960932938157 HIT: 0.3742693345323741

#### val Acc: 0, NDCG: 0.5436746918998624 HIT: 0.6257306654676259
Epoch: 120, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.22665180496832849 HIT: 0.3661733297185781

#### val Acc: 0, NDCG: 0.5228190151360151 HIT: 0.6073540983389759
Epoch: 128, plus 0 steps train_loss: 0.7029

#### test Acc: 0, NDCG: 0.26348530685542254 HIT: 0.40351826994286927

#### val Acc: 0, NDCG: 0.5520469463796852 HIT: 0.6357988058082945
Epoch: 136, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.2912526392255715 HIT: 0.4296461727676682

#### val Acc: 0, NDCG: 0.5685728662523796 HIT: 0.646972036341515
Epoch: 144, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.25479472009627996 HIT: 0.3941336820249683

#### val Acc: 0, NDCG: 0.544008925050099 HIT: 0.632218214399069
Epoch: 160, plus 0 steps train_loss: 0.7016

#### test Acc: 0, NDCG: 0.22165806298729185 HIT: 0.3593584691070673

#### val Acc: 0, NDCG: 0.5368240420909108 HIT: 0.6222476063267033
Epoch: 176, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.2301201603376931 HIT: 0.3715252063055438

#### val Acc: 0, NDCG: 0.5357728000757078 HIT: 0.6222707495768091
Epoch: 192, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.23074868498962114 HIT: 0.37462557527507406

#### val Acc: 0, NDCG: 0.5378983851397853 HIT: 0.6211466488573847
Epoch: 208, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.36031647029435154 HIT: 0.4897508463817181

#### val Acc: 0, NDCG: 0.6164565908972153 HIT: 0.6959629906369023
Epoch: 224, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.29670128060479156 HIT: 0.4300635778142192

#### val Acc: 0, NDCG: 0.57367056888235 HIT: 0.6524330168218366
Epoch: 240, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.29453579326860846 HIT: 0.43708920731062206

#### val Acc: 0, NDCG: 0.5520578056727841 HIT: 0.6319041274333475
Epoch: 256, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.26719745223466657 HIT: 0.4031736008252222

#### val Acc: 0, NDCG: 0.541646146380297 HIT: 0.6259356485399915
Epoch: 272, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.331670044674765 HIT: 0.458301649121879

#### val Acc: 0, NDCG: 0.5797474232573644 HIT: 0.6608199653512484
Epoch: 288, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.30880851776089924 HIT: 0.44485955353364365

#### val Acc: 0, NDCG: 0.5933819315702221 HIT: 0.6716179446148963
Epoch: 304, plus 0 steps train_loss: 0.693

#### test Acc: 0, NDCG: 0.3025400886268801 HIT: 0.437996753332628

#### val Acc: 0, NDCG: 0.5847483497146102 HIT: 0.6660379417054592
Epoch: 320, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.3576055214627888 HIT: 0.4824822127592044

#### val Acc: 0, NDCG: 0.605789585013451 HIT: 0.6849583752115954
Epoch: 352, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.28261439178329284 HIT: 0.4252803639441388

#### val Acc: 0, NDCG: 0.5686144797431955 HIT: 0.6499649545069827
Epoch: 384, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.3908079048319579 HIT: 0.5298109857702074

#### val Acc: 0, NDCG: 0.6376484449234323 HIT: 0.7133534900021159
Epoch: 416, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.4036975993785027 HIT: 0.5419529266292847

#### val Acc: 0, NDCG: 0.623138568567415 HIT: 0.6987988653195091
Epoch: 448, plus 0 steps train_loss: 0.6931

#### test Acc: 0, NDCG: 0.4696156473553629 HIT: 0.6016881347862887

#### val Acc: 0, NDCG: 0.6680780284244501 HIT: 0.7424817498942023
Epoch: 480, plus 0 steps train_loss: 0.6938

#### test Acc: 0, NDCG: 0.6278058159345656 HIT: 0.7311539555120609

#### val Acc: 0, NDCG: 0.7820895754000414 HIT: 0.8400809683135845
Epoch: 512, plus 0 steps train_loss: 0.6881

#### test Acc: 0, NDCG: 0.5907880158372965 HIT: 0.7032489816969953

#### val Acc: 0, NDCG: 0.7426685503044806 HIT: 0.8108031038404571
Epoch: 544, plus 0 steps train_loss: 0.6805

#### test Acc: 0, NDCG: 0.5694139656670469 HIT: 0.6810942789885738

#### val Acc: 0, NDCG: 0.7277950138186198 HIT: 0.7929588314642404
Epoch: 576, plus 0 steps train_loss: 0.6834

#### test Acc: 0, NDCG: 0.452258163548529 HIT: 0.60529186944562

#### val Acc: 0, NDCG: 0.6389920198429081 HIT: 0.7220793218366482
Epoch: 608, plus 0 steps train_loss: 0.6788

#### test Acc: 0, NDCG: 0.45081436566450056 HIT: 0.5946319231379602

#### val Acc: 0, NDCG: 0.6577863269044629 HIT: 0.741779186944562
Epoch: 640, plus 0 steps train_loss: 0.6762

#### test Acc: 0, NDCG: 0.4439571170691674 HIT: 0.5970198106220906

#### val Acc: 0, NDCG: 0.6459679357232191 HIT: 0.7302133477041896
Epoch: 704, plus 0 steps train_loss: 0.6764

#### test Acc: 0, NDCG: 0.3443217691696657 HIT: 0.5305118956305543

#### val Acc: 0, NDCG: 0.6011347325317061 HIT: 0.6911797767668219
Epoch: 768, plus 0 steps train_loss: 0.6653

#### test Acc: 0, NDCG: 0.3107425505288775 HIT: 0.49218832654464667

#### val Acc: 0, NDCG: 0.5768622737625924 HIT: 0.6792312473550571
Epoch: 832, plus 0 steps train_loss: 0.6718

#### test Acc: 0, NDCG: 0.31147504351836336 HIT: 0.4975633463817181

#### val Acc: 0, NDCG: 0.5668232346026507 HIT: 0.6646286830829454
Epoch: 896, plus 0 steps train_loss: 0.6688

#### test Acc: 0, NDCG: 0.3096383121639029 HIT: 0.5017415295704613

#### val Acc: 0, NDCG: 0.5750173556837013 HIT: 0.6772839081675837
Epoch: 960, plus 0 steps train_loss: 0.6632

#### test Acc: 0, NDCG: 0.3191014482490161 HIT: 0.507315746667372

#### val Acc: 0, NDCG: 0.5718930672606982 HIT: 0.6760085497778248
Epoch: 1017, plus 0 steps train_loss: 0.6677
Done: it took 82823.65226721764
max value of NDCG: 0.6278058159345656
max value of HIT: 0.7311539555120609

After 20 validations
max value of NDCG: 0.6278058159345656
max value of HIT: 0.7311539555120609
