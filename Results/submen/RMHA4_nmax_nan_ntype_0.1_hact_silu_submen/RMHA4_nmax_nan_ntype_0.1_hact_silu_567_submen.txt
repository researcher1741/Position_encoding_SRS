 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12404121713586799 HIT: 0.27844718710325855

#### val Acc: 0, NDCG: 0.48691316789920847 HIT: 0.5781299592678798
Epoch: 1, plus 0 steps train_loss: 0.7647

#### test Acc: 0, NDCG: 0.12422582535345876 HIT: 0.2803639441388066

#### val Acc: 0, NDCG: 0.4754059353260498 HIT: 0.5679295717837495
Epoch: 2, plus 0 steps train_loss: 0.7806

#### test Acc: 0, NDCG: 0.1261762519594953 HIT: 0.2858902216462124

#### val Acc: 0, NDCG: 0.47413844298183394 HIT: 0.5625355414198053
Epoch: 3, plus 0 steps train_loss: 0.7691

#### test Acc: 0, NDCG: 0.1235090759772322 HIT: 0.2805209876216674

#### val Acc: 0, NDCG: 0.4777908346116283 HIT: 0.5705588103046974
Epoch: 4, plus 0 steps train_loss: 0.7625

#### test Acc: 0, NDCG: 0.1251885671158084 HIT: 0.28269810622090563

#### val Acc: 0, NDCG: 0.4849752976202413 HIT: 0.576067730374524
Epoch: 5, plus 0 steps train_loss: 0.7852

#### test Acc: 0, NDCG: 0.1268581464091847 HIT: 0.278452972915785

#### val Acc: 0, NDCG: 0.47573400715449715 HIT: 0.5661392760791367
Epoch: 6, plus 0 steps train_loss: 0.7727

#### test Acc: 0, NDCG: 0.12092496986661053 HIT: 0.27442604739737625

#### val Acc: 0, NDCG: 0.4806799250540857 HIT: 0.5723069522323319
Epoch: 7, plus 0 steps train_loss: 0.7682

#### test Acc: 0, NDCG: 0.12081995765412715 HIT: 0.2766990451756242

#### val Acc: 0, NDCG: 0.4819610654214154 HIT: 0.565945864631824
Epoch: 8, plus 0 steps train_loss: 0.7707

#### test Acc: 0, NDCG: 0.12695464635037298 HIT: 0.285467030787135

#### val Acc: 0, NDCG: 0.47077362367404435 HIT: 0.5591863825116378
Epoch: 9, plus 0 steps train_loss: 0.7728

#### test Acc: 0, NDCG: 0.1297968847561371 HIT: 0.2922455234341938

#### val Acc: 0, NDCG: 0.47823042607238925 HIT: 0.5655474701121456
Epoch: 10, plus 0 steps train_loss: 0.7713

#### test Acc: 0, NDCG: 0.1352970050396498 HIT: 0.2943804882564537

#### val Acc: 0, NDCG: 0.47006305070750787 HIT: 0.5590409106538299
Epoch: 12, plus 0 steps train_loss: 0.7592

#### test Acc: 0, NDCG: 0.1283937949199853 HIT: 0.2922339518091409

#### val Acc: 0, NDCG: 0.472304846250998 HIT: 0.5669740861722387
Epoch: 14, plus 0 steps train_loss: 0.7573

#### test Acc: 0, NDCG: 0.12880165604820848 HIT: 0.28952453845746934

#### val Acc: 0, NDCG: 0.477516531716252 HIT: 0.5684370701967838
Epoch: 16, plus 0 steps train_loss: 0.7484

#### test Acc: 0, NDCG: 0.12424543912253345 HIT: 0.2698304591620821

#### val Acc: 0, NDCG: 0.4828303770349538 HIT: 0.5769198979052053
Epoch: 18, plus 0 steps train_loss: 0.7441

#### test Acc: 0, NDCG: 0.12857409075382928 HIT: 0.2819360320567076

#### val Acc: 0, NDCG: 0.47027551368753684 HIT: 0.5584243083474396
Epoch: 20, plus 0 steps train_loss: 0.7207

#### test Acc: 0, NDCG: 0.14267989820732996 HIT: 0.29738497804697417

#### val Acc: 0, NDCG: 0.4909491495597192 HIT: 0.5808393726195513
Epoch: 22, plus 0 steps train_loss: 0.7252

#### test Acc: 0, NDCG: 0.15713215322543372 HIT: 0.31259257300042315

#### val Acc: 0, NDCG: 0.4981630452644437 HIT: 0.589322200327973
Epoch: 24, plus 0 steps train_loss: 0.7222

#### test Acc: 0, NDCG: 0.18995720966541818 HIT: 0.33710623413034274

#### val Acc: 0, NDCG: 0.5158246433075349 HIT: 0.608497209585273
Epoch: 26, plus 0 steps train_loss: 0.7122

#### test Acc: 0, NDCG: 0.2771299985881261 HIT: 0.42709380289885734

#### val Acc: 0, NDCG: 0.5704754288910432 HIT: 0.6566475679750318
Epoch: 28, plus 0 steps train_loss: 0.7145

#### test Acc: 0, NDCG: 0.30153106969552207 HIT: 0.45163804618070247

#### val Acc: 0, NDCG: 0.5789190749992051 HIT: 0.6695631546233601
Epoch: 30, plus 0 steps train_loss: 0.7145

#### test Acc: 0, NDCG: 0.31732955717251365 HIT: 0.4687202443927211

#### val Acc: 0, NDCG: 0.5988320970849269 HIT: 0.6847765353893356
Epoch: 32, plus 0 steps train_loss: 0.714

#### test Acc: 0, NDCG: 0.335133331404949 HIT: 0.4835468022640711

#### val Acc: 0, NDCG: 0.6032558956422198 HIT: 0.6885083844688955
Epoch: 36, plus 0 steps train_loss: 0.7098

#### test Acc: 0, NDCG: 0.30531929524882484 HIT: 0.4508453898645789

#### val Acc: 0, NDCG: 0.5867682000965065 HIT: 0.6738810238573847
Epoch: 40, plus 0 steps train_loss: 0.7122

#### test Acc: 0, NDCG: 0.28777477618825154 HIT: 0.4279765525814642

#### val Acc: 0, NDCG: 0.5691774605161991 HIT: 0.6514775312103259
Epoch: 44, plus 0 steps train_loss: 0.7075

#### test Acc: 0, NDCG: 0.37860182390189207 HIT: 0.5146934841832416

#### val Acc: 0, NDCG: 0.6227448035473312 HIT: 0.7039631162716885
Epoch: 48, plus 0 steps train_loss: 0.7061

#### test Acc: 0, NDCG: 0.3025575629028336 HIT: 0.4449322894625476

#### val Acc: 0, NDCG: 0.5789613081769607 HIT: 0.6604141319297503
Epoch: 52, plus 0 steps train_loss: 0.7054

#### test Acc: 0, NDCG: 0.3269006012612368 HIT: 0.4650016200275074

#### val Acc: 0, NDCG: 0.602714115313713 HIT: 0.6875528988573847
Epoch: 56, plus 0 steps train_loss: 0.7031

#### test Acc: 0, NDCG: 0.34310364062383203 HIT: 0.4845692379919594

#### val Acc: 0, NDCG: 0.6091085602790731 HIT: 0.6882174407532797
Epoch: 60, plus 0 steps train_loss: 0.7069

#### test Acc: 0, NDCG: 0.3055863405635827 HIT: 0.4483541842996191

#### val Acc: 0, NDCG: 0.5827792311707924 HIT: 0.6684200433770631
Epoch: 64, plus 0 steps train_loss: 0.7018

#### test Acc: 0, NDCG: 0.28398670477108334 HIT: 0.42801870635844264

#### val Acc: 0, NDCG: 0.5676490598432509 HIT: 0.6502980519995768
Epoch: 68, plus 0 steps train_loss: 0.7061

#### test Acc: 0, NDCG: 0.2912092494088202 HIT: 0.43546917980321626

#### val Acc: 0, NDCG: 0.5710203415179835 HIT: 0.6589627195302581
Epoch: 72, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.23090910388065009 HIT: 0.38736676100296236

#### val Acc: 0, NDCG: 0.5414516646393197 HIT: 0.6378726063267033
Epoch: 80, plus 0 steps train_loss: 0.7033

#### test Acc: 0, NDCG: 0.3078386689262041 HIT: 0.44771443874312317

#### val Acc: 0, NDCG: 0.5888330571796763 HIT: 0.6691151674248835
Epoch: 88, plus 0 steps train_loss: 0.7036

#### test Acc: 0, NDCG: 0.27891715547101315 HIT: 0.42965195858019467

#### val Acc: 0, NDCG: 0.5771755244658474 HIT: 0.6650345165044436
Epoch: 96, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.29019756238848915 HIT: 0.43791823159119764

#### val Acc: 0, NDCG: 0.5720794404125712 HIT: 0.6566533537875582
Epoch: 104, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.39101658451896837 HIT: 0.5210793681231486

#### val Acc: 0, NDCG: 0.6218844460054812 HIT: 0.7047003940964875
Epoch: 112, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.2695635489820656 HIT: 0.4174124854528142

#### val Acc: 0, NDCG: 0.5532258708460266 HIT: 0.6446800280363945
Epoch: 120, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.2542821598681768 HIT: 0.4065359844477359

#### val Acc: 0, NDCG: 0.5520198317642233 HIT: 0.6449594001269573
Epoch: 128, plus 0 steps train_loss: 0.7002

#### test Acc: 0, NDCG: 0.384998909908495 HIT: 0.5249971897482014

#### val Acc: 0, NDCG: 0.6283319141086189 HIT: 0.7096712336013542
Epoch: 136, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.3209920440335316 HIT: 0.4658116337812103

#### val Acc: 0, NDCG: 0.6030728647285143 HIT: 0.68474595323741
Epoch: 144, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.33906803922755635 HIT: 0.4818713962653407

#### val Acc: 0, NDCG: 0.6150427360350511 HIT: 0.7019372553427846
Epoch: 160, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.3493242256222018 HIT: 0.48890446466356324

#### val Acc: 0, NDCG: 0.6050887961661954 HIT: 0.6945537320143885
Epoch: 176, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.45758259638467413 HIT: 0.5855672079983072

#### val Acc: 0, NDCG: 0.6682772662062517 HIT: 0.751127406898011
Epoch: 192, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.5280672728536216 HIT: 0.6463554340351249

#### val Acc: 0, NDCG: 0.7163006450255157 HIT: 0.7918405165573423
Epoch: 208, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.4149666081057092 HIT: 0.5446549010791367

#### val Acc: 0, NDCG: 0.6368272190859452 HIT: 0.7192318755289886
Epoch: 224, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.375088880254217 HIT: 0.5164474119234024

#### val Acc: 0, NDCG: 0.604256420186578 HIT: 0.6853509839187474
Epoch: 240, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.34862478633608857 HIT: 0.4886019493228946

#### val Acc: 0, NDCG: 0.5996718284414294 HIT: 0.6858948502962336
Epoch: 256, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.40726132360762174 HIT: 0.5447582191599661

#### val Acc: 0, NDCG: 0.6503221982326335 HIT: 0.7427288867435464
Epoch: 272, plus 0 steps train_loss: 0.6936

#### test Acc: 0, NDCG: 0.3420326711976531 HIT: 0.4906509535019043

#### val Acc: 0, NDCG: 0.5834751228033681 HIT: 0.6751315859077444
Epoch: 288, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.2560766484939133 HIT: 0.4112580340139653

#### val Acc: 0, NDCG: 0.5550477307145298 HIT: 0.6487623320461279
Epoch: 304, plus 0 steps train_loss: 0.6953

#### test Acc: 0, NDCG: 0.36031460221100053 HIT: 0.5085373796550995

#### val Acc: 0, NDCG: 0.6060259997454506 HIT: 0.7014719107067287
Epoch: 320, plus 0 steps train_loss: 0.6942

#### test Acc: 0, NDCG: 0.32936785461951457 HIT: 0.49278591832416424

#### val Acc: 0, NDCG: 0.6017271860101433 HIT: 0.6940404477888278
Epoch: 352, plus 0 steps train_loss: 0.6943

#### test Acc: 0, NDCG: 0.42007002744387745 HIT: 0.5640596897482014

#### val Acc: 0, NDCG: 0.6404679093890844 HIT: 0.7280593723550571
Epoch: 384, plus 0 steps train_loss: 0.6918

#### test Acc: 0, NDCG: 0.52924903219853 HIT: 0.6456660957998307

#### val Acc: 0, NDCG: 0.7103275544970609 HIT: 0.7826857080512061
Epoch: 416, plus 0 steps train_loss: 0.6915

#### test Acc: 0, NDCG: 0.4776627646866705 HIT: 0.6134432527507405

#### val Acc: 0, NDCG: 0.6790732492233638 HIT: 0.7601979078501904
Epoch: 448, plus 0 steps train_loss: 0.6849

#### test Acc: 0, NDCG: 0.5484385260293466 HIT: 0.6604389282691494

#### val Acc: 0, NDCG: 0.737752254901969 HIT: 0.8105733244286923
Epoch: 480, plus 0 steps train_loss: 0.6802

#### test Acc: 0, NDCG: 0.4898616305029805 HIT: 0.6261117025497249

#### val Acc: 0, NDCG: 0.6802765196746091 HIT: 0.7629188928269149
Epoch: 512, plus 0 steps train_loss: 0.6834

#### test Acc: 0, NDCG: 0.3906933010195304 HIT: 0.5448731088658485

#### val Acc: 0, NDCG: 0.6187024681955187 HIT: 0.7122351750952179
Epoch: 544, plus 0 steps train_loss: 0.6714

#### test Acc: 0, NDCG: 0.2855719873062941 HIT: 0.4766476340986035

#### val Acc: 0, NDCG: 0.5601016857088342 HIT: 0.6687589266821836
Epoch: 576, plus 0 steps train_loss: 0.6828

#### test Acc: 0, NDCG: 0.2672618042848561 HIT: 0.4492253623571731

#### val Acc: 0, NDCG: 0.5445960840650571 HIT: 0.6405630091515023
Epoch: 608, plus 0 steps train_loss: 0.6646

#### test Acc: 0, NDCG: 0.2849992206018592 HIT: 0.46814579586330934

#### val Acc: 0, NDCG: 0.5575969556999759 HIT: 0.6620168019995768
Epoch: 640, plus 0 steps train_loss: 0.6712

#### test Acc: 0, NDCG: 0.2857549500531078 HIT: 0.47142221884257296

#### val Acc: 0, NDCG: 0.5584216389058253 HIT: 0.6654329110241219
Epoch: 704, plus 0 steps train_loss: 0.6618

#### test Acc: 0, NDCG: 0.28746460930072504 HIT: 0.47635090457046125

#### val Acc: 0, NDCG: 0.5643049957514055 HIT: 0.6665512259310199
Epoch: 768, plus 0 steps train_loss: 0.6531

#### test Acc: 0, NDCG: 0.27918891489083825 HIT: 0.4563791062738045

#### val Acc: 0, NDCG: 0.5534418254541789 HIT: 0.6516651568451122
Epoch: 832, plus 0 steps train_loss: 0.6591

#### test Acc: 0, NDCG: 0.2873980241642218 HIT: 0.47690799566229375

#### val Acc: 0, NDCG: 0.5548824390547824 HIT: 0.6559698013647906
Epoch: 896, plus 0 steps train_loss: 0.6412

#### test Acc: 0, NDCG: 0.28800406002885964 HIT: 0.47179168429961915

#### val Acc: 0, NDCG: 0.5507331398311159 HIT: 0.6567682434934405
Epoch: 960, plus 0 steps train_loss: 0.6403

#### test Acc: 0, NDCG: 0.2863490895903893 HIT: 0.4723719186415573

#### val Acc: 0, NDCG: 0.554659638742435 HIT: 0.6568889190118493
Epoch: 1017, plus 0 steps train_loss: 0.6563
Done: it took 81181.38791942596
max value of NDCG: 0.5484385260293466
max value of HIT: 0.6604389282691494

After 20 validations
max value of NDCG: 0.5484385260293466
max value of HIT: 0.6604389282691494
