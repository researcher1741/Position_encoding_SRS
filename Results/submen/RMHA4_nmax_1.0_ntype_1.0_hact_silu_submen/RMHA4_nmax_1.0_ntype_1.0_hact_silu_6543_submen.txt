 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	1.0
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13094724745643216 HIT: 0.2888599965615743

#### val Acc: 0, NDCG: 0.4829488071761898 HIT: 0.5682684550888701
Epoch: 1, plus 0 steps train_loss: 0.7876

#### test Acc: 0, NDCG: 0.12595834204976855 HIT: 0.28397925042319083

#### val Acc: 0, NDCG: 0.4777239011891329 HIT: 0.5663211159013964
Epoch: 2, plus 0 steps train_loss: 0.7656

#### test Acc: 0, NDCG: 0.12708532414656623 HIT: 0.2839007286817605

#### val Acc: 0, NDCG: 0.48133696729729264 HIT: 0.572948350878121
Epoch: 3, plus 0 steps train_loss: 0.7559

#### test Acc: 0, NDCG: 0.12278579322395256 HIT: 0.2743417398434194

#### val Acc: 0, NDCG: 0.48230642840000176 HIT: 0.5753056562103259
Epoch: 4, plus 0 steps train_loss: 0.7579

#### test Acc: 0, NDCG: 0.12991125665708145 HIT: 0.28455369895260263

#### val Acc: 0, NDCG: 0.4986211251545564 HIT: 0.5946856485399915
Epoch: 5, plus 0 steps train_loss: 0.7396

#### test Acc: 0, NDCG: 0.12579879037458455 HIT: 0.2806722452920017

#### val Acc: 0, NDCG: 0.47383878486608777 HIT: 0.5664360056072788
Epoch: 6, plus 0 steps train_loss: 0.7364

#### test Acc: 0, NDCG: 0.12502712098474214 HIT: 0.27868275232754974

#### val Acc: 0, NDCG: 0.4801527039001795 HIT: 0.577725778935675
Epoch: 7, plus 0 steps train_loss: 0.7405

#### test Acc: 0, NDCG: 0.1321083552208695 HIT: 0.28593237542319083

#### val Acc: 0, NDCG: 0.47862634297399964 HIT: 0.570443920598815
Epoch: 8, plus 0 steps train_loss: 0.7241

#### test Acc: 0, NDCG: 0.12601816502079607 HIT: 0.27047764362039783

#### val Acc: 0, NDCG: 0.4792623149322293 HIT: 0.5649060714663563
Epoch: 9, plus 0 steps train_loss: 0.7178

#### test Acc: 0, NDCG: 0.12969487357335371 HIT: 0.2844330234341938

#### val Acc: 0, NDCG: 0.47912905200176387 HIT: 0.5669856577972916
Epoch: 10, plus 0 steps train_loss: 0.7209

#### test Acc: 0, NDCG: 0.13046612576964475 HIT: 0.28416687605797714

#### val Acc: 0, NDCG: 0.47244117623053666 HIT: 0.5645977703131612
Epoch: 12, plus 0 steps train_loss: 0.7155

#### test Acc: 0, NDCG: 0.1406197991609655 HIT: 0.2974155601988997

#### val Acc: 0, NDCG: 0.4845387951653969 HIT: 0.5727607252433348
Epoch: 14, plus 0 steps train_loss: 0.7152

#### test Acc: 0, NDCG: 0.15913681299789925 HIT: 0.3109477491536183

#### val Acc: 0, NDCG: 0.487828306423343 HIT: 0.5777604938108337
Epoch: 16, plus 0 steps train_loss: 0.7177

#### test Acc: 0, NDCG: 0.15782962856771088 HIT: 0.31095932077867117

#### val Acc: 0, NDCG: 0.48465118943852054 HIT: 0.5758321651502327
Epoch: 18, plus 0 steps train_loss: 0.7108

#### test Acc: 0, NDCG: 0.1479475513605554 HIT: 0.3025798111510791

#### val Acc: 0, NDCG: 0.490310232952809 HIT: 0.5790854448793906
Epoch: 20, plus 0 steps train_loss: 0.7091

#### test Acc: 0, NDCG: 0.19442639762933933 HIT: 0.33821297741218787

#### val Acc: 0, NDCG: 0.5014256026561767 HIT: 0.5930656210325856
Epoch: 22, plus 0 steps train_loss: 0.7119

#### test Acc: 0, NDCG: 0.37110805601775326 HIT: 0.5063734857702074

#### val Acc: 0, NDCG: 0.6175294947460268 HIT: 0.701979409119763
Epoch: 24, plus 0 steps train_loss: 0.7087

#### test Acc: 0, NDCG: 0.21522843604358963 HIT: 0.36592453977994077

#### val Acc: 0, NDCG: 0.524054046939347 HIT: 0.6195993572788827
Epoch: 26, plus 0 steps train_loss: 0.7084

#### test Acc: 0, NDCG: 0.14628136017497523 HIT: 0.2961459876216674

#### val Acc: 0, NDCG: 0.47797547055714773 HIT: 0.5740187261955141
Epoch: 28, plus 0 steps train_loss: 0.7119

#### test Acc: 0, NDCG: 0.1443550312260275 HIT: 0.29909096619763015

#### val Acc: 0, NDCG: 0.4841770291565768 HIT: 0.574139401713923
Epoch: 30, plus 0 steps train_loss: 0.7097

#### test Acc: 0, NDCG: 0.20618808847797626 HIT: 0.3536734950275074

#### val Acc: 0, NDCG: 0.5316569039196559 HIT: 0.6174338103046974
Epoch: 32, plus 0 steps train_loss: 0.7058

#### test Acc: 0, NDCG: 0.1883005353779547 HIT: 0.33651442816335164

#### val Acc: 0, NDCG: 0.49930864423712046 HIT: 0.5931689391134152
Epoch: 36, plus 0 steps train_loss: 0.7047

#### test Acc: 0, NDCG: 0.20627475946063373 HIT: 0.3589906567393144

#### val Acc: 0, NDCG: 0.5171936920358577 HIT: 0.6101362476195513
Epoch: 40, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.3958357186997013 HIT: 0.5323864988891239

#### val Acc: 0, NDCG: 0.6360419599803768 HIT: 0.7206948595535336
Epoch: 44, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.3999903307664817 HIT: 0.5459186878438426

#### val Acc: 0, NDCG: 0.643174575145196 HIT: 0.730085233283961
Epoch: 48, plus 0 steps train_loss: 0.7052

#### test Acc: 0, NDCG: 0.3110933498799134 HIT: 0.45975306152137113

#### val Acc: 0, NDCG: 0.594829405934787 HIT: 0.6851038470694033
Epoch: 52, plus 0 steps train_loss: 0.7023

#### test Acc: 0, NDCG: 0.4384315199549791 HIT: 0.569325605691917

#### val Acc: 0, NDCG: 0.6707204552207428 HIT: 0.7500512457680915
Epoch: 56, plus 0 steps train_loss: 0.704

#### test Acc: 0, NDCG: 0.26290480098201685 HIT: 0.41897878755818874

#### val Acc: 0, NDCG: 0.553115354345965 HIT: 0.6481151475878121
Epoch: 60, plus 0 steps train_loss: 0.7038

#### test Acc: 0, NDCG: 0.5522635881270533 HIT: 0.6707178374947101

#### val Acc: 0, NDCG: 0.717579177838465 HIT: 0.7924934868281844
Epoch: 64, plus 0 steps train_loss: 0.701

#### test Acc: 0, NDCG: 0.5688627651878571 HIT: 0.6834284410706729

#### val Acc: 0, NDCG: 0.7431062259318628 HIT: 0.810851043429962
Epoch: 68, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.5109624008169242 HIT: 0.6463918019995768

#### val Acc: 0, NDCG: 0.7155186360627583 HIT: 0.7858240980744816
Epoch: 72, plus 0 steps train_loss: 0.7022

#### test Acc: 0, NDCG: 0.45176548058566157 HIT: 0.5860879311256877

#### val Acc: 0, NDCG: 0.6728384552194885 HIT: 0.7600044964028777
Epoch: 80, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.4364900785250584 HIT: 0.5624876018303004

#### val Acc: 0, NDCG: 0.6580767108405802 HIT: 0.7436116364261531
Epoch: 88, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.5681232576864875 HIT: 0.6868809180596699

#### val Acc: 0, NDCG: 0.7309564941379461 HIT: 0.7987818384997883
Epoch: 96, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.5818535224939694 HIT: 0.6837557527507405

#### val Acc: 0, NDCG: 0.753780837132143 HIT: 0.8219110373465933
Epoch: 104, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.5876228831442117 HIT: 0.6944752102729581

#### val Acc: 0, NDCG: 0.7516614853605224 HIT: 0.8185792358760051
Epoch: 112, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.602062508255103 HIT: 0.7076395868599238

#### val Acc: 0, NDCG: 0.7655499124237851 HIT: 0.826845508887008
Epoch: 120, plus 0 steps train_loss: 0.7018

#### test Acc: 0, NDCG: 0.6024930888896335 HIT: 0.7069254522852306

#### val Acc: 0, NDCG: 0.7560482336139004 HIT: 0.8166930609923826
Epoch: 128, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.6086905708700596 HIT: 0.7081165031210326

#### val Acc: 0, NDCG: 0.7711026382681614 HIT: 0.8300376243123149
Epoch: 136, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.6223768765558578 HIT: 0.7233852623783326

#### val Acc: 0, NDCG: 0.7697693705533131 HIT: 0.8315254046762589
Epoch: 144, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.6241015088122894 HIT: 0.7238696175412611

#### val Acc: 0, NDCG: 0.7732092874432863 HIT: 0.8334843154887854
Epoch: 160, plus 0 steps train_loss: 0.6945

#### test Acc: 0, NDCG: 0.6093524947857477 HIT: 0.7143031898011003

#### val Acc: 0, NDCG: 0.7583091546743821 HIT: 0.8168501044752433
Epoch: 176, plus 0 steps train_loss: 0.6911

#### test Acc: 0, NDCG: 0.593719154179758 HIT: 0.6954976460008463

#### val Acc: 0, NDCG: 0.7450466361771989 HIT: 0.8111419871455777
Epoch: 192, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.6100043078697942 HIT: 0.7085107649174778

#### val Acc: 0, NDCG: 0.7570042333046118 HIT: 0.8183858244286923
Epoch: 208, plus 0 steps train_loss: 0.6874

#### test Acc: 0, NDCG: 0.39956596882228124 HIT: 0.5411660561256877

#### val Acc: 0, NDCG: 0.6189952871019705 HIT: 0.6948273182924248
Epoch: 224, plus 0 steps train_loss: 0.6908

#### test Acc: 0, NDCG: 0.33501572972923804 HIT: 0.4834798521476936

#### val Acc: 0, NDCG: 0.5851481591342327 HIT: 0.6706335299407533
Epoch: 240, plus 0 steps train_loss: 0.6828

#### test Acc: 0, NDCG: 0.33361204710165265 HIT: 0.48396420731062206

#### val Acc: 0, NDCG: 0.5962819211055346 HIT: 0.6803991549407533
Epoch: 256, plus 0 steps train_loss: 0.686

#### test Acc: 0, NDCG: 0.40352334595626504 HIT: 0.5437721513965298

#### val Acc: 0, NDCG: 0.62451347220126 HIT: 0.7132386002962336
Epoch: 272, plus 0 steps train_loss: 0.6837

#### test Acc: 0, NDCG: 0.3923919415423363 HIT: 0.5346611497566652

#### val Acc: 0, NDCG: 0.6151389192229832 HIT: 0.6989980625793484
Epoch: 288, plus 0 steps train_loss: 0.676

#### test Acc: 0, NDCG: 0.42827366444426374 HIT: 0.5578077060410495

#### val Acc: 0, NDCG: 0.6408128656736657 HIT: 0.7187111524016081
Epoch: 304, plus 0 steps train_loss: 0.6852

#### test Acc: 0, NDCG: 0.3768464644540305 HIT: 0.5178624563584426

#### val Acc: 0, NDCG: 0.6168594583603954 HIT: 0.6999899161553111
Epoch: 320, plus 0 steps train_loss: 0.6819

#### test Acc: 0, NDCG: 0.20257304583571117 HIT: 0.37155578845746934

#### val Acc: 0, NDCG: 0.5212462143248815 HIT: 0.6221153591832416
Epoch: 352, plus 0 steps train_loss: 0.6745

#### test Acc: 0, NDCG: 0.1913592036966098 HIT: 0.3737312539674143

#### val Acc: 0, NDCG: 0.5103125481295143 HIT: 0.6199977517985612
Epoch: 384, plus 0 steps train_loss: 0.6424

#### test Acc: 0, NDCG: 0.17167708197503803 HIT: 0.35925515102623784

#### val Acc: 0, NDCG: 0.5123487132979786 HIT: 0.622736094212865
Epoch: 416, plus 0 steps train_loss: 0.6207

#### test Acc: 0, NDCG: 0.18021744795111153 HIT: 0.36445576994286927

#### val Acc: 0, NDCG: 0.5129657302782327 HIT: 0.6223013317287346
Epoch: 448, plus 0 steps train_loss: 0.5959

#### test Acc: 0, NDCG: 0.1902912425755297 HIT: 0.37225091250528985

#### val Acc: 0, NDCG: 0.5161462167151905 HIT: 0.6212557527507405
Epoch: 480, plus 0 steps train_loss: 0.5809

#### test Acc: 0, NDCG: 0.2012604159095775 HIT: 0.3857888872725349

#### val Acc: 0, NDCG: 0.5136471594708863 HIT: 0.6182876309246721
Epoch: 512, plus 0 steps train_loss: 0.589

#### test Acc: 0, NDCG: 0.20674491085089033 HIT: 0.39255002248201437

#### val Acc: 0, NDCG: 0.5242971916879191 HIT: 0.6334034794223444
Epoch: 544, plus 0 steps train_loss: 0.5469

#### test Acc: 0, NDCG: 0.212698296284274 HIT: 0.4050424182712653

#### val Acc: 0, NDCG: 0.5378940311634743 HIT: 0.648544124259416
Epoch: 576, plus 0 steps train_loss: 0.5385

#### test Acc: 0, NDCG: 0.21427980090112472 HIT: 0.40667401740372405

#### val Acc: 0, NDCG: 0.5269425857999055 HIT: 0.6365286447312738
Epoch: 608, plus 0 steps train_loss: 0.541

#### test Acc: 0, NDCG: 0.21133646653905894 HIT: 0.4016320950592467

#### val Acc: 0, NDCG: 0.5281673554477476 HIT: 0.6322603681760475
Epoch: 640, plus 0 steps train_loss: 0.5164

#### test Acc: 0, NDCG: 0.22130671357133713 HIT: 0.41281855030681336

#### val Acc: 0, NDCG: 0.5338530936334391 HIT: 0.638077589399069
Epoch: 704, plus 0 steps train_loss: 0.5284

#### test Acc: 0, NDCG: 0.23445736740045178 HIT: 0.4275533617223868

#### val Acc: 0, NDCG: 0.5367320005802482 HIT: 0.6436460206834532
Epoch: 768, plus 0 steps train_loss: 0.51

#### test Acc: 0, NDCG: 0.22665965168442076 HIT: 0.42623006374312317

#### val Acc: 0, NDCG: 0.525779024094877 HIT: 0.637303943609818
Epoch: 832, plus 0 steps train_loss: 0.4915

#### test Acc: 0, NDCG: 0.23466931843231564 HIT: 0.43199934537663987

#### val Acc: 0, NDCG: 0.5257965531134844 HIT: 0.6371105321625052
Epoch: 896, plus 0 steps train_loss: 0.5255

#### test Acc: 0, NDCG: 0.2459672383076531 HIT: 0.4457001494392721

#### val Acc: 0, NDCG: 0.5241424284832567 HIT: 0.6319636386479052
Epoch: 960, plus 0 steps train_loss: 0.5093

#### test Acc: 0, NDCG: 0.2395428899112483 HIT: 0.4420906289674143

#### val Acc: 0, NDCG: 0.5315327220959116 HIT: 0.6404844874100719
Epoch: 1017, plus 0 steps train_loss: 0.5195
Done: it took 138859.01791524887
max value of NDCG: 0.6241015088122894
max value of HIT: 0.7238696175412611

After 20 validations
max value of NDCG: 0.6241015088122894
max value of HIT: 0.7238696175412611
