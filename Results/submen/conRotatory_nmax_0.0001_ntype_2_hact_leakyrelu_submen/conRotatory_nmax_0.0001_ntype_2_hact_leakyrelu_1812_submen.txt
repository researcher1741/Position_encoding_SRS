 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2
max_norm:             	0.0001
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	rotatory
position_concatenation: 	True
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11889541
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12774821114958632 HIT: 0.27884558162293693

#### val Acc: 0, NDCG: 0.4777409216668055 HIT: 0.5719986510791367
Epoch: 1, plus 0 steps train_loss: 0.7825

#### test Acc: 0, NDCG: 0.13255964992624758 HIT: 0.28527361933982226

#### val Acc: 0, NDCG: 0.4664184924497353 HIT: 0.5604385976512907
Epoch: 2, plus 0 steps train_loss: 0.7817

#### test Acc: 0, NDCG: 0.12112775029771905 HIT: 0.27194641345746934

#### val Acc: 0, NDCG: 0.49047963973285547 HIT: 0.5812799209162083
Epoch: 3, plus 0 steps train_loss: 0.7767

#### test Acc: 0, NDCG: 0.12286966159208479 HIT: 0.2805631413986458

#### val Acc: 0, NDCG: 0.46780266402664783 HIT: 0.5579399531845112
Epoch: 4, plus 0 steps train_loss: 0.7792

#### test Acc: 0, NDCG: 0.12578943547717916 HIT: 0.28471074243546335

#### val Acc: 0, NDCG: 0.48254337461973074 HIT: 0.5731954877274651
Epoch: 5, plus 0 steps train_loss: 0.7798

#### test Acc: 0, NDCG: 0.12772812964513572 HIT: 0.2771949719636056

#### val Acc: 0, NDCG: 0.4785855866374707 HIT: 0.5666120596170122
Epoch: 6, plus 0 steps train_loss: 0.7672

#### test Acc: 0, NDCG: 0.12097118316247875 HIT: 0.2662746640922556

#### val Acc: 0, NDCG: 0.4756921574173898 HIT: 0.5721556945619974
Epoch: 7, plus 0 steps train_loss: 0.7626

#### test Acc: 0, NDCG: 0.126286483432945 HIT: 0.2805515697735929

#### val Acc: 0, NDCG: 0.4799344425300234 HIT: 0.5732144982543377
Epoch: 8, plus 0 steps train_loss: 0.7498

#### test Acc: 0, NDCG: 0.12977388563847272 HIT: 0.28093839266821835

#### val Acc: 0, NDCG: 0.48410872002895716 HIT: 0.5785167821625052
Epoch: 9, plus 0 steps train_loss: 0.7468

#### test Acc: 0, NDCG: 0.12589420302219775 HIT: 0.27442604739737625

#### val Acc: 0, NDCG: 0.464444569121374 HIT: 0.5576506625581887
Epoch: 10, plus 0 steps train_loss: 0.7518

#### test Acc: 0, NDCG: 0.1294420033893319 HIT: 0.2813921656792213

#### val Acc: 0, NDCG: 0.48038399462372205 HIT: 0.5682378729369446
Epoch: 12, plus 0 steps train_loss: 0.7383

#### test Acc: 0, NDCG: 0.12801555207970503 HIT: 0.2791786791155311

#### val Acc: 0, NDCG: 0.4884447321884676 HIT: 0.5852473352200592
Epoch: 14, plus 0 steps train_loss: 0.7412

#### test Acc: 0, NDCG: 0.1232639037754302 HIT: 0.27473434855057133

#### val Acc: 0, NDCG: 0.4807885410344286 HIT: 0.5775728681760475
Epoch: 16, plus 0 steps train_loss: 0.7417

#### test Acc: 0, NDCG: 0.13746480632684097 HIT: 0.29627244895260263

#### val Acc: 0, NDCG: 0.4842434942312975 HIT: 0.5770174301735083
Epoch: 18, plus 0 steps train_loss: 0.7397

#### test Acc: 0, NDCG: 0.12459675553588889 HIT: 0.27985644572577234

#### val Acc: 0, NDCG: 0.4769877013417658 HIT: 0.5687395855374524
Epoch: 20, plus 0 steps train_loss: 0.7316

#### test Acc: 0, NDCG: 0.12169532394342987 HIT: 0.27561131242065173

#### val Acc: 0, NDCG: 0.48150615195970314 HIT: 0.5736434749259416
Epoch: 22, plus 0 steps train_loss: 0.7221

#### test Acc: 0, NDCG: 0.2174944416471419 HIT: 0.3748743652137114

#### val Acc: 0, NDCG: 0.5374018773132979 HIT: 0.6304585008463817
Epoch: 24, plus 0 steps train_loss: 0.7225

#### test Acc: 0, NDCG: 0.35015503979969004 HIT: 0.5056477795704613

#### val Acc: 0, NDCG: 0.6237069134427408 HIT: 0.717187004073212
Epoch: 26, plus 0 steps train_loss: 0.7274

#### test Acc: 0, NDCG: 0.44260633406728667 HIT: 0.5808087904676259

#### val Acc: 0, NDCG: 0.6679805532067455 HIT: 0.7491627102729581
Epoch: 28, plus 0 steps train_loss: 0.7209

#### test Acc: 0, NDCG: 0.4500023727630804 HIT: 0.5886403009944985

#### val Acc: 0, NDCG: 0.6887553789271874 HIT: 0.7655729276872619
Epoch: 30, plus 0 steps train_loss: 0.7189

#### test Acc: 0, NDCG: 0.45019626683757447 HIT: 0.5884163073952603

#### val Acc: 0, NDCG: 0.6769663325150843 HIT: 0.7551485466038934
Epoch: 32, plus 0 steps train_loss: 0.7261

#### test Acc: 0, NDCG: 0.4459422060624331 HIT: 0.5735649531845112

#### val Acc: 0, NDCG: 0.6719208759864824 HIT: 0.7491916393355903
Epoch: 36, plus 0 steps train_loss: 0.7165

#### test Acc: 0, NDCG: 0.434908278107407 HIT: 0.5720829586330936

#### val Acc: 0, NDCG: 0.6755447583511937 HIT: 0.760856663933559
Epoch: 40, plus 0 steps train_loss: 0.7197

#### test Acc: 0, NDCG: 0.4649171713126286 HIT: 0.603744577867118

#### val Acc: 0, NDCG: 0.6787909907047224 HIT: 0.762047714769361
Epoch: 44, plus 0 steps train_loss: 0.7127

#### test Acc: 0, NDCG: 0.4675250437711909 HIT: 0.6048934749259416

#### val Acc: 0, NDCG: 0.6846893303848856 HIT: 0.7702776198159119
Epoch: 48, plus 0 steps train_loss: 0.7155

#### test Acc: 0, NDCG: 0.47015942470863287 HIT: 0.6027105705141769

#### val Acc: 0, NDCG: 0.6923805917608744 HIT: 0.7688510037558189
Epoch: 52, plus 0 steps train_loss: 0.711

#### test Acc: 0, NDCG: 0.47890967775763693 HIT: 0.6129894797397376

#### val Acc: 0, NDCG: 0.6790307304926673 HIT: 0.7599565568133728
Epoch: 56, plus 0 steps train_loss: 0.7099

#### test Acc: 0, NDCG: 0.4817482813364585 HIT: 0.6099353972704189

#### val Acc: 0, NDCG: 0.6752909292170176 HIT: 0.761618738097757
Epoch: 60, plus 0 steps train_loss: 0.7111

#### test Acc: 0, NDCG: 0.4764926269950751 HIT: 0.6134068847862887

#### val Acc: 0, NDCG: 0.6827059411317817 HIT: 0.7690807831675837
Epoch: 64, plus 0 steps train_loss: 0.7128

#### test Acc: 0, NDCG: 0.47041052480097406 HIT: 0.6009087031845112

#### val Acc: 0, NDCG: 0.6907795636258501 HIT: 0.7701147905205248
Epoch: 68, plus 0 steps train_loss: 0.715

#### test Acc: 0, NDCG: 0.4808212942358927 HIT: 0.6121315263965298

#### val Acc: 0, NDCG: 0.680810401224627 HIT: 0.7585167160389336
Epoch: 72, plus 0 steps train_loss: 0.7155

#### test Acc: 0, NDCG: 0.49148984370366383 HIT: 0.6217632511637748

#### val Acc: 0, NDCG: 0.6962929996971697 HIT: 0.7732473947312738
Epoch: 80, plus 0 steps train_loss: 0.7092

#### test Acc: 0, NDCG: 0.48635260943631947 HIT: 0.6205664145154465

#### val Acc: 0, NDCG: 0.6851305976221048 HIT: 0.7647744855586119
Epoch: 88, plus 0 steps train_loss: 0.7068

#### test Acc: 0, NDCG: 0.49107434279813955 HIT: 0.6288690554909014

#### val Acc: 0, NDCG: 0.7090696112008646 HIT: 0.7841123241112992
Epoch: 96, plus 0 steps train_loss: 0.7058

#### test Acc: 0, NDCG: 0.47594644310396544 HIT: 0.6090047079983072

#### val Acc: 0, NDCG: 0.6846737774013065 HIT: 0.7665110558611934
Epoch: 104, plus 0 steps train_loss: 0.705

#### test Acc: 0, NDCG: 0.5052180111118619 HIT: 0.6295699653512484

#### val Acc: 0, NDCG: 0.6920060923199559 HIT: 0.7672003940964875
Epoch: 112, plus 0 steps train_loss: 0.7039

#### test Acc: 0, NDCG: 0.5164181287108631 HIT: 0.6472497553427846

#### val Acc: 0, NDCG: 0.7170621136124948 HIT: 0.7927348378650021
Epoch: 120, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.5144109375499067 HIT: 0.649626071201862

#### val Acc: 0, NDCG: 0.7137269415046115 HIT: 0.7908486629813796
Epoch: 128, plus 0 steps train_loss: 0.7028

#### test Acc: 0, NDCG: 0.5180288175444627 HIT: 0.6547423825645365

#### val Acc: 0, NDCG: 0.7123715070731329 HIT: 0.7864828541578502
Epoch: 136, plus 0 steps train_loss: 0.7029

#### test Acc: 0, NDCG: 0.507368315458011 HIT: 0.630362621667372

#### val Acc: 0, NDCG: 0.7136020849261738 HIT: 0.7907337732754973
Epoch: 144, plus 0 steps train_loss: 0.7029

#### test Acc: 0, NDCG: 0.5338521533973716 HIT: 0.660546379073212

#### val Acc: 0, NDCG: 0.7169351536130155 HIT: 0.7938052131823953
Epoch: 160, plus 0 steps train_loss: 0.7021

#### test Acc: 0, NDCG: 0.5363789804929803 HIT: 0.6553474132458739

#### val Acc: 0, NDCG: 0.7255877036386292 HIT: 0.7996588023698687
Epoch: 176, plus 0 steps train_loss: 0.7024

#### test Acc: 0, NDCG: 0.519144522056112 HIT: 0.646198390552264

#### val Acc: 0, NDCG: 0.7263216891930655 HIT: 0.7996588023698687
Epoch: 192, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.5178392873762492 HIT: 0.6397951491747778

#### val Acc: 0, NDCG: 0.7196932425303559 HIT: 0.7948028525708845
Epoch: 208, plus 0 steps train_loss: 0.7003

#### test Acc: 0, NDCG: 0.5229650046347325 HIT: 0.6457024637642828

#### val Acc: 0, NDCG: 0.7015279995746129 HIT: 0.7751815092044012
Epoch: 224, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.5320894617558976 HIT: 0.6562053665890817

#### val Acc: 0, NDCG: 0.7255166385078202 HIT: 0.7964476764176894
Epoch: 240, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.4663004829950255 HIT: 0.6150996482225984

#### val Acc: 0, NDCG: 0.6794523819441284 HIT: 0.7676715245450698
Epoch: 256, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.46827619672913645 HIT: 0.6117256929750318

#### val Acc: 0, NDCG: 0.6888958038421257 HIT: 0.7682881268514601
Epoch: 272, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.4473393632333413 HIT: 0.5912158141134152

#### val Acc: 0, NDCG: 0.6808551471543126 HIT: 0.7639586859923826
Epoch: 288, plus 0 steps train_loss: 0.6995

#### test Acc: 0, NDCG: 0.46695924757666296 HIT: 0.6103833844688955

#### val Acc: 0, NDCG: 0.6685794768159105 HIT: 0.7528391808611934
Epoch: 304, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.4660572705860896 HIT: 0.5972074362568769

#### val Acc: 0, NDCG: 0.6848937634688381 HIT: 0.7709190184617013
Epoch: 320, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.4778947313292941 HIT: 0.6229848841515023

#### val Acc: 0, NDCG: 0.6838023393837513 HIT: 0.7615344305438002
Epoch: 352, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.47088186698182133 HIT: 0.6142838486563691

#### val Acc: 0, NDCG: 0.6772818725631062 HIT: 0.7588861814959796
Epoch: 384, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.44769479423062564 HIT: 0.5857796299724926

#### val Acc: 0, NDCG: 0.6779190558230809 HIT: 0.7607417742276766
Epoch: 416, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.4620548711742868 HIT: 0.600931846434617

#### val Acc: 0, NDCG: 0.6847056476464826 HIT: 0.7685732847545493
Epoch: 448, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.15055254610973498 HIT: 0.30446598603470165

#### val Acc: 0, NDCG: 0.48547304951881715 HIT: 0.5777067684088024
Epoch: 480, plus 0 steps train_loss: 0.6982

#### test Acc: 0, NDCG: 0.3719725232326082 HIT: 0.5302035944773592

#### val Acc: 0, NDCG: 0.6406343712492396 HIT: 0.7327276965192552
Epoch: 512, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.4657222029615062 HIT: 0.6083095839504867

#### val Acc: 0, NDCG: 0.6830388606510528 HIT: 0.7708578541578502
Epoch: 544, plus 0 steps train_loss: 0.6989

#### test Acc: 0, NDCG: 0.33191441550992434 HIT: 0.4922957773487093

#### val Acc: 0, NDCG: 0.6106617151034927 HIT: 0.7055046220376641
Epoch: 576, plus 0 steps train_loss: 0.6972

#### test Acc: 0, NDCG: 0.47248749986945954 HIT: 0.6112545625264495

#### val Acc: 0, NDCG: 0.6783192876651722 HIT: 0.7653985267668219
Epoch: 608, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.4744999143399978 HIT: 0.6107528499259416

#### val Acc: 0, NDCG: 0.6867434013155163 HIT: 0.76908656898011
Epoch: 640, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.46164324163838916 HIT: 0.6005160944773592

#### val Acc: 0, NDCG: 0.678229063267745 HIT: 0.7650232754972492
Epoch: 704, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.47729274384481063 HIT: 0.6134184564113415

#### val Acc: 0, NDCG: 0.6856405643915047 HIT: 0.769896582733813
Epoch: 768, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.4544458486890916 HIT: 0.589063491853576

#### val Acc: 0, NDCG: 0.6807193307744583 HIT: 0.7641711079665678
Epoch: 832, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.4676270446254636 HIT: 0.6106916856220906

#### val Acc: 0, NDCG: 0.6727294440028647 HIT: 0.7546352623783326
Epoch: 896, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.4537209091531952 HIT: 0.5971289145154465

#### val Acc: 0, NDCG: 0.6738972492909968 HIT: 0.7549071955670758
Epoch: 960, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.46319178175543385 HIT: 0.5984042729052053

#### val Acc: 0, NDCG: 0.6797424532460541 HIT: 0.7581968432606855
Epoch: 1017, plus 0 steps train_loss: 0.6957
Done: it took 139697.4812822342
max value of NDCG: 0.5363789804929803
max value of HIT: 0.660546379073212

After 20 validations
max value of NDCG: 0.5363789804929803
max value of HIT: 0.660546379073212
