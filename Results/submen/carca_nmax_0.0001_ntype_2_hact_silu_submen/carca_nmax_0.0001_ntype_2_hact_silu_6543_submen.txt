 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2
max_norm:             	0.0001
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11571301
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13008718831845598 HIT: 0.28755984183241645

#### val Acc: 0, NDCG: 0.48162928134109106 HIT: 0.5713456808082945
Epoch: 1, plus 0 steps train_loss: 0.7867

#### test Acc: 0, NDCG: 0.1260718147671261 HIT: 0.27966882009098604

#### val Acc: 0, NDCG: 0.4755419056144105 HIT: 0.5720903975349133
Epoch: 2, plus 0 steps train_loss: 0.7744

#### test Acc: 0, NDCG: 0.12824342752758533 HIT: 0.27996389652983494

#### val Acc: 0, NDCG: 0.47146059242231286 HIT: 0.5614287981379602
Epoch: 3, plus 0 steps train_loss: 0.7688

#### test Acc: 0, NDCG: 0.12411988609233704 HIT: 0.27619154676258995

#### val Acc: 0, NDCG: 0.47521624275668584 HIT: 0.562420651713923
Epoch: 4, plus 0 steps train_loss: 0.7728

#### test Acc: 0, NDCG: 0.13168867623185912 HIT: 0.29300181178586543

#### val Acc: 0, NDCG: 0.486387422492737 HIT: 0.5738120900338552
Epoch: 5, plus 0 steps train_loss: 0.7449

#### test Acc: 0, NDCG: 0.12819294223791378 HIT: 0.28978490002115953

#### val Acc: 0, NDCG: 0.4762744166397725 HIT: 0.5691569905840034
Epoch: 6, plus 0 steps train_loss: 0.757

#### test Acc: 0, NDCG: 0.12762555105139203 HIT: 0.2835560595641134

#### val Acc: 0, NDCG: 0.4811804851596944 HIT: 0.5751676232543377
Epoch: 7, plus 0 steps train_loss: 0.7574

#### test Acc: 0, NDCG: 0.13327641382365205 HIT: 0.28830290546974185

#### val Acc: 0, NDCG: 0.4798939972027399 HIT: 0.574913047503174
Epoch: 8, plus 0 steps train_loss: 0.7429

#### test Acc: 0, NDCG: 0.1311110063317925 HIT: 0.2914355096804909

#### val Acc: 0, NDCG: 0.4824046239278334 HIT: 0.5743270273487093
Epoch: 9, plus 0 steps train_loss: 0.7397

#### test Acc: 0, NDCG: 0.12722964363797712 HIT: 0.28367094926999575

#### val Acc: 0, NDCG: 0.48769699134212063 HIT: 0.5841100097862887
Epoch: 10, plus 0 steps train_loss: 0.7392

#### test Acc: 0, NDCG: 0.1243217349644888 HIT: 0.2770015605162928

#### val Acc: 0, NDCG: 0.4743662927496258 HIT: 0.5618883569614896
Epoch: 12, plus 0 steps train_loss: 0.7469

#### test Acc: 0, NDCG: 0.12912264933445847 HIT: 0.2791365253385527

#### val Acc: 0, NDCG: 0.48989151702879613 HIT: 0.5808815263965298
Epoch: 14, plus 0 steps train_loss: 0.7328

#### test Acc: 0, NDCG: 0.19591727713197124 HIT: 0.35342635817816337

#### val Acc: 0, NDCG: 0.5195583290640766 HIT: 0.6163270670228522
Epoch: 16, plus 0 steps train_loss: 0.7256

#### test Acc: 0, NDCG: 0.4001512219923795 HIT: 0.5507936481696996

#### val Acc: 0, NDCG: 0.6352609821858091 HIT: 0.726190554909014
Epoch: 18, plus 0 steps train_loss: 0.736

#### test Acc: 0, NDCG: 0.4534827711333713 HIT: 0.5847877763965298

#### val Acc: 0, NDCG: 0.6829748043159704 HIT: 0.7581720469212865
Epoch: 20, plus 0 steps train_loss: 0.7295

#### test Acc: 0, NDCG: 0.47127402890807135 HIT: 0.5910703422556073

#### val Acc: 0, NDCG: 0.6859987665777032 HIT: 0.7665532096381719
Epoch: 22, plus 0 steps train_loss: 0.7213

#### test Acc: 0, NDCG: 0.5144750414806857 HIT: 0.6575840430596699

#### val Acc: 0, NDCG: 0.6808943915251076 HIT: 0.7642132617435464
Epoch: 24, plus 0 steps train_loss: 0.7237

#### test Acc: 0, NDCG: 0.5009111855176334 HIT: 0.6372923719847651

#### val Acc: 0, NDCG: 0.697770436449164 HIT: 0.7781628557448159
Epoch: 26, plus 0 steps train_loss: 0.716

#### test Acc: 0, NDCG: 0.5657962865467514 HIT: 0.677176457363521

#### val Acc: 0, NDCG: 0.7436504322475566 HIT: 0.8064315092044012
Epoch: 28, plus 0 steps train_loss: 0.7296

#### test Acc: 0, NDCG: 0.5996201829636789 HIT: 0.7109829599555649

#### val Acc: 0, NDCG: 0.7658695853958313 HIT: 0.8291970284066865
Epoch: 30, plus 0 steps train_loss: 0.7167

#### test Acc: 0, NDCG: 0.6021858754090591 HIT: 0.7088918019995768

#### val Acc: 0, NDCG: 0.7619420344526127 HIT: 0.8229086767350825
Epoch: 32, plus 0 steps train_loss: 0.7188

#### test Acc: 0, NDCG: 0.4204009449584718 HIT: 0.5487008371244181

#### val Acc: 0, NDCG: 0.6386335351882978 HIT: 0.7222537227570884
Epoch: 36, plus 0 steps train_loss: 0.719

#### test Acc: 0, NDCG: 0.4220609329427349 HIT: 0.558539198053322

#### val Acc: 0, NDCG: 0.6698398811209416 HIT: 0.7394218816123572
Epoch: 40, plus 0 steps train_loss: 0.715

#### test Acc: 0, NDCG: 0.5841650773619281 HIT: 0.6990707985082523

#### val Acc: 0, NDCG: 0.7451212441960352 HIT: 0.8143704705353364
Epoch: 44, plus 0 steps train_loss: 0.7134

#### test Acc: 0, NDCG: 0.37569512637636643 HIT: 0.5189444033008886

#### val Acc: 0, NDCG: 0.6366395894410652 HIT: 0.7138915705670758
Epoch: 48, plus 0 steps train_loss: 0.7131

#### test Acc: 0, NDCG: 0.3016423305063882 HIT: 0.452762146900127

#### val Acc: 0, NDCG: 0.5672192378467724 HIT: 0.656664925412611
Epoch: 52, plus 0 steps train_loss: 0.7211

#### test Acc: 0, NDCG: 0.5737463345658604 HIT: 0.6853394122936944

#### val Acc: 0, NDCG: 0.7466733953690324 HIT: 0.8141406911235718
Epoch: 56, plus 0 steps train_loss: 0.7139

#### test Acc: 0, NDCG: 0.5729024213937269 HIT: 0.6874380091515023

#### val Acc: 0, NDCG: 0.7556283469616091 HIT: 0.8194619855586119
Epoch: 60, plus 0 steps train_loss: 0.7053

#### test Acc: 0, NDCG: 0.5815453738423111 HIT: 0.6919360651184934

#### val Acc: 0, NDCG: 0.7368851012931451 HIT: 0.8051677224396954
Epoch: 64, plus 0 steps train_loss: 0.7063

#### test Acc: 0, NDCG: 0.5740354807253932 HIT: 0.6797825526343632

#### val Acc: 0, NDCG: 0.7410800803636596 HIT: 0.8083656236775285
Epoch: 68, plus 0 steps train_loss: 0.7117

#### test Acc: 0, NDCG: 0.5784209116875761 HIT: 0.6838574177422768

#### val Acc: 0, NDCG: 0.7454797577002156 HIT: 0.8057305993440542
Epoch: 72, plus 0 steps train_loss: 0.708

#### test Acc: 0, NDCG: 0.589185053698741 HIT: 0.6996874008146424

#### val Acc: 0, NDCG: 0.7662098172558518 HIT: 0.8324197259839188
Epoch: 80, plus 0 steps train_loss: 0.7023

#### test Acc: 0, NDCG: 0.5774674143891138 HIT: 0.6932362198476513

#### val Acc: 0, NDCG: 0.7490533975983985 HIT: 0.8161549804274228
Epoch: 88, plus 0 steps train_loss: 0.7083

#### test Acc: 0, NDCG: 0.5831929167878686 HIT: 0.6964589174248835

#### val Acc: 0, NDCG: 0.7444521913009684 HIT: 0.8129190581358443
Epoch: 96, plus 0 steps train_loss: 0.7026

#### test Acc: 0, NDCG: 0.5718948231084662 HIT: 0.6841847294223444

#### val Acc: 0, NDCG: 0.7371558021853686 HIT: 0.8094550095217943
Epoch: 104, plus 0 steps train_loss: 0.7042

#### test Acc: 0, NDCG: 0.5973409744373507 HIT: 0.704706179909014

#### val Acc: 0, NDCG: 0.747949700570188 HIT: 0.8158946188637326
Epoch: 112, plus 0 steps train_loss: 0.7046

#### test Acc: 0, NDCG: 0.5835147265509218 HIT: 0.7009528406686416

#### val Acc: 0, NDCG: 0.7504500384600324 HIT: 0.8225102822154041
Epoch: 120, plus 0 steps train_loss: 0.7028

#### test Acc: 0, NDCG: 0.4351851711830869 HIT: 0.5721920625264495

#### val Acc: 0, NDCG: 0.6733411634315826 HIT: 0.7525060833685993
Epoch: 128, plus 0 steps train_loss: 0.6995

#### test Acc: 0, NDCG: 0.3334216865688802 HIT: 0.4782560899809565

#### val Acc: 0, NDCG: 0.6058525511838603 HIT: 0.6915550280363945
Epoch: 136, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.3165878403322512 HIT: 0.4664282360876005

#### val Acc: 0, NDCG: 0.5913760494652315 HIT: 0.6759969781527718
Epoch: 144, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.13507795162164307 HIT: 0.30285174433982226

#### val Acc: 0, NDCG: 0.48447482417591203 HIT: 0.579581371667372
Epoch: 160, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.6440237543093522 HIT: 0.738387874259416

#### val Acc: 0, NDCG: 0.7992164329437592 HIT: 0.8560390658061785
Epoch: 176, plus 0 steps train_loss: 0.7037

#### test Acc: 0, NDCG: 0.13306836888564527 HIT: 0.2942887418006771

#### val Acc: 0, NDCG: 0.4718872254926178 HIT: 0.5559446744075328
Epoch: 192, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.12840838697326318 HIT: 0.28645888436309774

#### val Acc: 0, NDCG: 0.4809451723117455 HIT: 0.5761520379284808
Epoch: 208, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.1298918939253713 HIT: 0.2914892350825222

#### val Acc: 0, NDCG: 0.4731762246197179 HIT: 0.5613213473338976
Epoch: 224, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.13233940619541668 HIT: 0.29684689748201437

#### val Acc: 0, NDCG: 0.46324192859555535 HIT: 0.5528120701967838
Epoch: 240, plus 0 steps train_loss: 0.6984

#### test Acc: 0, NDCG: 0.17351878342752533 HIT: 0.3295846778459585

#### val Acc: 0, NDCG: 0.5036755978755051 HIT: 0.5930829784701651
Epoch: 256, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.5627408780032694 HIT: 0.6857741747778248

#### val Acc: 0, NDCG: 0.7454187292500284 HIT: 0.8135604567816335
Epoch: 272, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.27525123787523065 HIT: 0.42751699375793484

#### val Acc: 0, NDCG: 0.5438193495612116 HIT: 0.6283061785865425
Epoch: 288, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.13089722840978332 HIT: 0.28668287796233605

#### val Acc: 0, NDCG: 0.47274069854945966 HIT: 0.5629281501269573
Epoch: 304, plus 0 steps train_loss: 0.7

#### test Acc: 0, NDCG: 0.12961294745549093 HIT: 0.28861699243546335

#### val Acc: 0, NDCG: 0.47048262805776947 HIT: 0.5581755184088024
Epoch: 320, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.16344803316067041 HIT: 0.3186032056707575

#### val Acc: 0, NDCG: 0.48579585235140194 HIT: 0.5799144691599661
Epoch: 352, plus 0 steps train_loss: 0.7003

#### test Acc: 0, NDCG: 0.13533189637923707 HIT: 0.28648946651502327

#### val Acc: 0, NDCG: 0.4825700009055499 HIT: 0.578317584902666
Epoch: 384, plus 0 steps train_loss: 0.6954

#### test Acc: 0, NDCG: 0.1471011718947006 HIT: 0.312012338658485

#### val Acc: 0, NDCG: 0.4793555588367145 HIT: 0.569017304538722
Epoch: 416, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.1431973378852199 HIT: 0.29625509151502327

#### val Acc: 0, NDCG: 0.47812691957958564 HIT: 0.5638108998095641
Epoch: 448, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.15408750521449416 HIT: 0.30699934537663987

#### val Acc: 0, NDCG: 0.4915134184988952 HIT: 0.5773083738891239
Epoch: 480, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.4129291919348108 HIT: 0.5534592546550995

#### val Acc: 0, NDCG: 0.6416808882816473 HIT: 0.7257194244604317
Epoch: 512, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.573475973941188 HIT: 0.6848550571307659

#### val Acc: 0, NDCG: 0.7546151694001945 HIT: 0.8213903142192128
Epoch: 544, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.3421009390128124 HIT: 0.48733816255818874

#### val Acc: 0, NDCG: 0.6091360894732106 HIT: 0.6951587626957257
Epoch: 576, plus 0 steps train_loss: 0.6945

#### test Acc: 0, NDCG: 0.4899687505710952 HIT: 0.6213822140816758

#### val Acc: 0, NDCG: 0.6850350509311497 HIT: 0.7613947444985188
Epoch: 608, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.18890355554173355 HIT: 0.352930431390182

#### val Acc: 0, NDCG: 0.5146894362871832 HIT: 0.608780714399069
Epoch: 640, plus 0 steps train_loss: 0.6954

#### test Acc: 0, NDCG: 0.36476280246003284 HIT: 0.5138413166525604

#### val Acc: 0, NDCG: 0.622294176835231 HIT: 0.7112912611087601
Epoch: 704, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.3667606785801935 HIT: 0.5238119247249259

#### val Acc: 0, NDCG: 0.635105537365759 HIT: 0.7149140062949639
Epoch: 768, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.41457057188001245 HIT: 0.5492620609394837

#### val Acc: 0, NDCG: 0.6434405311063298 HIT: 0.7295950923085062
Epoch: 832, plus 0 steps train_loss: 0.6954

#### test Acc: 0, NDCG: 0.3718634970973984 HIT: 0.5184311190753279

#### val Acc: 0, NDCG: 0.6158126833920337 HIT: 0.7035341396000847
Epoch: 896, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.3851493149564671 HIT: 0.5285529848180279

#### val Acc: 0, NDCG: 0.6334021128760425 HIT: 0.7184450050253914
Epoch: 960, plus 0 steps train_loss: 0.6948

#### test Acc: 0, NDCG: 0.38887815009539495 HIT: 0.5347380184088024

#### val Acc: 0, NDCG: 0.6374318252394141 HIT: 0.7250300862251375
Epoch: 1017, plus 0 steps train_loss: 0.6953
Done: it took 134131.71757173538
max value of NDCG: 0.6440237543093522
max value of HIT: 0.738387874259416

After 20 validations
max value of NDCG: 0.6440237543093522
max value of HIT: 0.738387874259416
