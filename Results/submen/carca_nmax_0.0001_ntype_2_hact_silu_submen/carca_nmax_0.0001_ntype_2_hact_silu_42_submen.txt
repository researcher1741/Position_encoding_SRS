 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2
max_norm:             	0.0001
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11571301
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12665020561294812 HIT: 0.27698998889123994

#### val Acc: 0, NDCG: 0.4916620537666951 HIT: 0.5861548812420652
Epoch: 1, plus 0 steps train_loss: 0.7764

#### test Acc: 0, NDCG: 0.12492004172312005 HIT: 0.276463479951333

#### val Acc: 0, NDCG: 0.49361105980251035 HIT: 0.5875872831146848
Epoch: 2, plus 0 steps train_loss: 0.7817

#### test Acc: 0, NDCG: 0.12321379344150643 HIT: 0.2746500409966145

#### val Acc: 0, NDCG: 0.47771781857415857 HIT: 0.5701604157850191
Epoch: 3, plus 0 steps train_loss: 0.7646

#### test Acc: 0, NDCG: 0.12558817512380568 HIT: 0.27513274307024965

#### val Acc: 0, NDCG: 0.48355657128298546 HIT: 0.5778216581146848
Epoch: 4, plus 0 steps train_loss: 0.7673

#### test Acc: 0, NDCG: 0.1254613100958843 HIT: 0.27882243837283116

#### val Acc: 0, NDCG: 0.47519129114628966 HIT: 0.5663806271159543
Epoch: 5, plus 0 steps train_loss: 0.7483

#### test Acc: 0, NDCG: 0.12460998729345958 HIT: 0.27726192207998307

#### val Acc: 0, NDCG: 0.4637380474508329 HIT: 0.5493306641451545
Epoch: 6, plus 0 steps train_loss: 0.7506

#### test Acc: 0, NDCG: 0.12755512389036794 HIT: 0.279988692869234

#### val Acc: 0, NDCG: 0.4798825537908584 HIT: 0.5661814298561151
Epoch: 7, plus 0 steps train_loss: 0.747

#### test Acc: 0, NDCG: 0.1241189810421345 HIT: 0.27848934088023697

#### val Acc: 0, NDCG: 0.4744306781414662 HIT: 0.5672939589504867
Epoch: 8, plus 0 steps train_loss: 0.7466

#### test Acc: 0, NDCG: 0.12088704307824617 HIT: 0.26921964266821835

#### val Acc: 0, NDCG: 0.46770020528496997 HIT: 0.5577407559246721
Epoch: 9, plus 0 steps train_loss: 0.7399

#### test Acc: 0, NDCG: 0.1295803736115774 HIT: 0.28347753782268303

#### val Acc: 0, NDCG: 0.47771021144014414 HIT: 0.5730020762801523
Epoch: 10, plus 0 steps train_loss: 0.7404

#### test Acc: 0, NDCG: 0.1462248337485815 HIT: 0.2957897468789674

#### val Acc: 0, NDCG: 0.4922719008823523 HIT: 0.5913480612568769
Epoch: 12, plus 0 steps train_loss: 0.7322

#### test Acc: 0, NDCG: 0.17491722656597097 HIT: 0.3215423984341938

#### val Acc: 0, NDCG: 0.5113768457139196 HIT: 0.6054373413034279
Epoch: 14, plus 0 steps train_loss: 0.7455

#### test Acc: 0, NDCG: 0.17644554085829936 HIT: 0.3345307210114261

#### val Acc: 0, NDCG: 0.5079725878657299 HIT: 0.605672906527719
Epoch: 16, plus 0 steps train_loss: 0.7354

#### test Acc: 0, NDCG: 0.1354466064763743 HIT: 0.29933231723444775

#### val Acc: 0, NDCG: 0.4831927552664977 HIT: 0.5796598934088024
Epoch: 18, plus 0 steps train_loss: 0.7305

#### test Acc: 0, NDCG: 0.158143642271821 HIT: 0.32013313981168007

#### val Acc: 0, NDCG: 0.5050933686150727 HIT: 0.6013914052581464
Epoch: 20, plus 0 steps train_loss: 0.7313

#### test Acc: 0, NDCG: 0.16588670196068342 HIT: 0.32394929644519677

#### val Acc: 0, NDCG: 0.4994558422982203 HIT: 0.5987795241747778
Epoch: 22, plus 0 steps train_loss: 0.7283

#### test Acc: 0, NDCG: 0.20383147827603165 HIT: 0.3594733588129497

#### val Acc: 0, NDCG: 0.5357029082160204 HIT: 0.6299088486563691
Epoch: 24, plus 0 steps train_loss: 0.7201

#### test Acc: 0, NDCG: 0.20583119652244675 HIT: 0.3573689761426153

#### val Acc: 0, NDCG: 0.5280129125598519 HIT: 0.6231419276343632
Epoch: 26, plus 0 steps train_loss: 0.7248

#### test Acc: 0, NDCG: 0.24736525359740302 HIT: 0.40087002089504864

#### val Acc: 0, NDCG: 0.5472171277241556 HIT: 0.6460777150338552
Epoch: 28, plus 0 steps train_loss: 0.7212

#### test Acc: 0, NDCG: 0.1709118549504108 HIT: 0.32809689748201437

#### val Acc: 0, NDCG: 0.5169308668355369 HIT: 0.6112355519995768
Epoch: 30, plus 0 steps train_loss: 0.721

#### test Acc: 0, NDCG: 0.20880911161380158 HIT: 0.3675768025285654

#### val Acc: 0, NDCG: 0.5306892746720497 HIT: 0.6196109289039358
Epoch: 32, plus 0 steps train_loss: 0.7153

#### test Acc: 0, NDCG: 0.13046293017048768 HIT: 0.2864283022111722

#### val Acc: 0, NDCG: 0.486885101490311 HIT: 0.5859788272323319
Epoch: 36, plus 0 steps train_loss: 0.7182

#### test Acc: 0, NDCG: 0.19910438940704803 HIT: 0.3531180570249683

#### val Acc: 0, NDCG: 0.5161072528745649 HIT: 0.6088840324798985
Epoch: 40, plus 0 steps train_loss: 0.7206

#### test Acc: 0, NDCG: 0.2914602047759022 HIT: 0.444273533379179

#### val Acc: 0, NDCG: 0.5773434624758796 HIT: 0.6731916856220906
Epoch: 44, plus 0 steps train_loss: 0.7193

#### test Acc: 0, NDCG: 0.276316463888695 HIT: 0.431792709214981

#### val Acc: 0, NDCG: 0.5782126298114602 HIT: 0.675016696201862
Epoch: 48, plus 0 steps train_loss: 0.7139

#### test Acc: 0, NDCG: 0.37439429305041166 HIT: 0.5222282651819721

#### val Acc: 0, NDCG: 0.6258364242450462 HIT: 0.7132576108231062
Epoch: 52, plus 0 steps train_loss: 0.7092

#### test Acc: 0, NDCG: 0.42175647900010554 HIT: 0.5567736986881083

#### val Acc: 0, NDCG: 0.6574082447129431 HIT: 0.7393243493440542
Epoch: 56, plus 0 steps train_loss: 0.7099

#### test Acc: 0, NDCG: 0.4379216367186616 HIT: 0.5760255765975455

#### val Acc: 0, NDCG: 0.6613082298076514 HIT: 0.7461449957680915
Epoch: 60, plus 0 steps train_loss: 0.7067

#### test Acc: 0, NDCG: 0.3808379268501118 HIT: 0.5283785838975879

#### val Acc: 0, NDCG: 0.6293103178148853 HIT: 0.7147090232225984
Epoch: 64, plus 0 steps train_loss: 0.7102

#### test Acc: 0, NDCG: 0.1516827692675853 HIT: 0.3175865557553957

#### val Acc: 0, NDCG: 0.4915197970779155 HIT: 0.5840257022323319
Epoch: 68, plus 0 steps train_loss: 0.7108

#### test Acc: 0, NDCG: 0.3945168905733304 HIT: 0.5368671974185357

#### val Acc: 0, NDCG: 0.6518957631205463 HIT: 0.7323830274016081
Epoch: 72, plus 0 steps train_loss: 0.7082

#### test Acc: 0, NDCG: 0.46631888369198427 HIT: 0.5992812367752857

#### val Acc: 0, NDCG: 0.6927861991959103 HIT: 0.7657547675095218
Epoch: 80, plus 0 steps train_loss: 0.7063

#### test Acc: 0, NDCG: 0.5614309828025347 HIT: 0.6858890644837071

#### val Acc: 0, NDCG: 0.7375655143565378 HIT: 0.8092847413245874
Epoch: 88, plus 0 steps train_loss: 0.7054

#### test Acc: 0, NDCG: 0.5177278347406158 HIT: 0.6445171987410072

#### val Acc: 0, NDCG: 0.7133203915349167 HIT: 0.7900750171921287
Epoch: 96, plus 0 steps train_loss: 0.7025

#### test Acc: 0, NDCG: 0.2396807753826359 HIT: 0.39100686362674564

#### val Acc: 0, NDCG: 0.541826671460404 HIT: 0.624369346434617
Epoch: 104, plus 0 steps train_loss: 0.7071

#### test Acc: 0, NDCG: 0.25040166942588676 HIT: 0.395899181390182

#### val Acc: 0, NDCG: 0.5672612136838359 HIT: 0.6586428467520102
Epoch: 112, plus 0 steps train_loss: 0.7032

#### test Acc: 0, NDCG: 0.6168101134965147 HIT: 0.7264509164727042

#### val Acc: 0, NDCG: 0.7814491629506616 HIT: 0.8403049619128227
Epoch: 120, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.4211934614097193 HIT: 0.5506903300888701

#### val Acc: 0, NDCG: 0.6566879823376115 HIT: 0.7442703925095218
Epoch: 128, plus 0 steps train_loss: 0.7045

#### test Acc: 0, NDCG: 0.2517639540176063 HIT: 0.4120564761426153

#### val Acc: 0, NDCG: 0.5621738418060191 HIT: 0.6589627195302581
Epoch: 136, plus 0 steps train_loss: 0.7016

#### test Acc: 0, NDCG: 0.2711743991074418 HIT: 0.4295064867223868

#### val Acc: 0, NDCG: 0.555666463952362 HIT: 0.6491797370926788
Epoch: 144, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.196088355844936 HIT: 0.3347299182712653

#### val Acc: 0, NDCG: 0.5201822003954613 HIT: 0.6132862092678798
Epoch: 160, plus 0 steps train_loss: 0.7003

#### test Acc: 0, NDCG: 0.2940303596842222 HIT: 0.4371140036500212

#### val Acc: 0, NDCG: 0.5791056970119646 HIT: 0.6664611325645365
Epoch: 176, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.6484430149616177 HIT: 0.7523663973233178

#### val Acc: 0, NDCG: 0.7804520031085018 HIT: 0.8422101473233178
Epoch: 192, plus 0 steps train_loss: 0.6984

#### test Acc: 0, NDCG: 0.648082170885432 HIT: 0.7499057739102836

#### val Acc: 0, NDCG: 0.7938713544386746 HIT: 0.8511715443821413
Epoch: 208, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.5559189237117899 HIT: 0.6790510606220906

#### val Acc: 0, NDCG: 0.7328908002493788 HIT: 0.8015466303427846
Epoch: 224, plus 0 steps train_loss: 0.7003

#### test Acc: 0, NDCG: 0.5054126004864644 HIT: 0.6330340139652983

#### val Acc: 0, NDCG: 0.7077183731593694 HIT: 0.7825766041578502
Epoch: 240, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.5322559832703194 HIT: 0.6600388806601777

#### val Acc: 0, NDCG: 0.7176570006760992 HIT: 0.7874325539568345
Epoch: 256, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.4304573946687004 HIT: 0.5703596130448583

#### val Acc: 0, NDCG: 0.6609032811647485 HIT: 0.7433454890499366
Epoch: 272, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.32493110982842965 HIT: 0.4663133463817181

#### val Acc: 0, NDCG: 0.6040815474458082 HIT: 0.6947661539885738
Epoch: 288, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.3189229814239938 HIT: 0.469530258146424

#### val Acc: 0, NDCG: 0.5840789482314263 HIT: 0.6695995225878121
Epoch: 304, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.5173616020461074 HIT: 0.6377444919064749

#### val Acc: 0, NDCG: 0.7196438631186152 HIT: 0.7916107371455777
Epoch: 320, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.6728673027771541 HIT: 0.7683071373783326

#### val Acc: 0, NDCG: 0.8086240704496067 HIT: 0.8653930715721541
Epoch: 352, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.2290254897299245 HIT: 0.3894174182712653

#### val Acc: 0, NDCG: 0.5260176757304696 HIT: 0.6220178269149387
Epoch: 384, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.2496010612815508 HIT: 0.4014196730850614

#### val Acc: 0, NDCG: 0.5318694657192192 HIT: 0.62793092731697
Epoch: 416, plus 0 steps train_loss: 0.6953

#### test Acc: 0, NDCG: 0.2578207918986087 HIT: 0.4060689867223868

#### val Acc: 0, NDCG: 0.5491651525087831 HIT: 0.6437625634786288
Epoch: 448, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.2947196697190754 HIT: 0.4570378623571731

#### val Acc: 0, NDCG: 0.5746967042876228 HIT: 0.670518640234871
Epoch: 480, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.2626474516702967 HIT: 0.4277352015446466

#### val Acc: 0, NDCG: 0.5512495743585173 HIT: 0.6542348841515023
Epoch: 512, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.29832826051450034 HIT: 0.45269684987304276

#### val Acc: 0, NDCG: 0.57596091325347 HIT: 0.6687052012801523
Epoch: 544, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.40414316538625544 HIT: 0.548197471434617

#### val Acc: 0, NDCG: 0.6383828393715086 HIT: 0.7231191150021159
Epoch: 576, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.1842381446524385 HIT: 0.3513715681866272

#### val Acc: 0, NDCG: 0.5072007761499732 HIT: 0.6118595932077867
Epoch: 608, plus 0 steps train_loss: 0.6937

#### test Acc: 0, NDCG: 0.25970674989761494 HIT: 0.422789158379179

#### val Acc: 0, NDCG: 0.5512553611638333 HIT: 0.6461025113732544
Epoch: 640, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.18409886360455083 HIT: 0.3621943437896742

#### val Acc: 0, NDCG: 0.502014352244494 HIT: 0.6109098934088024
Epoch: 704, plus 0 steps train_loss: 0.694

#### test Acc: 0, NDCG: 0.18063957299999345 HIT: 0.3634217625899281

#### val Acc: 0, NDCG: 0.5004455225885881 HIT: 0.6127481287029201
Epoch: 768, plus 0 steps train_loss: 0.6931

#### test Acc: 0, NDCG: 0.18519889815229676 HIT: 0.3733807990372408

#### val Acc: 0, NDCG: 0.5010388035850328 HIT: 0.6134068847862887
Epoch: 832, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.1934130034521116 HIT: 0.38385311971011427

#### val Acc: 0, NDCG: 0.5206910037009056 HIT: 0.6379626996931866
Epoch: 896, plus 0 steps train_loss: 0.6941

#### test Acc: 0, NDCG: 0.19887133437342777 HIT: 0.394388257776132

#### val Acc: 0, NDCG: 0.5111587919240519 HIT: 0.6242908246931866
Epoch: 960, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.19782335864646394 HIT: 0.386514593472281

#### val Acc: 0, NDCG: 0.5180186712153833 HIT: 0.6290682527507405
Epoch: 1017, plus 0 steps train_loss: 0.6945
Done: it took 81926.87774896622
max value of NDCG: 0.6728673027771541
max value of HIT: 0.7683071373783326

After 20 validations
max value of NDCG: 0.6728673027771541
max value of HIT: 0.7683071373783326
