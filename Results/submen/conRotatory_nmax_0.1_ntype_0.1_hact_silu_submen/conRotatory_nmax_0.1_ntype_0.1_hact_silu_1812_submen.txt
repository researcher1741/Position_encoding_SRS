 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	0.1
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	rotatory
position_concatenation: 	True
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11889541
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12848091332834888 HIT: 0.27506744604316546

#### val Acc: 0, NDCG: 0.4748685028790762 HIT: 0.5677609566758358
Epoch: 1, plus 0 steps train_loss: 0.8011

#### test Acc: 0, NDCG: 0.13073344156281075 HIT: 0.2814516768937791

#### val Acc: 0, NDCG: 0.46984797872833683 HIT: 0.5625851340986036
Epoch: 2, plus 0 steps train_loss: 0.7854

#### test Acc: 0, NDCG: 0.13187864185213694 HIT: 0.2873953594477359

#### val Acc: 0, NDCG: 0.4860999592214958 HIT: 0.5780266411870504
Epoch: 3, plus 0 steps train_loss: 0.7808

#### test Acc: 0, NDCG: 0.12792660409456924 HIT: 0.2798258635738468

#### val Acc: 0, NDCG: 0.4678172002245521 HIT: 0.5613139084320778
Epoch: 4, plus 0 steps train_loss: 0.7811

#### test Acc: 0, NDCG: 0.1247536824801023 HIT: 0.27757022323317815

#### val Acc: 0, NDCG: 0.48306377254970934 HIT: 0.5785225679750318
Epoch: 5, plus 0 steps train_loss: 0.7738

#### test Acc: 0, NDCG: 0.13322453453017125 HIT: 0.29431932395260263

#### val Acc: 0, NDCG: 0.4785388098674222 HIT: 0.5697256533008886
Epoch: 6, plus 0 steps train_loss: 0.7737

#### test Acc: 0, NDCG: 0.12483282234397354 HIT: 0.27362181945619973

#### val Acc: 0, NDCG: 0.4732915822663835 HIT: 0.5634430874418113
Epoch: 7, plus 0 steps train_loss: 0.7652

#### test Acc: 0, NDCG: 0.13241909599744672 HIT: 0.2907271609183241

#### val Acc: 0, NDCG: 0.47734797468368806 HIT: 0.5738848259627592
Epoch: 8, plus 0 steps train_loss: 0.7707

#### test Acc: 0, NDCG: 0.12663992154549855 HIT: 0.28186329612780364

#### val Acc: 0, NDCG: 0.47954596256433163 HIT: 0.57093406157427
Epoch: 9, plus 0 steps train_loss: 0.755

#### test Acc: 0, NDCG: 0.13139681341640863 HIT: 0.288955875740584

#### val Acc: 0, NDCG: 0.4671986873733575 HIT: 0.56161063796022
Epoch: 10, plus 0 steps train_loss: 0.7715

#### test Acc: 0, NDCG: 0.13159850940544612 HIT: 0.29089164330300465

#### val Acc: 0, NDCG: 0.4799264565036843 HIT: 0.5685098061256877
Epoch: 12, plus 0 steps train_loss: 0.7505

#### test Acc: 0, NDCG: 0.12619444756930107 HIT: 0.2796746059035125

#### val Acc: 0, NDCG: 0.4804821533798927 HIT: 0.5706447709479475
Epoch: 14, plus 0 steps train_loss: 0.756

#### test Acc: 0, NDCG: 0.13083281028353944 HIT: 0.2869126573741007

#### val Acc: 0, NDCG: 0.47970199539928005 HIT: 0.5674757987727466
Epoch: 16, plus 0 steps train_loss: 0.756

#### test Acc: 0, NDCG: 0.12449509662275753 HIT: 0.27634280443292425

#### val Acc: 0, NDCG: 0.47715064436527116 HIT: 0.567996521900127
Epoch: 18, plus 0 steps train_loss: 0.7373

#### test Acc: 0, NDCG: 0.1280422276143514 HIT: 0.2704470614684723

#### val Acc: 0, NDCG: 0.4792730258772436 HIT: 0.5686304816440966
Epoch: 20, plus 0 steps train_loss: 0.7519

#### test Acc: 0, NDCG: 0.13010017645322672 HIT: 0.2831998188214135

#### val Acc: 0, NDCG: 0.48116440474646227 HIT: 0.5723375343842573
Epoch: 22, plus 0 steps train_loss: 0.751

#### test Acc: 0, NDCG: 0.12221156718078369 HIT: 0.2664201359500635

#### val Acc: 0, NDCG: 0.4799104917888865 HIT: 0.5770232159860347
Epoch: 24, plus 0 steps train_loss: 0.7495

#### test Acc: 0, NDCG: 0.12594936912465177 HIT: 0.28108386452602624

#### val Acc: 0, NDCG: 0.47276250295580824 HIT: 0.5638778499259416
Epoch: 26, plus 0 steps train_loss: 0.7458

#### test Acc: 0, NDCG: 0.12414320198063124 HIT: 0.27740739393779096

#### val Acc: 0, NDCG: 0.4765988818378027 HIT: 0.5747981577972916
Epoch: 28, plus 0 steps train_loss: 0.7395

#### test Acc: 0, NDCG: 0.12207322820723553 HIT: 0.2723522468789674

#### val Acc: 0, NDCG: 0.48472535498495 HIT: 0.578880461807025
Epoch: 30, plus 0 steps train_loss: 0.7314

#### test Acc: 0, NDCG: 0.12560014061764166 HIT: 0.28074498122090563

#### val Acc: 0, NDCG: 0.4840090773077665 HIT: 0.5716060423719848
Epoch: 32, plus 0 steps train_loss: 0.7321

#### test Acc: 0, NDCG: 0.1320183915479035 HIT: 0.29425981273804486

#### val Acc: 0, NDCG: 0.48251056016085403 HIT: 0.5774100388806601
Epoch: 36, plus 0 steps train_loss: 0.7335

#### test Acc: 0, NDCG: 0.12704985127713259 HIT: 0.27723133992805754

#### val Acc: 0, NDCG: 0.4811877137335266 HIT: 0.5769025404676259
Epoch: 40, plus 0 steps train_loss: 0.7325

#### test Acc: 0, NDCG: 0.15590525561493998 HIT: 0.3136629483178163

#### val Acc: 0, NDCG: 0.4846416754292321 HIT: 0.5779059656686416
Epoch: 44, plus 0 steps train_loss: 0.7235

#### test Acc: 0, NDCG: 0.21624883412230325 HIT: 0.3715252063055438

#### val Acc: 0, NDCG: 0.5245702377327355 HIT: 0.6113446558929327
Epoch: 48, plus 0 steps train_loss: 0.718

#### test Acc: 0, NDCG: 0.20184630400711034 HIT: 0.36027758675412613

#### val Acc: 0, NDCG: 0.5180498012676515 HIT: 0.6064655628438426
Epoch: 52, plus 0 steps train_loss: 0.7194

#### test Acc: 0, NDCG: 0.29879229846104743 HIT: 0.45435324534490057

#### val Acc: 0, NDCG: 0.5638049511153173 HIT: 0.654083626481168
Epoch: 56, plus 0 steps train_loss: 0.7179

#### test Acc: 0, NDCG: 0.3018249743325267 HIT: 0.4560096408167583

#### val Acc: 0, NDCG: 0.5694539204383785 HIT: 0.665101466620821
Epoch: 60, plus 0 steps train_loss: 0.714

#### test Acc: 0, NDCG: 0.35430245986480824 HIT: 0.5007265327443927

#### val Acc: 0, NDCG: 0.6153684486432888 HIT: 0.7108201306601777
Epoch: 64, plus 0 steps train_loss: 0.7154

#### test Acc: 0, NDCG: 0.4727069814551793 HIT: 0.5927994736563691

#### val Acc: 0, NDCG: 0.6856735488016511 HIT: 0.7604946373783326
Epoch: 68, plus 0 steps train_loss: 0.7191

#### test Acc: 0, NDCG: 0.47921863280325305 HIT: 0.5989613639970377

#### val Acc: 0, NDCG: 0.6861120187320556 HIT: 0.7595565092044012
Epoch: 72, plus 0 steps train_loss: 0.7091

#### test Acc: 0, NDCG: 0.49987689976717614 HIT: 0.6172651951967838

#### val Acc: 0, NDCG: 0.7085758158904985 HIT: 0.7739904583685993
Epoch: 80, plus 0 steps train_loss: 0.7099

#### test Acc: 0, NDCG: 0.5071255321865356 HIT: 0.6198828620926788

#### val Acc: 0, NDCG: 0.7154479643508371 HIT: 0.7865861722386797
Epoch: 88, plus 0 steps train_loss: 0.7059

#### test Acc: 0, NDCG: 0.40836549704531777 HIT: 0.5408519691599661

#### val Acc: 0, NDCG: 0.651295562563223 HIT: 0.730133172873466
Epoch: 96, plus 0 steps train_loss: 0.7066

#### test Acc: 0, NDCG: 0.336709091988571 HIT: 0.4811762722175201

#### val Acc: 0, NDCG: 0.5902483843443989 HIT: 0.6763895868599238
Epoch: 104, plus 0 steps train_loss: 0.705

#### test Acc: 0, NDCG: 0.3129316249797731 HIT: 0.4548185899809564

#### val Acc: 0, NDCG: 0.5826762942950715 HIT: 0.6699557633305121
Epoch: 112, plus 0 steps train_loss: 0.7038

#### test Acc: 0, NDCG: 0.501735479314476 HIT: 0.6234080750105797

#### val Acc: 0, NDCG: 0.7000690068205087 HIT: 0.767870721804909
Epoch: 120, plus 0 steps train_loss: 0.7058

#### test Acc: 0, NDCG: 0.5060028254146575 HIT: 0.629110406527719

#### val Acc: 0, NDCG: 0.7014883321649986 HIT: 0.7719588116271688
Epoch: 128, plus 0 steps train_loss: 0.7044

#### test Acc: 0, NDCG: 0.5185528956522264 HIT: 0.6363005184088024

#### val Acc: 0, NDCG: 0.7019818896068789 HIT: 0.7743524849238256
Epoch: 136, plus 0 steps train_loss: 0.7018

#### test Acc: 0, NDCG: 0.5451942937146815 HIT: 0.6613944138806601

#### val Acc: 0, NDCG: 0.7213847422394927 HIT: 0.7901841210854845
Epoch: 144, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.5804891189505428 HIT: 0.6922327946466357

#### val Acc: 0, NDCG: 0.7494925441666874 HIT: 0.8135720284066865
Epoch: 160, plus 0 steps train_loss: 0.6972

#### test Acc: 0, NDCG: 0.5897455196269105 HIT: 0.6963076597545493

#### val Acc: 0, NDCG: 0.7600576737488991 HIT: 0.8224433320990266
Epoch: 176, plus 0 steps train_loss: 0.7023

#### test Acc: 0, NDCG: 0.23909297758237968 HIT: 0.38341257141345747

#### val Acc: 0, NDCG: 0.553325356920369 HIT: 0.6297154372090563
Epoch: 192, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.43977983521355846 HIT: 0.5685941136796445

#### val Acc: 0, NDCG: 0.6431726171309812 HIT: 0.7174473656369023
Epoch: 208, plus 0 steps train_loss: 0.7002

#### test Acc: 0, NDCG: 0.4537111830955355 HIT: 0.5899999669382142

#### val Acc: 0, NDCG: 0.6608188890764352 HIT: 0.7373232847545493
Epoch: 224, plus 0 steps train_loss: 0.7024

#### test Acc: 0, NDCG: 0.4229111458223124 HIT: 0.5616395670228522

#### val Acc: 0, NDCG: 0.662317751532662 HIT: 0.7437744657215405
Epoch: 240, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.5151839236231356 HIT: 0.6278524055755396

#### val Acc: 0, NDCG: 0.7189890565952632 HIT: 0.7907701412399492
Epoch: 256, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.6330818452140208 HIT: 0.7264567022852306

#### val Acc: 0, NDCG: 0.7785827204132744 HIT: 0.8326131374312316
Epoch: 272, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.6261312747906338 HIT: 0.725024300412611

#### val Acc: 0, NDCG: 0.770494302075559 HIT: 0.8282894823846805
Epoch: 288, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.6122109674321199 HIT: 0.7082371786394414

#### val Acc: 0, NDCG: 0.7694742524183315 HIT: 0.8275158365954296
Epoch: 304, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.6366636475132617 HIT: 0.7333864526026238

#### val Acc: 0, NDCG: 0.781141073377186 HIT: 0.8450154398539992
Epoch: 320, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.5599073913025905 HIT: 0.6663520286711807

#### val Acc: 0, NDCG: 0.7296470631060105 HIT: 0.7953483720376641
Epoch: 352, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.5536492512258085 HIT: 0.657608839399069

#### val Acc: 0, NDCG: 0.7223508369639032 HIT: 0.790189906898011
Epoch: 384, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.6089376641961064 HIT: 0.7213536156369023

#### val Acc: 0, NDCG: 0.7580384385644124 HIT: 0.821868883569615
Epoch: 416, plus 0 steps train_loss: 0.6944

#### test Acc: 0, NDCG: 0.4876523156045942 HIT: 0.60919811944562

#### val Acc: 0, NDCG: 0.6865430737159487 HIT: 0.7621452470376641
Epoch: 448, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.14138535782607387 HIT: 0.2990240160812526

#### val Acc: 0, NDCG: 0.47772485143733723 HIT: 0.5671427012801523
Epoch: 480, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.3719019033929121 HIT: 0.5077042226512907

#### val Acc: 0, NDCG: 0.6109197791240477 HIT: 0.6932668019995768
Epoch: 512, plus 0 steps train_loss: 0.6953

#### test Acc: 0, NDCG: 0.25314004277602137 HIT: 0.4070972082628015

#### val Acc: 0, NDCG: 0.5608050297472955 HIT: 0.6481994551417689
Epoch: 544, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.2040476383619985 HIT: 0.35393385659119764

#### val Acc: 0, NDCG: 0.5243608071843822 HIT: 0.61780906157427
Epoch: 576, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.24638518424539188 HIT: 0.38917606723444775

#### val Acc: 0, NDCG: 0.5417548383561064 HIT: 0.6279135698793906
Epoch: 608, plus 0 steps train_loss: 0.6954

#### test Acc: 0, NDCG: 0.3028655347425359 HIT: 0.442125343842573

#### val Acc: 0, NDCG: 0.5637420121954198 HIT: 0.6449767575645365
Epoch: 640, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.382612725246574 HIT: 0.5149538457469318

#### val Acc: 0, NDCG: 0.627331060061699 HIT: 0.7055773579665678
Epoch: 704, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.2801633665170953 HIT: 0.41994749788404573

#### val Acc: 0, NDCG: 0.5726034868628495 HIT: 0.6507154570461279
Epoch: 768, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.41994148588308816 HIT: 0.5503382220694033

#### val Acc: 0, NDCG: 0.6402581536542011 HIT: 0.712997249259416
Epoch: 832, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.43290142566067447 HIT: 0.5626198489737622

#### val Acc: 0, NDCG: 0.6519984951902154 HIT: 0.7257136386479052
Epoch: 896, plus 0 steps train_loss: 0.6932

#### test Acc: 0, NDCG: 0.3653581889132071 HIT: 0.5042385209479475

#### val Acc: 0, NDCG: 0.6176683256560457 HIT: 0.6967308506136267
Epoch: 960, plus 0 steps train_loss: 0.6936

#### test Acc: 0, NDCG: 0.36288237760793596 HIT: 0.5022490279834956

#### val Acc: 0, NDCG: 0.6089962125157422 HIT: 0.6868445500952179
Epoch: 1017, plus 0 steps train_loss: 0.6926
Done: it took 89546.64339375496
max value of NDCG: 0.6366636475132617
max value of HIT: 0.7333864526026238

After 20 validations
max value of NDCG: 0.6366636475132617
max value of HIT: 0.7333864526026238
