 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2
max_norm:             	1
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.1327445684649544 HIT: 0.291326405787135

#### val Acc: 0, NDCG: 0.48633512939419865 HIT: 0.5748882511637748
Epoch: 1, plus 0 steps train_loss: 0.7749

#### test Acc: 0, NDCG: 0.12883686046443465 HIT: 0.28240716250528985

#### val Acc: 0, NDCG: 0.47052063235715974 HIT: 0.5588474992065171
Epoch: 2, plus 0 steps train_loss: 0.7584

#### test Acc: 0, NDCG: 0.13211759302808732 HIT: 0.28458428110452816

#### val Acc: 0, NDCG: 0.47462455219729854 HIT: 0.5626140631612356
Epoch: 3, plus 0 steps train_loss: 0.7633

#### test Acc: 0, NDCG: 0.13041990056140526 HIT: 0.28326098312526454

#### val Acc: 0, NDCG: 0.4746034469558141 HIT: 0.5658003927740162
Epoch: 4, plus 0 steps train_loss: 0.7551

#### test Acc: 0, NDCG: 0.12848587741311301 HIT: 0.2841610902454507

#### val Acc: 0, NDCG: 0.48775424263616274 HIT: 0.5748882511637748
Epoch: 5, plus 0 steps train_loss: 0.7608

#### test Acc: 0, NDCG: 0.13038800271930484 HIT: 0.28937906659966145

#### val Acc: 0, NDCG: 0.4686242391275601 HIT: 0.5563257114896318
Epoch: 6, plus 0 steps train_loss: 0.7582

#### test Acc: 0, NDCG: 0.12308477442091403 HIT: 0.27477071651502327

#### val Acc: 0, NDCG: 0.4792864742045535 HIT: 0.5665872632776132
Epoch: 7, plus 0 steps train_loss: 0.7594

#### test Acc: 0, NDCG: 0.1283124538335029 HIT: 0.28174262060939487

#### val Acc: 0, NDCG: 0.47914940210669943 HIT: 0.5685461740901396
Epoch: 8, plus 0 steps train_loss: 0.7528

#### test Acc: 0, NDCG: 0.12128973793849455 HIT: 0.2817789885738468

#### val Acc: 0, NDCG: 0.48286098006451644 HIT: 0.5744055490901396
Epoch: 9, plus 0 steps train_loss: 0.7469

#### test Acc: 0, NDCG: 0.12790975543999536 HIT: 0.2869358006242065

#### val Acc: 0, NDCG: 0.48903587229122936 HIT: 0.5755833752115954
Epoch: 10, plus 0 steps train_loss: 0.7445

#### test Acc: 0, NDCG: 0.12493342608932376 HIT: 0.27446820117435466

#### val Acc: 0, NDCG: 0.4760899688468466 HIT: 0.5633877089504867
Epoch: 12, plus 0 steps train_loss: 0.7325

#### test Acc: 0, NDCG: 0.13668036163769903 HIT: 0.29045522772958104

#### val Acc: 0, NDCG: 0.48751182707929613 HIT: 0.5796904755607278
Epoch: 14, plus 0 steps train_loss: 0.7348

#### test Acc: 0, NDCG: 0.13253752689529397 HIT: 0.28347753782268303

#### val Acc: 0, NDCG: 0.48403730425888347 HIT: 0.5772166274333475
Epoch: 16, plus 0 steps train_loss: 0.7266

#### test Acc: 0, NDCG: 0.12802683427878658 HIT: 0.2783265115848498

#### val Acc: 0, NDCG: 0.4693718791863701 HIT: 0.558575566017774
Epoch: 18, plus 0 steps train_loss: 0.7245

#### test Acc: 0, NDCG: 0.13610096764502946 HIT: 0.29523844159966145

#### val Acc: 0, NDCG: 0.4851660833809028 HIT: 0.5784688425730004
Epoch: 20, plus 0 steps train_loss: 0.7259

#### test Acc: 0, NDCG: 0.12791424859023243 HIT: 0.2841610902454507

#### val Acc: 0, NDCG: 0.47838960946477926 HIT: 0.5748287399492171
Epoch: 22, plus 0 steps train_loss: 0.7128

#### test Acc: 0, NDCG: 0.13433616161406375 HIT: 0.2894939563055438

#### val Acc: 0, NDCG: 0.4855011136925082 HIT: 0.580282281527719
Epoch: 24, plus 0 steps train_loss: 0.713

#### test Acc: 0, NDCG: 0.1611664644530078 HIT: 0.3176840880236987

#### val Acc: 0, NDCG: 0.4898670923151035 HIT: 0.5886328620926788
Epoch: 26, plus 0 steps train_loss: 0.7171

#### test Acc: 0, NDCG: 0.14882339605520126 HIT: 0.3018177369868811

#### val Acc: 0, NDCG: 0.4873305493160047 HIT: 0.5894503147482014
Epoch: 28, plus 0 steps train_loss: 0.7138

#### test Acc: 0, NDCG: 0.14660502737471992 HIT: 0.3081003028459585

#### val Acc: 0, NDCG: 0.4966271769052587 HIT: 0.5941054141980534
Epoch: 30, plus 0 steps train_loss: 0.7128

#### test Acc: 0, NDCG: 0.1487262637001486 HIT: 0.307749847915785

#### val Acc: 0, NDCG: 0.505329042281548 HIT: 0.5997350097862887
Epoch: 32, plus 0 steps train_loss: 0.7124

#### test Acc: 0, NDCG: 0.1552566038325095 HIT: 0.31322240002115953

#### val Acc: 0, NDCG: 0.49115725451003156 HIT: 0.5865474899492171
Epoch: 36, plus 0 steps train_loss: 0.7108

#### test Acc: 0, NDCG: 0.1729443609784762 HIT: 0.31700797450275076

#### val Acc: 0, NDCG: 0.5168330213022454 HIT: 0.6083401661024121
Epoch: 40, plus 0 steps train_loss: 0.7083

#### test Acc: 0, NDCG: 0.160982857554395 HIT: 0.31804776766821835

#### val Acc: 0, NDCG: 0.49801585716983254 HIT: 0.590919084585273
Epoch: 44, plus 0 steps train_loss: 0.7105

#### test Acc: 0, NDCG: 0.18426674554697126 HIT: 0.3324089809035125

#### val Acc: 0, NDCG: 0.5053109581648325 HIT: 0.5975826875264495
Epoch: 48, plus 0 steps train_loss: 0.7034

#### test Acc: 0, NDCG: 0.2430077647778922 HIT: 0.3846399902137114

#### val Acc: 0, NDCG: 0.5451617440588442 HIT: 0.6372312076809141
Epoch: 52, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.2249013469670095 HIT: 0.37644066731908593

#### val Acc: 0, NDCG: 0.5309580278859622 HIT: 0.6179181654676259
Epoch: 56, plus 0 steps train_loss: 0.705

#### test Acc: 0, NDCG: 0.14434899438027424 HIT: 0.29038993070249686

#### val Acc: 0, NDCG: 0.4841604478651914 HIT: 0.5754874960325856
Epoch: 60, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.35918737450281046 HIT: 0.49077906792213294

#### val Acc: 0, NDCG: 0.5907752810241229 HIT: 0.6771458752115954
Epoch: 64, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.296024046449591 HIT: 0.4399440925201016

#### val Acc: 0, NDCG: 0.575846633257116 HIT: 0.6588784119763013
Epoch: 68, plus 0 steps train_loss: 0.7044

#### test Acc: 0, NDCG: 0.3364733403423264 HIT: 0.4766592057236564

#### val Acc: 0, NDCG: 0.6028055161974956 HIT: 0.6890464650338552
Epoch: 72, plus 0 steps train_loss: 0.7035

#### test Acc: 0, NDCG: 0.26424917452289765 HIT: 0.42058145762801524

#### val Acc: 0, NDCG: 0.5570944359740438 HIT: 0.6406778988573847
Epoch: 80, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.4174193806895807 HIT: 0.5548742990901396

#### val Acc: 0, NDCG: 0.6395075113191723 HIT: 0.7157967559775709
Epoch: 88, plus 0 steps train_loss: 0.7024

#### test Acc: 0, NDCG: 0.3621406411865325 HIT: 0.4968855797714769

#### val Acc: 0, NDCG: 0.6067488024685055 HIT: 0.6848550571307659
Epoch: 96, plus 0 steps train_loss: 0.7003

#### test Acc: 0, NDCG: 0.28214439373584155 HIT: 0.41843492118070247

#### val Acc: 0, NDCG: 0.5688488851981932 HIT: 0.6496335101036818
Epoch: 104, plus 0 steps train_loss: 0.701

#### test Acc: 0, NDCG: 0.37699885559104307 HIT: 0.5107930199957681

#### val Acc: 0, NDCG: 0.6163981545512917 HIT: 0.6982186309775709
Epoch: 112, plus 0 steps train_loss: 0.6989

#### test Acc: 0, NDCG: 0.5126494727778735 HIT: 0.6337845165044436

#### val Acc: 0, NDCG: 0.6975343988491793 HIT: 0.7719893937790944
Epoch: 120, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.21804289432803856 HIT: 0.36374907426999575

#### val Acc: 0, NDCG: 0.5152744121166876 HIT: 0.6061804049407533
Epoch: 128, plus 0 steps train_loss: 0.7009

#### test Acc: 0, NDCG: 0.4633671296131151 HIT: 0.5832636280681338

#### val Acc: 0, NDCG: 0.6865582539625817 HIT: 0.7609236140499366
Epoch: 136, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.6304347740742194 HIT: 0.7403277745450698

#### val Acc: 0, NDCG: 0.7808175502786395 HIT: 0.8448947643355903
Epoch: 144, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.24475812786146256 HIT: 0.39548177634363096

#### val Acc: 0, NDCG: 0.5405130566705189 HIT: 0.6300047278353788
Epoch: 160, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.6228027247180232 HIT: 0.7317110466038934

#### val Acc: 0, NDCG: 0.7548094153802426 HIT: 0.8199215443821413
Epoch: 176, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.6403502483551496 HIT: 0.7435389004972492

#### val Acc: 0, NDCG: 0.7730493590003192 HIT: 0.8398511889018198
Epoch: 192, plus 0 steps train_loss: 0.6984

#### test Acc: 0, NDCG: 0.6745673042815525 HIT: 0.765597724026661

#### val Acc: 0, NDCG: 0.795411948919773 HIT: 0.8493812486775285
Epoch: 208, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.4948397959718002 HIT: 0.6291831424566229

#### val Acc: 0, NDCG: 0.6984887717453668 HIT: 0.7779694442975033
Epoch: 224, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.5739603591421618 HIT: 0.680211529305967

#### val Acc: 0, NDCG: 0.7375022385244896 HIT: 0.8075804062632247
Epoch: 240, plus 0 steps train_loss: 0.6886

#### test Acc: 0, NDCG: 0.5005797304733789 HIT: 0.6291641319297503

#### val Acc: 0, NDCG: 0.709302352242215 HIT: 0.7833940568133728
Epoch: 256, plus 0 steps train_loss: 0.6822

#### test Acc: 0, NDCG: 0.6116033461647641 HIT: 0.716878702920017

#### val Acc: 0, NDCG: 0.7768284834737025 HIT: 0.8394527943821413
Epoch: 272, plus 0 steps train_loss: 0.688

#### test Acc: 0, NDCG: 0.5558812454416279 HIT: 0.6718072233389759

#### val Acc: 0, NDCG: 0.7347925228633684 HIT: 0.8100178864261531
Epoch: 288, plus 0 steps train_loss: 0.6773

#### test Acc: 0, NDCG: 0.5676412448342145 HIT: 0.6896977822154041

#### val Acc: 0, NDCG: 0.7437991157118321 HIT: 0.8129744366271688
Epoch: 304, plus 0 steps train_loss: 0.6878

#### test Acc: 0, NDCG: 0.5877070860380114 HIT: 0.7004188928269149

#### val Acc: 0, NDCG: 0.7584564847881033 HIT: 0.8286283656898011
Epoch: 320, plus 0 steps train_loss: 0.6761

#### test Acc: 0, NDCG: 0.6289958765522501 HIT: 0.7351883199322895

#### val Acc: 0, NDCG: 0.7738794187139427 HIT: 0.8331280747460855
Epoch: 352, plus 0 steps train_loss: 0.679

#### test Acc: 0, NDCG: 0.5770850251369092 HIT: 0.6889853007300042

#### val Acc: 0, NDCG: 0.7471370091866207 HIT: 0.8135298746297079
Epoch: 384, plus 0 steps train_loss: 0.6564

#### test Acc: 0, NDCG: 0.5593294391572842 HIT: 0.6769408921392298

#### val Acc: 0, NDCG: 0.7278565455874813 HIT: 0.8016962349238256
Epoch: 416, plus 0 steps train_loss: 0.6652

#### test Acc: 0, NDCG: 0.546584543646807 HIT: 0.6732875648011003

#### val Acc: 0, NDCG: 0.7337664646372495 HIT: 0.811122976618705
Epoch: 448, plus 0 steps train_loss: 0.6478

#### test Acc: 0, NDCG: 0.4820434466479894 HIT: 0.6214243678586542

#### val Acc: 0, NDCG: 0.6878357820079682 HIT: 0.7774793033220483
Epoch: 480, plus 0 steps train_loss: 0.6361

#### test Acc: 0, NDCG: 0.5032172624388048 HIT: 0.6406721130448583

#### val Acc: 0, NDCG: 0.6906156642618386 HIT: 0.78630845323741
Epoch: 512, plus 0 steps train_loss: 0.6322

#### test Acc: 0, NDCG: 0.22366288719419614 HIT: 0.4161734950275074

#### val Acc: 0, NDCG: 0.5357072048517881 HIT: 0.6529463010473974
Epoch: 544, plus 0 steps train_loss: 0.6178

#### test Acc: 0, NDCG: 0.2266543217946187 HIT: 0.4217129972492594

#### val Acc: 0, NDCG: 0.5397911753717493 HIT: 0.6549779477888278
Epoch: 576, plus 0 steps train_loss: 0.5983

#### test Acc: 0, NDCG: 0.22566010604867187 HIT: 0.4181935701438849

#### val Acc: 0, NDCG: 0.5338901477065007 HIT: 0.6522321664727042
Epoch: 608, plus 0 steps train_loss: 0.6036

#### test Acc: 0, NDCG: 0.22181777472635184 HIT: 0.4111737264600085

#### val Acc: 0, NDCG: 0.541220218266154 HIT: 0.6600636769995768
Epoch: 640, plus 0 steps train_loss: 0.5712

#### test Acc: 0, NDCG: 0.2303716674487522 HIT: 0.41795800491959373

#### val Acc: 0, NDCG: 0.5425638845930072 HIT: 0.6564351460008463
Epoch: 704, plus 0 steps train_loss: 0.5827

#### test Acc: 0, NDCG: 0.2359886065621902 HIT: 0.429803216250529

#### val Acc: 0, NDCG: 0.5413125922236185 HIT: 0.6600273090351249
Epoch: 768, plus 0 steps train_loss: 0.5604

#### test Acc: 0, NDCG: 0.23250291345248536 HIT: 0.4232602888277613

#### val Acc: 0, NDCG: 0.5323918731007604 HIT: 0.6465124775179856
Epoch: 832, plus 0 steps train_loss: 0.555

#### test Acc: 0, NDCG: 0.23436910623515367 HIT: 0.4199243546339399

#### val Acc: 0, NDCG: 0.5373111829388739 HIT: 0.6543134058929327
Epoch: 896, plus 0 steps train_loss: 0.5807

#### test Acc: 0, NDCG: 0.24206442607389728 HIT: 0.42473071175412613

#### val Acc: 0, NDCG: 0.5344349906046615 HIT: 0.6502980519995768
Epoch: 960, plus 0 steps train_loss: 0.5661

#### test Acc: 0, NDCG: 0.24238695453228754 HIT: 0.4311587494710114

#### val Acc: 0, NDCG: 0.5358550428654278 HIT: 0.647069568609818
Epoch: 1017, plus 0 steps train_loss: 0.5862
Done: it took 87892.97405028343
max value of NDCG: 0.6745673042815525
max value of HIT: 0.765597724026661

After 20 validations
max value of NDCG: 0.6745673042815525
max value of HIT: 0.765597724026661
