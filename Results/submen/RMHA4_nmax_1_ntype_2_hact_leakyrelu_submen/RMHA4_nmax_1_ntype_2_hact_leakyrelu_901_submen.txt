 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2
max_norm:             	1
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12094915182186995 HIT: 0.26877909437156156

#### val Acc: 0, NDCG: 0.47840880287863724 HIT: 0.5727665110558613
Epoch: 1, plus 0 steps train_loss: 0.7915

#### test Acc: 0, NDCG: 0.131026197345386 HIT: 0.2911693623042742

#### val Acc: 0, NDCG: 0.47425564465269365 HIT: 0.5669683003597122
Epoch: 2, plus 0 steps train_loss: 0.7693

#### test Acc: 0, NDCG: 0.12988483385919924 HIT: 0.2838891570567076

#### val Acc: 0, NDCG: 0.4823639560749294 HIT: 0.5679659397482014
Epoch: 3, plus 0 steps train_loss: 0.7587

#### test Acc: 0, NDCG: 0.12653707023640423 HIT: 0.27894311389123994

#### val Acc: 0, NDCG: 0.48501914613334873 HIT: 0.5729714941282268
Epoch: 4, plus 0 steps train_loss: 0.761

#### test Acc: 0, NDCG: 0.1361181004737345 HIT: 0.2986735611510791

#### val Acc: 0, NDCG: 0.4790140052768982 HIT: 0.5659210682924248
Epoch: 5, plus 0 steps train_loss: 0.7677

#### test Acc: 0, NDCG: 0.13035003792116404 HIT: 0.2897601036817605

#### val Acc: 0, NDCG: 0.4792652894175391 HIT: 0.5688238930914092
Epoch: 6, plus 0 steps train_loss: 0.748

#### test Acc: 0, NDCG: 0.12968861862780745 HIT: 0.29372751798561153

#### val Acc: 0, NDCG: 0.48348738915166023 HIT: 0.5710795334320778
Epoch: 7, plus 0 steps train_loss: 0.7511

#### test Acc: 0, NDCG: 0.12059896950615734 HIT: 0.26672843710325855

#### val Acc: 0, NDCG: 0.4620506128922132 HIT: 0.5523657360876005
Epoch: 8, plus 0 steps train_loss: 0.7518

#### test Acc: 0, NDCG: 0.12665054543128618 HIT: 0.27507323185569194

#### val Acc: 0, NDCG: 0.48463879941870547 HIT: 0.5794970641134152
Epoch: 9, plus 0 steps train_loss: 0.7485

#### test Acc: 0, NDCG: 0.126089037618223 HIT: 0.27883400999788405

#### val Acc: 0, NDCG: 0.48101302120999945 HIT: 0.5704687169382142
Epoch: 10, plus 0 steps train_loss: 0.7494

#### test Acc: 0, NDCG: 0.13370430412879872 HIT: 0.2901890803533643

#### val Acc: 0, NDCG: 0.47887432846903943 HIT: 0.5757842255607278
Epoch: 12, plus 0 steps train_loss: 0.7288

#### test Acc: 0, NDCG: 0.12484106021423637 HIT: 0.27936630475031743

#### val Acc: 0, NDCG: 0.4774782545445987 HIT: 0.5595732054062632
Epoch: 14, plus 0 steps train_loss: 0.7275

#### test Acc: 0, NDCG: 0.12441053874736768 HIT: 0.2847413245873889

#### val Acc: 0, NDCG: 0.4696070081759217 HIT: 0.5573291366906474
Epoch: 16, plus 0 steps train_loss: 0.7197

#### test Acc: 0, NDCG: 0.12117598848677416 HIT: 0.2771949719636056

#### val Acc: 0, NDCG: 0.47912853093017405 HIT: 0.5685155919382142
Epoch: 18, plus 0 steps train_loss: 0.7292

#### test Acc: 0, NDCG: 0.12314968317404418 HIT: 0.27249771873677525

#### val Acc: 0, NDCG: 0.4736775265954904 HIT: 0.5615626983707153
Epoch: 20, plus 0 steps train_loss: 0.7213

#### test Acc: 0, NDCG: 0.1262042882147417 HIT: 0.2776008053851037

#### val Acc: 0, NDCG: 0.4854955058291614 HIT: 0.5805426430914092
Epoch: 22, plus 0 steps train_loss: 0.7146

#### test Acc: 0, NDCG: 0.1304449455037132 HIT: 0.2814401052687262

#### val Acc: 0, NDCG: 0.47869320458857656 HIT: 0.5706869247249259
Epoch: 24, plus 0 steps train_loss: 0.7151

#### test Acc: 0, NDCG: 0.13246262727672894 HIT: 0.2853042014917478

#### val Acc: 0, NDCG: 0.490585047135783 HIT: 0.58771374444562
Epoch: 26, plus 0 steps train_loss: 0.7146

#### test Acc: 0, NDCG: 0.14868172182367068 HIT: 0.30482222677740156

#### val Acc: 0, NDCG: 0.5059970744167639 HIT: 0.6034652057765553
Epoch: 28, plus 0 steps train_loss: 0.7143

#### test Acc: 0, NDCG: 0.22080773992263542 HIT: 0.3759389547185781

#### val Acc: 0, NDCG: 0.5355108290394187 HIT: 0.6231609381612356
Epoch: 30, plus 0 steps train_loss: 0.7088

#### test Acc: 0, NDCG: 0.1821890030769847 HIT: 0.33708887669276344

#### val Acc: 0, NDCG: 0.5160105198755696 HIT: 0.6085203528353788
Epoch: 32, plus 0 steps train_loss: 0.7094

#### test Acc: 0, NDCG: 0.152346546049541 HIT: 0.3044411896953026

#### val Acc: 0, NDCG: 0.503045658397544 HIT: 0.6031453329983072
Epoch: 36, plus 0 steps train_loss: 0.7131

#### test Acc: 0, NDCG: 0.14559931287275035 HIT: 0.30412710272958104

#### val Acc: 0, NDCG: 0.49216819737235784 HIT: 0.5915472585167161
Epoch: 40, plus 0 steps train_loss: 0.7095

#### test Acc: 0, NDCG: 0.21297584362934008 HIT: 0.37191202920016925

#### val Acc: 0, NDCG: 0.5319294940592102 HIT: 0.6300906884786288
Epoch: 44, plus 0 steps train_loss: 0.7032

#### test Acc: 0, NDCG: 0.24390151232412827 HIT: 0.3894537862357173

#### val Acc: 0, NDCG: 0.5387222618259387 HIT: 0.6287773090351249
Epoch: 48, plus 0 steps train_loss: 0.7046

#### test Acc: 0, NDCG: 0.21419402763584247 HIT: 0.36486738917689376

#### val Acc: 0, NDCG: 0.5294359310859904 HIT: 0.6170164052581464
Epoch: 52, plus 0 steps train_loss: 0.7027

#### test Acc: 0, NDCG: 0.5040978941022111 HIT: 0.6246718617752857

#### val Acc: 0, NDCG: 0.6965744541489852 HIT: 0.7742987595217943
Epoch: 56, plus 0 steps train_loss: 0.7029

#### test Acc: 0, NDCG: 0.5942169367309957 HIT: 0.6931576981062209

#### val Acc: 0, NDCG: 0.758797835658395 HIT: 0.819733918747355
Epoch: 60, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.5633172313995392 HIT: 0.6757366165890817

#### val Acc: 0, NDCG: 0.740987299259015 HIT: 0.8036377882987727
Epoch: 64, plus 0 steps train_loss: 0.7038

#### test Acc: 0, NDCG: 0.5221100594123792 HIT: 0.6465926523487093

#### val Acc: 0, NDCG: 0.7219450965573613 HIT: 0.794132524862463
Epoch: 68, plus 0 steps train_loss: 0.7062

#### test Acc: 0, NDCG: 0.43069696964305115 HIT: 0.5612948979052053

#### val Acc: 0, NDCG: 0.661605746633616 HIT: 0.7394144427105375
Epoch: 72, plus 0 steps train_loss: 0.7069

#### test Acc: 0, NDCG: 0.5857474284500173 HIT: 0.6919187076809141

#### val Acc: 0, NDCG: 0.7532174383863631 HIT: 0.810077397640711
Epoch: 80, plus 0 steps train_loss: 0.7023

#### test Acc: 0, NDCG: 0.5925367310085017 HIT: 0.6970217943292425

#### val Acc: 0, NDCG: 0.7639874935185094 HIT: 0.8234715536394414
Epoch: 88, plus 0 steps train_loss: 0.7037

#### test Acc: 0, NDCG: 0.6667154800537589 HIT: 0.7549014097545493

#### val Acc: 0, NDCG: 0.7894330924017039 HIT: 0.8423192512166737
Epoch: 96, plus 0 steps train_loss: 0.703

#### test Acc: 0, NDCG: 0.6038128829952119 HIT: 0.7087579017668219

#### val Acc: 0, NDCG: 0.7575201693879698 HIT: 0.8202356313478629
Epoch: 104, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.6338684686892418 HIT: 0.7318507326491748

#### val Acc: 0, NDCG: 0.7785783244689535 HIT: 0.8349605242276766
Epoch: 112, plus 0 steps train_loss: 0.7

#### test Acc: 0, NDCG: 0.6590324997656808 HIT: 0.7482187962865002

#### val Acc: 0, NDCG: 0.7795243206836796 HIT: 0.8381104858760051
Epoch: 120, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.6559845983776165 HIT: 0.747638561944562

#### val Acc: 0, NDCG: 0.8019276796081652 HIT: 0.8591716700169276
Epoch: 128, plus 0 steps train_loss: 0.6891

#### test Acc: 0, NDCG: 0.6088780134090629 HIT: 0.701979409119763

#### val Acc: 0, NDCG: 0.7745296132035723 HIT: 0.8314468829348286
Epoch: 136, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.6397344350457712 HIT: 0.7337732754972492

#### val Acc: 0, NDCG: 0.7847576772854749 HIT: 0.8391387074164198
Epoch: 144, plus 0 steps train_loss: 0.6886

#### test Acc: 0, NDCG: 0.6633736524227353 HIT: 0.7502388714028777

#### val Acc: 0, NDCG: 0.799340787846776 HIT: 0.8515583672767668
Epoch: 160, plus 0 steps train_loss: 0.6893

#### test Acc: 0, NDCG: 0.6758055483164691 HIT: 0.7657969212865002

#### val Acc: 0, NDCG: 0.8133856181271031 HIT: 0.8628291300782903
Epoch: 176, plus 0 steps train_loss: 0.6916

#### test Acc: 0, NDCG: 0.6541361610546335 HIT: 0.7406608720376641

#### val Acc: 0, NDCG: 0.7822701309597829 HIT: 0.8341678679115531
Epoch: 192, plus 0 steps train_loss: 0.6888

#### test Acc: 0, NDCG: 0.6548442746958335 HIT: 0.7442951888489208

#### val Acc: 0, NDCG: 0.7953127473316792 HIT: 0.8507541393355903
Epoch: 208, plus 0 steps train_loss: 0.6916

#### test Acc: 0, NDCG: 0.6417345957391972 HIT: 0.7341848947312738

#### val Acc: 0, NDCG: 0.7734867347179348 HIT: 0.8347307448159119
Epoch: 224, plus 0 steps train_loss: 0.6849

#### test Acc: 0, NDCG: 0.6493181848530685 HIT: 0.7406666578501904

#### val Acc: 0, NDCG: 0.7989833948340754 HIT: 0.853710689536606
Epoch: 240, plus 0 steps train_loss: 0.6889

#### test Acc: 0, NDCG: 0.5930171232552254 HIT: 0.6951893448476513

#### val Acc: 0, NDCG: 0.7446074728265681 HIT: 0.8122065766504444
Epoch: 256, plus 0 steps train_loss: 0.6838

#### test Acc: 0, NDCG: 0.6119284379117761 HIT: 0.7089223841515023

#### val Acc: 0, NDCG: 0.7721077669113602 HIT: 0.8319180133834109
Epoch: 272, plus 0 steps train_loss: 0.6683

#### test Acc: 0, NDCG: 0.6321045989335277 HIT: 0.7318143646847228

#### val Acc: 0, NDCG: 0.7902809539291527 HIT: 0.8447013528882776
Epoch: 288, plus 0 steps train_loss: 0.678

#### test Acc: 0, NDCG: 0.6291191507070993 HIT: 0.7245878848391875

#### val Acc: 0, NDCG: 0.772270730171106 HIT: 0.8284655363944138
Epoch: 304, plus 0 steps train_loss: 0.6578

#### test Acc: 0, NDCG: 0.6395073573529342 HIT: 0.7354123135315277

#### val Acc: 0, NDCG: 0.7945644868491872 HIT: 0.8481596156898011
Epoch: 320, plus 0 steps train_loss: 0.6608

#### test Acc: 0, NDCG: 0.6127887244324164 HIT: 0.717284536341515

#### val Acc: 0, NDCG: 0.7695098931566055 HIT: 0.8258958090880236
Epoch: 352, plus 0 steps train_loss: 0.6478

#### test Acc: 0, NDCG: 0.5753120399108743 HIT: 0.6886464174248835

#### val Acc: 0, NDCG: 0.7555971877227461 HIT: 0.8231748241112992
Epoch: 384, plus 0 steps train_loss: 0.6425

#### test Acc: 0, NDCG: 0.5730898282741876 HIT: 0.6907871680596699

#### val Acc: 0, NDCG: 0.7409438081040132 HIT: 0.8107113573846805
Epoch: 416, plus 0 steps train_loss: 0.6631

#### test Acc: 0, NDCG: 0.504411625202207 HIT: 0.6314024148328397

#### val Acc: 0, NDCG: 0.6857588801303834 HIT: 0.768632795969107
Epoch: 448, plus 0 steps train_loss: 0.6401

#### test Acc: 0, NDCG: 0.46142739654363085 HIT: 0.5989729356220906

#### val Acc: 0, NDCG: 0.6637861150324241 HIT: 0.7518836952496826
Epoch: 480, plus 0 steps train_loss: 0.614

#### test Acc: 0, NDCG: 0.38676426001353215 HIT: 0.541009012642827

#### val Acc: 0, NDCG: 0.6180443721370952 HIT: 0.7165282479898434
Epoch: 512, plus 0 steps train_loss: 0.6106

#### test Acc: 0, NDCG: 0.3076392714768879 HIT: 0.47756096593313585

#### val Acc: 0, NDCG: 0.5788008020852993 HIT: 0.6776897415890817
Epoch: 544, plus 0 steps train_loss: 0.5997

#### test Acc: 0, NDCG: 0.24787912581206348 HIT: 0.4522968022640711

#### val Acc: 0, NDCG: 0.5497688878957397 HIT: 0.6643145961172239
Epoch: 576, plus 0 steps train_loss: 0.5835

#### test Acc: 0, NDCG: 0.2461178162940606 HIT: 0.44377182077867117

#### val Acc: 0, NDCG: 0.5482700810424612 HIT: 0.6624590033855269
Epoch: 608, plus 0 steps train_loss: 0.5961

#### test Acc: 0, NDCG: 0.25677115862606154 HIT: 0.4602489883093525

#### val Acc: 0, NDCG: 0.5605121747367757 HIT: 0.675409304909014
Epoch: 640, plus 0 steps train_loss: 0.5912

#### test Acc: 0, NDCG: 0.2509923348119689 HIT: 0.45025936971011427

#### val Acc: 0, NDCG: 0.5552903540514894 HIT: 0.66814811018832
Epoch: 704, plus 0 steps train_loss: 0.5422

#### test Acc: 0, NDCG: 0.26060544814029263 HIT: 0.4559691401290732

#### val Acc: 0, NDCG: 0.5580079341552521 HIT: 0.6776897415890817
Epoch: 768, plus 0 steps train_loss: 0.5518

#### test Acc: 0, NDCG: 0.276112444589159 HIT: 0.4727529557236564

#### val Acc: 0, NDCG: 0.5565580260579777 HIT: 0.6732511968366482
Epoch: 832, plus 0 steps train_loss: 0.5294

#### test Acc: 0, NDCG: 0.2639458153923139 HIT: 0.4607449150973339

#### val Acc: 0, NDCG: 0.5572991644346365 HIT: 0.6791237965509945
Epoch: 896, plus 0 steps train_loss: 0.5611

#### test Acc: 0, NDCG: 0.26603907580479114 HIT: 0.46027213155945834

#### val Acc: 0, NDCG: 0.5563758746356973 HIT: 0.6713708077655522
Epoch: 960, plus 0 steps train_loss: 0.5299

#### test Acc: 0, NDCG: 0.2635748041680274 HIT: 0.4563981168006771

#### val Acc: 0, NDCG: 0.5630896026762592 HIT: 0.6769830459162083
Epoch: 1017, plus 0 steps train_loss: 0.5723
Done: it took 86303.03286743164
max value of NDCG: 0.6758055483164691
max value of HIT: 0.7657969212865002

After 20 validations
max value of NDCG: 0.6758055483164691
max value of HIT: 0.7657969212865002
