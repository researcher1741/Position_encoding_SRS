 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2.0
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13296868712569712 HIT: 0.29016015129073214

#### val Acc: 0, NDCG: 0.4883253969121315 HIT: 0.5834991932924248
Epoch: 1, plus 0 steps train_loss: 0.8067

#### test Acc: 0, NDCG: 0.1383073673493099 HIT: 0.3009217625899281

#### val Acc: 0, NDCG: 0.47367137046263735 HIT: 0.5699306363732544
Epoch: 2, plus 0 steps train_loss: 0.7872

#### test Acc: 0, NDCG: 0.13108569037269147 HIT: 0.28879883225772324

#### val Acc: 0, NDCG: 0.47691010992164684 HIT: 0.5706009640816758
Epoch: 3, plus 0 steps train_loss: 0.8008

#### test Acc: 0, NDCG: 0.13203184206859225 HIT: 0.29102389044646637

#### val Acc: 0, NDCG: 0.47157646976489515 HIT: 0.5650573291366906
Epoch: 4, plus 0 steps train_loss: 0.7769

#### test Acc: 0, NDCG: 0.1299466068496785 HIT: 0.28615636902242914

#### val Acc: 0, NDCG: 0.4829090864070415 HIT: 0.5776340324798985
Epoch: 5, plus 0 steps train_loss: 0.7797

#### test Acc: 0, NDCG: 0.1310307041440195 HIT: 0.2879946043165468

#### val Acc: 0, NDCG: 0.4728216444761812 HIT: 0.5665814774650867
Epoch: 6, plus 0 steps train_loss: 0.762

#### test Acc: 0, NDCG: 0.13271398190215622 HIT: 0.2922397376216674

#### val Acc: 0, NDCG: 0.47616724481126 HIT: 0.564682077867118
Epoch: 7, plus 0 steps train_loss: 0.7774

#### test Acc: 0, NDCG: 0.12943727621513257 HIT: 0.287002750740584

#### val Acc: 0, NDCG: 0.48333359847861673 HIT: 0.5707348643144308
Epoch: 8, plus 0 steps train_loss: 0.7668

#### test Acc: 0, NDCG: 0.13424891583652862 HIT: 0.29372173217308506

#### val Acc: 0, NDCG: 0.4736592659581438 HIT: 0.5633281977359289
Epoch: 9, plus 0 steps train_loss: 0.7664

#### test Acc: 0, NDCG: 0.12717459512765802 HIT: 0.2803639441388066

#### val Acc: 0, NDCG: 0.47755860650659215 HIT: 0.5680866152666102
Epoch: 10, plus 0 steps train_loss: 0.7602

#### test Acc: 0, NDCG: 0.13471008946109608 HIT: 0.2902808268091409

#### val Acc: 0, NDCG: 0.4712916202620385 HIT: 0.5566761664198053
Epoch: 12, plus 0 steps train_loss: 0.7542

#### test Acc: 0, NDCG: 0.12251971253890186 HIT: 0.271511650973339

#### val Acc: 0, NDCG: 0.47350093882211036 HIT: 0.5692297265129074
Epoch: 14, plus 0 steps train_loss: 0.7516

#### test Acc: 0, NDCG: 0.1252182924245621 HIT: 0.27477071651502327

#### val Acc: 0, NDCG: 0.4770549000576241 HIT: 0.5699554327126534
Epoch: 16, plus 0 steps train_loss: 0.7545

#### test Acc: 0, NDCG: 0.12297995783114801 HIT: 0.2737557196889547

#### val Acc: 0, NDCG: 0.48258831619925713 HIT: 0.5833421498095641
Epoch: 18, plus 0 steps train_loss: 0.741

#### test Acc: 0, NDCG: 0.1230882252498691 HIT: 0.2785736484341938

#### val Acc: 0, NDCG: 0.4731054301910401 HIT: 0.5682436587494709
Epoch: 20, plus 0 steps train_loss: 0.7451

#### test Acc: 0, NDCG: 0.12919505091436903 HIT: 0.28650103814007616

#### val Acc: 0, NDCG: 0.4854321463588063 HIT: 0.5805310714663563
Epoch: 22, plus 0 steps train_loss: 0.7483

#### test Acc: 0, NDCG: 0.12977163633585628 HIT: 0.28664072418535763

#### val Acc: 0, NDCG: 0.48095368008057676 HIT: 0.5746047463499789
Epoch: 24, plus 0 steps train_loss: 0.7325

#### test Acc: 0, NDCG: 0.12340122575693221 HIT: 0.2789183175518409

#### val Acc: 0, NDCG: 0.47752384171510054 HIT: 0.5762206411341515
Epoch: 26, plus 0 steps train_loss: 0.7278

#### test Acc: 0, NDCG: 0.12908496586945295 HIT: 0.286966382776132

#### val Acc: 0, NDCG: 0.4826124254213382 HIT: 0.5804641213499789
Epoch: 28, plus 0 steps train_loss: 0.7379

#### test Acc: 0, NDCG: 0.13090055879412604 HIT: 0.29522686997460856

#### val Acc: 0, NDCG: 0.48627814124850594 HIT: 0.5770901661024121
Epoch: 30, plus 0 steps train_loss: 0.7272

#### test Acc: 0, NDCG: 0.1314144590919641 HIT: 0.2950640406792213

#### val Acc: 0, NDCG: 0.4790379048814333 HIT: 0.571387834585273
Epoch: 32, plus 0 steps train_loss: 0.7234

#### test Acc: 0, NDCG: 0.12902287754054698 HIT: 0.28454791314007616

#### val Acc: 0, NDCG: 0.4852910648955087 HIT: 0.5817163364896318
Epoch: 36, plus 0 steps train_loss: 0.7219

#### test Acc: 0, NDCG: 0.1315675576435411 HIT: 0.2925116708104105

#### val Acc: 0, NDCG: 0.4702131980697767 HIT: 0.555860366853576
Epoch: 40, plus 0 steps train_loss: 0.7169

#### test Acc: 0, NDCG: 0.1422272868615885 HIT: 0.3038245873889124

#### val Acc: 0, NDCG: 0.4769047474012276 HIT: 0.5733715417371984
Epoch: 44, plus 0 steps train_loss: 0.7141

#### test Acc: 0, NDCG: 0.14791933087437234 HIT: 0.30617197418535763

#### val Acc: 0, NDCG: 0.48893016421247876 HIT: 0.5832214742911553
Epoch: 48, plus 0 steps train_loss: 0.7124

#### test Acc: 0, NDCG: 0.1609568645937391 HIT: 0.32472872804697417

#### val Acc: 0, NDCG: 0.49082507892648813 HIT: 0.5786680398328397
Epoch: 52, plus 0 steps train_loss: 0.7137

#### test Acc: 0, NDCG: 0.18561229328550527 HIT: 0.3391378808717732

#### val Acc: 0, NDCG: 0.5023868120930106 HIT: 0.5912579678903935
Epoch: 56, plus 0 steps train_loss: 0.709

#### test Acc: 0, NDCG: 0.20142165799440168 HIT: 0.36031974053110455

#### val Acc: 0, NDCG: 0.5217743153522512 HIT: 0.613963975878121
Epoch: 60, plus 0 steps train_loss: 0.708

#### test Acc: 0, NDCG: 0.19251846667674666 HIT: 0.35023424275285653

#### val Acc: 0, NDCG: 0.5112299911228892 HIT: 0.610341230691917
Epoch: 64, plus 0 steps train_loss: 0.7069

#### test Acc: 0, NDCG: 0.2335257718670807 HIT: 0.38858260817816337

#### val Acc: 0, NDCG: 0.5436813339555141 HIT: 0.6411010897164621
Epoch: 68, plus 0 steps train_loss: 0.7066

#### test Acc: 0, NDCG: 0.19228284586576147 HIT: 0.3442236100825222

#### val Acc: 0, NDCG: 0.518242278047555 HIT: 0.6128440078819297
Epoch: 72, plus 0 steps train_loss: 0.7057

#### test Acc: 0, NDCG: 0.178689872728666 HIT: 0.3272389441388066

#### val Acc: 0, NDCG: 0.5082678827557786 HIT: 0.6007938134786288
Epoch: 80, plus 0 steps train_loss: 0.7042

#### test Acc: 0, NDCG: 0.2032068644785443 HIT: 0.35696314272111723

#### val Acc: 0, NDCG: 0.5126773589328655 HIT: 0.5999284212336013
Epoch: 88, plus 0 steps train_loss: 0.7007

#### test Acc: 0, NDCG: 0.1978738013317626 HIT: 0.3447195368705036

#### val Acc: 0, NDCG: 0.5144206972933368 HIT: 0.6032602227041896
Epoch: 96, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.270355228927712 HIT: 0.4346765234870927

#### val Acc: 0, NDCG: 0.5508787736274303 HIT: 0.6407374100719424
Epoch: 104, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.24374766517122584 HIT: 0.39888631374312317

#### val Acc: 0, NDCG: 0.5449430972087954 HIT: 0.6286624193292425
Epoch: 112, plus 0 steps train_loss: 0.703

#### test Acc: 0, NDCG: 0.3262225774097403 HIT: 0.4773485439589505

#### val Acc: 0, NDCG: 0.5964733555451806 HIT: 0.6854295056601777
Epoch: 120, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.32333043947285917 HIT: 0.4658653591832417

#### val Acc: 0, NDCG: 0.5882384631829103 HIT: 0.6763300756453661
Epoch: 128, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.32548460364312226 HIT: 0.4719181456305544

#### val Acc: 0, NDCG: 0.6068322265609076 HIT: 0.6944694244604317
Epoch: 136, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.31235687898718933 HIT: 0.4692756823952603

#### val Acc: 0, NDCG: 0.5956253458389474 HIT: 0.6835606882141346
Epoch: 144, plus 0 steps train_loss: 0.7015

#### test Acc: 0, NDCG: 0.3316165400554293 HIT: 0.48137546947735926

#### val Acc: 0, NDCG: 0.600450840493601 HIT: 0.6907929538721964
Epoch: 160, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.3002919356191156 HIT: 0.4507916644625476

#### val Acc: 0, NDCG: 0.5763182783404378 HIT: 0.6603298243757935
Epoch: 176, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.3114413210827637 HIT: 0.47374480929961915

#### val Acc: 0, NDCG: 0.5766211209697459 HIT: 0.6665454401184934
Epoch: 192, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.31755342550831617 HIT: 0.4604060317922133

#### val Acc: 0, NDCG: 0.5857066260209836 HIT: 0.670826941388066
Epoch: 208, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.35453687109934195 HIT: 0.5032102994075328

#### val Acc: 0, NDCG: 0.5982274940608436 HIT: 0.6887803176576386
Epoch: 224, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.41775786091841843 HIT: 0.556119075327973

#### val Acc: 0, NDCG: 0.6542659798507653 HIT: 0.7432058030046551
Epoch: 240, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.4521562962820488 HIT: 0.5825569323952603

#### val Acc: 0, NDCG: 0.693310103859343 HIT: 0.776765168747355
Epoch: 256, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.3976952240968091 HIT: 0.5462939391134152

#### val Acc: 0, NDCG: 0.6317186018874351 HIT: 0.7239654967202709
Epoch: 272, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.4373157447080704 HIT: 0.5796119538192975

#### val Acc: 0, NDCG: 0.6695928938625825 HIT: 0.749628054909014
Epoch: 288, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.4259302937921728 HIT: 0.565492091620821

#### val Acc: 0, NDCG: 0.6525514981433328 HIT: 0.7376853113097758
Epoch: 304, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.5115333712119686 HIT: 0.6431327364578925

#### val Acc: 0, NDCG: 0.6976792136105832 HIT: 0.7820806773698687
Epoch: 320, plus 0 steps train_loss: 0.693

#### test Acc: 0, NDCG: 0.46627236042429643 HIT: 0.6046331133622515

#### val Acc: 0, NDCG: 0.6951432962413726 HIT: 0.7744136492276766
Epoch: 352, plus 0 steps train_loss: 0.6942

#### test Acc: 0, NDCG: 0.5489578675872379 HIT: 0.6709955564959796

#### val Acc: 0, NDCG: 0.7409799662300746 HIT: 0.8197281329348286
Epoch: 384, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.39978212146520964 HIT: 0.5442680781845112

#### val Acc: 0, NDCG: 0.6418430867621179 HIT: 0.729704196201862
Epoch: 416, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.4084944829950748 HIT: 0.554190746667372

#### val Acc: 0, NDCG: 0.6584703468549448 HIT: 0.7482551642509522
Epoch: 448, plus 0 steps train_loss: 0.6941

#### test Acc: 0, NDCG: 0.5698290919171426 HIT: 0.6920509548243757

#### val Acc: 0, NDCG: 0.7460670031471499 HIT: 0.817780793747355
Epoch: 480, plus 0 steps train_loss: 0.6942

#### test Acc: 0, NDCG: 0.5642609782563135 HIT: 0.6923286738256453

#### val Acc: 0, NDCG: 0.7381692149871951 HIT: 0.8177022720059247
Epoch: 512, plus 0 steps train_loss: 0.6879

#### test Acc: 0, NDCG: 0.5358667935237592 HIT: 0.6641823489737622

#### val Acc: 0, NDCG: 0.725441952064538 HIT: 0.8039650999788405
Epoch: 544, plus 0 steps train_loss: 0.6886

#### test Acc: 0, NDCG: 0.615239528035644 HIT: 0.7239654967202709

#### val Acc: 0, NDCG: 0.7731232965863954 HIT: 0.8374748730427423
Epoch: 576, plus 0 steps train_loss: 0.6941

#### test Acc: 0, NDCG: 0.6106122714658498 HIT: 0.726535224026661

#### val Acc: 0, NDCG: 0.7762775484446967 HIT: 0.8426027560304697
Epoch: 608, plus 0 steps train_loss: 0.681

#### test Acc: 0, NDCG: 0.5763107646810058 HIT: 0.6939619260473974

#### val Acc: 0, NDCG: 0.7481135967669238 HIT: 0.8168195223233178
Epoch: 640, plus 0 steps train_loss: 0.6812

#### test Acc: 0, NDCG: 0.52937109821117 HIT: 0.653738957363521

#### val Acc: 0, NDCG: 0.7246757380748522 HIT: 0.7991513039568345
Epoch: 704, plus 0 steps train_loss: 0.6676

#### test Acc: 0, NDCG: 0.4934894065377767 HIT: 0.6181595165044436

#### val Acc: 0, NDCG: 0.7100982103901724 HIT: 0.7917314126639864
Epoch: 768, plus 0 steps train_loss: 0.67

#### test Acc: 0, NDCG: 0.46571305785900374 HIT: 0.6056307527507405

#### val Acc: 0, NDCG: 0.6810833233037703 HIT: 0.7708826504972492
Epoch: 832, plus 0 steps train_loss: 0.6717

#### test Acc: 0, NDCG: 0.42316403018740395 HIT: 0.5732872341832416

#### val Acc: 0, NDCG: 0.6654734041632439 HIT: 0.7547253557448159
Epoch: 896, plus 0 steps train_loss: 0.6579

#### test Acc: 0, NDCG: 0.3893383488973143 HIT: 0.5406337613732544

#### val Acc: 0, NDCG: 0.6380870021045941 HIT: 0.7299513330512061
Epoch: 960, plus 0 steps train_loss: 0.6584

#### test Acc: 0, NDCG: 0.39477001581667537 HIT: 0.5475519400655946

#### val Acc: 0, NDCG: 0.6403662226432432 HIT: 0.734456827920017
Epoch: 1017, plus 0 steps train_loss: 0.6596
Done: it took 80646.81611084938
max value of NDCG: 0.615239528035644
max value of HIT: 0.726535224026661

After 20 validations
max value of NDCG: 0.615239528035644
max value of HIT: 0.726535224026661
