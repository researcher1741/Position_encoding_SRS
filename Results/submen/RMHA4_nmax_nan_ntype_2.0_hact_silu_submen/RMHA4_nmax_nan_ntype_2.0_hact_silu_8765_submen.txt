 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2.0
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13261643388542152 HIT: 0.2941316983178163

#### val Acc: 0, NDCG: 0.4735475670458918 HIT: 0.5687337997249259
Epoch: 1, plus 0 steps train_loss: 0.7843

#### test Acc: 0, NDCG: 0.12836320505436336 HIT: 0.2852984156792213

#### val Acc: 0, NDCG: 0.4720766983429217 HIT: 0.5605766306072788
Epoch: 2, plus 0 steps train_loss: 0.7964

#### test Acc: 0, NDCG: 0.13116046212915208 HIT: 0.28879304644519677

#### val Acc: 0, NDCG: 0.4818592009913387 HIT: 0.5714357741747778
Epoch: 3, plus 0 steps train_loss: 0.7844

#### test Acc: 0, NDCG: 0.13139042878970197 HIT: 0.28396767879813795

#### val Acc: 0, NDCG: 0.48263781422415186 HIT: 0.5661872156686416
Epoch: 4, plus 0 steps train_loss: 0.7776

#### test Acc: 0, NDCG: 0.13095077099268912 HIT: 0.2849711039991536

#### val Acc: 0, NDCG: 0.4781689282731056 HIT: 0.5740840232225984
Epoch: 5, plus 0 steps train_loss: 0.7828

#### test Acc: 0, NDCG: 0.13256282956197937 HIT: 0.2894154345641134

#### val Acc: 0, NDCG: 0.4720531757895036 HIT: 0.5677419461489631
Epoch: 6, plus 0 steps train_loss: 0.7735

#### test Acc: 0, NDCG: 0.1343550517008156 HIT: 0.29603688372831144

#### val Acc: 0, NDCG: 0.47839240037208663 HIT: 0.5698041750423191
Epoch: 7, plus 0 steps train_loss: 0.7844

#### test Acc: 0, NDCG: 0.13182916974476255 HIT: 0.28592080379813795

#### val Acc: 0, NDCG: 0.4716742435504873 HIT: 0.5591078607702074
Epoch: 8, plus 0 steps train_loss: 0.7652

#### test Acc: 0, NDCG: 0.1367704590721658 HIT: 0.30110360241218787

#### val Acc: 0, NDCG: 0.4850866757588032 HIT: 0.5759164727041896
Epoch: 9, plus 0 steps train_loss: 0.7721

#### test Acc: 0, NDCG: 0.1329218180885511 HIT: 0.28649525232754974

#### val Acc: 0, NDCG: 0.47886608104917733 HIT: 0.5737525788192975
Epoch: 10, plus 0 steps train_loss: 0.7644

#### test Acc: 0, NDCG: 0.12882869570927924 HIT: 0.28592080379813795

#### val Acc: 0, NDCG: 0.49433368942677935 HIT: 0.5897949838658485
Epoch: 12, plus 0 steps train_loss: 0.7718

#### test Acc: 0, NDCG: 0.12926047278644928 HIT: 0.2821848219953449

#### val Acc: 0, NDCG: 0.4858831665104 HIT: 0.579973980374524
Epoch: 14, plus 0 steps train_loss: 0.7518

#### test Acc: 0, NDCG: 0.1315917219204418 HIT: 0.2871482225983919

#### val Acc: 0, NDCG: 0.48154484772215395 HIT: 0.5751180305755396
Epoch: 16, plus 0 steps train_loss: 0.7446

#### test Acc: 0, NDCG: 0.1359755113696701 HIT: 0.29782139362039783

#### val Acc: 0, NDCG: 0.4705431657778551 HIT: 0.5579399531845112
Epoch: 18, plus 0 steps train_loss: 0.7463

#### test Acc: 0, NDCG: 0.14090753976641 HIT: 0.29246373122090563

#### val Acc: 0, NDCG: 0.48236044696139213 HIT: 0.5783481670545916
Epoch: 20, plus 0 steps train_loss: 0.7466

#### test Acc: 0, NDCG: 0.13527513096911256 HIT: 0.29006261902242914

#### val Acc: 0, NDCG: 0.48223989830689423 HIT: 0.573660832363521
Epoch: 22, plus 0 steps train_loss: 0.7294

#### test Acc: 0, NDCG: 0.12822349544146 HIT: 0.2825220522111722

#### val Acc: 0, NDCG: 0.4758782329164233 HIT: 0.5691437658696572
Epoch: 24, plus 0 steps train_loss: 0.7299

#### test Acc: 0, NDCG: 0.12985203454707614 HIT: 0.2819476036817605

#### val Acc: 0, NDCG: 0.4955508114801449 HIT: 0.5966139772005925
Epoch: 26, plus 0 steps train_loss: 0.7185

#### test Acc: 0, NDCG: 0.13589343201696447 HIT: 0.2890591938214135

#### val Acc: 0, NDCG: 0.49592368737998715 HIT: 0.5922192393144308
Epoch: 28, plus 0 steps train_loss: 0.7169

#### test Acc: 0, NDCG: 0.14131691881674577 HIT: 0.2904800240689801

#### val Acc: 0, NDCG: 0.4931323525576975 HIT: 0.5931019889970377
Epoch: 30, plus 0 steps train_loss: 0.7094

#### test Acc: 0, NDCG: 0.1631848971796836 HIT: 0.3175270445408379

#### val Acc: 0, NDCG: 0.5051501516645602 HIT: 0.6003821942446044
Epoch: 32, plus 0 steps train_loss: 0.7206

#### test Acc: 0, NDCG: 0.18597310990001445 HIT: 0.3377344080617859

#### val Acc: 0, NDCG: 0.5075495167394591 HIT: 0.6017740954295387
Epoch: 36, plus 0 steps train_loss: 0.709

#### test Acc: 0, NDCG: 0.1837425706305329 HIT: 0.3410967916842996

#### val Acc: 0, NDCG: 0.5262286918875926 HIT: 0.6178148473867965
Epoch: 40, plus 0 steps train_loss: 0.7103

#### test Acc: 0, NDCG: 0.17819150510510395 HIT: 0.323374847915785

#### val Acc: 0, NDCG: 0.5100662978250571 HIT: 0.6031874867752857
Epoch: 44, plus 0 steps train_loss: 0.7134

#### test Acc: 0, NDCG: 0.17922471459248612 HIT: 0.33358102121244176

#### val Acc: 0, NDCG: 0.516832363151912 HIT: 0.6089741258463817
Epoch: 48, plus 0 steps train_loss: 0.7047

#### test Acc: 0, NDCG: 0.19715578022225347 HIT: 0.35161291922344473

#### val Acc: 0, NDCG: 0.5233115480376661 HIT: 0.6203961463182396
Epoch: 52, plus 0 steps train_loss: 0.705

#### test Acc: 0, NDCG: 0.1981520305669793 HIT: 0.3465941401290732

#### val Acc: 0, NDCG: 0.5267163569535981 HIT: 0.62597780231697
Epoch: 56, plus 0 steps train_loss: 0.7044

#### test Acc: 0, NDCG: 0.21369636487793492 HIT: 0.3606586238362251

#### val Acc: 0, NDCG: 0.5418532728653628 HIT: 0.6384280443292425
Epoch: 60, plus 0 steps train_loss: 0.7102

#### test Acc: 0, NDCG: 0.20798383474007445 HIT: 0.3522948185569192

#### val Acc: 0, NDCG: 0.5380296212904118 HIT: 0.6358161632458739
Epoch: 64, plus 0 steps train_loss: 0.7065

#### test Acc: 0, NDCG: 0.21062787821046017 HIT: 0.36604686838764283

#### val Acc: 0, NDCG: 0.5254417226377103 HIT: 0.6161948198793906
Epoch: 68, plus 0 steps train_loss: 0.7038

#### test Acc: 0, NDCG: 0.18095309357278655 HIT: 0.3322750806707575

#### val Acc: 0, NDCG: 0.5274705296480141 HIT: 0.6212921207151926
Epoch: 72, plus 0 steps train_loss: 0.702

#### test Acc: 0, NDCG: 0.2326940114378883 HIT: 0.3846151938743123

#### val Acc: 0, NDCG: 0.5448954305538405 HIT: 0.6377461449957681
Epoch: 80, plus 0 steps train_loss: 0.7012

#### test Acc: 0, NDCG: 0.29132117300159527 HIT: 0.43368632300042315

#### val Acc: 0, NDCG: 0.5862548091921463 HIT: 0.6719088883305121
Epoch: 88, plus 0 steps train_loss: 0.7023

#### test Acc: 0, NDCG: 0.3180422280039562 HIT: 0.46285508358019467

#### val Acc: 0, NDCG: 0.59177299970263 HIT: 0.6770251996931866
Epoch: 96, plus 0 steps train_loss: 0.7018

#### test Acc: 0, NDCG: 0.29554344311301284 HIT: 0.44274359923825646

#### val Acc: 0, NDCG: 0.5757934816644297 HIT: 0.6683473074481592
Epoch: 104, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.28983918212130044 HIT: 0.4375545519466779

#### val Acc: 0, NDCG: 0.5963087647918868 HIT: 0.6795395485082523
Epoch: 112, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.28939151151731296 HIT: 0.4344657546022006

#### val Acc: 0, NDCG: 0.5835344019954194 HIT: 0.6713286539885738
Epoch: 120, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.2507536210963764 HIT: 0.4005790771794329

#### val Acc: 0, NDCG: 0.5478638349327539 HIT: 0.6385007802581464
Epoch: 128, plus 0 steps train_loss: 0.7022

#### test Acc: 0, NDCG: 0.2840418048519022 HIT: 0.4327176126745662

#### val Acc: 0, NDCG: 0.5713400527794836 HIT: 0.659561964399069
Epoch: 136, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.2315472591710067 HIT: 0.37725068107278886

#### val Acc: 0, NDCG: 0.5409310345897277 HIT: 0.6320305887642828
Epoch: 144, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.2314818933810386 HIT: 0.37740193874312317

#### val Acc: 0, NDCG: 0.5392085300816158 HIT: 0.6323388899174778
Epoch: 160, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.39453766305612764 HIT: 0.5400477412187897

#### val Acc: 0, NDCG: 0.6373945406886306 HIT: 0.7141883000952179
Epoch: 176, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.3990346818962519 HIT: 0.5416256149492171

#### val Acc: 0, NDCG: 0.6368204958246603 HIT: 0.7117508199322895
Epoch: 192, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.43191477865647193 HIT: 0.5533270075116378

#### val Acc: 0, NDCG: 0.6702354782082975 HIT: 0.7418634944985188
Epoch: 208, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.3867801595464899 HIT: 0.5254145947947525

#### val Acc: 0, NDCG: 0.6342123564332364 HIT: 0.7173018937790944
Epoch: 224, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.3851709856990838 HIT: 0.5167805094159966

#### val Acc: 0, NDCG: 0.6248777442515631 HIT: 0.7043325817287346
Epoch: 240, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.4449058679002103 HIT: 0.5693925558082945

#### val Acc: 0, NDCG: 0.6676668142544792 HIT: 0.7405939219212865
Epoch: 256, plus 0 steps train_loss: 0.6945

#### test Acc: 0, NDCG: 0.5134319529330791 HIT: 0.6321702748095641

#### val Acc: 0, NDCG: 0.6940814111312515 HIT: 0.7662928480744816
Epoch: 272, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.3900787425474648 HIT: 0.5298762827972916

#### val Acc: 0, NDCG: 0.6347319043656676 HIT: 0.7154157188954718
Epoch: 288, plus 0 steps train_loss: 0.694

#### test Acc: 0, NDCG: 0.44597852326955734 HIT: 0.5833727319614896

#### val Acc: 0, NDCG: 0.6743541235241116 HIT: 0.7451109884151502
Epoch: 304, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.494409773050333 HIT: 0.612686964399069

#### val Acc: 0, NDCG: 0.7040961815417366 HIT: 0.7769048547926365
Epoch: 320, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.5484330051233748 HIT: 0.6584362105903513

#### val Acc: 0, NDCG: 0.7239845119244976 HIT: 0.7955533551100296
Epoch: 352, plus 0 steps train_loss: 0.6936

#### test Acc: 0, NDCG: 0.5708709769930095 HIT: 0.6811364327655522

#### val Acc: 0, NDCG: 0.7371688286834395 HIT: 0.8024293800253914
Epoch: 384, plus 0 steps train_loss: 0.6929

#### test Acc: 0, NDCG: 0.4885615760318634 HIT: 0.6188967943292425

#### val Acc: 0, NDCG: 0.6907268946213448 HIT: 0.7668672966038934
Epoch: 416, plus 0 steps train_loss: 0.6926

#### test Acc: 0, NDCG: 0.5708870665002718 HIT: 0.6899945117435464

#### val Acc: 0, NDCG: 0.7187516591363439 HIT: 0.7883938253808718
Epoch: 448, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.5344753615797022 HIT: 0.6558912796233601

#### val Acc: 0, NDCG: 0.7046991775201757 HIT: 0.7785802607913669
Epoch: 480, plus 0 steps train_loss: 0.6888

#### test Acc: 0, NDCG: 0.5717470209306244 HIT: 0.6853261875793484

#### val Acc: 0, NDCG: 0.7515268633644558 HIT: 0.8191594702179432
Epoch: 512, plus 0 steps train_loss: 0.6866

#### test Acc: 0, NDCG: 0.44089142389157965 HIT: 0.5884700327972916

#### val Acc: 0, NDCG: 0.6459089043210335 HIT: 0.7288636002962336
Epoch: 544, plus 0 steps train_loss: 0.6753

#### test Acc: 0, NDCG: 0.40138577109182616 HIT: 0.5645308201967838

#### val Acc: 0, NDCG: 0.6355131146104988 HIT: 0.7202105043906052
Epoch: 576, plus 0 steps train_loss: 0.6792

#### test Acc: 0, NDCG: 0.2973866076527363 HIT: 0.4740051708633094

#### val Acc: 0, NDCG: 0.554049842976178 HIT: 0.6535571175412611
Epoch: 608, plus 0 steps train_loss: 0.6671

#### test Acc: 0, NDCG: 0.2892942693779079 HIT: 0.4670026846170123

#### val Acc: 0, NDCG: 0.5683902209091046 HIT: 0.6699979171074905
Epoch: 640, plus 0 steps train_loss: 0.6699

#### test Acc: 0, NDCG: 0.2270319001201655 HIT: 0.43280935913034274

#### val Acc: 0, NDCG: 0.5290273998984817 HIT: 0.641591230691917
Epoch: 704, plus 0 steps train_loss: 0.6577

#### test Acc: 0, NDCG: 0.2877146220679846 HIT: 0.4897508463817181

#### val Acc: 0, NDCG: 0.5551006219393918 HIT: 0.6614481392826914
Epoch: 768, plus 0 steps train_loss: 0.6535

#### test Acc: 0, NDCG: 0.2823190331586744 HIT: 0.4872960087812103

#### val Acc: 0, NDCG: 0.5604851837824765 HIT: 0.6721866073317817
Epoch: 832, plus 0 steps train_loss: 0.6501

#### test Acc: 0, NDCG: 0.2836453598635962 HIT: 0.48361953819297504

#### val Acc: 0, NDCG: 0.5482849469834666 HIT: 0.6584973748942023
Epoch: 896, plus 0 steps train_loss: 0.6459

#### test Acc: 0, NDCG: 0.2902812255172959 HIT: 0.4914857635950063

#### val Acc: 0, NDCG: 0.5608466177981261 HIT: 0.6685828726724502
Epoch: 960, plus 0 steps train_loss: 0.6429

#### test Acc: 0, NDCG: 0.2919775081544815 HIT: 0.4912138304062632

#### val Acc: 0, NDCG: 0.5525598394845984 HIT: 0.6641327562949639
Epoch: 1017, plus 0 steps train_loss: 0.651
Done: it took 80926.99064564705
max value of NDCG: 0.5717470209306244
max value of HIT: 0.6899945117435464

After 20 validations
max value of NDCG: 0.5717470209306244
max value of HIT: 0.6899945117435464
