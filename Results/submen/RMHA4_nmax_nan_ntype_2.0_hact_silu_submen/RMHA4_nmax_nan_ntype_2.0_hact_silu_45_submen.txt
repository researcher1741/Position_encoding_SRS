 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2.0
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.1366876528909067 HIT: 0.2932258053851037

#### val Acc: 0, NDCG: 0.4758124786099437 HIT: 0.5701124761955141
Epoch: 1, plus 0 steps train_loss: 0.835

#### test Acc: 0, NDCG: 0.13859756279020724 HIT: 0.3034741324587389

#### val Acc: 0, NDCG: 0.47993890639701725 HIT: 0.5777910759627592
Epoch: 2, plus 0 steps train_loss: 0.8224

#### test Acc: 0, NDCG: 0.13235975929047475 HIT: 0.2868283498201439

#### val Acc: 0, NDCG: 0.48784494666806877 HIT: 0.5862929141980534
Epoch: 3, plus 0 steps train_loss: 0.826

#### test Acc: 0, NDCG: 0.13493834460512213 HIT: 0.29236619895260263

#### val Acc: 0, NDCG: 0.47162080301837306 HIT: 0.5696834995239103
Epoch: 4, plus 0 steps train_loss: 0.803

#### test Acc: 0, NDCG: 0.13864921097039057 HIT: 0.29838261743546335

#### val Acc: 0, NDCG: 0.47850100670578627 HIT: 0.5715812460325856
Epoch: 5, plus 0 steps train_loss: 0.7992

#### test Acc: 0, NDCG: 0.12757903592174313 HIT: 0.27657258384468897

#### val Acc: 0, NDCG: 0.4694505748131344 HIT: 0.5596632987727466
Epoch: 6, plus 0 steps train_loss: 0.785

#### test Acc: 0, NDCG: 0.12911951864791754 HIT: 0.2846206490689801

#### val Acc: 0, NDCG: 0.47860067326656075 HIT: 0.5683759058929327
Epoch: 7, plus 0 steps train_loss: 0.7907

#### test Acc: 0, NDCG: 0.13302169735753913 HIT: 0.28185172450275076

#### val Acc: 0, NDCG: 0.4773359964419952 HIT: 0.5660665401502327
Epoch: 8, plus 0 steps train_loss: 0.7915

#### test Acc: 0, NDCG: 0.12666011568935742 HIT: 0.2771048785971223

#### val Acc: 0, NDCG: 0.4725309710933941 HIT: 0.5683163946783749
Epoch: 9, plus 0 steps train_loss: 0.7894

#### test Acc: 0, NDCG: 0.12744525521403688 HIT: 0.27725613626745665

#### val Acc: 0, NDCG: 0.47521804954394803 HIT: 0.5679775113732544
Epoch: 10, plus 0 steps train_loss: 0.7737

#### test Acc: 0, NDCG: 0.12779802143890442 HIT: 0.27990438531527717

#### val Acc: 0, NDCG: 0.4817779816810173 HIT: 0.576890968842573
Epoch: 12, plus 0 steps train_loss: 0.7771

#### test Acc: 0, NDCG: 0.1272078792164933 HIT: 0.28044825169276344

#### val Acc: 0, NDCG: 0.477190125506698 HIT: 0.5747196360558613
Epoch: 14, plus 0 steps train_loss: 0.7694

#### test Acc: 0, NDCG: 0.12708938532355799 HIT: 0.2773040758569615

#### val Acc: 0, NDCG: 0.48774564890733874 HIT: 0.5732260698793906
Epoch: 16, plus 0 steps train_loss: 0.7463

#### test Acc: 0, NDCG: 0.12493429003068277 HIT: 0.27611302502115953

#### val Acc: 0, NDCG: 0.4761649210624397 HIT: 0.5729731472175201
Epoch: 18, plus 0 steps train_loss: 0.7446

#### test Acc: 0, NDCG: 0.13249342981292525 HIT: 0.2974461423508252

#### val Acc: 0, NDCG: 0.4777915044166998 HIT: 0.5678568358548455
Epoch: 20, plus 0 steps train_loss: 0.7463

#### test Acc: 0, NDCG: 0.1296272807472519 HIT: 0.28170625264494287

#### val Acc: 0, NDCG: 0.47801360472665116 HIT: 0.576854600878121
Epoch: 22, plus 0 steps train_loss: 0.725

#### test Acc: 0, NDCG: 0.13404267167829034 HIT: 0.29689649016081254

#### val Acc: 0, NDCG: 0.47498801727708556 HIT: 0.5657582389970377
Epoch: 24, plus 0 steps train_loss: 0.7229

#### test Acc: 0, NDCG: 0.15023305190217473 HIT: 0.3118131413986458

#### val Acc: 0, NDCG: 0.4808958371548359 HIT: 0.57013561944562
Epoch: 26, plus 0 steps train_loss: 0.7205

#### test Acc: 0, NDCG: 0.15386022149356732 HIT: 0.3208282638595006

#### val Acc: 0, NDCG: 0.4995688467618011 HIT: 0.5848299301735083
Epoch: 28, plus 0 steps train_loss: 0.7188

#### test Acc: 0, NDCG: 0.16442639454413174 HIT: 0.32483783194033006

#### val Acc: 0, NDCG: 0.4971896136664268 HIT: 0.5909918205141769
Epoch: 30, plus 0 steps train_loss: 0.7178

#### test Acc: 0, NDCG: 0.17552160368656597 HIT: 0.3308600362357173

#### val Acc: 0, NDCG: 0.508177670080521 HIT: 0.601803024492171
Epoch: 32, plus 0 steps train_loss: 0.7122

#### test Acc: 0, NDCG: 0.20662495758715863 HIT: 0.3623819694244604

#### val Acc: 0, NDCG: 0.5340939185108384 HIT: 0.6255008860558613
Epoch: 36, plus 0 steps train_loss: 0.7125

#### test Acc: 0, NDCG: 0.23258139070513886 HIT: 0.3791500806707575

#### val Acc: 0, NDCG: 0.5326452583601794 HIT: 0.6233047569297503
Epoch: 40, plus 0 steps train_loss: 0.7103

#### test Acc: 0, NDCG: 0.2788102850169803 HIT: 0.42109639494286927

#### val Acc: 0, NDCG: 0.5541055085978338 HIT: 0.6405266411870504
Epoch: 44, plus 0 steps train_loss: 0.7113

#### test Acc: 0, NDCG: 0.28136684720122546 HIT: 0.4243438888595006

#### val Acc: 0, NDCG: 0.5632540275654209 HIT: 0.6516345746931866
Epoch: 48, plus 0 steps train_loss: 0.7073

#### test Acc: 0, NDCG: 0.2695916662503387 HIT: 0.41769764335590354

#### val Acc: 0, NDCG: 0.5444100084462319 HIT: 0.6319520670228522
Epoch: 52, plus 0 steps train_loss: 0.7082

#### test Acc: 0, NDCG: 0.24617747217934677 HIT: 0.40037987991959373

#### val Acc: 0, NDCG: 0.5376349445941265 HIT: 0.624013105691917
Epoch: 56, plus 0 steps train_loss: 0.7094

#### test Acc: 0, NDCG: 0.2057217118347306 HIT: 0.3659972757088447

#### val Acc: 0, NDCG: 0.5242332342830872 HIT: 0.6091328224185357
Epoch: 60, plus 0 steps train_loss: 0.7082

#### test Acc: 0, NDCG: 0.23093193543676074 HIT: 0.3792343882247144

#### val Acc: 0, NDCG: 0.5285859732312872 HIT: 0.6161526661024121
Epoch: 64, plus 0 steps train_loss: 0.7054

#### test Acc: 0, NDCG: 0.27907164410949015 HIT: 0.42162125079348284

#### val Acc: 0, NDCG: 0.5519187457528685 HIT: 0.638113957363521
Epoch: 68, plus 0 steps train_loss: 0.702

#### test Acc: 0, NDCG: 0.29778046112891193 HIT: 0.43889107464028776

#### val Acc: 0, NDCG: 0.564874117836297 HIT: 0.6425640737410072
Epoch: 72, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.2530214934068651 HIT: 0.40278512484130347

#### val Acc: 0, NDCG: 0.5362268561634735 HIT: 0.6196836648328397
Epoch: 80, plus 0 steps train_loss: 0.7054

#### test Acc: 0, NDCG: 0.27534507680296216 HIT: 0.4250811666842996

#### val Acc: 0, NDCG: 0.5527373545269127 HIT: 0.633681198423614
Epoch: 88, plus 0 steps train_loss: 0.7029

#### test Acc: 0, NDCG: 0.2704623134641063 HIT: 0.4202252168853153

#### val Acc: 0, NDCG: 0.5573829600443699 HIT: 0.6444808307765553
Epoch: 96, plus 0 steps train_loss: 0.7025

#### test Acc: 0, NDCG: 0.27803240604842955 HIT: 0.4275839438743123

#### val Acc: 0, NDCG: 0.5501729862106395 HIT: 0.6306039727041896
Epoch: 104, plus 0 steps train_loss: 0.7042

#### test Acc: 0, NDCG: 0.29826057783508936 HIT: 0.4478830538510368

#### val Acc: 0, NDCG: 0.5468523919110261 HIT: 0.6269638700804063
Epoch: 112, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.2901612400162624 HIT: 0.43975068107278886

#### val Acc: 0, NDCG: 0.5619130822870594 HIT: 0.6362335682924248
Epoch: 120, plus 0 steps train_loss: 0.7023

#### test Acc: 0, NDCG: 0.3329929457864625 HIT: 0.4786065449111299

#### val Acc: 0, NDCG: 0.5871253560217377 HIT: 0.6700342850719424
Epoch: 128, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.34466161455900124 HIT: 0.48764646371138387

#### val Acc: 0, NDCG: 0.6001158101951665 HIT: 0.6848376996931866
Epoch: 136, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.32022457402923815 HIT: 0.464124656157427

#### val Acc: 0, NDCG: 0.5833745888139198 HIT: 0.6657602227041896
Epoch: 144, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.38530642806798643 HIT: 0.5217554816440966

#### val Acc: 0, NDCG: 0.6130205505010919 HIT: 0.6951223947312738
Epoch: 160, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.3552189672198649 HIT: 0.4992618956305544

#### val Acc: 0, NDCG: 0.5999481836344221 HIT: 0.6784154477888278
Epoch: 176, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.3185508149735649 HIT: 0.4545888105691917

#### val Acc: 0, NDCG: 0.5684680416426497 HIT: 0.6485573489737622
Epoch: 192, plus 0 steps train_loss: 0.6995

#### test Acc: 0, NDCG: 0.250117727190275 HIT: 0.397852306390182

#### val Acc: 0, NDCG: 0.5417227120107101 HIT: 0.6264489327655522
Epoch: 208, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.36007078641332624 HIT: 0.4905608601354211

#### val Acc: 0, NDCG: 0.5988510023898501 HIT: 0.676439179538722
Epoch: 224, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.26891439180238585 HIT: 0.4214832178374947

#### val Acc: 0, NDCG: 0.5508176874789908 HIT: 0.6381866932924248
Epoch: 240, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.3364049025806281 HIT: 0.47551774756665255

#### val Acc: 0, NDCG: 0.595936433339513 HIT: 0.6791890935780787
Epoch: 256, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.3530748614352067 HIT: 0.4950721408167584

#### val Acc: 0, NDCG: 0.618698413534309 HIT: 0.698907969212865
Epoch: 272, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.4717411122215416 HIT: 0.5984464266821836

#### val Acc: 0, NDCG: 0.6698021128559747 HIT: 0.7469855916737198
Epoch: 288, plus 0 steps train_loss: 0.6946

#### test Acc: 0, NDCG: 0.3181605808304048 HIT: 0.4628914515446466

#### val Acc: 0, NDCG: 0.5851465614810755 HIT: 0.6671984103893356
Epoch: 304, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.2780311241820942 HIT: 0.4314901938743123

#### val Acc: 0, NDCG: 0.5374772220504233 HIT: 0.6207713975878121
Epoch: 320, plus 0 steps train_loss: 0.6924

#### test Acc: 0, NDCG: 0.3050659901116531 HIT: 0.4532159199111299

#### val Acc: 0, NDCG: 0.5580390337363098 HIT: 0.6428855996085484
Epoch: 352, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.2874882826326489 HIT: 0.4393274902137114

#### val Acc: 0, NDCG: 0.5665471843652451 HIT: 0.6559524439272112
Epoch: 384, plus 0 steps train_loss: 0.6914

#### test Acc: 0, NDCG: 0.3807588882671001 HIT: 0.5295564100190435

#### val Acc: 0, NDCG: 0.6093136211796406 HIT: 0.6937916578501904
Epoch: 416, plus 0 steps train_loss: 0.6885

#### test Acc: 0, NDCG: 0.36837313383314 HIT: 0.5131213962653407

#### val Acc: 0, NDCG: 0.6067158426284052 HIT: 0.6901515552264071
Epoch: 448, plus 0 steps train_loss: 0.6891

#### test Acc: 0, NDCG: 0.3881110625890999 HIT: 0.5285108310410495

#### val Acc: 0, NDCG: 0.6266400732443786 HIT: 0.7138188346381719
Epoch: 480, plus 0 steps train_loss: 0.6793

#### test Acc: 0, NDCG: 0.39184423956944703 HIT: 0.541244577867118

#### val Acc: 0, NDCG: 0.6277814574797013 HIT: 0.7123980043906052
Epoch: 512, plus 0 steps train_loss: 0.683

#### test Acc: 0, NDCG: 0.3996116269193409 HIT: 0.5390269585801947

#### val Acc: 0, NDCG: 0.6263423399536128 HIT: 0.71635219398011
Epoch: 544, plus 0 steps train_loss: 0.6794

#### test Acc: 0, NDCG: 0.40555701868558247 HIT: 0.5570993572788827

#### val Acc: 0, NDCG: 0.6375312312774557 HIT: 0.7257673640499366
Epoch: 576, plus 0 steps train_loss: 0.6797

#### test Acc: 0, NDCG: 0.2365192679817195 HIT: 0.41950529649809565

#### val Acc: 0, NDCG: 0.5255786778275531 HIT: 0.6352417147164621
Epoch: 608, plus 0 steps train_loss: 0.6649

#### test Acc: 0, NDCG: 0.2512250471795741 HIT: 0.4329168099344054

#### val Acc: 0, NDCG: 0.5409383898960326 HIT: 0.6468149928586542
Epoch: 640, plus 0 steps train_loss: 0.6733

#### test Acc: 0, NDCG: 0.25484158171847765 HIT: 0.43350448317816337

#### val Acc: 0, NDCG: 0.5357682489034831 HIT: 0.6396438915044436
Epoch: 704, plus 0 steps train_loss: 0.6561

#### test Acc: 0, NDCG: 0.25678618465162545 HIT: 0.4397316705459162

#### val Acc: 0, NDCG: 0.5530033108949755 HIT: 0.6673496680596699
Epoch: 768, plus 0 steps train_loss: 0.6601

#### test Acc: 0, NDCG: 0.2694488431278049 HIT: 0.4596133754760897

#### val Acc: 0, NDCG: 0.548228669796332 HIT: 0.6526206424566229
Epoch: 832, plus 0 steps train_loss: 0.6485

#### test Acc: 0, NDCG: 0.2667405282457863 HIT: 0.4492253623571731

#### val Acc: 0, NDCG: 0.553126407656647 HIT: 0.6619019122936944
Epoch: 896, plus 0 steps train_loss: 0.6505

#### test Acc: 0, NDCG: 0.2718574928789006 HIT: 0.4582842916842996

#### val Acc: 0, NDCG: 0.5572387664559216 HIT: 0.6668058016821836
Epoch: 960, plus 0 steps train_loss: 0.6314

#### test Acc: 0, NDCG: 0.26977358072866314 HIT: 0.45804128755818874

#### val Acc: 0, NDCG: 0.5541891606938946 HIT: 0.6598223259627592
Epoch: 1017, plus 0 steps train_loss: 0.6413
Done: it took 82587.76870536804
max value of NDCG: 0.4717411122215416
max value of HIT: 0.5984464266821836

After 20 validations
max value of NDCG: 0.4717411122215416
max value of HIT: 0.5984464266821836
