 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2.0
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13593046953406251 HIT: 0.29644850296233605

#### val Acc: 0, NDCG: 0.4762097324203123 HIT: 0.5791945487727466
Epoch: 1, plus 0 steps train_loss: 0.8468

#### test Acc: 0, NDCG: 0.13293998220090664 HIT: 0.2892947590457046

#### val Acc: 0, NDCG: 0.4853263867460116 HIT: 0.5879567485717309
Epoch: 2, plus 0 steps train_loss: 0.8503

#### test Acc: 0, NDCG: 0.13378757170785896 HIT: 0.2912057302687262

#### val Acc: 0, NDCG: 0.4931973987673492 HIT: 0.5907372447630131
Epoch: 3, plus 0 steps train_loss: 0.8458

#### test Acc: 0, NDCG: 0.12744135360663733 HIT: 0.27955971619763015

#### val Acc: 0, NDCG: 0.4851156994921394 HIT: 0.5826949653512484
Epoch: 4, plus 0 steps train_loss: 0.8358

#### test Acc: 0, NDCG: 0.1313302688557504 HIT: 0.2885632670334321

#### val Acc: 0, NDCG: 0.48628598305547543 HIT: 0.5891651568451122
Epoch: 5, plus 0 steps train_loss: 0.8141

#### test Acc: 0, NDCG: 0.13226698441085155 HIT: 0.2926323463288193

#### val Acc: 0, NDCG: 0.47508013326181964 HIT: 0.571805239631824
Epoch: 6, plus 0 steps train_loss: 0.8055

#### test Acc: 0, NDCG: 0.1321836685973905 HIT: 0.2878127644942869

#### val Acc: 0, NDCG: 0.4836179318209922 HIT: 0.5788498796550995
Epoch: 7, plus 0 steps train_loss: 0.7775

#### test Acc: 0, NDCG: 0.13572182701818544 HIT: 0.2925959783643673

#### val Acc: 0, NDCG: 0.47618952085180044 HIT: 0.5714432130765976
Epoch: 8, plus 0 steps train_loss: 0.7849

#### test Acc: 0, NDCG: 0.1295771031349271 HIT: 0.2921074904782057

#### val Acc: 0, NDCG: 0.4778381947527426 HIT: 0.572850818609818
Epoch: 9, plus 0 steps train_loss: 0.7762

#### test Acc: 0, NDCG: 0.12933199911719467 HIT: 0.2864283022111722

#### val Acc: 0, NDCG: 0.4793035232092693 HIT: 0.5695611709162083
Epoch: 10, plus 0 steps train_loss: 0.7886

#### test Acc: 0, NDCG: 0.1380230435479557 HIT: 0.30017869895260263

#### val Acc: 0, NDCG: 0.4790795433215522 HIT: 0.5670831900655946
Epoch: 12, plus 0 steps train_loss: 0.7647

#### test Acc: 0, NDCG: 0.1353028920686591 HIT: 0.29368371111933983

#### val Acc: 0, NDCG: 0.4805644417862078 HIT: 0.5726458355374524
Epoch: 14, plus 0 steps train_loss: 0.7721

#### test Acc: 0, NDCG: 0.13800428312654106 HIT: 0.30650920440118495

#### val Acc: 0, NDCG: 0.47912277032481587 HIT: 0.5760867409013964
Epoch: 16, plus 0 steps train_loss: 0.7636

#### test Acc: 0, NDCG: 0.13986952048769274 HIT: 0.3113172146106644

#### val Acc: 0, NDCG: 0.4755725728198504 HIT: 0.5696413457469318
Epoch: 18, plus 0 steps train_loss: 0.742

#### test Acc: 0, NDCG: 0.1287362555337146 HIT: 0.28454212732754974

#### val Acc: 0, NDCG: 0.4810648294480155 HIT: 0.5736798428903935
Epoch: 20, plus 0 steps train_loss: 0.7491

#### test Acc: 0, NDCG: 0.13649388493872996 HIT: 0.2889691004549302

#### val Acc: 0, NDCG: 0.4747038687457191 HIT: 0.5669377182077867
Epoch: 22, plus 0 steps train_loss: 0.7357

#### test Acc: 0, NDCG: 0.13019917974810646 HIT: 0.28485621429327124

#### val Acc: 0, NDCG: 0.48445832688606577 HIT: 0.5754031884786288
Epoch: 24, plus 0 steps train_loss: 0.7338

#### test Acc: 0, NDCG: 0.13066724666946877 HIT: 0.29859503940964877

#### val Acc: 0, NDCG: 0.4702060667571558 HIT: 0.5672038655840034
Epoch: 26, plus 0 steps train_loss: 0.7185

#### test Acc: 0, NDCG: 0.12561181960251452 HIT: 0.2771528181866272

#### val Acc: 0, NDCG: 0.4817318454260859 HIT: 0.5807418403512484
Epoch: 28, plus 0 steps train_loss: 0.7244

#### test Acc: 0, NDCG: 0.12553293146044964 HIT: 0.27690568133728316

#### val Acc: 0, NDCG: 0.4884103715621406 HIT: 0.5907314589504867
Epoch: 30, plus 0 steps train_loss: 0.7235

#### test Acc: 0, NDCG: 0.1399185088614867 HIT: 0.2997133543165468

#### val Acc: 0, NDCG: 0.48453829691217554 HIT: 0.5826048719847651
Epoch: 32, plus 0 steps train_loss: 0.724

#### test Acc: 0, NDCG: 0.18621191947852703 HIT: 0.33483902216462125

#### val Acc: 0, NDCG: 0.49932248516309025 HIT: 0.5847571942446044
Epoch: 36, plus 0 steps train_loss: 0.7157

#### test Acc: 0, NDCG: 0.21718728679344088 HIT: 0.36923319800042315

#### val Acc: 0, NDCG: 0.5369356742200153 HIT: 0.628028459585273
Epoch: 40, plus 0 steps train_loss: 0.7132

#### test Acc: 0, NDCG: 0.23974717020552525 HIT: 0.3938005845323741

#### val Acc: 0, NDCG: 0.54279151018631 HIT: 0.6323752578819297
Epoch: 44, plus 0 steps train_loss: 0.7114

#### test Acc: 0, NDCG: 0.21675267423730774 HIT: 0.37054492435463393

#### val Acc: 0, NDCG: 0.529425881967884 HIT: 0.6227493189272112
Epoch: 48, plus 0 steps train_loss: 0.7158

#### test Acc: 0, NDCG: 0.21398059344270806 HIT: 0.36480787796233605

#### val Acc: 0, NDCG: 0.5471266805076928 HIT: 0.6393835299407533
Epoch: 52, plus 0 steps train_loss: 0.7122

#### test Acc: 0, NDCG: 0.19473874531806956 HIT: 0.35075331279094374

#### val Acc: 0, NDCG: 0.5145659545282554 HIT: 0.6116951108231062
Epoch: 56, plus 0 steps train_loss: 0.7111

#### test Acc: 0, NDCG: 0.2125973679029236 HIT: 0.3649459109183241

#### val Acc: 0, NDCG: 0.5316485134510822 HIT: 0.6237585299407533
Epoch: 60, plus 0 steps train_loss: 0.7122

#### test Acc: 0, NDCG: 0.21374709036267434 HIT: 0.35487198476512904

#### val Acc: 0, NDCG: 0.5449818934560688 HIT: 0.6342019215509945
Epoch: 64, plus 0 steps train_loss: 0.7041

#### test Acc: 0, NDCG: 0.21459448454706642 HIT: 0.36642046656792215

#### val Acc: 0, NDCG: 0.528119864694296 HIT: 0.6192489023487093
Epoch: 68, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.23178279942863705 HIT: 0.3778441401290732

#### val Acc: 0, NDCG: 0.5426521701787389 HIT: 0.6319462812103259
Epoch: 72, plus 0 steps train_loss: 0.7065

#### test Acc: 0, NDCG: 0.3037567972414414 HIT: 0.44831781633516715

#### val Acc: 0, NDCG: 0.5859680505108368 HIT: 0.6804049407532797
Epoch: 80, plus 0 steps train_loss: 0.7096

#### test Acc: 0, NDCG: 0.36253969959389964 HIT: 0.49752697841726623

#### val Acc: 0, NDCG: 0.6184418249539154 HIT: 0.7043441533537875
Epoch: 88, plus 0 steps train_loss: 0.7056

#### test Acc: 0, NDCG: 0.31719004547033514 HIT: 0.4656314470482438

#### val Acc: 0, NDCG: 0.603833899178519 HIT: 0.6907334426576386
Epoch: 96, plus 0 steps train_loss: 0.7041

#### test Acc: 0, NDCG: 0.40706700441966864 HIT: 0.5457442869234024

#### val Acc: 0, NDCG: 0.6461041567785589 HIT: 0.728204844212865
Epoch: 104, plus 0 steps train_loss: 0.7036

#### test Acc: 0, NDCG: 0.34498127329758516 HIT: 0.481605248889124

#### val Acc: 0, NDCG: 0.6196858520569573 HIT: 0.7052938531527718
Epoch: 112, plus 0 steps train_loss: 0.7055

#### test Acc: 0, NDCG: 0.40968581730965914 HIT: 0.547176688796022

#### val Acc: 0, NDCG: 0.6609694750000772 HIT: 0.7328425862251375
Epoch: 120, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.41551932397510816 HIT: 0.5489901277507405

#### val Acc: 0, NDCG: 0.64703396594047 HIT: 0.7290206437790944
Epoch: 128, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.48427943559755127 HIT: 0.6168957297397376

#### val Acc: 0, NDCG: 0.6777978716128028 HIT: 0.7545988944138806
Epoch: 136, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.46336646113993996 HIT: 0.5880716382776132

#### val Acc: 0, NDCG: 0.6832914171958049 HIT: 0.7569082601565806
Epoch: 144, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.5250918700017005 HIT: 0.6476613745768091

#### val Acc: 0, NDCG: 0.7214148918384297 HIT: 0.7942589861933982
Epoch: 160, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.5311477209726653 HIT: 0.6527644612251375

#### val Acc: 0, NDCG: 0.7183825546398114 HIT: 0.7942895683453237
Epoch: 176, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.4935804586054381 HIT: 0.6203845746931866

#### val Acc: 0, NDCG: 0.698914545740818 HIT: 0.7747161645683454
Epoch: 192, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.4981103067469905 HIT: 0.6259298627274651

#### val Acc: 0, NDCG: 0.6952710714682012 HIT: 0.7711355731591197
Epoch: 208, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.5275101147904476 HIT: 0.6482969874100719

#### val Acc: 0, NDCG: 0.709778152205611 HIT: 0.7884244075327973
Epoch: 224, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.45226787233890015 HIT: 0.5849084519149387

#### val Acc: 0, NDCG: 0.6813628568846248 HIT: 0.7588192313796022
Epoch: 240, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.40588061590198754 HIT: 0.54163718657427

#### val Acc: 0, NDCG: 0.6407590669736295 HIT: 0.7226116165890817
Epoch: 256, plus 0 steps train_loss: 0.6984

#### test Acc: 0, NDCG: 0.46778840285027284 HIT: 0.6007632313267033

#### val Acc: 0, NDCG: 0.6915684128336962 HIT: 0.7722497553427846
Epoch: 272, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.528774070004261 HIT: 0.651785832363521

#### val Acc: 0, NDCG: 0.7076839711487077 HIT: 0.7829460696148963
Epoch: 288, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.5545025806201052 HIT: 0.6772243969530258

#### val Acc: 0, NDCG: 0.7148273908622338 HIT: 0.7849719305438002
Epoch: 304, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.591612664618045 HIT: 0.7113160574481592

#### val Acc: 0, NDCG: 0.734678735061418 HIT: 0.8073084730744816
Epoch: 320, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.5481709573416557 HIT: 0.6699078237410072

#### val Acc: 0, NDCG: 0.7272655504286695 HIT: 0.8029178679115531
Epoch: 352, plus 0 steps train_loss: 0.694

#### test Acc: 0, NDCG: 0.5540707694671932 HIT: 0.668565515234871

#### val Acc: 0, NDCG: 0.7241192558422093 HIT: 0.7950326319826492
Epoch: 384, plus 0 steps train_loss: 0.691

#### test Acc: 0, NDCG: 0.59176601520832 HIT: 0.7030555702496826

#### val Acc: 0, NDCG: 0.7507785132704045 HIT: 0.8202777851248414
Epoch: 416, plus 0 steps train_loss: 0.6916

#### test Acc: 0, NDCG: 0.597704647523584 HIT: 0.7157603880131189

#### val Acc: 0, NDCG: 0.7383606473713159 HIT: 0.8088499788404571
Epoch: 448, plus 0 steps train_loss: 0.6914

#### test Acc: 0, NDCG: 0.564325199926672 HIT: 0.6811612291049514

#### val Acc: 0, NDCG: 0.7347079905307256 HIT: 0.8085127486246297
Epoch: 480, plus 0 steps train_loss: 0.69

#### test Acc: 0, NDCG: 0.55941251953719 HIT: 0.6737529094371562

#### val Acc: 0, NDCG: 0.727009826998629 HIT: 0.8088441930279306
Epoch: 512, plus 0 steps train_loss: 0.6834

#### test Acc: 0, NDCG: 0.5594516319728567 HIT: 0.6869900219530258

#### val Acc: 0, NDCG: 0.7274521326345746 HIT: 0.7999786751481168
Epoch: 544, plus 0 steps train_loss: 0.6829

#### test Acc: 0, NDCG: 0.5762212678121851 HIT: 0.7011636095535336

#### val Acc: 0, NDCG: 0.7386711031653613 HIT: 0.8153259561468472
Epoch: 576, plus 0 steps train_loss: 0.677

#### test Acc: 0, NDCG: 0.5449127358152016 HIT: 0.6695325724714346

#### val Acc: 0, NDCG: 0.7122838933960384 HIT: 0.7925546511320355
Epoch: 608, plus 0 steps train_loss: 0.6757

#### test Acc: 0, NDCG: 0.48566503578074427 HIT: 0.6247024439272112

#### val Acc: 0, NDCG: 0.6761992726485037 HIT: 0.7645215628967414
Epoch: 640, plus 0 steps train_loss: 0.6684

#### test Acc: 0, NDCG: 0.31900052595016903 HIT: 0.49584000079348284

#### val Acc: 0, NDCG: 0.5883915834017847 HIT: 0.6949959334003385
Epoch: 704, plus 0 steps train_loss: 0.6722

#### test Acc: 0, NDCG: 0.27967399211391625 HIT: 0.46462058294540837

#### val Acc: 0, NDCG: 0.5506093094395007 HIT: 0.6529710973867965
Epoch: 768, plus 0 steps train_loss: 0.6585

#### test Acc: 0, NDCG: 0.2956880066349907 HIT: 0.4884870596170123

#### val Acc: 0, NDCG: 0.5575588438193803 HIT: 0.6654825037029201
Epoch: 832, plus 0 steps train_loss: 0.6451

#### test Acc: 0, NDCG: 0.29478282982584586 HIT: 0.4755351050042319

#### val Acc: 0, NDCG: 0.5703210001534177 HIT: 0.6739769030363945
Epoch: 896, plus 0 steps train_loss: 0.6514

#### test Acc: 0, NDCG: 0.28881459816583904 HIT: 0.4754012047714769

#### val Acc: 0, NDCG: 0.5731143304975249 HIT: 0.6776955274016081
Epoch: 960, plus 0 steps train_loss: 0.6377

#### test Acc: 0, NDCG: 0.2869221170575487 HIT: 0.4701295030152349

#### val Acc: 0, NDCG: 0.5680866340966706 HIT: 0.6770367713182396
Epoch: 1017, plus 0 steps train_loss: 0.6559
Done: it took 81435.36601805687
max value of NDCG: 0.597704647523584
max value of HIT: 0.7157603880131189

After 20 validations
max value of NDCG: 0.597704647523584
max value of HIT: 0.7157603880131189
