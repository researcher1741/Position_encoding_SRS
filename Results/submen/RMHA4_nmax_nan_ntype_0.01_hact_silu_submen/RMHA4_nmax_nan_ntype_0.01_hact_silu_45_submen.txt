 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.01
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12249300550744546 HIT: 0.27227372513753706

#### val Acc: 0, NDCG: 0.478154654491004 HIT: 0.5751543985399915
Epoch: 1, plus 0 steps train_loss: 0.7871

#### test Acc: 0, NDCG: 0.11692659669115846 HIT: 0.2599978840457046

#### val Acc: 0, NDCG: 0.46970719661667765 HIT: 0.5581275788192975
Epoch: 2, plus 0 steps train_loss: 0.7735

#### test Acc: 0, NDCG: 0.12043906255385002 HIT: 0.2699627063055438

#### val Acc: 0, NDCG: 0.4862481623099659 HIT: 0.5795392178903935
Epoch: 3, plus 0 steps train_loss: 0.7859

#### test Acc: 0, NDCG: 0.11990196042473616 HIT: 0.26253702920016925

#### val Acc: 0, NDCG: 0.4722966095222399 HIT: 0.5723011664198053
Epoch: 4, plus 0 steps train_loss: 0.7815

#### test Acc: 0, NDCG: 0.12059681834346048 HIT: 0.26722436389123994

#### val Acc: 0, NDCG: 0.4796920656772656 HIT: 0.5739154081146848
Epoch: 5, plus 0 steps train_loss: 0.778

#### test Acc: 0, NDCG: 0.11841121930227792 HIT: 0.2701139639758781

#### val Acc: 0, NDCG: 0.4740921411024903 HIT: 0.5712671590668642
Epoch: 6, plus 0 steps train_loss: 0.7649

#### test Acc: 0, NDCG: 0.12187838738911863 HIT: 0.2713298111510791

#### val Acc: 0, NDCG: 0.47986126952308333 HIT: 0.5763454493757935
Epoch: 7, plus 0 steps train_loss: 0.7656

#### test Acc: 0, NDCG: 0.12008764287905613 HIT: 0.2703015896106644

#### val Acc: 0, NDCG: 0.48262013683767496 HIT: 0.5779001798561151
Epoch: 8, plus 0 steps train_loss: 0.77

#### test Acc: 0, NDCG: 0.12475978410557073 HIT: 0.27698998889123994

#### val Acc: 0, NDCG: 0.4744644210205095 HIT: 0.5692239407003808
Epoch: 9, plus 0 steps train_loss: 0.7636

#### test Acc: 0, NDCG: 0.12736685474242518 HIT: 0.2811318041155311

#### val Acc: 0, NDCG: 0.47948417632320345 HIT: 0.5797384151502327
Epoch: 10, plus 0 steps train_loss: 0.7703

#### test Acc: 0, NDCG: 0.12174382430135058 HIT: 0.26659618995979684

#### val Acc: 0, NDCG: 0.4802253600615702 HIT: 0.5793094384786288
Epoch: 12, plus 0 steps train_loss: 0.7603

#### test Acc: 0, NDCG: 0.12433909743806468 HIT: 0.27351271556284384

#### val Acc: 0, NDCG: 0.47506656984540274 HIT: 0.5649845932077867
Epoch: 14, plus 0 steps train_loss: 0.7456

#### test Acc: 0, NDCG: 0.12833072905554743 HIT: 0.2726183942551841

#### val Acc: 0, NDCG: 0.49414221821945115 HIT: 0.5853010606220906
Epoch: 16, plus 0 steps train_loss: 0.7426

#### test Acc: 0, NDCG: 0.1278870774772258 HIT: 0.27941424433982226

#### val Acc: 0, NDCG: 0.4775530604270909 HIT: 0.570711721064325
Epoch: 18, plus 0 steps train_loss: 0.7458

#### test Acc: 0, NDCG: 0.13253158976835633 HIT: 0.2805631413986458

#### val Acc: 0, NDCG: 0.47985386551196413 HIT: 0.5754453422556073
Epoch: 20, plus 0 steps train_loss: 0.7357

#### test Acc: 0, NDCG: 0.12848768183178527 HIT: 0.2723522468789674

#### val Acc: 0, NDCG: 0.47437020736248053 HIT: 0.5680080935251799
Epoch: 22, plus 0 steps train_loss: 0.7244

#### test Acc: 0, NDCG: 0.13337809479906268 HIT: 0.2879582363520948

#### val Acc: 0, NDCG: 0.4790564503105296 HIT: 0.5772777917371984
Epoch: 24, plus 0 steps train_loss: 0.7222

#### test Acc: 0, NDCG: 0.13485115983782278 HIT: 0.2914892350825222

#### val Acc: 0, NDCG: 0.47518026104348177 HIT: 0.5690115187261955
Epoch: 26, plus 0 steps train_loss: 0.7225

#### test Acc: 0, NDCG: 0.13733046762380843 HIT: 0.2950756123042742

#### val Acc: 0, NDCG: 0.490706001470384 HIT: 0.5821205168218366
Epoch: 28, plus 0 steps train_loss: 0.7163

#### test Acc: 0, NDCG: 0.1450680804674433 HIT: 0.31204870662293693

#### val Acc: 0, NDCG: 0.48149229725256054 HIT: 0.5719259151502327
Epoch: 30, plus 0 steps train_loss: 0.7178

#### test Acc: 0, NDCG: 0.1349733491637642 HIT: 0.29098173666948796

#### val Acc: 0, NDCG: 0.4844183682072086 HIT: 0.5739939298561151
Epoch: 32, plus 0 steps train_loss: 0.7162

#### test Acc: 0, NDCG: 0.1357761061128328 HIT: 0.30516689589504864

#### val Acc: 0, NDCG: 0.49229845004629724 HIT: 0.5860573489737622
Epoch: 36, plus 0 steps train_loss: 0.7128

#### test Acc: 0, NDCG: 0.13435751028201073 HIT: 0.29887854422344473

#### val Acc: 0, NDCG: 0.4857953919257604 HIT: 0.5790184947630131
Epoch: 40, plus 0 steps train_loss: 0.7131

#### test Acc: 0, NDCG: 0.13196293120007432 HIT: 0.2932605202602624

#### val Acc: 0, NDCG: 0.4836612728249996 HIT: 0.5787292041366906
Epoch: 44, plus 0 steps train_loss: 0.7118

#### test Acc: 0, NDCG: 0.13394955226524652 HIT: 0.28965843869022434

#### val Acc: 0, NDCG: 0.4771804070713761 HIT: 0.5717630858548455
Epoch: 48, plus 0 steps train_loss: 0.7084

#### test Acc: 0, NDCG: 0.1387468526216825 HIT: 0.2995678824587389

#### val Acc: 0, NDCG: 0.47615484644722095 HIT: 0.5678088962653407
Epoch: 52, plus 0 steps train_loss: 0.7108

#### test Acc: 0, NDCG: 0.1376797861467821 HIT: 0.29342500264494287

#### val Acc: 0, NDCG: 0.4907149180554238 HIT: 0.5847629800571308
Epoch: 56, plus 0 steps train_loss: 0.7087

#### test Acc: 0, NDCG: 0.14722426856181528 HIT: 0.3018714623889124

#### val Acc: 0, NDCG: 0.4786540571927765 HIT: 0.5682205154993651
Epoch: 60, plus 0 steps train_loss: 0.704

#### test Acc: 0, NDCG: 0.1589028567707206 HIT: 0.313609222915785

#### val Acc: 0, NDCG: 0.4815297127416539 HIT: 0.5705720350190435
Epoch: 64, plus 0 steps train_loss: 0.7084

#### test Acc: 0, NDCG: 0.1913308288874433 HIT: 0.3457229620715192

#### val Acc: 0, NDCG: 0.5105392204265575 HIT: 0.5954477227041896
Epoch: 68, plus 0 steps train_loss: 0.71

#### test Acc: 0, NDCG: 0.21558105216591744 HIT: 0.3712896410812526

#### val Acc: 0, NDCG: 0.5339708973418246 HIT: 0.623153499259416
Epoch: 72, plus 0 steps train_loss: 0.7071

#### test Acc: 0, NDCG: 0.16319975107314513 HIT: 0.3162880541155311

#### val Acc: 0, NDCG: 0.49877041340788264 HIT: 0.5853142853364367
Epoch: 80, plus 0 steps train_loss: 0.706

#### test Acc: 0, NDCG: 0.1776622902208135 HIT: 0.3273827629073212

#### val Acc: 0, NDCG: 0.4970454911879041 HIT: 0.5889775312103259
Epoch: 88, plus 0 steps train_loss: 0.7043

#### test Acc: 0, NDCG: 0.2269092925753897 HIT: 0.3709449719636056

#### val Acc: 0, NDCG: 0.54210854426613 HIT: 0.6336696267985612
Epoch: 96, plus 0 steps train_loss: 0.7037

#### test Acc: 0, NDCG: 0.267192162698873 HIT: 0.4146551325116377

#### val Acc: 0, NDCG: 0.562914610669027 HIT: 0.6479638899174778
Epoch: 104, plus 0 steps train_loss: 0.7015

#### test Acc: 0, NDCG: 0.26881509367764533 HIT: 0.4098429895789251

#### val Acc: 0, NDCG: 0.5608245637436694 HIT: 0.6553895670228522
Epoch: 112, plus 0 steps train_loss: 0.7024

#### test Acc: 0, NDCG: 0.30984325984989103 HIT: 0.4470730400973339

#### val Acc: 0, NDCG: 0.5951093325009221 HIT: 0.6859675862251375
Epoch: 120, plus 0 steps train_loss: 0.6995

#### test Acc: 0, NDCG: 0.19764596295639109 HIT: 0.3428143514600085

#### val Acc: 0, NDCG: 0.5322078617283945 HIT: 0.6245685436944561
Epoch: 128, plus 0 steps train_loss: 0.7007

#### test Acc: 0, NDCG: 0.2875698481913067 HIT: 0.42979743043800256

#### val Acc: 0, NDCG: 0.5656530168015822 HIT: 0.6556978681760475
Epoch: 136, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.32830257249718636 HIT: 0.4601093022640711

#### val Acc: 0, NDCG: 0.5987603163024751 HIT: 0.6810215430596699
Epoch: 144, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.42443491559857055 HIT: 0.548773573053322

#### val Acc: 0, NDCG: 0.6449112163222663 HIT: 0.7244192697312738
Epoch: 160, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.4220370278074121 HIT: 0.5575589161024121

#### val Acc: 0, NDCG: 0.6370461056770907 HIT: 0.7213899836013542
Epoch: 176, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.3812312190242549 HIT: 0.5213992409013964

#### val Acc: 0, NDCG: 0.6160871345430615 HIT: 0.7043805213182396
Epoch: 192, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.47605922972882103 HIT: 0.6055943847862887

#### val Acc: 0, NDCG: 0.668933843348507 HIT: 0.7490420347545493
Epoch: 208, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.5241551638293699 HIT: 0.6416565277190012

#### val Acc: 0, NDCG: 0.6964478402753356 HIT: 0.7702660481908591
Epoch: 224, plus 0 steps train_loss: 0.6972

#### test Acc: 0, NDCG: 0.41869799550087294 HIT: 0.5503630184088024

#### val Acc: 0, NDCG: 0.654319828328817 HIT: 0.7368637259310199
Epoch: 240, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.5210513391362461 HIT: 0.6358814602729581

#### val Acc: 0, NDCG: 0.717467564108021 HIT: 0.7896576121455777
Epoch: 256, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.4572856715215988 HIT: 0.5843397891980534

#### val Acc: 0, NDCG: 0.6675486479592765 HIT: 0.7438356300253914
Epoch: 272, plus 0 steps train_loss: 0.6945

#### test Acc: 0, NDCG: 0.49738900021519244 HIT: 0.6230154663034279

#### val Acc: 0, NDCG: 0.6793468655084464 HIT: 0.7548344596381719
Epoch: 288, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.5628523310020029 HIT: 0.6767168985399915

#### val Acc: 0, NDCG: 0.7280938987273833 HIT: 0.7995496984765129
Epoch: 304, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.50414982960865 HIT: 0.6308089557765553

#### val Acc: 0, NDCG: 0.692281576984079 HIT: 0.7663655840033856
Epoch: 320, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.5414482780192209 HIT: 0.6565748320461279

#### val Acc: 0, NDCG: 0.7086814792381845 HIT: 0.7887996588023699
Epoch: 352, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.5454755839281434 HIT: 0.6663404570461279

#### val Acc: 0, NDCG: 0.7174379341175746 HIT: 0.7896212441811257
Epoch: 384, plus 0 steps train_loss: 0.6945

#### test Acc: 0, NDCG: 0.5293984635369408 HIT: 0.6508551430914092

#### val Acc: 0, NDCG: 0.7092912044507118 HIT: 0.7868638912399492
Epoch: 416, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.5846027324130338 HIT: 0.6969242620609395

#### val Acc: 0, NDCG: 0.7376288427777705 HIT: 0.8127504430279306
Epoch: 448, plus 0 steps train_loss: 0.6928

#### test Acc: 0, NDCG: 0.5008546587629628 HIT: 0.626848980374524

#### val Acc: 0, NDCG: 0.7101468654439786 HIT: 0.7888897521688532
Epoch: 480, plus 0 steps train_loss: 0.6904

#### test Acc: 0, NDCG: 0.6146412954656572 HIT: 0.730085233283961

#### val Acc: 0, NDCG: 0.7565427314720805 HIT: 0.8279332416419806
Epoch: 512, plus 0 steps train_loss: 0.6916

#### test Acc: 0, NDCG: 0.6259620835068294 HIT: 0.7368752975560727

#### val Acc: 0, NDCG: 0.7623312709751197 HIT: 0.8281688068662717
Epoch: 544, plus 0 steps train_loss: 0.6849

#### test Acc: 0, NDCG: 0.6069019326105213 HIT: 0.7169630104739738

#### val Acc: 0, NDCG: 0.7679031874249242 HIT: 0.8360540427951756
Epoch: 576, plus 0 steps train_loss: 0.6826

#### test Acc: 0, NDCG: 0.6049315026722054 HIT: 0.7114978972704189

#### val Acc: 0, NDCG: 0.7535250599504453 HIT: 0.8252006850402032
Epoch: 608, plus 0 steps train_loss: 0.6751

#### test Acc: 0, NDCG: 0.6098858394348657 HIT: 0.7229620715192552

#### val Acc: 0, NDCG: 0.7597534790807202 HIT: 0.8246741761002961
Epoch: 640, plus 0 steps train_loss: 0.6783

#### test Acc: 0, NDCG: 0.6124239141571478 HIT: 0.7205493876957257

#### val Acc: 0, NDCG: 0.7584277866577072 HIT: 0.8262346923931443
Epoch: 704, plus 0 steps train_loss: 0.6759

#### test Acc: 0, NDCG: 0.6068503752667167 HIT: 0.7148949957680915

#### val Acc: 0, NDCG: 0.7604010682690123 HIT: 0.8258594411235718
Epoch: 768, plus 0 steps train_loss: 0.6832

#### test Acc: 0, NDCG: 0.5916417290783412 HIT: 0.7055104078501904

#### val Acc: 0, NDCG: 0.7566866760232832 HIT: 0.8227880012166737
Epoch: 832, plus 0 steps train_loss: 0.6606

#### test Acc: 0, NDCG: 0.6111935731292987 HIT: 0.7213536156369023

#### val Acc: 0, NDCG: 0.749616860790932 HIT: 0.8188569548772747
Epoch: 896, plus 0 steps train_loss: 0.6712

#### test Acc: 0, NDCG: 0.6004904783874927 HIT: 0.7125914158379179

#### val Acc: 0, NDCG: 0.7578657496486451 HIT: 0.8280902851248414
Epoch: 960, plus 0 steps train_loss: 0.6589

#### test Acc: 0, NDCG: 0.6012822162128572 HIT: 0.7204402838023699

#### val Acc: 0, NDCG: 0.7619103579458786 HIT: 0.8282299711701228
Epoch: 1017, plus 0 steps train_loss: 0.6661
Done: it took 81272.70737338066
max value of NDCG: 0.6259620835068294
max value of HIT: 0.7368752975560727

After 20 validations
max value of NDCG: 0.6259620835068294
max value of HIT: 0.7368752975560727
