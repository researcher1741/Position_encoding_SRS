 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	0.0001
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11571301
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13217181423700033 HIT: 0.29144129549301734

#### val Acc: 0, NDCG: 0.47567890576983995 HIT: 0.564815978099873
Epoch: 1, plus 0 steps train_loss: 0.7421

#### test Acc: 0, NDCG: 0.11804420919252812 HIT: 0.26949736166948796

#### val Acc: 0, NDCG: 0.4725358673378144 HIT: 0.5616718022640711
Epoch: 2, plus 0 steps train_loss: 0.7519

#### test Acc: 0, NDCG: 0.12595105278522545 HIT: 0.2805094159966145

#### val Acc: 0, NDCG: 0.484184661045592 HIT: 0.5725003636796445
Epoch: 3, plus 0 steps train_loss: 0.7404

#### test Acc: 0, NDCG: 0.11881695607736459 HIT: 0.26608125264494287

#### val Acc: 0, NDCG: 0.4672568559796656 HIT: 0.5578672172556073
Epoch: 4, plus 0 steps train_loss: 0.7535

#### test Acc: 0, NDCG: 0.11947674272273934 HIT: 0.27185632009098604

#### val Acc: 0, NDCG: 0.4827429794560905 HIT: 0.5700876798561151
Epoch: 5, plus 0 steps train_loss: 0.7502

#### test Acc: 0, NDCG: 0.12827501672600292 HIT: 0.28434871588023697

#### val Acc: 0, NDCG: 0.4830434512567534 HIT: 0.5732508662187897
Epoch: 6, plus 0 steps train_loss: 0.7502

#### test Acc: 0, NDCG: 0.12822716154172914 HIT: 0.27938366218789673

#### val Acc: 0, NDCG: 0.4776510699702181 HIT: 0.576067730374524
Epoch: 7, plus 0 steps train_loss: 0.7476

#### test Acc: 0, NDCG: 0.12356273188322293 HIT: 0.2781926113520948

#### val Acc: 0, NDCG: 0.4751245949591547 HIT: 0.5639257895154465
Epoch: 8, plus 0 steps train_loss: 0.735

#### test Acc: 0, NDCG: 0.12367936370103164 HIT: 0.27498148539991535

#### val Acc: 0, NDCG: 0.48151738461612686 HIT: 0.5699058400338552
Epoch: 9, plus 0 steps train_loss: 0.7484

#### test Acc: 0, NDCG: 0.12448839680704556 HIT: 0.27423098286077024

#### val Acc: 0, NDCG: 0.4756667910089658 HIT: 0.5725730996085484
Epoch: 10, plus 0 steps train_loss: 0.7343

#### test Acc: 0, NDCG: 0.11778399550959084 HIT: 0.2581728734659331

#### val Acc: 0, NDCG: 0.48514452214665055 HIT: 0.5810327840668642
Epoch: 12, plus 0 steps train_loss: 0.743

#### test Acc: 0, NDCG: 0.1557707312408274 HIT: 0.3103617289991536

#### val Acc: 0, NDCG: 0.49906038613946463 HIT: 0.5879683201967838
Epoch: 14, plus 0 steps train_loss: 0.7357

#### test Acc: 0, NDCG: 0.19425528813635778 HIT: 0.3389328977994075

#### val Acc: 0, NDCG: 0.5300189352716463 HIT: 0.6224468035865425
Epoch: 16, plus 0 steps train_loss: 0.7351

#### test Acc: 0, NDCG: 0.3478761158503909 HIT: 0.4882093406157427

#### val Acc: 0, NDCG: 0.5897878802922318 HIT: 0.6795643448476513
Epoch: 18, plus 0 steps train_loss: 0.7332

#### test Acc: 0, NDCG: 0.39232182147755473 HIT: 0.5296770855374524

#### val Acc: 0, NDCG: 0.6308864343701517 HIT: 0.7151859394837071
Epoch: 20, plus 0 steps train_loss: 0.7264

#### test Acc: 0, NDCG: 0.32241995809662427 HIT: 0.46615630289885734

#### val Acc: 0, NDCG: 0.6046335672477469 HIT: 0.6901341977888278
Epoch: 22, plus 0 steps train_loss: 0.715

#### test Acc: 0, NDCG: 0.23192845081246477 HIT: 0.38680388409860345

#### val Acc: 0, NDCG: 0.5408453111511369 HIT: 0.6349028314113415
Epoch: 24, plus 0 steps train_loss: 0.7185

#### test Acc: 0, NDCG: 0.12730211092597063 HIT: 0.2735970231168007

#### val Acc: 0, NDCG: 0.4766330196672926 HIT: 0.5739096223021583
Epoch: 26, plus 0 steps train_loss: 0.7178

#### test Acc: 0, NDCG: 0.13670701656403414 HIT: 0.29035934855057133

#### val Acc: 0, NDCG: 0.47755072286276307 HIT: 0.5709224899492171
Epoch: 28, plus 0 steps train_loss: 0.7182

#### test Acc: 0, NDCG: 0.17850748859971977 HIT: 0.3247419527613204

#### val Acc: 0, NDCG: 0.5181930906266163 HIT: 0.6083459519149387
Epoch: 30, plus 0 steps train_loss: 0.7189

#### test Acc: 0, NDCG: 0.2699578269802311 HIT: 0.4193656104528142

#### val Acc: 0, NDCG: 0.5720437626975385 HIT: 0.6567566718683876
Epoch: 32, plus 0 steps train_loss: 0.7206

#### test Acc: 0, NDCG: 0.5511210269474749 HIT: 0.6722477716356327

#### val Acc: 0, NDCG: 0.7382457011847938 HIT: 0.8117280073000424
Epoch: 36, plus 0 steps train_loss: 0.719

#### test Acc: 0, NDCG: 0.5930067650195334 HIT: 0.7025538576491748

#### val Acc: 0, NDCG: 0.7593752416296173 HIT: 0.8232897138171815
Epoch: 40, plus 0 steps train_loss: 0.7084

#### test Acc: 0, NDCG: 0.48872345085202784 HIT: 0.6190786341515023

#### val Acc: 0, NDCG: 0.6949134257376243 HIT: 0.7730771265340668
Epoch: 44, plus 0 steps train_loss: 0.7113

#### test Acc: 0, NDCG: 0.6169871811699881 HIT: 0.7240688148011003

#### val Acc: 0, NDCG: 0.7682844325743722 HIT: 0.8345546908061785
Epoch: 48, plus 0 steps train_loss: 0.7073

#### test Acc: 0, NDCG: 0.5130251292024891 HIT: 0.6473472876110876

#### val Acc: 0, NDCG: 0.6976401547074017 HIT: 0.7739483045916209
Epoch: 52, plus 0 steps train_loss: 0.7076

#### test Acc: 0, NDCG: 0.5379262050041786 HIT: 0.6657469979898434

#### val Acc: 0, NDCG: 0.7148067020243569 HIT: 0.7929108918747355
Epoch: 56, plus 0 steps train_loss: 0.7072

#### test Acc: 0, NDCG: 0.5844802493805719 HIT: 0.7024926933453237

#### val Acc: 0, NDCG: 0.7450438655586826 HIT: 0.8161723378650021
Epoch: 60, plus 0 steps train_loss: 0.7029

#### test Acc: 0, NDCG: 0.4868999034274735 HIT: 0.6195745609394837

#### val Acc: 0, NDCG: 0.6786974184446708 HIT: 0.7565999590033856
Epoch: 64, plus 0 steps train_loss: 0.71

#### test Acc: 0, NDCG: 0.3046708251583632 HIT: 0.45106938346381714

#### val Acc: 0, NDCG: 0.5741059627791417 HIT: 0.6594470746931866
Epoch: 68, plus 0 steps train_loss: 0.7095

#### test Acc: 0, NDCG: 0.13071672174829016 HIT: 0.2816814563055438

#### val Acc: 0, NDCG: 0.47826550810798757 HIT: 0.5664591488573847
Epoch: 72, plus 0 steps train_loss: 0.7119

#### test Acc: 0, NDCG: 0.1270130279813213 HIT: 0.27885880633728316

#### val Acc: 0, NDCG: 0.4791038390395298 HIT: 0.5658615570778671
Epoch: 80, plus 0 steps train_loss: 0.7084

#### test Acc: 0, NDCG: 0.12429611925133871 HIT: 0.2734399796339399

#### val Acc: 0, NDCG: 0.47331486251198696 HIT: 0.5613560622090563
Epoch: 88, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.31270065400477354 HIT: 0.46355020762801524

#### val Acc: 0, NDCG: 0.5993837550034885 HIT: 0.6892630197312738
Epoch: 96, plus 0 steps train_loss: 0.7053

#### test Acc: 0, NDCG: 0.6248765391889899 HIT: 0.7365901396529835

#### val Acc: 0, NDCG: 0.7814388719148774 HIT: 0.8420167358760051
Epoch: 104, plus 0 steps train_loss: 0.701

#### test Acc: 0, NDCG: 0.62280311395267 HIT: 0.7337790613097758

#### val Acc: 0, NDCG: 0.7741565998358195 HIT: 0.8366284913245874
Epoch: 112, plus 0 steps train_loss: 0.7045

#### test Acc: 0, NDCG: 0.6329946721154772 HIT: 0.7374381744604317

#### val Acc: 0, NDCG: 0.791001522191124 HIT: 0.8529734117118071
Epoch: 120, plus 0 steps train_loss: 0.703

#### test Acc: 0, NDCG: 0.6346169080230072 HIT: 0.7345237780363945

#### val Acc: 0, NDCG: 0.7755966784964136 HIT: 0.8423192512166737
Epoch: 128, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.632866615338165 HIT: 0.7318565184617013

#### val Acc: 0, NDCG: 0.7841538436178999 HIT: 0.8452815872302158
Epoch: 136, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.6220574393636911 HIT: 0.7287065568133728

#### val Acc: 0, NDCG: 0.7805428314562537 HIT: 0.8434797199005502
Epoch: 144, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.6401794227852419 HIT: 0.7391673058611934

#### val Acc: 0, NDCG: 0.779405852884543 HIT: 0.8458866179115531
Epoch: 160, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.6028163783771961 HIT: 0.7120591210854845

#### val Acc: 0, NDCG: 0.7572221708054604 HIT: 0.8263132141345747
Epoch: 176, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.6702672182766087 HIT: 0.7710454797926365

#### val Acc: 0, NDCG: 0.7920197609720487 HIT: 0.8480083580194668
Epoch: 192, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.4628662032485173 HIT: 0.5892436785865425

#### val Acc: 0, NDCG: 0.6646065806697391 HIT: 0.7414287320143885
Epoch: 208, plus 0 steps train_loss: 0.6972

#### test Acc: 0, NDCG: 0.4973342220406271 HIT: 0.6223624960325856

#### val Acc: 0, NDCG: 0.6856628663576023 HIT: 0.7611170254972492
Epoch: 224, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.6266473938629802 HIT: 0.7357801258992805

#### val Acc: 0, NDCG: 0.7880667530612051 HIT: 0.8486076028882776
Epoch: 240, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.524125992813522 HIT: 0.6432112581993229

#### val Acc: 0, NDCG: 0.7145590814811636 HIT: 0.7914594794752433
Epoch: 256, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.6380942797343049 HIT: 0.7426561508146424

#### val Acc: 0, NDCG: 0.8005009904494425 HIT: 0.8589170942657639
Epoch: 272, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.6664564190126796 HIT: 0.7669764004972492

#### val Acc: 0, NDCG: 0.7884210921110181 HIT: 0.8443087441811257
Epoch: 288, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.6326327192279877 HIT: 0.7359024545069827

#### val Acc: 0, NDCG: 0.7969626612000702 HIT: 0.8569333871138384
Epoch: 304, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.4158265404857834 HIT: 0.5451028882776132

#### val Acc: 0, NDCG: 0.6509194776527352 HIT: 0.7331566731908591
Epoch: 320, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.3262744963287969 HIT: 0.4726934445090986

#### val Acc: 0, NDCG: 0.586807339340068 HIT: 0.6706583262801523
Epoch: 352, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.17973464079992643 HIT: 0.3338835365531104

#### val Acc: 0, NDCG: 0.5167762145507395 HIT: 0.6128993863732544
Epoch: 384, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.14399694186352727 HIT: 0.310857655787135

#### val Acc: 0, NDCG: 0.48210197184462505 HIT: 0.5913422754443504
Epoch: 416, plus 0 steps train_loss: 0.6941

#### test Acc: 0, NDCG: 0.260583307009298 HIT: 0.4275955154993652

#### val Acc: 0, NDCG: 0.555385829788635 HIT: 0.6483945196783749
Epoch: 448, plus 0 steps train_loss: 0.6972

#### test Acc: 0, NDCG: 0.18573765855023963 HIT: 0.35040864367329666

#### val Acc: 0, NDCG: 0.49620014109392796 HIT: 0.5918861418218366
Epoch: 480, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.1665068029076061 HIT: 0.33797741218789673

#### val Acc: 0, NDCG: 0.4974349275584932 HIT: 0.6050199362568769
Epoch: 512, plus 0 steps train_loss: 0.6946

#### test Acc: 0, NDCG: 0.15392365241796274 HIT: 0.32640991985823103

#### val Acc: 0, NDCG: 0.5078782039084808 HIT: 0.6130853589187474
Epoch: 544, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.16476102105758758 HIT: 0.33531015261320357

#### val Acc: 0, NDCG: 0.49729547176906574 HIT: 0.6045661632458739
Epoch: 576, plus 0 steps train_loss: 0.6937

#### test Acc: 0, NDCG: 0.4127259805860975 HIT: 0.5440151555226408

#### val Acc: 0, NDCG: 0.6534365317148024 HIT: 0.7334418310939483
Epoch: 608, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.4203498431391736 HIT: 0.546512146900127

#### val Acc: 0, NDCG: 0.6469925091416667 HIT: 0.732503702920017
Epoch: 640, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.6308815415614447 HIT: 0.7319714081675837

#### val Acc: 0, NDCG: 0.7611235431842842 HIT: 0.8283870146529835
Epoch: 704, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.6156744735318773 HIT: 0.7245457310622091

#### val Acc: 0, NDCG: 0.7779189018000566 HIT: 0.8442897336542531
Epoch: 768, plus 0 steps train_loss: 0.6938

#### test Acc: 0, NDCG: 0.5704068045190334 HIT: 0.6855691917054592

#### val Acc: 0, NDCG: 0.7507057536276712 HIT: 0.8209018263330512
Epoch: 832, plus 0 steps train_loss: 0.6919

#### test Acc: 0, NDCG: 0.5635388563652208 HIT: 0.6791527256136267

#### val Acc: 0, NDCG: 0.7422754283689645 HIT: 0.8124421418747355
Epoch: 896, plus 0 steps train_loss: 0.6944

#### test Acc: 0, NDCG: 0.5752226934696525 HIT: 0.6903160376110876

#### val Acc: 0, NDCG: 0.7428888145791048 HIT: 0.8133248915573423
Epoch: 960, plus 0 steps train_loss: 0.6912

#### test Acc: 0, NDCG: 0.5642065870602878 HIT: 0.6845657665044436

#### val Acc: 0, NDCG: 0.7430862070600855 HIT: 0.8117164356749894
Epoch: 1017, plus 0 steps train_loss: 0.692
Done: it took 78086.08137249947
max value of NDCG: 0.6702672182766087
max value of HIT: 0.7710454797926365

After 20 validations
max value of NDCG: 0.6702672182766087
max value of HIT: 0.7710454797926365
