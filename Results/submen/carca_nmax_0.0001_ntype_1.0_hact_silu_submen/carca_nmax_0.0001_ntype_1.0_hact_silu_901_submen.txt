 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	0.0001
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11571301
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.1269715111256642 HIT: 0.28898645789250954

#### val Acc: 0, NDCG: 0.48324941740662636 HIT: 0.5772777917371984
Epoch: 1, plus 0 steps train_loss: 0.7836

#### test Acc: 0, NDCG: 0.1275374284288836 HIT: 0.28511079004443507

#### val Acc: 0, NDCG: 0.47965978875518356 HIT: 0.5688850573952603
Epoch: 2, plus 0 steps train_loss: 0.7735

#### test Acc: 0, NDCG: 0.13647579953974953 HIT: 0.29519050201015656

#### val Acc: 0, NDCG: 0.48586323281793775 HIT: 0.5752345733707153
Epoch: 3, plus 0 steps train_loss: 0.7559

#### test Acc: 0, NDCG: 0.1327616112038035 HIT: 0.29094536870503596

#### val Acc: 0, NDCG: 0.4871411038134421 HIT: 0.5792598457998307
Epoch: 4, plus 0 steps train_loss: 0.78

#### test Acc: 0, NDCG: 0.12130606923503949 HIT: 0.27637917239737625

#### val Acc: 0, NDCG: 0.482110551442284 HIT: 0.5743385989737622
Epoch: 5, plus 0 steps train_loss: 0.7719

#### test Acc: 0, NDCG: 0.11742631705839096 HIT: 0.26163113626745665

#### val Acc: 0, NDCG: 0.48137729911521693 HIT: 0.5739269797397376
Epoch: 6, plus 0 steps train_loss: 0.7749

#### test Acc: 0, NDCG: 0.12501377945422867 HIT: 0.2793357225983919

#### val Acc: 0, NDCG: 0.4853704929986911 HIT: 0.578317584902666
Epoch: 7, plus 0 steps train_loss: 0.7599

#### test Acc: 0, NDCG: 0.1309446634992394 HIT: 0.28258321651502327

#### val Acc: 0, NDCG: 0.461770151957319 HIT: 0.552335153935675
Epoch: 8, plus 0 steps train_loss: 0.7568

#### test Acc: 0, NDCG: 0.12725252038027193 HIT: 0.2821542398434194

#### val Acc: 0, NDCG: 0.4807782271620831 HIT: 0.5678262537029201
Epoch: 9, plus 0 steps train_loss: 0.7531

#### test Acc: 0, NDCG: 0.1252043728490158 HIT: 0.2751517535971223

#### val Acc: 0, NDCG: 0.47784174227392584 HIT: 0.5700397402666102
Epoch: 10, plus 0 steps train_loss: 0.7529

#### test Acc: 0, NDCG: 0.1256219823933853 HIT: 0.2812524796339399

#### val Acc: 0, NDCG: 0.4772276153586427 HIT: 0.5719259151502327
Epoch: 12, plus 0 steps train_loss: 0.7548

#### test Acc: 0, NDCG: 0.12354374461618388 HIT: 0.27274485558611933

#### val Acc: 0, NDCG: 0.4872836278314689 HIT: 0.5750585193609818
Epoch: 14, plus 0 steps train_loss: 0.7337

#### test Acc: 0, NDCG: 0.1890950459677808 HIT: 0.3492787571413457

#### val Acc: 0, NDCG: 0.5089285795171131 HIT: 0.6092402732225984
Epoch: 16, plus 0 steps train_loss: 0.7254

#### test Acc: 0, NDCG: 0.4554664957216867 HIT: 0.5914207971857808

#### val Acc: 0, NDCG: 0.6748111003763734 HIT: 0.7599681284384258
Epoch: 18, plus 0 steps train_loss: 0.7231

#### test Acc: 0, NDCG: 0.5327401661567052 HIT: 0.6563756347862887

#### val Acc: 0, NDCG: 0.6970816330665469 HIT: 0.7723282770842149
Epoch: 20, plus 0 steps train_loss: 0.7211

#### test Acc: 0, NDCG: 0.4824399636669578 HIT: 0.6062663655840034

#### val Acc: 0, NDCG: 0.6964705474502043 HIT: 0.7712504628650021
Epoch: 22, plus 0 steps train_loss: 0.7177

#### test Acc: 0, NDCG: 0.4668094975423804 HIT: 0.5969297172556073

#### val Acc: 0, NDCG: 0.6660524931067707 HIT: 0.7422329599555649
Epoch: 24, plus 0 steps train_loss: 0.7252

#### test Acc: 0, NDCG: 0.19064347747745458 HIT: 0.353347836436733

#### val Acc: 0, NDCG: 0.5196106980987878 HIT: 0.6174395961172239
Epoch: 26, plus 0 steps train_loss: 0.7249

#### test Acc: 0, NDCG: 0.2804615783804596 HIT: 0.42892046656792215

#### val Acc: 0, NDCG: 0.5708832474111235 HIT: 0.6653543892826914
Epoch: 28, plus 0 steps train_loss: 0.7114

#### test Acc: 0, NDCG: 0.28751224549372145 HIT: 0.4352146040520525

#### val Acc: 0, NDCG: 0.5815519018233003 HIT: 0.6736264481062209
Epoch: 30, plus 0 steps train_loss: 0.7182

#### test Acc: 0, NDCG: 0.3872474894278917 HIT: 0.5279115861722387

#### val Acc: 0, NDCG: 0.635876509259769 HIT: 0.7217520101565806
Epoch: 32, plus 0 steps train_loss: 0.7161

#### test Acc: 0, NDCG: 0.5599612615802103 HIT: 0.6858642681443081

#### val Acc: 0, NDCG: 0.7338139103336 HIT: 0.80184749259416
Epoch: 36, plus 0 steps train_loss: 0.7245

#### test Acc: 0, NDCG: 0.6275344775114415 HIT: 0.7315118493440542

#### val Acc: 0, NDCG: 0.7866545165420117 HIT: 0.8485348669593736
Epoch: 40, plus 0 steps train_loss: 0.7069

#### test Acc: 0, NDCG: 0.6211675106938487 HIT: 0.7257847214875158

#### val Acc: 0, NDCG: 0.7784105811880773 HIT: 0.8369615888171815
Epoch: 44, plus 0 steps train_loss: 0.7096

#### test Acc: 0, NDCG: 0.5155063044945015 HIT: 0.6483622844371562

#### val Acc: 0, NDCG: 0.7152394566179563 HIT: 0.7865192221223021
Epoch: 48, plus 0 steps train_loss: 0.7082

#### test Acc: 0, NDCG: 0.595229459877166 HIT: 0.7092174605903513

#### val Acc: 0, NDCG: 0.7517682806452235 HIT: 0.8183188743123149
Epoch: 52, plus 0 steps train_loss: 0.7077

#### test Acc: 0, NDCG: 0.4552404844740074 HIT: 0.5854291750423191

#### val Acc: 0, NDCG: 0.6743415357512849 HIT: 0.7586679737092679
Epoch: 56, plus 0 steps train_loss: 0.7065

#### test Acc: 0, NDCG: 0.4602168207848817 HIT: 0.5917596804909014

#### val Acc: 0, NDCG: 0.6900781250947103 HIT: 0.7668003464875158
Epoch: 60, plus 0 steps train_loss: 0.7039

#### test Acc: 0, NDCG: 0.34182041890093484 HIT: 0.48613967282056714

#### val Acc: 0, NDCG: 0.6142047161412174 HIT: 0.7029770485082523
Epoch: 64, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.5857220685232617 HIT: 0.6996030932606855

#### val Acc: 0, NDCG: 0.7495756560948699 HIT: 0.8158830472386797
Epoch: 68, plus 0 steps train_loss: 0.7076

#### test Acc: 0, NDCG: 0.5035568552199442 HIT: 0.629491443609818

#### val Acc: 0, NDCG: 0.7044136946274017 HIT: 0.775290613097757
Epoch: 72, plus 0 steps train_loss: 0.7084

#### test Acc: 0, NDCG: 0.2825465056397959 HIT: 0.4335524227676682

#### val Acc: 0, NDCG: 0.58361360712564 HIT: 0.6752902824798985
Epoch: 80, plus 0 steps train_loss: 0.7066

#### test Acc: 0, NDCG: 0.6416477889094299 HIT: 0.750807534119763

#### val Acc: 0, NDCG: 0.7787669910480158 HIT: 0.839265168747355
Epoch: 88, plus 0 steps train_loss: 0.7052

#### test Acc: 0, NDCG: 0.5307874978586872 HIT: 0.651785832363521

#### val Acc: 0, NDCG: 0.7171532595932463 HIT: 0.7927290520524757
Epoch: 96, plus 0 steps train_loss: 0.7061

#### test Acc: 0, NDCG: 0.493094655736059 HIT: 0.6147434074798985

#### val Acc: 0, NDCG: 0.6754631484743511 HIT: 0.7573372368281844
Epoch: 104, plus 0 steps train_loss: 0.7026

#### test Acc: 0, NDCG: 0.29839196485587743 HIT: 0.44646222360347015

#### val Acc: 0, NDCG: 0.5661020368266256 HIT: 0.6571434947630131
Epoch: 112, plus 0 steps train_loss: 0.7032

#### test Acc: 0, NDCG: 0.5697602337595187 HIT: 0.6862221619763013

#### val Acc: 0, NDCG: 0.7355309860941855 HIT: 0.8075498241112992
Epoch: 120, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.38183934410469145 HIT: 0.5218951676893779

#### val Acc: 0, NDCG: 0.6325828018371178 HIT: 0.7178647706834532
Epoch: 128, plus 0 steps train_loss: 0.7026

#### test Acc: 0, NDCG: 0.20726262741318804 HIT: 0.3725038351671604

#### val Acc: 0, NDCG: 0.5194977757284441 HIT: 0.6174106670545916
Epoch: 136, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.16560699974673077 HIT: 0.34312843842573004

#### val Acc: 0, NDCG: 0.49933180136864774 HIT: 0.6025766702814219
Epoch: 144, plus 0 steps train_loss: 0.6995

#### test Acc: 0, NDCG: 0.1663463771286126 HIT: 0.3345480784490055

#### val Acc: 0, NDCG: 0.5096728273325377 HIT: 0.6050563042213288
Epoch: 160, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.537617333490427 HIT: 0.661036520048667

#### val Acc: 0, NDCG: 0.7186031531706036 HIT: 0.7892286354739738
Epoch: 176, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.6747400563634229 HIT: 0.7685980810939483

#### val Acc: 0, NDCG: 0.8157115075576599 HIT: 0.8654963896529835
Epoch: 192, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.6711071592722557 HIT: 0.7599871389652983

#### val Acc: 0, NDCG: 0.8127886011806016 HIT: 0.8668386981591197
Epoch: 208, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.6403995827692356 HIT: 0.7411204308611934

#### val Acc: 0, NDCG: 0.7856976352206924 HIT: 0.8492605731591197
Epoch: 224, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.6836349283961715 HIT: 0.7756774359923826

#### val Acc: 0, NDCG: 0.8102215012689725 HIT: 0.8613603602412188
Epoch: 240, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.6958617435730526 HIT: 0.7752484593207787

#### val Acc: 0, NDCG: 0.8147578338448287 HIT: 0.8707813161235718
Epoch: 256, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.4536044922186007 HIT: 0.5884526753597122

#### val Acc: 0, NDCG: 0.665049644185094 HIT: 0.7471004813796022
Epoch: 272, plus 0 steps train_loss: 0.6982

#### test Acc: 0, NDCG: 0.6913741329836814 HIT: 0.783568457733813

#### val Acc: 0, NDCG: 0.8248416906921309 HIT: 0.8763133794435041
Epoch: 288, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.6878153025371624 HIT: 0.7804780073000424

#### val Acc: 0, NDCG: 0.8137882862184781 HIT: 0.8701762854422345
Epoch: 304, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.7034250530906788 HIT: 0.7844396357913669

#### val Acc: 0, NDCG: 0.8057173207092857 HIT: 0.8578045651713924
Epoch: 320, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.5310954241466017 HIT: 0.6538232649174778

#### val Acc: 0, NDCG: 0.716218216611516 HIT: 0.7874267681443081
Epoch: 352, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.20148996065647734 HIT: 0.36476985690859076

#### val Acc: 0, NDCG: 0.5222899421695131 HIT: 0.6262861034701651
Epoch: 384, plus 0 steps train_loss: 0.6949

#### test Acc: 0, NDCG: 0.16918888573182558 HIT: 0.3365202139758781

#### val Acc: 0, NDCG: 0.5052856044466865 HIT: 0.6173362780363945
Epoch: 416, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.18873046339395572 HIT: 0.3542132286817605

#### val Acc: 0, NDCG: 0.5145741160565924 HIT: 0.6202581133622515
Epoch: 448, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.18390386175076923 HIT: 0.35011356723444775

#### val Acc: 0, NDCG: 0.5149697570910822 HIT: 0.6174643924566229
Epoch: 480, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.1804207081488011 HIT: 0.3481968101988997

#### val Acc: 0, NDCG: 0.5058848607426668 HIT: 0.6105346421392298
Epoch: 512, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.17073878069972176 HIT: 0.33870890420016925

#### val Acc: 0, NDCG: 0.5108676586196811 HIT: 0.6163692207998307
Epoch: 544, plus 0 steps train_loss: 0.6943

#### test Acc: 0, NDCG: 0.17664334698192694 HIT: 0.34813564589504864

#### val Acc: 0, NDCG: 0.5022620354239312 HIT: 0.6108487291049514
Epoch: 576, plus 0 steps train_loss: 0.6946

#### test Acc: 0, NDCG: 0.17554830489761247 HIT: 0.34826954612780364

#### val Acc: 0, NDCG: 0.5104240751589223 HIT: 0.6191034304909014
Epoch: 608, plus 0 steps train_loss: 0.6928

#### test Acc: 0, NDCG: 0.19547894851157752 HIT: 0.3752917702602624

#### val Acc: 0, NDCG: 0.5254431454679921 HIT: 0.634454844212865
Epoch: 640, plus 0 steps train_loss: 0.6948

#### test Acc: 0, NDCG: 0.22996252758750702 HIT: 0.39739274756665255

#### val Acc: 0, NDCG: 0.5445177651462584 HIT: 0.6497905535865425
Epoch: 704, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.1904810045445253 HIT: 0.3757339716462124

#### val Acc: 0, NDCG: 0.5132425339548954 HIT: 0.6289649346699111
Epoch: 768, plus 0 steps train_loss: 0.6933

#### test Acc: 0, NDCG: 0.19680329357830392 HIT: 0.38871485532162503

#### val Acc: 0, NDCG: 0.5200363092246895 HIT: 0.6357492131294964
Epoch: 832, plus 0 steps train_loss: 0.6922

#### test Acc: 0, NDCG: 0.19986620482566134 HIT: 0.39524042530681336

#### val Acc: 0, NDCG: 0.51624814517566 HIT: 0.6344317009627592
Epoch: 896, plus 0 steps train_loss: 0.6921

#### test Acc: 0, NDCG: 0.20352193244982072 HIT: 0.3971629681548879

#### val Acc: 0, NDCG: 0.5221350815591828 HIT: 0.633397693609818
Epoch: 960, plus 0 steps train_loss: 0.6898

#### test Acc: 0, NDCG: 0.20218362468342527 HIT: 0.3991698185569192

#### val Acc: 0, NDCG: 0.5317286914247573 HIT: 0.653666221434617
Epoch: 1017, plus 0 steps train_loss: 0.694
Done: it took 81868.54486441612
max value of NDCG: 0.7034250530906788
max value of HIT: 0.7844396357913669

After 20 validations
max value of NDCG: 0.7034250530906788
max value of HIT: 0.7844396357913669
