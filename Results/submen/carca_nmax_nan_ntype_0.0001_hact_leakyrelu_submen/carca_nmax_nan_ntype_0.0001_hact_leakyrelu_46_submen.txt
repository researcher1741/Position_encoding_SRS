 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.0001
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11571301
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12929033305163337 HIT: 0.2830543469636056

#### val Acc: 0, NDCG: 0.4763078184879518 HIT: 0.5737525788192975
Epoch: 1, plus 0 steps train_loss: 0.8132

#### test Acc: 0, NDCG: 0.1290270021754063 HIT: 0.28414373280787136

#### val Acc: 0, NDCG: 0.4844545988302121 HIT: 0.58114188796022
Epoch: 2, plus 0 steps train_loss: 0.8052

#### test Acc: 0, NDCG: 0.12579162773093833 HIT: 0.27458309088023697

#### val Acc: 0, NDCG: 0.4850944046807028 HIT: 0.5840984381612356
Epoch: 3, plus 0 steps train_loss: 0.8065

#### test Acc: 0, NDCG: 0.13263488304473356 HIT: 0.2880251864684723

#### val Acc: 0, NDCG: 0.48244926645065056 HIT: 0.57599499444562
Epoch: 4, plus 0 steps train_loss: 0.796

#### test Acc: 0, NDCG: 0.12252804013488025 HIT: 0.2685129469953449

#### val Acc: 0, NDCG: 0.4783448382434087 HIT: 0.5707712322788827
Epoch: 5, plus 0 steps train_loss: 0.8243

#### test Acc: 0, NDCG: 0.12722657398268325 HIT: 0.2791249537134998

#### val Acc: 0, NDCG: 0.4848836432404082 HIT: 0.578710193609818
Epoch: 6, plus 0 steps train_loss: 0.8126

#### test Acc: 0, NDCG: 0.12889509949905315 HIT: 0.27885136743546335

#### val Acc: 0, NDCG: 0.48166489092552617 HIT: 0.575650325327973
Epoch: 7, plus 0 steps train_loss: 0.7976

#### test Acc: 0, NDCG: 0.1302413314499111 HIT: 0.2864646701756242

#### val Acc: 0, NDCG: 0.4748596949798589 HIT: 0.5699000542213288
Epoch: 8, plus 0 steps train_loss: 0.7928

#### test Acc: 0, NDCG: 0.12397032421220686 HIT: 0.2751939073741007

#### val Acc: 0, NDCG: 0.49220633538640873 HIT: 0.5852894889970377
Epoch: 9, plus 0 steps train_loss: 0.8042

#### test Acc: 0, NDCG: 0.13053774986441327 HIT: 0.29147766345746934

#### val Acc: 0, NDCG: 0.47694673072929844 HIT: 0.5644944522323319
Epoch: 10, plus 0 steps train_loss: 0.8005

#### test Acc: 0, NDCG: 0.1299159906318047 HIT: 0.2925116708104105

#### val Acc: 0, NDCG: 0.47804261838555284 HIT: 0.5688238930914092
Epoch: 12, plus 0 steps train_loss: 0.791

#### test Acc: 0, NDCG: 0.1337718635016486 HIT: 0.2972279345641134

#### val Acc: 0, NDCG: 0.469523583799866 HIT: 0.5592574653512484
Epoch: 14, plus 0 steps train_loss: 0.7747

#### test Acc: 0, NDCG: 0.13082856676764812 HIT: 0.28238236616589085

#### val Acc: 0, NDCG: 0.4854421625161212 HIT: 0.5810807236563691
Epoch: 16, plus 0 steps train_loss: 0.7702

#### test Acc: 0, NDCG: 0.13470499023937552 HIT: 0.29714362701015656

#### val Acc: 0, NDCG: 0.4804057942790544 HIT: 0.5728450327972916
Epoch: 18, plus 0 steps train_loss: 0.7568

#### test Acc: 0, NDCG: 0.1442437822631294 HIT: 0.3073440144942869

#### val Acc: 0, NDCG: 0.4736366639456771 HIT: 0.5691627763965298
Epoch: 20, plus 0 steps train_loss: 0.7683

#### test Acc: 0, NDCG: 0.1326305049212539 HIT: 0.291042900973339

#### val Acc: 0, NDCG: 0.47408776278839454 HIT: 0.5658615570778671
Epoch: 22, plus 0 steps train_loss: 0.7584

#### test Acc: 0, NDCG: 0.1309402781977351 HIT: 0.2866159278459585

#### val Acc: 0, NDCG: 0.4830825370779466 HIT: 0.5753552488891239
Epoch: 24, plus 0 steps train_loss: 0.7777

#### test Acc: 0, NDCG: 0.12645999054984486 HIT: 0.2805267734341938

#### val Acc: 0, NDCG: 0.4755906832768615 HIT: 0.5730938227359289
Epoch: 26, plus 0 steps train_loss: 0.7589

#### test Acc: 0, NDCG: 0.1272766939592582 HIT: 0.2840329758252222

#### val Acc: 0, NDCG: 0.4769497760766337 HIT: 0.5698099608548455
Epoch: 28, plus 0 steps train_loss: 0.7555

#### test Acc: 0, NDCG: 0.1283793502441951 HIT: 0.2765114195408379

#### val Acc: 0, NDCG: 0.47601738946130195 HIT: 0.570553024492171
Epoch: 30, plus 0 steps train_loss: 0.7535

#### test Acc: 0, NDCG: 0.1310114437543877 HIT: 0.28627125872831144

#### val Acc: 0, NDCG: 0.4782177586706619 HIT: 0.5707902428057554
Epoch: 32, plus 0 steps train_loss: 0.7504

#### test Acc: 0, NDCG: 0.1308339683746595 HIT: 0.29079989684722807

#### val Acc: 0, NDCG: 0.4767878417258359 HIT: 0.5715027242911553
Epoch: 36, plus 0 steps train_loss: 0.739

#### test Acc: 0, NDCG: 0.12891140662853925 HIT: 0.2838527890922556

#### val Acc: 0, NDCG: 0.4775338935648301 HIT: 0.5715696744075328
Epoch: 40, plus 0 steps train_loss: 0.7406

#### test Acc: 0, NDCG: 0.133493382095667 HIT: 0.30221613150655946

#### val Acc: 0, NDCG: 0.4763602151713781 HIT: 0.5652028009944985
Epoch: 44, plus 0 steps train_loss: 0.7352

#### test Acc: 0, NDCG: 0.13056826212350925 HIT: 0.2879408789145155

#### val Acc: 0, NDCG: 0.480267328835782 HIT: 0.5723069522323319
Epoch: 48, plus 0 steps train_loss: 0.7336

#### test Acc: 0, NDCG: 0.12261959225749319 HIT: 0.2729440528459585

#### val Acc: 0, NDCG: 0.4701368091634067 HIT: 0.5600021820778671
Epoch: 52, plus 0 steps train_loss: 0.7269

#### test Acc: 0, NDCG: 0.12506681615214235 HIT: 0.2756782625370292

#### val Acc: 0, NDCG: 0.4751531707745377 HIT: 0.5646878636796445
Epoch: 56, plus 0 steps train_loss: 0.7255

#### test Acc: 0, NDCG: 0.12973598257695734 HIT: 0.28053255924672027

#### val Acc: 0, NDCG: 0.47880872550835074 HIT: 0.5735459426576386
Epoch: 60, plus 0 steps train_loss: 0.731

#### test Acc: 0, NDCG: 0.13290312789241893 HIT: 0.28983862542319083

#### val Acc: 0, NDCG: 0.4822185330321506 HIT: 0.5719738547397376
Epoch: 64, plus 0 steps train_loss: 0.7343

#### test Acc: 0, NDCG: 0.12452459903983447 HIT: 0.2786521701756242

#### val Acc: 0, NDCG: 0.4831192046247554 HIT: 0.5813526568451122
Epoch: 68, plus 0 steps train_loss: 0.728

#### test Acc: 0, NDCG: 0.13260221649868784 HIT: 0.28981382908379183

#### val Acc: 0, NDCG: 0.478446655095512 HIT: 0.5718721897482014
Epoch: 72, plus 0 steps train_loss: 0.7234

#### test Acc: 0, NDCG: 0.13857981361206057 HIT: 0.3079126772111722

#### val Acc: 0, NDCG: 0.47370698200503036 HIT: 0.5647052211172239
Epoch: 80, plus 0 steps train_loss: 0.7191

#### test Acc: 0, NDCG: 0.13126203903310163 HIT: 0.28909556178586543

#### val Acc: 0, NDCG: 0.48320008017901417 HIT: 0.5761098841515023
Epoch: 88, plus 0 steps train_loss: 0.7204

#### test Acc: 0, NDCG: 0.13044160245287642 HIT: 0.2886475745873889

#### val Acc: 0, NDCG: 0.476832098117811 HIT: 0.5700397402666102
Epoch: 96, plus 0 steps train_loss: 0.7163

#### test Acc: 0, NDCG: 0.12631055874638242 HIT: 0.2841015790308929

#### val Acc: 0, NDCG: 0.4767531825438771 HIT: 0.5668765539039358
Epoch: 104, plus 0 steps train_loss: 0.714

#### test Acc: 0, NDCG: 0.1348325227551714 HIT: 0.2926323463288193

#### val Acc: 0, NDCG: 0.4770121626207119 HIT: 0.5762189880448583
Epoch: 112, plus 0 steps train_loss: 0.7145

#### test Acc: 0, NDCG: 0.12594444283605075 HIT: 0.278035567869234

#### val Acc: 0, NDCG: 0.4778171212503506 HIT: 0.5683833447947525
Epoch: 120, plus 0 steps train_loss: 0.718

#### test Acc: 0, NDCG: 0.13479970738243668 HIT: 0.2895493347968684

#### val Acc: 0, NDCG: 0.48098727790332274 HIT: 0.5750700909860347
Epoch: 128, plus 0 steps train_loss: 0.7105

#### test Acc: 0, NDCG: 0.1379204227734344 HIT: 0.2925728351142616

#### val Acc: 0, NDCG: 0.49249556015111995 HIT: 0.5854597571942446
Epoch: 136, plus 0 steps train_loss: 0.7153

#### test Acc: 0, NDCG: 0.12892437147242236 HIT: 0.28347753782268303

#### val Acc: 0, NDCG: 0.4821138454800572 HIT: 0.5752651555226408
Epoch: 144, plus 0 steps train_loss: 0.7208

#### test Acc: 0, NDCG: 0.12847931067149704 HIT: 0.2821773830935252

#### val Acc: 0, NDCG: 0.48870540857079314 HIT: 0.587296339399069
Epoch: 160, plus 0 steps train_loss: 0.7057

#### test Acc: 0, NDCG: 0.16626889927165428 HIT: 0.31335464716462125

#### val Acc: 0, NDCG: 0.49882493971789155 HIT: 0.5959800174566229
Epoch: 176, plus 0 steps train_loss: 0.7146

#### test Acc: 0, NDCG: 0.16635599428617245 HIT: 0.3235376772111722

#### val Acc: 0, NDCG: 0.5065966508483878 HIT: 0.6004301338341091
Epoch: 192, plus 0 steps train_loss: 0.7078

#### test Acc: 0, NDCG: 0.2137660801867079 HIT: 0.36744290229581045

#### val Acc: 0, NDCG: 0.5223060324290458 HIT: 0.6124629707998307
Epoch: 208, plus 0 steps train_loss: 0.7059

#### test Acc: 0, NDCG: 0.29901948263627154 HIT: 0.4441032651819721

#### val Acc: 0, NDCG: 0.5774995007806797 HIT: 0.6701739711172239
Epoch: 224, plus 0 steps train_loss: 0.702

#### test Acc: 0, NDCG: 0.3921978704209419 HIT: 0.528062843842573

#### val Acc: 0, NDCG: 0.6334791852823841 HIT: 0.7156818662716885
Epoch: 240, plus 0 steps train_loss: 0.7021

#### test Acc: 0, NDCG: 0.4320089697659098 HIT: 0.5694537201121456

#### val Acc: 0, NDCG: 0.6611260821502806 HIT: 0.7444348748942023
Epoch: 256, plus 0 steps train_loss: 0.7041

#### test Acc: 0, NDCG: 0.4088029976910779 HIT: 0.5378590509944985

#### val Acc: 0, NDCG: 0.6385703616676749 HIT: 0.7182631652031316
Epoch: 272, plus 0 steps train_loss: 0.7047

#### test Acc: 0, NDCG: 0.5161614283835193 HIT: 0.6343953329983072

#### val Acc: 0, NDCG: 0.6982968238044776 HIT: 0.770658656898011
Epoch: 288, plus 0 steps train_loss: 0.7022

#### test Acc: 0, NDCG: 0.5601687876316124 HIT: 0.6638244551417689

#### val Acc: 0, NDCG: 0.7406476024887054 HIT: 0.8016425095217943
Epoch: 304, plus 0 steps train_loss: 0.7023

#### test Acc: 0, NDCG: 0.5030947491193756 HIT: 0.6182132419064749

#### val Acc: 0, NDCG: 0.6869118583124556 HIT: 0.7624345376639864
Epoch: 320, plus 0 steps train_loss: 0.7039

#### test Acc: 0, NDCG: 0.5527076978877126 HIT: 0.6539381546233601

#### val Acc: 0, NDCG: 0.7348961235021237 HIT: 0.7995860664409649
Epoch: 352, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.6199845729822424 HIT: 0.7132691824481592

#### val Acc: 0, NDCG: 0.7642600912948166 HIT: 0.8226788973233178
Epoch: 384, plus 0 steps train_loss: 0.7026

#### test Acc: 0, NDCG: 0.6537522916979613 HIT: 0.7428553480744816

#### val Acc: 0, NDCG: 0.7845084785460253 HIT: 0.8392535971223021
Epoch: 416, plus 0 steps train_loss: 0.7029

#### test Acc: 0, NDCG: 0.6799107028776603 HIT: 0.7691039264176894

#### val Acc: 0, NDCG: 0.8187401328076185 HIT: 0.8726311230427423
Epoch: 448, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.681755955627286 HIT: 0.773337488097757

#### val Acc: 0, NDCG: 0.8022633498771383 HIT: 0.8558878081358443
Epoch: 480, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.6973171570083407 HIT: 0.7765238177105375

#### val Acc: 0, NDCG: 0.8275859573443904 HIT: 0.8780730929961913
Epoch: 512, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.705704169836191 HIT: 0.7788943477570884

#### val Acc: 0, NDCG: 0.807415620911678 HIT: 0.8597692617964452
Epoch: 544, plus 0 steps train_loss: 0.7002

#### test Acc: 0, NDCG: 0.6883039966783261 HIT: 0.7708214861933982

#### val Acc: 0, NDCG: 0.8014108882930235 HIT: 0.8531610373465933
Epoch: 576, plus 0 steps train_loss: 0.6972

#### test Acc: 0, NDCG: 0.7013836123243405 HIT: 0.7852918033220483

#### val Acc: 0, NDCG: 0.8135227410308209 HIT: 0.8605619181125688
Epoch: 608, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.7061297804518849 HIT: 0.7885087150867541

#### val Acc: 0, NDCG: 0.8205918706575361 HIT: 0.8710954030892932
Epoch: 640, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.7098376916004785 HIT: 0.7849355625793484

#### val Acc: 0, NDCG: 0.8202880814793734 HIT: 0.8690331741959374
Epoch: 704, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.7003200651537704 HIT: 0.7836659900021159

#### val Acc: 0, NDCG: 0.8266422101321 HIT: 0.8728435450169276
Epoch: 768, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.7131466378748093 HIT: 0.7928133596064325

#### val Acc: 0, NDCG: 0.8253762585523566 HIT: 0.8757389309140923
Epoch: 832, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.7246535081452363 HIT: 0.8035286844054168

#### val Acc: 0, NDCG: 0.8268554730001021 HIT: 0.8690753279729159
Epoch: 896, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.7005821884922547 HIT: 0.7774065673931443

#### val Acc: 0, NDCG: 0.8150542694308881 HIT: 0.8601387272534913
Epoch: 960, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.7115645419153874 HIT: 0.7891368890181972

#### val Acc: 0, NDCG: 0.8280288553471631 HIT: 0.878302872407956
Epoch: 1017, plus 0 steps train_loss: 0.6974
Done: it took 83336.3126282692
max value of NDCG: 0.7246535081452363
max value of HIT: 0.8035286844054168

After 20 validations
max value of NDCG: 0.7246535081452363
max value of HIT: 0.8035286844054168
