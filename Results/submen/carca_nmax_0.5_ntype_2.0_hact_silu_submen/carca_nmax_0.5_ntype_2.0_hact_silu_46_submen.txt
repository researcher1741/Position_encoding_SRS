 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2.0
max_norm:             	0.5
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11571301
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13311519868668442 HIT: 0.2994777890922556

#### val Acc: 0, NDCG: 0.471418340854429 HIT: 0.5673666948793906
Epoch: 1, plus 0 steps train_loss: 0.8092

#### test Acc: 0, NDCG: 0.12968056778368428 HIT: 0.2892220231168007

#### val Acc: 0, NDCG: 0.47556070795751837 HIT: 0.5678932038192975
Epoch: 2, plus 0 steps train_loss: 0.7839

#### test Acc: 0, NDCG: 0.13081215647595063 HIT: 0.2924273632564537

#### val Acc: 0, NDCG: 0.4719074183799673 HIT: 0.5579341673719848
Epoch: 3, plus 0 steps train_loss: 0.7869

#### test Acc: 0, NDCG: 0.1380826895583107 HIT: 0.2981949918006771

#### val Acc: 0, NDCG: 0.4733775361707956 HIT: 0.5632058691282268
Epoch: 4, plus 0 steps train_loss: 0.7788

#### test Acc: 0, NDCG: 0.12655530533368248 HIT: 0.28364780601989

#### val Acc: 0, NDCG: 0.4724178802118421 HIT: 0.5570935714663563
Epoch: 5, plus 0 steps train_loss: 0.7661

#### test Acc: 0, NDCG: 0.12858154153746224 HIT: 0.28132521556284384

#### val Acc: 0, NDCG: 0.48433103856528026 HIT: 0.5791275986563691
Epoch: 6, plus 0 steps train_loss: 0.7594

#### test Acc: 0, NDCG: 0.13661949889981023 HIT: 0.2932010090457046

#### val Acc: 0, NDCG: 0.4865972808464521 HIT: 0.5852283246931866
Epoch: 7, plus 0 steps train_loss: 0.7664

#### test Acc: 0, NDCG: 0.1275923365406638 HIT: 0.2790580035971223

#### val Acc: 0, NDCG: 0.4754002596661593 HIT: 0.5753362383622515
Epoch: 8, plus 0 steps train_loss: 0.7565

#### test Acc: 0, NDCG: 0.13060926211674712 HIT: 0.28653740610452816

#### val Acc: 0, NDCG: 0.48622412853072966 HIT: 0.566696367170969
Epoch: 9, plus 0 steps train_loss: 0.7529

#### test Acc: 0, NDCG: 0.13235983588360375 HIT: 0.29035356273804486

#### val Acc: 0, NDCG: 0.4831294562608812 HIT: 0.5744171207151926
Epoch: 10, plus 0 steps train_loss: 0.761

#### test Acc: 0, NDCG: 0.13102491009032008 HIT: 0.28381642112780364

#### val Acc: 0, NDCG: 0.4804714902991113 HIT: 0.5779671299724926
Epoch: 12, plus 0 steps train_loss: 0.7569

#### test Acc: 0, NDCG: 0.12248954098157838 HIT: 0.2748434524439272

#### val Acc: 0, NDCG: 0.47552948519683674 HIT: 0.5768777441282268
Epoch: 14, plus 0 steps train_loss: 0.7513

#### test Acc: 0, NDCG: 0.1199485738786928 HIT: 0.2652654530787135

#### val Acc: 0, NDCG: 0.48185868342134114 HIT: 0.574386538563267
Epoch: 16, plus 0 steps train_loss: 0.7366

#### test Acc: 0, NDCG: 0.13139005678965687 HIT: 0.28312708289250954

#### val Acc: 0, NDCG: 0.48721473692480544 HIT: 0.584642304538722
Epoch: 18, plus 0 steps train_loss: 0.7345

#### test Acc: 0, NDCG: 0.1536356463325069 HIT: 0.31250826544646637

#### val Acc: 0, NDCG: 0.48668001969255836 HIT: 0.5788978192446044
Epoch: 20, plus 0 steps train_loss: 0.7278

#### test Acc: 0, NDCG: 0.16498204981000422 HIT: 0.3316336820249683

#### val Acc: 0, NDCG: 0.49779665524578753 HIT: 0.5964147799407533
Epoch: 22, plus 0 steps train_loss: 0.7371

#### test Acc: 0, NDCG: 0.16639360919843188 HIT: 0.32576273539991535

#### val Acc: 0, NDCG: 0.5084005410271465 HIT: 0.6063506731379602
Epoch: 24, plus 0 steps train_loss: 0.7294

#### test Acc: 0, NDCG: 0.16982017663805613 HIT: 0.3344695567075751

#### val Acc: 0, NDCG: 0.5021923068418715 HIT: 0.6022088579136691
Epoch: 26, plus 0 steps train_loss: 0.7218

#### test Acc: 0, NDCG: 0.14541242996851605 HIT: 0.31232063981168007

#### val Acc: 0, NDCG: 0.4959646292839615 HIT: 0.5977455168218366
Epoch: 28, plus 0 steps train_loss: 0.7221

#### test Acc: 0, NDCG: 0.13181863725414344 HIT: 0.292481088658485

#### val Acc: 0, NDCG: 0.47770670194946246 HIT: 0.5732797952814219
Epoch: 30, plus 0 steps train_loss: 0.7208

#### test Acc: 0, NDCG: 0.14646638503849896 HIT: 0.31134779676258995

#### val Acc: 0, NDCG: 0.49359294493357797 HIT: 0.5905744154676259
Epoch: 32, plus 0 steps train_loss: 0.7185

#### test Acc: 0, NDCG: 0.20222501292104708 HIT: 0.35950972677740156

#### val Acc: 0, NDCG: 0.5305095192304286 HIT: 0.6355078620926788
Epoch: 36, plus 0 steps train_loss: 0.723

#### test Acc: 0, NDCG: 0.18344108943748824 HIT: 0.3415447788827761

#### val Acc: 0, NDCG: 0.5214052045657647 HIT: 0.6203060529517562
Epoch: 40, plus 0 steps train_loss: 0.7223

#### test Acc: 0, NDCG: 0.3803139017600122 HIT: 0.5221191612886161

#### val Acc: 0, NDCG: 0.6300047531760472 HIT: 0.7180887642826914
Epoch: 44, plus 0 steps train_loss: 0.7152

#### test Acc: 0, NDCG: 0.22234954091817527 HIT: 0.37402219768303

#### val Acc: 0, NDCG: 0.5344138549164082 HIT: 0.6201853774333475
Epoch: 48, plus 0 steps train_loss: 0.7151

#### test Acc: 0, NDCG: 0.14923010193561123 HIT: 0.3032633635738468

#### val Acc: 0, NDCG: 0.4848119146922636 HIT: 0.5717093604528142
Epoch: 52, plus 0 steps train_loss: 0.7171

#### test Acc: 0, NDCG: 0.18399249621807148 HIT: 0.34060830379813795

#### val Acc: 0, NDCG: 0.5020279436076196 HIT: 0.593954156527719
Epoch: 56, plus 0 steps train_loss: 0.7174

#### test Acc: 0, NDCG: 0.16595387593430821 HIT: 0.31693937129708

#### val Acc: 0, NDCG: 0.49968540844408493 HIT: 0.5854101645154465
Epoch: 60, plus 0 steps train_loss: 0.708

#### test Acc: 0, NDCG: 0.23297108197328353 HIT: 0.3890727491536183

#### val Acc: 0, NDCG: 0.5498946609614483 HIT: 0.639086800412611
Epoch: 64, plus 0 steps train_loss: 0.7098

#### test Acc: 0, NDCG: 0.2078537734455874 HIT: 0.3687546286500212

#### val Acc: 0, NDCG: 0.5204757661266507 HIT: 0.6143260024333475
Epoch: 68, plus 0 steps train_loss: 0.7157

#### test Acc: 0, NDCG: 0.18433878729249636 HIT: 0.3470826280152349

#### val Acc: 0, NDCG: 0.5095008878111702 HIT: 0.5944806654676259
Epoch: 72, plus 0 steps train_loss: 0.715

#### test Acc: 0, NDCG: 0.16289491216502408 HIT: 0.3210464716462124

#### val Acc: 0, NDCG: 0.4977442738708812 HIT: 0.5920068173402455
Epoch: 80, plus 0 steps train_loss: 0.7049

#### test Acc: 0, NDCG: 0.14526723451667176 HIT: 0.30715060304697417

#### val Acc: 0, NDCG: 0.4975023767516235 HIT: 0.595932077867118
Epoch: 88, plus 0 steps train_loss: 0.706

#### test Acc: 0, NDCG: 0.34896967879896434 HIT: 0.4991048521476936

#### val Acc: 0, NDCG: 0.6029863862819889 HIT: 0.6843302012801523
Epoch: 96, plus 0 steps train_loss: 0.7119

#### test Acc: 0, NDCG: 0.2938186310189869 HIT: 0.4427493850507829

#### val Acc: 0, NDCG: 0.5766107027373881 HIT: 0.6689217559775709
Epoch: 104, plus 0 steps train_loss: 0.712

#### test Acc: 0, NDCG: 0.3191925059645398 HIT: 0.4773601155840034

#### val Acc: 0, NDCG: 0.5823991921086613 HIT: 0.6744844014494288
Epoch: 112, plus 0 steps train_loss: 0.7042

#### test Acc: 0, NDCG: 0.6118966362143327 HIT: 0.7253747553427846

#### val Acc: 0, NDCG: 0.7454821012224833 HIT: 0.8164632815806179
Epoch: 120, plus 0 steps train_loss: 0.704

#### test Acc: 0, NDCG: 0.5850530401907256 HIT: 0.6985938822471435

#### val Acc: 0, NDCG: 0.7410665786893177 HIT: 0.8107245820990266
Epoch: 128, plus 0 steps train_loss: 0.7038

#### test Acc: 0, NDCG: 0.6529251949578069 HIT: 0.7627618493440542

#### val Acc: 0, NDCG: 0.7718817358573901 HIT: 0.8374690872302158
Epoch: 136, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.6590927499737201 HIT: 0.7621816150021159

#### val Acc: 0, NDCG: 0.7739422513928057 HIT: 0.8326627301100296
Epoch: 144, plus 0 steps train_loss: 0.7025

#### test Acc: 0, NDCG: 0.6779214584656285 HIT: 0.769540341991113

#### val Acc: 0, NDCG: 0.8197244977273298 HIT: 0.8703754827020737
Epoch: 160, plus 0 steps train_loss: 0.7037

#### test Acc: 0, NDCG: 0.627912230997433 HIT: 0.7370992911553111

#### val Acc: 0, NDCG: 0.7772657776733889 HIT: 0.8427540137008042
Epoch: 176, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.12973292578383808 HIT: 0.2846991708104105

#### val Acc: 0, NDCG: 0.48508309778740055 HIT: 0.5860937169382142
Epoch: 192, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.3702724817281233 HIT: 0.5165432911024121

#### val Acc: 0, NDCG: 0.6062837898324239 HIT: 0.6957332112251375
Epoch: 208, plus 0 steps train_loss: 0.7007

#### test Acc: 0, NDCG: 0.6462331631498405 HIT: 0.7410782770842149

#### val Acc: 0, NDCG: 0.7840384719021379 HIT: 0.8477975891345747
Epoch: 224, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.4257399477252617 HIT: 0.5588532850190435

#### val Acc: 0, NDCG: 0.6530053790029599 HIT: 0.7306902639652983
Epoch: 240, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.27038941138511335 HIT: 0.41712319482649174

#### val Acc: 0, NDCG: 0.5728976522208914 HIT: 0.6585221712336013
Epoch: 256, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.49304563639268284 HIT: 0.6234022891980534

#### val Acc: 0, NDCG: 0.683085422413948 HIT: 0.7582753650021159
Epoch: 272, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.6781173627454553 HIT: 0.7663597981908591

#### val Acc: 0, NDCG: 0.8051629091672987 HIT: 0.8614810357596276
Epoch: 288, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.6891560148237886 HIT: 0.7843536751481168

#### val Acc: 0, NDCG: 0.8146245347022587 HIT: 0.8710648209373677
Epoch: 304, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.6957928480417963 HIT: 0.7865977438637326

#### val Acc: 0, NDCG: 0.8117202058123323 HIT: 0.8646367832204824
Epoch: 320, plus 0 steps train_loss: 0.6982

#### test Acc: 0, NDCG: 0.6834358939358158 HIT: 0.7774793033220483

#### val Acc: 0, NDCG: 0.8101301343674558 HIT: 0.8693836291261109
Epoch: 352, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.4872500404157535 HIT: 0.6072623518831993

#### val Acc: 0, NDCG: 0.6880283619906947 HIT: 0.7630337825327973
Epoch: 384, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.3977353390692367 HIT: 0.5409916552052475

#### val Acc: 0, NDCG: 0.6533012237438526 HIT: 0.7405096143673296
Epoch: 416, plus 0 steps train_loss: 0.6938

#### test Acc: 0, NDCG: 0.5239494339264731 HIT: 0.6533405628438426

#### val Acc: 0, NDCG: 0.7132504824850997 HIT: 0.7867680120609395
Epoch: 448, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.4584019626012915 HIT: 0.5950608998095641

#### val Acc: 0, NDCG: 0.6692451800175714 HIT: 0.757465351248413
Epoch: 480, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.6854522897319678 HIT: 0.7777454506982648

#### val Acc: 0, NDCG: 0.8109490756746949 HIT: 0.8678727055120609
Epoch: 512, plus 0 steps train_loss: 0.6953

#### test Acc: 0, NDCG: 0.7042701986577881 HIT: 0.7853091607596276

#### val Acc: 0, NDCG: 0.8355221145651481 HIT: 0.8872394731273805
Epoch: 544, plus 0 steps train_loss: 0.6927

#### test Acc: 0, NDCG: 0.7028652479954312 HIT: 0.7921967573000424

#### val Acc: 0, NDCG: 0.8140804666954172 HIT: 0.8674610862780364
Epoch: 576, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.542564172597637 HIT: 0.6543076200804063

#### val Acc: 0, NDCG: 0.7275134529078915 HIT: 0.7939754813796022
Epoch: 608, plus 0 steps train_loss: 0.6938

#### test Acc: 0, NDCG: 0.5865686453157245 HIT: 0.6994460497778248

#### val Acc: 0, NDCG: 0.7525771462211318 HIT: 0.8156896357913669
Epoch: 640, plus 0 steps train_loss: 0.6939

#### test Acc: 0, NDCG: 0.40318948018783685 HIT: 0.549903459585273

#### val Acc: 0, NDCG: 0.640576687056406 HIT: 0.7248366747778248
Epoch: 704, plus 0 steps train_loss: 0.6944

#### test Acc: 0, NDCG: 0.5872494373767406 HIT: 0.6994576214028777

#### val Acc: 0, NDCG: 0.7536814824649356 HIT: 0.8258230731591197
Epoch: 768, plus 0 steps train_loss: 0.6949

#### test Acc: 0, NDCG: 0.6543468542481449 HIT: 0.7506984302264071

#### val Acc: 0, NDCG: 0.7712798532976128 HIT: 0.8381104858760051
Epoch: 832, plus 0 steps train_loss: 0.6875

#### test Acc: 0, NDCG: 0.6596650011855905 HIT: 0.7589151105586119

#### val Acc: 0, NDCG: 0.7983485219905321 HIT: 0.8607131757829031
Epoch: 896, plus 0 steps train_loss: 0.6886

#### test Acc: 0, NDCG: 0.6560578923656295 HIT: 0.7574463407215405

#### val Acc: 0, NDCG: 0.8005534521368542 HIT: 0.8541280945831571
Epoch: 960, plus 0 steps train_loss: 0.6866

#### test Acc: 0, NDCG: 0.6466195814868205 HIT: 0.7482857464028777

#### val Acc: 0, NDCG: 0.7991218362136655 HIT: 0.8581244379496402
Epoch: 1017, plus 0 steps train_loss: 0.6763
Done: it took 135094.97042632103
max value of NDCG: 0.7042701986577881
max value of HIT: 0.7921967573000424

After 20 validations
max value of NDCG: 0.7042701986577881
max value of HIT: 0.7921967573000424
