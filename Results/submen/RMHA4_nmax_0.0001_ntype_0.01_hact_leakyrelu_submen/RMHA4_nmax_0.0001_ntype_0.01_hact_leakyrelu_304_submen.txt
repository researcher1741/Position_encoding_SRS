 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.01
max_norm:             	0.0001
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12516839987008774 HIT: 0.27567247672450274

#### val Acc: 0, NDCG: 0.4715496741199053 HIT: 0.5637092348180279
Epoch: 1, plus 0 steps train_loss: 0.789

#### test Acc: 0, NDCG: 0.12346222026896018 HIT: 0.2770015605162928

#### val Acc: 0, NDCG: 0.4823023710179148 HIT: 0.5752403591832416
Epoch: 2, plus 0 steps train_loss: 0.7984

#### test Acc: 0, NDCG: 0.1286176842869303 HIT: 0.28947081305543804

#### val Acc: 0, NDCG: 0.4954724919241889 HIT: 0.5905306086013542
Epoch: 3, plus 0 steps train_loss: 0.7834

#### test Acc: 0, NDCG: 0.1278628487663787 HIT: 0.28615058320990266

#### val Acc: 0, NDCG: 0.4799094084712453 HIT: 0.574350170598815
Epoch: 4, plus 0 steps train_loss: 0.7893

#### test Acc: 0, NDCG: 0.12544090712661757 HIT: 0.27991595694033006

#### val Acc: 0, NDCG: 0.4849344014214947 HIT: 0.5810327840668642
Epoch: 5, plus 0 steps train_loss: 0.7845

#### test Acc: 0, NDCG: 0.13021552372516823 HIT: 0.2873110518937791

#### val Acc: 0, NDCG: 0.4777948766167963 HIT: 0.5747617898328397
Epoch: 6, plus 0 steps train_loss: 0.7734

#### test Acc: 0, NDCG: 0.13084057115890307 HIT: 0.2872209585272958

#### val Acc: 0, NDCG: 0.4898936158109553 HIT: 0.5867888409860347
Epoch: 7, plus 0 steps train_loss: 0.7651

#### test Acc: 0, NDCG: 0.1308217150165428 HIT: 0.2894402309035125

#### val Acc: 0, NDCG: 0.48117729256698355 HIT: 0.5813774531845112
Epoch: 8, plus 0 steps train_loss: 0.7818

#### test Acc: 0, NDCG: 0.12788402612728833 HIT: 0.28307914330300465

#### val Acc: 0, NDCG: 0.4840013239087849 HIT: 0.5766727610558613
Epoch: 9, plus 0 steps train_loss: 0.782

#### test Acc: 0, NDCG: 0.13168886626591536 HIT: 0.2931762127063055

#### val Acc: 0, NDCG: 0.4858846123749894 HIT: 0.5792540599873043
Epoch: 10, plus 0 steps train_loss: 0.7766

#### test Acc: 0, NDCG: 0.13074210366498115 HIT: 0.2910544725983919

#### val Acc: 0, NDCG: 0.478256703234947 HIT: 0.5711828515129074
Epoch: 12, plus 0 steps train_loss: 0.7651

#### test Acc: 0, NDCG: 0.12337112585415033 HIT: 0.276953620926788

#### val Acc: 0, NDCG: 0.47691509692433437 HIT: 0.5681957191599661
Epoch: 14, plus 0 steps train_loss: 0.7612

#### test Acc: 0, NDCG: 0.1294209296433626 HIT: 0.281240908008887

#### val Acc: 0, NDCG: 0.4772639041242326 HIT: 0.5789284013965298
Epoch: 16, plus 0 steps train_loss: 0.7548

#### test Acc: 0, NDCG: 0.1322850769561399 HIT: 0.2954070567075751

#### val Acc: 0, NDCG: 0.4805479131969997 HIT: 0.5797384151502327
Epoch: 18, plus 0 steps train_loss: 0.7371

#### test Acc: 0, NDCG: 0.132715608239413 HIT: 0.2974213460114261

#### val Acc: 0, NDCG: 0.47585662319086924 HIT: 0.5667137246085484
Epoch: 20, plus 0 steps train_loss: 0.7441

#### test Acc: 0, NDCG: 0.12195855296980665 HIT: 0.2801763185040203

#### val Acc: 0, NDCG: 0.4784253826307834 HIT: 0.5689999471011427
Epoch: 22, plus 0 steps train_loss: 0.7358

#### test Acc: 0, NDCG: 0.12648452001522134 HIT: 0.2860720614684723

#### val Acc: 0, NDCG: 0.4780774902078576 HIT: 0.5679775113732544
Epoch: 24, plus 0 steps train_loss: 0.734

#### test Acc: 0, NDCG: 0.13516152437504883 HIT: 0.29488798666948796

#### val Acc: 0, NDCG: 0.4734084840069675 HIT: 0.5720598153829878
Epoch: 26, plus 0 steps train_loss: 0.7263

#### test Acc: 0, NDCG: 0.14062249093964674 HIT: 0.3056090972809987

#### val Acc: 0, NDCG: 0.47863728489778623 HIT: 0.5701546299724926
Epoch: 28, plus 0 steps train_loss: 0.7204

#### test Acc: 0, NDCG: 0.14379281872959038 HIT: 0.3142258252221752

#### val Acc: 0, NDCG: 0.48874867914646175 HIT: 0.5800525021159543
Epoch: 30, plus 0 steps train_loss: 0.7267

#### test Acc: 0, NDCG: 0.14113171995343687 HIT: 0.3065034185886585

#### val Acc: 0, NDCG: 0.4770776525726608 HIT: 0.5682742409013964
Epoch: 32, plus 0 steps train_loss: 0.7172

#### test Acc: 0, NDCG: 0.13724468655665745 HIT: 0.2981834201756242

#### val Acc: 0, NDCG: 0.47303974096650875 HIT: 0.5673245411024121
Epoch: 36, plus 0 steps train_loss: 0.7159

#### test Acc: 0, NDCG: 0.14620251972684764 HIT: 0.3101625317393144

#### val Acc: 0, NDCG: 0.4829385120938589 HIT: 0.5772893633622515
Epoch: 40, plus 0 steps train_loss: 0.7135

#### test Acc: 0, NDCG: 0.1444228425550091 HIT: 0.3043568821413457

#### val Acc: 0, NDCG: 0.4950513395272927 HIT: 0.5832636280681338
Epoch: 44, plus 0 steps train_loss: 0.7096

#### test Acc: 0, NDCG: 0.1549255220448722 HIT: 0.31975210272958104

#### val Acc: 0, NDCG: 0.4798527406355321 HIT: 0.568413926946678
Epoch: 48, plus 0 steps train_loss: 0.7111

#### test Acc: 0, NDCG: 0.14908679049182197 HIT: 0.30958808320990266

#### val Acc: 0, NDCG: 0.49280957825546223 HIT: 0.5840620701967838
Epoch: 52, plus 0 steps train_loss: 0.714

#### test Acc: 0, NDCG: 0.1483048464354242 HIT: 0.3032997315382988

#### val Acc: 0, NDCG: 0.4911335374994352 HIT: 0.5844431072788827
Epoch: 56, plus 0 steps train_loss: 0.7068

#### test Acc: 0, NDCG: 0.16411272243197114 HIT: 0.3235128808717732

#### val Acc: 0, NDCG: 0.5026097336606652 HIT: 0.5926730123254337
Epoch: 60, plus 0 steps train_loss: 0.7061

#### test Acc: 0, NDCG: 0.17004048048283305 HIT: 0.3327652216462124

#### val Acc: 0, NDCG: 0.5055739481750073 HIT: 0.5962767469847651
Epoch: 64, plus 0 steps train_loss: 0.7084

#### test Acc: 0, NDCG: 0.18600265350745296 HIT: 0.3434557501057977

#### val Acc: 0, NDCG: 0.5114804817038694 HIT: 0.6004607159860347
Epoch: 68, plus 0 steps train_loss: 0.7073

#### test Acc: 0, NDCG: 0.19796450530119653 HIT: 0.35505961039991535

#### val Acc: 0, NDCG: 0.50686931554389 HIT: 0.5921886571625052
Epoch: 72, plus 0 steps train_loss: 0.7076

#### test Acc: 0, NDCG: 0.20189377141395726 HIT: 0.36016848286077024

#### val Acc: 0, NDCG: 0.5274299848937256 HIT: 0.6180082588341091
Epoch: 80, plus 0 steps train_loss: 0.7025

#### test Acc: 0, NDCG: 0.2207844376542632 HIT: 0.37527275973338975

#### val Acc: 0, NDCG: 0.5273069111198193 HIT: 0.6173437169382142
Epoch: 88, plus 0 steps train_loss: 0.7094

#### test Acc: 0, NDCG: 0.23645539633721124 HIT: 0.3884735042848075

#### val Acc: 0, NDCG: 0.5453609857680098 HIT: 0.6297575909860347
Epoch: 96, plus 0 steps train_loss: 0.7066

#### test Acc: 0, NDCG: 0.282025122771639 HIT: 0.42531673190859076

#### val Acc: 0, NDCG: 0.5802598102816423 HIT: 0.6643989036711807
Epoch: 104, plus 0 steps train_loss: 0.7083

#### test Acc: 0, NDCG: 0.25600881171845524 HIT: 0.39589339557765557

#### val Acc: 0, NDCG: 0.551745456786907 HIT: 0.6401819720694033
Epoch: 112, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.3075143426519822 HIT: 0.4495700314748201

#### val Acc: 0, NDCG: 0.5863993019592616 HIT: 0.6691399637642828
Epoch: 120, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.2701782346001851 HIT: 0.41665206437790947

#### val Acc: 0, NDCG: 0.5530281073224752 HIT: 0.6436766028353788
Epoch: 128, plus 0 steps train_loss: 0.7072

#### test Acc: 0, NDCG: 0.2657885241184169 HIT: 0.4138104038827761

#### val Acc: 0, NDCG: 0.5577887547476562 HIT: 0.6433145762801523
Epoch: 136, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.37756063631139863 HIT: 0.5111087600507829

#### val Acc: 0, NDCG: 0.627950356591227 HIT: 0.7085223365425306
Epoch: 144, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.4174067631742582 HIT: 0.5422306456305543

#### val Acc: 0, NDCG: 0.6537544666523502 HIT: 0.7244977914727042
Epoch: 160, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.47676448144394096 HIT: 0.5900900603046974

#### val Acc: 0, NDCG: 0.6915757429724383 HIT: 0.7606632524862463
Epoch: 176, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.5112034543108728 HIT: 0.6287103589187474

#### val Acc: 0, NDCG: 0.7006508299193794 HIT: 0.7670912902031316
Epoch: 192, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.5952389769826378 HIT: 0.6994997751798562

#### val Acc: 0, NDCG: 0.7540646706171421 HIT: 0.8154350600402032
Epoch: 208, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.620017951203719 HIT: 0.7189409318133728

#### val Acc: 0, NDCG: 0.7709686865256268 HIT: 0.8270331345217943
Epoch: 224, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.6989842288052924 HIT: 0.7906552515340668

#### val Acc: 0, NDCG: 0.8247828639504137 HIT: 0.872087256665256
Epoch: 240, plus 0 steps train_loss: 0.6972

#### test Acc: 0, NDCG: 0.7045295644520367 HIT: 0.7832659423931443

#### val Acc: 0, NDCG: 0.815700021953515 HIT: 0.8653814999471011
Epoch: 256, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.7137394428470505 HIT: 0.7912660680279306

#### val Acc: 0, NDCG: 0.8241704155388218 HIT: 0.8761083963711384
Epoch: 272, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.7198850913615242 HIT: 0.8004266623465933

#### val Acc: 0, NDCG: 0.8294549418513595 HIT: 0.8768093062314853
Epoch: 288, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.7023379243912536 HIT: 0.7834114142509522

#### val Acc: 0, NDCG: 0.8348770770712369 HIT: 0.8801411077020737
Epoch: 304, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.6959438671254572 HIT: 0.7734523778036394

#### val Acc: 0, NDCG: 0.821758505373667 HIT: 0.8704060648539992
Epoch: 320, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.7190815832147073 HIT: 0.7961220178269149

#### val Acc: 0, NDCG: 0.8209303393037503 HIT: 0.8663121892192128
Epoch: 352, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.7034797915954211 HIT: 0.7898088698159119

#### val Acc: 0, NDCG: 0.8079090096401973 HIT: 0.8564680424777825
Epoch: 384, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.7288042876215461 HIT: 0.8005415520524757

#### val Acc: 0, NDCG: 0.8292335192140738 HIT: 0.8765737410071943
Epoch: 416, plus 0 steps train_loss: 0.6942

#### test Acc: 0, NDCG: 0.7084509257874856 HIT: 0.7892402070990266

#### val Acc: 0, NDCG: 0.8235105224481922 HIT: 0.8743296722915785
Epoch: 448, plus 0 steps train_loss: 0.6927

#### test Acc: 0, NDCG: 0.7131579562460709 HIT: 0.7954806191811257

#### val Acc: 0, NDCG: 0.8271774418291211 HIT: 0.872897270418959
Epoch: 480, plus 0 steps train_loss: 0.6935

#### test Acc: 0, NDCG: 0.6874584616830282 HIT: 0.7802250846381719

#### val Acc: 0, NDCG: 0.7901863989995667 HIT: 0.8418348960537453
Epoch: 512, plus 0 steps train_loss: 0.6948

#### test Acc: 0, NDCG: 0.2884490506297819 HIT: 0.4446603562738045

#### val Acc: 0, NDCG: 0.5743225475884068 HIT: 0.6650940277190012
Epoch: 544, plus 0 steps train_loss: 0.6929

#### test Acc: 0, NDCG: 0.3151388028758376 HIT: 0.4776874272640711

#### val Acc: 0, NDCG: 0.5845178375239191 HIT: 0.6795643448476513
Epoch: 576, plus 0 steps train_loss: 0.6934

#### test Acc: 0, NDCG: 0.3489664582479601 HIT: 0.5017778975349133

#### val Acc: 0, NDCG: 0.5928233279546631 HIT: 0.6860287505289886
Epoch: 608, plus 0 steps train_loss: 0.6948

#### test Acc: 0, NDCG: 0.2984835768023263 HIT: 0.45713374153618286

#### val Acc: 0, NDCG: 0.5621989136791938 HIT: 0.6602992422238679
Epoch: 640, plus 0 steps train_loss: 0.6873

#### test Acc: 0, NDCG: 0.2538920029657987 HIT: 0.42318176708633093

#### val Acc: 0, NDCG: 0.5422757967531924 HIT: 0.6444924024016081
Epoch: 704, plus 0 steps train_loss: 0.6895

#### test Acc: 0, NDCG: 0.2767295620817362 HIT: 0.4542019876745662

#### val Acc: 0, NDCG: 0.544983200465116 HIT: 0.6577237291049514
Epoch: 768, plus 0 steps train_loss: 0.6769

#### test Acc: 0, NDCG: 0.28718076395041386 HIT: 0.46364773989631825

#### val Acc: 0, NDCG: 0.5516849828896655 HIT: 0.6555350388806601
Epoch: 832, plus 0 steps train_loss: 0.6646

#### test Acc: 0, NDCG: 0.2934615722428324 HIT: 0.4689326663669065

#### val Acc: 0, NDCG: 0.5697264421445454 HIT: 0.6714856974714346
Epoch: 896, plus 0 steps train_loss: 0.6755

#### test Acc: 0, NDCG: 0.29383597893372493 HIT: 0.47161563028988573

#### val Acc: 0, NDCG: 0.5686949890381122 HIT: 0.6686556086013542
Epoch: 960, plus 0 steps train_loss: 0.6642

#### test Acc: 0, NDCG: 0.3017939890699275 HIT: 0.47783868493440546

#### val Acc: 0, NDCG: 0.5614718274996082 HIT: 0.6641633384468895
Epoch: 1017, plus 0 steps train_loss: 0.6757
Done: it took 82993.7064230442
max value of NDCG: 0.7288042876215461
max value of HIT: 0.8005415520524757

After 20 validations
max value of NDCG: 0.7288042876215461
max value of HIT: 0.8005415520524757
