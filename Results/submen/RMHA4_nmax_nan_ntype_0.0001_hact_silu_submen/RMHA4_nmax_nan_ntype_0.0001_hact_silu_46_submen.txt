 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.0001
max_norm:             	nan
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12958344548047346 HIT: 0.2851950975983919

#### val Acc: 0, NDCG: 0.4683677880943077 HIT: 0.5515788655840034
Epoch: 1, plus 0 steps train_loss: 0.7696

#### test Acc: 0, NDCG: 0.13847053713031687 HIT: 0.29669563981168007

#### val Acc: 0, NDCG: 0.4709693172323874 HIT: 0.5556248016292847
Epoch: 2, plus 0 steps train_loss: 0.7727

#### test Acc: 0, NDCG: 0.13179243278079755 HIT: 0.29250588499788405

#### val Acc: 0, NDCG: 0.4789877131976501 HIT: 0.5660376110876005
Epoch: 3, plus 0 steps train_loss: 0.7787

#### test Acc: 0, NDCG: 0.12980796552790505 HIT: 0.2873052660812526

#### val Acc: 0, NDCG: 0.47031599131464513 HIT: 0.5510159886796445
Epoch: 4, plus 0 steps train_loss: 0.7714

#### test Acc: 0, NDCG: 0.12870961013545718 HIT: 0.28864178877486246

#### val Acc: 0, NDCG: 0.4752225977308792 HIT: 0.5609998214663563
Epoch: 5, plus 0 steps train_loss: 0.7764

#### test Acc: 0, NDCG: 0.14039898009427224 HIT: 0.30968974820143885

#### val Acc: 0, NDCG: 0.48095958105513636 HIT: 0.5653466197630131
Epoch: 6, plus 0 steps train_loss: 0.77

#### test Acc: 0, NDCG: 0.1303571096995173 HIT: 0.28947659886796445

#### val Acc: 0, NDCG: 0.47674871208800307 HIT: 0.5627768924566229
Epoch: 7, plus 0 steps train_loss: 0.7739

#### test Acc: 0, NDCG: 0.12968586802303034 HIT: 0.28904183638383407

#### val Acc: 0, NDCG: 0.4757280213567185 HIT: 0.5680981868916631
Epoch: 8, plus 0 steps train_loss: 0.7701

#### test Acc: 0, NDCG: 0.13160309826818728 HIT: 0.290527963658485

#### val Acc: 0, NDCG: 0.4852273428662972 HIT: 0.5653176907003808
Epoch: 9, plus 0 steps train_loss: 0.7682

#### test Acc: 0, NDCG: 0.1353742657273038 HIT: 0.30136974978840453

#### val Acc: 0, NDCG: 0.47767171723045093 HIT: 0.5643853483389759
Epoch: 10, plus 0 steps train_loss: 0.7649

#### test Acc: 0, NDCG: 0.12492786909517306 HIT: 0.2772503504549302

#### val Acc: 0, NDCG: 0.47983602977791373 HIT: 0.5758685331146848
Epoch: 12, plus 0 steps train_loss: 0.7538

#### test Acc: 0, NDCG: 0.128115108059682 HIT: 0.28653740610452816

#### val Acc: 0, NDCG: 0.4772077927574356 HIT: 0.5773009349873043
Epoch: 14, plus 0 steps train_loss: 0.7547

#### test Acc: 0, NDCG: 0.12537382135498087 HIT: 0.27833808320990266

#### val Acc: 0, NDCG: 0.48881161471318285 HIT: 0.583414885738468
Epoch: 16, plus 0 steps train_loss: 0.738

#### test Acc: 0, NDCG: 0.13377993781412056 HIT: 0.2932547344477359

#### val Acc: 0, NDCG: 0.4865463932488961 HIT: 0.5848778697630131
Epoch: 18, plus 0 steps train_loss: 0.732

#### test Acc: 0, NDCG: 0.13359763420261794 HIT: 0.28369574560939487

#### val Acc: 0, NDCG: 0.48320911547140427 HIT: 0.5862871283855269
Epoch: 20, plus 0 steps train_loss: 0.7186

#### test Acc: 0, NDCG: 0.1614977876963059 HIT: 0.31737000105797714

#### val Acc: 0, NDCG: 0.49924277875684203 HIT: 0.5952733217837495
Epoch: 22, plus 0 steps train_loss: 0.7193

#### test Acc: 0, NDCG: 0.17636816949440726 HIT: 0.33158574243546335

#### val Acc: 0, NDCG: 0.5163357647239536 HIT: 0.6172346130448583
Epoch: 24, plus 0 steps train_loss: 0.7189

#### test Acc: 0, NDCG: 0.1807869686557284 HIT: 0.3422820567075751

#### val Acc: 0, NDCG: 0.5025137141681603 HIT: 0.5933144109712231
Epoch: 26, plus 0 steps train_loss: 0.7195

#### test Acc: 0, NDCG: 0.18766985576771272 HIT: 0.3458147085272958

#### val Acc: 0, NDCG: 0.5110207298602072 HIT: 0.5984348550571308
Epoch: 28, plus 0 steps train_loss: 0.711

#### test Acc: 0, NDCG: 0.21513634638842893 HIT: 0.36925055543800256

#### val Acc: 0, NDCG: 0.5225349044895009 HIT: 0.6176387933770631
Epoch: 30, plus 0 steps train_loss: 0.7096

#### test Acc: 0, NDCG: 0.26800220911399136 HIT: 0.41612555543800256

#### val Acc: 0, NDCG: 0.5589107869121168 HIT: 0.6519734579983072
Epoch: 32, plus 0 steps train_loss: 0.7143

#### test Acc: 0, NDCG: 0.2561596975980671 HIT: 0.40681948926153194

#### val Acc: 0, NDCG: 0.5589879132227132 HIT: 0.6499533828819297
Epoch: 36, plus 0 steps train_loss: 0.7109

#### test Acc: 0, NDCG: 0.3149890761357456 HIT: 0.4678680768620398

#### val Acc: 0, NDCG: 0.5865813365811441 HIT: 0.6741165890816758
Epoch: 40, plus 0 steps train_loss: 0.7102

#### test Acc: 0, NDCG: 0.3122081725148136 HIT: 0.4572312738044858

#### val Acc: 0, NDCG: 0.5921792047879604 HIT: 0.687286751481168
Epoch: 44, plus 0 steps train_loss: 0.7084

#### test Acc: 0, NDCG: 0.28896872765161835 HIT: 0.4305595046022006

#### val Acc: 0, NDCG: 0.5790212889167757 HIT: 0.6711352425412611
Epoch: 48, plus 0 steps train_loss: 0.7052

#### test Acc: 0, NDCG: 0.29703154388150055 HIT: 0.441769103099873

#### val Acc: 0, NDCG: 0.581250233137949 HIT: 0.6746546696466357
Epoch: 52, plus 0 steps train_loss: 0.7068

#### test Acc: 0, NDCG: 0.3194455458001858 HIT: 0.46760192948582313

#### val Acc: 0, NDCG: 0.5951026839428933 HIT: 0.6878669858231062
Epoch: 56, plus 0 steps train_loss: 0.7075

#### test Acc: 0, NDCG: 0.38945483885411014 HIT: 0.5201776079136691

#### val Acc: 0, NDCG: 0.6350858435140738 HIT: 0.7197319350402032
Epoch: 60, plus 0 steps train_loss: 0.705

#### test Acc: 0, NDCG: 0.35060600567685 HIT: 0.49886928692340243

#### val Acc: 0, NDCG: 0.6250931371150509 HIT: 0.7155115980744816
Epoch: 64, plus 0 steps train_loss: 0.7058

#### test Acc: 0, NDCG: 0.394961929274982 HIT: 0.530887146900127

#### val Acc: 0, NDCG: 0.6366113889035827 HIT: 0.7135221051100296
Epoch: 68, plus 0 steps train_loss: 0.704

#### test Acc: 0, NDCG: 0.43289924542471253 HIT: 0.5610783432077867

#### val Acc: 0, NDCG: 0.6618398028948499 HIT: 0.7381027163563267
Epoch: 72, plus 0 steps train_loss: 0.7022

#### test Acc: 0, NDCG: 0.4063059423717752 HIT: 0.5377383754760897

#### val Acc: 0, NDCG: 0.6555534621508747 HIT: 0.7389606696995346
Epoch: 80, plus 0 steps train_loss: 0.7024

#### test Acc: 0, NDCG: 0.39098669955409326 HIT: 0.5256443742065171

#### val Acc: 0, NDCG: 0.6307738521515924 HIT: 0.7172655258146424
Epoch: 88, plus 0 steps train_loss: 0.7003

#### test Acc: 0, NDCG: 0.45605273970944504 HIT: 0.5913307038192975

#### val Acc: 0, NDCG: 0.6829212455136421 HIT: 0.7632214081675837
Epoch: 96, plus 0 steps train_loss: 0.7036

#### test Acc: 0, NDCG: 0.4642044571408114 HIT: 0.5910645564430808

#### val Acc: 0, NDCG: 0.679780792347119 HIT: 0.7587580670757511
Epoch: 104, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.4051576686771276 HIT: 0.5399444231379602

#### val Acc: 0, NDCG: 0.6485541669395669 HIT: 0.7335988745768091
Epoch: 112, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.4050871703688051 HIT: 0.5395708249576809

#### val Acc: 0, NDCG: 0.6372299530779609 HIT: 0.7148296987410072
Epoch: 120, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.41130309139702304 HIT: 0.5448061587494709

#### val Acc: 0, NDCG: 0.6614968523963654 HIT: 0.7408179155205248
Epoch: 128, plus 0 steps train_loss: 0.7013

#### test Acc: 0, NDCG: 0.5103345530914555 HIT: 0.6367774346699111

#### val Acc: 0, NDCG: 0.7063255413968937 HIT: 0.7793539065806179
Epoch: 136, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.4374548742115594 HIT: 0.5592037399492171

#### val Acc: 0, NDCG: 0.6594880096747775 HIT: 0.7368827364578925
Epoch: 144, plus 0 steps train_loss: 0.7029

#### test Acc: 0, NDCG: 0.3309501887589103 HIT: 0.47249259415996614

#### val Acc: 0, NDCG: 0.593634945955437 HIT: 0.6827506744604317
Epoch: 160, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.436178258314848 HIT: 0.563931575327973

#### val Acc: 0, NDCG: 0.6661330333366743 HIT: 0.7480080274016081
Epoch: 176, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.5631783794225773 HIT: 0.680175161341515

#### val Acc: 0, NDCG: 0.730157418191573 HIT: 0.7987091025708845
Epoch: 192, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.5430608026303156 HIT: 0.6605901859394837

#### val Acc: 0, NDCG: 0.7338413177080418 HIT: 0.8034617342890394
Epoch: 208, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.6109032429234285 HIT: 0.7141883000952179

#### val Acc: 0, NDCG: 0.7655591759889182 HIT: 0.8317493982754973
Epoch: 224, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.6017248289711938 HIT: 0.7041507419064749

#### val Acc: 0, NDCG: 0.7615166313609607 HIT: 0.8257809193821413
Epoch: 240, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.6336490145162132 HIT: 0.7361016517668219

#### val Acc: 0, NDCG: 0.7859032138662814 HIT: 0.8400272429115531
Epoch: 256, plus 0 steps train_loss: 0.694

#### test Acc: 0, NDCG: 0.6417727397541023 HIT: 0.7412295347545493

#### val Acc: 0, NDCG: 0.7807053176574865 HIT: 0.8429895789250952
Epoch: 272, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.6763660881951721 HIT: 0.7694618202496826

#### val Acc: 0, NDCG: 0.7947959640434749 HIT: 0.8456626243123149
Epoch: 288, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.678431769300589 HIT: 0.7651861047926365

#### val Acc: 0, NDCG: 0.8029872253522763 HIT: 0.8572854951333051
Epoch: 304, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.6492654664461448 HIT: 0.7506562764494288

#### val Acc: 0, NDCG: 0.7709576035582669 HIT: 0.8299764600084638
Epoch: 320, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.6681288365433505 HIT: 0.7606574666737198

#### val Acc: 0, NDCG: 0.8061200968296242 HIT: 0.8570904305966991
Epoch: 352, plus 0 steps train_loss: 0.6933

#### test Acc: 0, NDCG: 0.673380737264579 HIT: 0.7636198026872619

#### val Acc: 0, NDCG: 0.803025455994552 HIT: 0.8559663298772747
Epoch: 384, plus 0 steps train_loss: 0.6936

#### test Acc: 0, NDCG: 0.6444132652290965 HIT: 0.7455283934617013

#### val Acc: 0, NDCG: 0.7838494118876975 HIT: 0.8413811230427423
Epoch: 416, plus 0 steps train_loss: 0.6937

#### test Acc: 0, NDCG: 0.6463210013050938 HIT: 0.7472517390499366

#### val Acc: 0, NDCG: 0.7849070605334663 HIT: 0.8443930517350825
Epoch: 448, plus 0 steps train_loss: 0.6948

#### test Acc: 0, NDCG: 0.6355216594019191 HIT: 0.7349106009310199

#### val Acc: 0, NDCG: 0.7886676873419303 HIT: 0.8459824970905628
Epoch: 480, plus 0 steps train_loss: 0.6934

#### test Acc: 0, NDCG: 0.6396461134640787 HIT: 0.7385333461172239

#### val Acc: 0, NDCG: 0.7835573301999824 HIT: 0.8469206252644943
Epoch: 512, plus 0 steps train_loss: 0.6949

#### test Acc: 0, NDCG: 0.6687201616155279 HIT: 0.7632156223550571

#### val Acc: 0, NDCG: 0.8084872111093739 HIT: 0.8637176655734237
Epoch: 544, plus 0 steps train_loss: 0.6934

#### test Acc: 0, NDCG: 0.6443442427997036 HIT: 0.7410592665573423

#### val Acc: 0, NDCG: 0.7982819609550311 HIT: 0.8569160296762589
Epoch: 576, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.4080281764304133 HIT: 0.5360266015129074

#### val Acc: 0, NDCG: 0.650750587633665 HIT: 0.7378307831675837
Epoch: 608, plus 0 steps train_loss: 0.6921

#### test Acc: 0, NDCG: 0.4884597323838237 HIT: 0.6215334717520102

#### val Acc: 0, NDCG: 0.6798016421755124 HIT: 0.7593705366589082
Epoch: 640, plus 0 steps train_loss: 0.6914

#### test Acc: 0, NDCG: 0.42793844147686094 HIT: 0.573746793006771

#### val Acc: 0, NDCG: 0.655311363338519 HIT: 0.7449175769678374
Epoch: 704, plus 0 steps train_loss: 0.6849

#### test Acc: 0, NDCG: 0.2575317256165156 HIT: 0.42979743043800256

#### val Acc: 0, NDCG: 0.559290342424251 HIT: 0.6668537412716885
Epoch: 768, plus 0 steps train_loss: 0.6918

#### test Acc: 0, NDCG: 0.21893954959614284 HIT: 0.4100611973656369

#### val Acc: 0, NDCG: 0.5301896512529812 HIT: 0.6396918310939483
Epoch: 832, plus 0 steps train_loss: 0.6849

#### test Acc: 0, NDCG: 0.2444973435419514 HIT: 0.4231280416842996

#### val Acc: 0, NDCG: 0.546474641914773 HIT: 0.6502674698476513
Epoch: 896, plus 0 steps train_loss: 0.675

#### test Acc: 0, NDCG: 0.25389592505906877 HIT: 0.4383414224502751

#### val Acc: 0, NDCG: 0.5507926719134475 HIT: 0.6545299605903513
Epoch: 960, plus 0 steps train_loss: 0.6713

#### test Acc: 0, NDCG: 0.26496645056039003 HIT: 0.4484822987198477

#### val Acc: 0, NDCG: 0.5584000713200687 HIT: 0.6658982556601777
Epoch: 1017, plus 0 steps train_loss: 0.677
Done: it took 83682.56672501564
max value of NDCG: 0.678431769300589
max value of HIT: 0.7694618202496826

After 20 validations
max value of NDCG: 0.678431769300589
max value of HIT: 0.7694618202496826
