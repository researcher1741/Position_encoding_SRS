 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	0.1
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12794959643481524 HIT: 0.277938035600931

#### val Acc: 0, NDCG: 0.47145020437834134 HIT: 0.5611147111722387
Epoch: 1, plus 0 steps train_loss: 0.7505

#### test Acc: 0, NDCG: 0.12132731357566895 HIT: 0.26736239684722807

#### val Acc: 0, NDCG: 0.47481479794802295 HIT: 0.5662310225349133
Epoch: 2, plus 0 steps train_loss: 0.7655

#### test Acc: 0, NDCG: 0.12508857135695206 HIT: 0.27176457363520945

#### val Acc: 0, NDCG: 0.4788865661805675 HIT: 0.5728028790203131
Epoch: 3, plus 0 steps train_loss: 0.7566

#### test Acc: 0, NDCG: 0.12342045945595155 HIT: 0.2769709783643673

#### val Acc: 0, NDCG: 0.48004127581629386 HIT: 0.5713456808082945
Epoch: 4, plus 0 steps train_loss: 0.7486

#### test Acc: 0, NDCG: 0.13259005826798023 HIT: 0.29612119128226827

#### val Acc: 0, NDCG: 0.467400659226652 HIT: 0.554632948053322
Epoch: 5, plus 0 steps train_loss: 0.7595

#### test Acc: 0, NDCG: 0.1276820358960755 HIT: 0.288218597915785

#### val Acc: 0, NDCG: 0.4696746931056316 HIT: 0.5585507696783749
Epoch: 6, plus 0 steps train_loss: 0.7412

#### test Acc: 0, NDCG: 0.12458104256838724 HIT: 0.26824101380660176

#### val Acc: 0, NDCG: 0.4765809448468853 HIT: 0.5705356670545916
Epoch: 7, plus 0 steps train_loss: 0.7366

#### test Acc: 0, NDCG: 0.12708486803452818 HIT: 0.27925141504443507

#### val Acc: 0, NDCG: 0.46961357439660806 HIT: 0.5626140631612356
Epoch: 8, plus 0 steps train_loss: 0.7446

#### test Acc: 0, NDCG: 0.12315295683743466 HIT: 0.2763485902454507

#### val Acc: 0, NDCG: 0.4739686895119335 HIT: 0.5721920625264495
Epoch: 9, plus 0 steps train_loss: 0.7279

#### test Acc: 0, NDCG: 0.12247114990739301 HIT: 0.2672970998201439

#### val Acc: 0, NDCG: 0.48185928672456874 HIT: 0.578782929538722
Epoch: 10, plus 0 steps train_loss: 0.74

#### test Acc: 0, NDCG: 0.1289032472023241 HIT: 0.2870697008569615

#### val Acc: 0, NDCG: 0.48771878678998737 HIT: 0.591692730374524
Epoch: 12, plus 0 steps train_loss: 0.7323

#### test Acc: 0, NDCG: 0.13011938640735968 HIT: 0.28652583447947527

#### val Acc: 0, NDCG: 0.47367746324852883 HIT: 0.5654805199957681
Epoch: 14, plus 0 steps train_loss: 0.7204

#### test Acc: 0, NDCG: 0.12678011478084455 HIT: 0.28175419223444775

#### val Acc: 0, NDCG: 0.47558724795781315 HIT: 0.5723375343842573
Epoch: 16, plus 0 steps train_loss: 0.7248

#### test Acc: 0, NDCG: 0.11262386537223515 HIT: 0.2582993347968684

#### val Acc: 0, NDCG: 0.47426720224867713 HIT: 0.5650441044223444
Epoch: 18, plus 0 steps train_loss: 0.7226

#### test Acc: 0, NDCG: 0.11891686368948917 HIT: 0.26016815224291157

#### val Acc: 0, NDCG: 0.462631764635668 HIT: 0.5503630184088024
Epoch: 20, plus 0 steps train_loss: 0.7227

#### test Acc: 0, NDCG: 0.11624316280054421 HIT: 0.2570834876216674

#### val Acc: 0, NDCG: 0.47753049208659903 HIT: 0.5603832191599661
Epoch: 22, plus 0 steps train_loss: 0.7139

#### test Acc: 0, NDCG: 0.14753634996709208 HIT: 0.2931167014917478

#### val Acc: 0, NDCG: 0.49190662051931633 HIT: 0.5797574256771054
Epoch: 24, plus 0 steps train_loss: 0.7175

#### test Acc: 0, NDCG: 0.17010766225063942 HIT: 0.3233500515763859

#### val Acc: 0, NDCG: 0.49828733210289095 HIT: 0.5949997355057131
Epoch: 26, plus 0 steps train_loss: 0.7198

#### test Acc: 0, NDCG: 0.16887523710601723 HIT: 0.3216324918006771

#### val Acc: 0, NDCG: 0.49333690390969936 HIT: 0.587786480374524
Epoch: 28, plus 0 steps train_loss: 0.7121

#### test Acc: 0, NDCG: 0.138792684894414 HIT: 0.28166409886796445

#### val Acc: 0, NDCG: 0.486572462445817 HIT: 0.5728392469847651
Epoch: 30, plus 0 steps train_loss: 0.7107

#### test Acc: 0, NDCG: 0.1566310690503619 HIT: 0.3064133252221752

#### val Acc: 0, NDCG: 0.5031299499754415 HIT: 0.588832059352518
Epoch: 32, plus 0 steps train_loss: 0.709

#### test Acc: 0, NDCG: 0.14566167796288007 HIT: 0.293279530787135

#### val Acc: 0, NDCG: 0.48429909303529295 HIT: 0.5740245120080406
Epoch: 36, plus 0 steps train_loss: 0.708

#### test Acc: 0, NDCG: 0.25219488830375053 HIT: 0.39689103496614475

#### val Acc: 0, NDCG: 0.5623133375636822 HIT: 0.647389441388066
Epoch: 40, plus 0 steps train_loss: 0.7137

#### test Acc: 0, NDCG: 0.13146257594868233 HIT: 0.27424999338764283

#### val Acc: 0, NDCG: 0.4741950990917096 HIT: 0.5623842837494709
Epoch: 44, plus 0 steps train_loss: 0.7056

#### test Acc: 0, NDCG: 0.2567059222776105 HIT: 0.40480685304697417

#### val Acc: 0, NDCG: 0.550218938654541 HIT: 0.6416928956834532
Epoch: 48, plus 0 steps train_loss: 0.708

#### test Acc: 0, NDCG: 0.19471485391814822 HIT: 0.34766451544646637

#### val Acc: 0, NDCG: 0.512028741228715 HIT: 0.6076987674566229
Epoch: 52, plus 0 steps train_loss: 0.705

#### test Acc: 0, NDCG: 0.25349281854415096 HIT: 0.41314999471011427

#### val Acc: 0, NDCG: 0.5412867283197716 HIT: 0.6412523473867965
Epoch: 56, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.30039416158110394 HIT: 0.45870004364155736

#### val Acc: 0, NDCG: 0.5765250378756552 HIT: 0.6647435727888278
Epoch: 60, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.12882333572284405 HIT: 0.2746004483178163

#### val Acc: 0, NDCG: 0.4815277133172434 HIT: 0.5786738256453661
Epoch: 64, plus 0 steps train_loss: 0.7046

#### test Acc: 0, NDCG: 0.3295109276538601 HIT: 0.48836059828607703

#### val Acc: 0, NDCG: 0.5887890498811579 HIT: 0.6755432051417689
Epoch: 68, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.182390758083915 HIT: 0.3430441308717732

#### val Acc: 0, NDCG: 0.5101860859738 HIT: 0.6057762246085484
Epoch: 72, plus 0 steps train_loss: 0.7017

#### test Acc: 0, NDCG: 0.372351421994687 HIT: 0.5210909397482014

#### val Acc: 0, NDCG: 0.625001788820462 HIT: 0.7146172767668219
Epoch: 80, plus 0 steps train_loss: 0.7

#### test Acc: 0, NDCG: 0.31334673540056035 HIT: 0.46446932527507406

#### val Acc: 0, NDCG: 0.5928266432442006 HIT: 0.6834342268831993
Epoch: 88, plus 0 steps train_loss: 0.7046

#### test Acc: 0, NDCG: 0.4182422773155254 HIT: 0.5607526846170122

#### val Acc: 0, NDCG: 0.647465864434082 HIT: 0.7341063729898434
Epoch: 96, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.3856803726622122 HIT: 0.5410817485717309

#### val Acc: 0, NDCG: 0.6478554693608621 HIT: 0.7352668416737198
Epoch: 104, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.34551497296950556 HIT: 0.4974658141134152

#### val Acc: 0, NDCG: 0.6035770493512902 HIT: 0.6876429922238679
Epoch: 112, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.44376969397394417 HIT: 0.5847762047714768

#### val Acc: 0, NDCG: 0.6730353195071346 HIT: 0.7576703343207787
Epoch: 120, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.5975287004041552 HIT: 0.7100159027190012

#### val Acc: 0, NDCG: 0.7555250018397792 HIT: 0.824522918429962
Epoch: 128, plus 0 steps train_loss: 0.7002

#### test Acc: 0, NDCG: 0.585032543242559 HIT: 0.6976383966356327

#### val Acc: 0, NDCG: 0.7488505906825318 HIT: 0.8235922291578502
Epoch: 136, plus 0 steps train_loss: 0.7009

#### test Acc: 0, NDCG: 0.5943826960464716 HIT: 0.7049243876957257

#### val Acc: 0, NDCG: 0.775239160444349 HIT: 0.8406496310304697
Epoch: 144, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.6558297414522488 HIT: 0.7483642681443081

#### val Acc: 0, NDCG: 0.8086066239993426 HIT: 0.8618199190647482
Epoch: 160, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.657192961626129 HIT: 0.7528871204506983

#### val Acc: 0, NDCG: 0.795497494570147 HIT: 0.8537528433135845
Epoch: 176, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.666917919885991 HIT: 0.7537582985082523

#### val Acc: 0, NDCG: 0.8006463064083293 HIT: 0.8553612991959374
Epoch: 192, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.6356928123974743 HIT: 0.7338402256136267

#### val Acc: 0, NDCG: 0.7972522565792413 HIT: 0.8508806006665256
Epoch: 208, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.6661779165910796 HIT: 0.7610079216038934

#### val Acc: 0, NDCG: 0.8003122709976146 HIT: 0.8551984699005502
Epoch: 224, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.663250775008739 HIT: 0.7569446281210326

#### val Acc: 0, NDCG: 0.7973648506160489 HIT: 0.8504879919593736
Epoch: 240, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.6669105529623639 HIT: 0.7516233336859923

#### val Acc: 0, NDCG: 0.7938220660283444 HIT: 0.8527436323000424
Epoch: 256, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.6658240498945982 HIT: 0.7505777547079983

#### val Acc: 0, NDCG: 0.7956661448200274 HIT: 0.8520542940647482
Epoch: 272, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.6732342541486944 HIT: 0.7643281514494288

#### val Acc: 0, NDCG: 0.796323735491324 HIT: 0.8479794289568345
Epoch: 288, plus 0 steps train_loss: 0.6944

#### test Acc: 0, NDCG: 0.6544484320113251 HIT: 0.7512613071307659

#### val Acc: 0, NDCG: 0.7971431364461784 HIT: 0.8485464385844266
Epoch: 304, plus 0 steps train_loss: 0.6953

#### test Acc: 0, NDCG: 0.671995582399842 HIT: 0.7708636399703765

#### val Acc: 0, NDCG: 0.8165937517794413 HIT: 0.8698621984765129
Epoch: 320, plus 0 steps train_loss: 0.6931

#### test Acc: 0, NDCG: 0.6333733089987088 HIT: 0.7253441731908591

#### val Acc: 0, NDCG: 0.773250607250505 HIT: 0.8378079705353364
Epoch: 352, plus 0 steps train_loss: 0.6876

#### test Acc: 0, NDCG: 0.6053118343453147 HIT: 0.7087215338023699

#### val Acc: 0, NDCG: 0.7664313626695831 HIT: 0.8249518951015657
Epoch: 384, plus 0 steps train_loss: 0.6867

#### test Acc: 0, NDCG: 0.6241380566732515 HIT: 0.7224909410706729

#### val Acc: 0, NDCG: 0.7776090928694003 HIT: 0.8358184775708845
Epoch: 416, plus 0 steps train_loss: 0.6786

#### test Acc: 0, NDCG: 0.5657233242142606 HIT: 0.6698350878121032

#### val Acc: 0, NDCG: 0.7315887949201716 HIT: 0.8004993982754973
Epoch: 448, plus 0 steps train_loss: 0.6709

#### test Acc: 0, NDCG: 0.5491898436994164 HIT: 0.6618713301417689

#### val Acc: 0, NDCG: 0.7331440291516815 HIT: 0.7991017112780364
Epoch: 480, plus 0 steps train_loss: 0.6689

#### test Acc: 0, NDCG: 0.5455158033271994 HIT: 0.6697987198476513

#### val Acc: 0, NDCG: 0.7193303644888377 HIT: 0.7892038391345747
Epoch: 512, plus 0 steps train_loss: 0.6593

#### test Acc: 0, NDCG: 0.5212122367483484 HIT: 0.6414036050571308

#### val Acc: 0, NDCG: 0.7029066481780408 HIT: 0.7758898579665678
Epoch: 544, plus 0 steps train_loss: 0.6679

#### test Acc: 0, NDCG: 0.4853047776085198 HIT: 0.6244726645154465

#### val Acc: 0, NDCG: 0.6956769237407374 HIT: 0.7739119366271688
Epoch: 576, plus 0 steps train_loss: 0.6585

#### test Acc: 0, NDCG: 0.48251301287806236 HIT: 0.6213706424566229

#### val Acc: 0, NDCG: 0.6809416997833427 HIT: 0.7602706437790944
Epoch: 608, plus 0 steps train_loss: 0.656

#### test Acc: 0, NDCG: 0.44794553398480536 HIT: 0.5996259058929327

#### val Acc: 0, NDCG: 0.6498147459934073 HIT: 0.738449038563267
Epoch: 640, plus 0 steps train_loss: 0.6407

#### test Acc: 0, NDCG: 0.2160747613322116 HIT: 0.4191854237198477

#### val Acc: 0, NDCG: 0.5153070414649092 HIT: 0.6287541657850191
Epoch: 704, plus 0 steps train_loss: 0.6307

#### test Acc: 0, NDCG: 0.22943967646700034 HIT: 0.43475504522852304

#### val Acc: 0, NDCG: 0.530033538525772 HIT: 0.6481399439272112
Epoch: 768, plus 0 steps train_loss: 0.6057

#### test Acc: 0, NDCG: 0.235441823031949 HIT: 0.4342111788510368

#### val Acc: 0, NDCG: 0.5289820309631499 HIT: 0.6449172463499789
Epoch: 832, plus 0 steps train_loss: 0.5885

#### test Acc: 0, NDCG: 0.2402338513145263 HIT: 0.44488848259627595

#### val Acc: 0, NDCG: 0.5436618433866617 HIT: 0.6603777639652983
Epoch: 896, plus 0 steps train_loss: 0.5798

#### test Acc: 0, NDCG: 0.24876290437081555 HIT: 0.4589430477676682

#### val Acc: 0, NDCG: 0.5404360228514986 HIT: 0.6564772997778248
Epoch: 960, plus 0 steps train_loss: 0.57

#### test Acc: 0, NDCG: 0.2409059230704638 HIT: 0.4447562354528142

#### val Acc: 0, NDCG: 0.5345784732949109 HIT: 0.6524578131612356
Epoch: 1017, plus 0 steps train_loss: 0.5881
Done: it took 139203.74193811417
max value of NDCG: 0.6732342541486944
max value of HIT: 0.7708636399703765

After 20 validations
max value of NDCG: 0.6732342541486944
max value of HIT: 0.7708636399703765
