 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	0.0001
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	rotatory
position_concatenation: 	True
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11889541
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.11597578949411946 HIT: 0.25431456305543804

#### val Acc: 0, NDCG: 0.4734321714932214 HIT: 0.5635695487727466
Epoch: 1, plus 0 steps train_loss: 0.754

#### test Acc: 0, NDCG: 0.12434743435567425 HIT: 0.26998750264494287

#### val Acc: 0, NDCG: 0.4704488592830231 HIT: 0.5631174288510369
Epoch: 2, plus 0 steps train_loss: 0.7654

#### test Acc: 0, NDCG: 0.11772152171365724 HIT: 0.2698610413140076

#### val Acc: 0, NDCG: 0.4821827299661788 HIT: 0.5714547847016505
Epoch: 3, plus 0 steps train_loss: 0.7485

#### test Acc: 0, NDCG: 0.13152025351373003 HIT: 0.2888715681866272

#### val Acc: 0, NDCG: 0.46505032405029234 HIT: 0.5560653499259416
Epoch: 4, plus 0 steps train_loss: 0.7581

#### test Acc: 0, NDCG: 0.13167841161668975 HIT: 0.2886302171498096

#### val Acc: 0, NDCG: 0.4837608621286686 HIT: 0.5733219490584004
Epoch: 5, plus 0 steps train_loss: 0.7523

#### test Acc: 0, NDCG: 0.12785609193532393 HIT: 0.28719037637537026

#### val Acc: 0, NDCG: 0.47993775220219503 HIT: 0.5707654464663563
Epoch: 6, plus 0 steps train_loss: 0.7484

#### test Acc: 0, NDCG: 0.13241466127257687 HIT: 0.29202731564748197

#### val Acc: 0, NDCG: 0.47243720143568013 HIT: 0.5686726354210749
Epoch: 7, plus 0 steps train_loss: 0.7515

#### test Acc: 0, NDCG: 0.1308618951649326 HIT: 0.287456523751587

#### val Acc: 0, NDCG: 0.47349980493504823 HIT: 0.5619362965509945
Epoch: 8, plus 0 steps train_loss: 0.7572

#### test Acc: 0, NDCG: 0.14020447613660747 HIT: 0.29553517112780364

#### val Acc: 0, NDCG: 0.48640418496576043 HIT: 0.5859176629284808
Epoch: 9, plus 0 steps train_loss: 0.7434

#### test Acc: 0, NDCG: 0.13038589692528826 HIT: 0.28430656210325855

#### val Acc: 0, NDCG: 0.46651244649057794 HIT: 0.5595789912187897
Epoch: 10, plus 0 steps train_loss: 0.7409

#### test Acc: 0, NDCG: 0.13062572296968497 HIT: 0.290135354951333

#### val Acc: 0, NDCG: 0.4882793335724846 HIT: 0.5894313042213288
Epoch: 12, plus 0 steps train_loss: 0.7398

#### test Acc: 0, NDCG: 0.13288868998149037 HIT: 0.2934423600825222

#### val Acc: 0, NDCG: 0.48497436612610345 HIT: 0.578045651713923
Epoch: 14, plus 0 steps train_loss: 0.745

#### test Acc: 0, NDCG: 0.14092442723685486 HIT: 0.3070414991536183

#### val Acc: 0, NDCG: 0.4811289550224748 HIT: 0.5749494154676259
Epoch: 16, plus 0 steps train_loss: 0.7377

#### test Acc: 0, NDCG: 0.13689553413222966 HIT: 0.30212025232754974

#### val Acc: 0, NDCG: 0.4780805817865132 HIT: 0.5722168588658485
Epoch: 18, plus 0 steps train_loss: 0.7295

#### test Acc: 0, NDCG: 0.12933530415250524 HIT: 0.28641673058611933

#### val Acc: 0, NDCG: 0.48622753928569235 HIT: 0.5856399439272112
Epoch: 20, plus 0 steps train_loss: 0.7377

#### test Acc: 0, NDCG: 0.12149562396777058 HIT: 0.27410038880660176

#### val Acc: 0, NDCG: 0.4946865805527041 HIT: 0.5928416274333475
Epoch: 22, plus 0 steps train_loss: 0.7252

#### test Acc: 0, NDCG: 0.13098167679850944 HIT: 0.2882723233178163

#### val Acc: 0, NDCG: 0.46842500392557634 HIT: 0.5530302779834956
Epoch: 24, plus 0 steps train_loss: 0.7285

#### test Acc: 0, NDCG: 0.13162574205884253 HIT: 0.2836345813055438

#### val Acc: 0, NDCG: 0.4731133342881996 HIT: 0.5628744247249259
Epoch: 26, plus 0 steps train_loss: 0.7261

#### test Acc: 0, NDCG: 0.12186495717094444 HIT: 0.27198856723444775

#### val Acc: 0, NDCG: 0.46802743968816374 HIT: 0.5544626798561151
Epoch: 28, plus 0 steps train_loss: 0.7212

#### test Acc: 0, NDCG: 0.12833879256469075 HIT: 0.2869605969636056

#### val Acc: 0, NDCG: 0.4777043947950735 HIT: 0.5728334611722387
Epoch: 30, plus 0 steps train_loss: 0.7214

#### test Acc: 0, NDCG: 0.14023047779650522 HIT: 0.3046230295175624

#### val Acc: 0, NDCG: 0.4934581952306984 HIT: 0.5878228483389759
Epoch: 32, plus 0 steps train_loss: 0.7278

#### test Acc: 0, NDCG: 0.2496115447089388 HIT: 0.3961347466144731

#### val Acc: 0, NDCG: 0.5641273068681492 HIT: 0.6606918509310199
Epoch: 36, plus 0 steps train_loss: 0.7229

#### test Acc: 0, NDCG: 0.12885339039922258 HIT: 0.2793109262589928

#### val Acc: 0, NDCG: 0.47103674621230773 HIT: 0.5550677105374524
Epoch: 40, plus 0 steps train_loss: 0.7192

#### test Acc: 0, NDCG: 0.1535774505228586 HIT: 0.3059173984341938

#### val Acc: 0, NDCG: 0.4844331536342674 HIT: 0.5788920334320778
Epoch: 44, plus 0 steps train_loss: 0.7091

#### test Acc: 0, NDCG: 0.3703538402260928 HIT: 0.5132420717837495

#### val Acc: 0, NDCG: 0.6368266422035279 HIT: 0.7205551735082523
Epoch: 48, plus 0 steps train_loss: 0.7111

#### test Acc: 0, NDCG: 0.45557155763653095 HIT: 0.5850291274333475

#### val Acc: 0, NDCG: 0.6802700975509 HIT: 0.7571206821307659
Epoch: 52, plus 0 steps train_loss: 0.7133

#### test Acc: 0, NDCG: 0.2625613369346831 HIT: 0.4041117289991536

#### val Acc: 0, NDCG: 0.5557906513628538 HIT: 0.652928943609818
Epoch: 56, plus 0 steps train_loss: 0.7102

#### test Acc: 0, NDCG: 0.38397394114207967 HIT: 0.5272586159013964

#### val Acc: 0, NDCG: 0.6458751179770035 HIT: 0.7323408736246297
Epoch: 60, plus 0 steps train_loss: 0.7117

#### test Acc: 0, NDCG: 0.4994882119753547 HIT: 0.6285475296233601

#### val Acc: 0, NDCG: 0.696517583192396 HIT: 0.7756716501798562
Epoch: 64, plus 0 steps train_loss: 0.709

#### test Acc: 0, NDCG: 0.5024627127392709 HIT: 0.6250644704824376

#### val Acc: 0, NDCG: 0.7167689868057407 HIT: 0.7858662518514601
Epoch: 68, plus 0 steps train_loss: 0.7107

#### test Acc: 0, NDCG: 0.2709812699624004 HIT: 0.42659209029834955

#### val Acc: 0, NDCG: 0.5573290892705554 HIT: 0.6464587521159543
Epoch: 72, plus 0 steps train_loss: 0.7067

#### test Acc: 0, NDCG: 0.3026864401490861 HIT: 0.443155218472281

#### val Acc: 0, NDCG: 0.5808495347566509 HIT: 0.6678761769995768
Epoch: 80, plus 0 steps train_loss: 0.712

#### test Acc: 0, NDCG: 0.4086642494741264 HIT: 0.5391534199111299

#### val Acc: 0, NDCG: 0.6453684097109048 HIT: 0.722665341991113
Epoch: 88, plus 0 steps train_loss: 0.7064

#### test Acc: 0, NDCG: 0.5508066293624989 HIT: 0.6598033154358866

#### val Acc: 0, NDCG: 0.73345210323764 HIT: 0.8053305517350825
Epoch: 96, plus 0 steps train_loss: 0.7066

#### test Acc: 0, NDCG: 0.5483966423832406 HIT: 0.6677001229898434

#### val Acc: 0, NDCG: 0.7291384904943945 HIT: 0.8035476949322895
Epoch: 104, plus 0 steps train_loss: 0.7108

#### test Acc: 0, NDCG: 0.5850125695469334 HIT: 0.6967614327655522

#### val Acc: 0, NDCG: 0.7440441761205306 HIT: 0.8065637563478629
Epoch: 112, plus 0 steps train_loss: 0.7034

#### test Acc: 0, NDCG: 0.5429248270597745 HIT: 0.6550506837177317

#### val Acc: 0, NDCG: 0.7338678814369033 HIT: 0.8080879046762589
Epoch: 120, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.5708531503129526 HIT: 0.6870801153195091

#### val Acc: 0, NDCG: 0.7465936879122261 HIT: 0.8105733244286923
Epoch: 128, plus 0 steps train_loss: 0.7026

#### test Acc: 0, NDCG: 0.5451873706487026 HIT: 0.6686861907532797

#### val Acc: 0, NDCG: 0.7222901786836453 HIT: 0.7920454996297079
Epoch: 136, plus 0 steps train_loss: 0.7021

#### test Acc: 0, NDCG: 0.566708553606641 HIT: 0.6838995715192552

#### val Acc: 0, NDCG: 0.7397772746329183 HIT: 0.8086449957680915
Epoch: 144, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.6086789178755352 HIT: 0.7149140062949639

#### val Acc: 0, NDCG: 0.7516658440282366 HIT: 0.8093574772534913
Epoch: 160, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.5858957671727982 HIT: 0.6934296312949639

#### val Acc: 0, NDCG: 0.7693767201686295 HIT: 0.8344455869128227
Epoch: 176, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.5808102171967109 HIT: 0.6908351076491748

#### val Acc: 0, NDCG: 0.7608957579620107 HIT: 0.8235674328184511
Epoch: 192, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.5366069936535834 HIT: 0.6554011386479052

#### val Acc: 0, NDCG: 0.7387708930402577 HIT: 0.8089285005818875
Epoch: 208, plus 0 steps train_loss: 0.7002

#### test Acc: 0, NDCG: 0.5891422831233193 HIT: 0.6907640248095641

#### val Acc: 0, NDCG: 0.7395648792449673 HIT: 0.8105005884997883
Epoch: 224, plus 0 steps train_loss: 0.7

#### test Acc: 0, NDCG: 0.567601936900243 HIT: 0.679769327920017

#### val Acc: 0, NDCG: 0.7537505926776936 HIT: 0.8188032294752433
Epoch: 240, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.6012808731828069 HIT: 0.7093323502962336

#### val Acc: 0, NDCG: 0.7637411796090836 HIT: 0.8275100507829031
Epoch: 256, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.5927987444843348 HIT: 0.7085892866589082

#### val Acc: 0, NDCG: 0.7568061074249791 HIT: 0.8188090152877698
Epoch: 272, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.6012184919933062 HIT: 0.7088422093207787

#### val Acc: 0, NDCG: 0.7485539265451859 HIT: 0.8093037518514601
Epoch: 288, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.6001368027650799 HIT: 0.7045491364261531

#### val Acc: 0, NDCG: 0.7567633531257104 HIT: 0.8210762272534913
Epoch: 304, plus 0 steps train_loss: 0.6984

#### test Acc: 0, NDCG: 0.5965186845373446 HIT: 0.7002924314959796

#### val Acc: 0, NDCG: 0.7588959998374538 HIT: 0.8219895590880236
Epoch: 320, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.5938937845699892 HIT: 0.7013206530363945

#### val Acc: 0, NDCG: 0.7780447923597098 HIT: 0.839646205829454
Epoch: 352, plus 0 steps train_loss: 0.7

#### test Acc: 0, NDCG: 0.569549996083703 HIT: 0.6796908061785866

#### val Acc: 0, NDCG: 0.7479077334157656 HIT: 0.815507795969107
Epoch: 384, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.6165949065212031 HIT: 0.7254532770842149

#### val Acc: 0, NDCG: 0.7649713467968358 HIT: 0.8278067803110453
Epoch: 416, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.6121650491798838 HIT: 0.7171390644837071

#### val Acc: 0, NDCG: 0.7548467229559525 HIT: 0.8166566930279306
Epoch: 448, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.6152335411673933 HIT: 0.722556238097757

#### val Acc: 0, NDCG: 0.7686854576749895 HIT: 0.8353283365954296
Epoch: 480, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.3980540903196234 HIT: 0.5263585087812103

#### val Acc: 0, NDCG: 0.6326083975553798 HIT: 0.7106151475878121
Epoch: 512, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.4866257163462669 HIT: 0.6101957588341091

#### val Acc: 0, NDCG: 0.6888529860102095 HIT: 0.7666011492276766
Epoch: 544, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.5952202327721019 HIT: 0.7004131070143885

#### val Acc: 0, NDCG: 0.7533341288804355 HIT: 0.8199389018197207
Epoch: 576, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.6128524149031552 HIT: 0.7203022508463817

#### val Acc: 0, NDCG: 0.7531069990374902 HIT: 0.8181560450169276
Epoch: 608, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.5983771674623072 HIT: 0.7026861047926365

#### val Acc: 0, NDCG: 0.7522696097297386 HIT: 0.8141712732754973
Epoch: 640, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.6178325375695406 HIT: 0.716449726248413

#### val Acc: 0, NDCG: 0.7638288696124418 HIT: 0.8299227346064325
Epoch: 704, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.6084480378233746 HIT: 0.7214263515658061

#### val Acc: 0, NDCG: 0.75718021787582 HIT: 0.8203811032056707
Epoch: 768, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.6159279141897028 HIT: 0.7171084823317817

#### val Acc: 0, NDCG: 0.7510746005557496 HIT: 0.8104890168747355
Epoch: 832, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.5833109062403928 HIT: 0.6965605824164198

#### val Acc: 0, NDCG: 0.7649507738626593 HIT: 0.8266884654041472
Epoch: 896, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.619128239507047 HIT: 0.7272377869763013

#### val Acc: 0, NDCG: 0.7643158348478083 HIT: 0.8302979858760051
Epoch: 960, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.5945843510651176 HIT: 0.699633675412611

#### val Acc: 0, NDCG: 0.764767596395252 HIT: 0.8315138330512061
Epoch: 1017, plus 0 steps train_loss: 0.6982
Done: it took 88757.6020822525
max value of NDCG: 0.619128239507047
max value of HIT: 0.7272377869763013

After 20 validations
max value of NDCG: 0.619128239507047
max value of HIT: 0.7272377869763013
