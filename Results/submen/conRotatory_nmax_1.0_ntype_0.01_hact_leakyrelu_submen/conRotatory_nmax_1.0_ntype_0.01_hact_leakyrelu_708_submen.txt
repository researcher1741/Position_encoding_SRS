 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.01
max_norm:             	1.0
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	rotatory
position_concatenation: 	True
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11889541
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12900723436374703 HIT: 0.28323618678586543

#### val Acc: 0, NDCG: 0.495261531708935 HIT: 0.5883857252433348
Epoch: 1, plus 0 steps train_loss: 0.7576

#### test Acc: 0, NDCG: 0.1288812756333747 HIT: 0.2826923204083792

#### val Acc: 0, NDCG: 0.49096769486391784 HIT: 0.5871392959162083
Epoch: 2, plus 0 steps train_loss: 0.7556

#### test Acc: 0, NDCG: 0.1263775355182053 HIT: 0.2775528657955988

#### val Acc: 0, NDCG: 0.4887370572679528 HIT: 0.5868921590668642
Epoch: 3, plus 0 steps train_loss: 0.7573

#### test Acc: 0, NDCG: 0.1333985273771282 HIT: 0.28755984183241645

#### val Acc: 0, NDCG: 0.4811239043921701 HIT: 0.5740493083474396
Epoch: 4, plus 0 steps train_loss: 0.7506

#### test Acc: 0, NDCG: 0.12737526029310858 HIT: 0.2730531567393144

#### val Acc: 0, NDCG: 0.48111083900312873 HIT: 0.5807302687261955
Epoch: 5, plus 0 steps train_loss: 0.7498

#### test Acc: 0, NDCG: 0.12549468865991975 HIT: 0.2702172820567076

#### val Acc: 0, NDCG: 0.47710928361714494 HIT: 0.5724102703131612
Epoch: 6, plus 0 steps train_loss: 0.7583

#### test Acc: 0, NDCG: 0.12160378251730215 HIT: 0.2631056919170546

#### val Acc: 0, NDCG: 0.48846673714671324 HIT: 0.5841711740901396
Epoch: 7, plus 0 steps train_loss: 0.7408

#### test Acc: 0, NDCG: 0.12047077964907826 HIT: 0.2617575975983919

#### val Acc: 0, NDCG: 0.49207076711694275 HIT: 0.5867524730215827
Epoch: 8, plus 0 steps train_loss: 0.7351

#### test Acc: 0, NDCG: 0.13226480730774093 HIT: 0.2821773830935252

#### val Acc: 0, NDCG: 0.48293405004168705 HIT: 0.5841042239737622
Epoch: 9, plus 0 steps train_loss: 0.7511

#### test Acc: 0, NDCG: 0.12007793616734373 HIT: 0.2693403181866272

#### val Acc: 0, NDCG: 0.47728511139114527 HIT: 0.5730996085484553
Epoch: 10, plus 0 steps train_loss: 0.7475

#### test Acc: 0, NDCG: 0.12671890660050114 HIT: 0.2753393792319086

#### val Acc: 0, NDCG: 0.4899982227124672 HIT: 0.5844794752433348
Epoch: 12, plus 0 steps train_loss: 0.7373

#### test Acc: 0, NDCG: 0.13791970944776988 HIT: 0.299175273751587

#### val Acc: 0, NDCG: 0.47568239127682355 HIT: 0.5629471606538299
Epoch: 14, plus 0 steps train_loss: 0.7422

#### test Acc: 0, NDCG: 0.131496188420313 HIT: 0.282359222915785

#### val Acc: 0, NDCG: 0.4840970633598425 HIT: 0.578365524492171
Epoch: 16, plus 0 steps train_loss: 0.7543

#### test Acc: 0, NDCG: 0.1261332276240815 HIT: 0.2810417107490478

#### val Acc: 0, NDCG: 0.4820578495340844 HIT: 0.5759776370080406
Epoch: 18, plus 0 steps train_loss: 0.7386

#### test Acc: 0, NDCG: 0.1214940260076635 HIT: 0.2724001864684723

#### val Acc: 0, NDCG: 0.47884529956407335 HIT: 0.5727722968683876
Epoch: 20, plus 0 steps train_loss: 0.7337

#### test Acc: 0, NDCG: 0.12543868480502438 HIT: 0.2781140896106644

#### val Acc: 0, NDCG: 0.48499128838295225 HIT: 0.5862086066440966
Epoch: 22, plus 0 steps train_loss: 0.7302

#### test Acc: 0, NDCG: 0.12604951949418092 HIT: 0.2771891861510791

#### val Acc: 0, NDCG: 0.47843509801016865 HIT: 0.5830338486563691
Epoch: 24, plus 0 steps train_loss: 0.7351

#### test Acc: 0, NDCG: 0.12973057181858982 HIT: 0.28893107940118495

#### val Acc: 0, NDCG: 0.48686334137585646 HIT: 0.5792614988891239
Epoch: 26, plus 0 steps train_loss: 0.7302

#### test Acc: 0, NDCG: 0.12752076932743947 HIT: 0.278071935833686

#### val Acc: 0, NDCG: 0.48212613900222023 HIT: 0.5741278300888701
Epoch: 28, plus 0 steps train_loss: 0.7326

#### test Acc: 0, NDCG: 0.1286114254466509 HIT: 0.27712802184722807

#### val Acc: 0, NDCG: 0.4807862826244358 HIT: 0.5802955062420652
Epoch: 30, plus 0 steps train_loss: 0.7347

#### test Acc: 0, NDCG: 0.11794663210782745 HIT: 0.260627711066441

#### val Acc: 0, NDCG: 0.4733769058708566 HIT: 0.5633397693609818
Epoch: 32, plus 0 steps train_loss: 0.73

#### test Acc: 0, NDCG: 0.1251132776182556 HIT: 0.2720555173508252

#### val Acc: 0, NDCG: 0.48354517404003566 HIT: 0.5770174301735083
Epoch: 36, plus 0 steps train_loss: 0.7227

#### test Acc: 0, NDCG: 0.12530851015645883 HIT: 0.27331351830300465

#### val Acc: 0, NDCG: 0.47764186257850355 HIT: 0.5678932038192975
Epoch: 40, plus 0 steps train_loss: 0.7278

#### test Acc: 0, NDCG: 0.1266331513779581 HIT: 0.2788819495873889

#### val Acc: 0, NDCG: 0.4733435155511186 HIT: 0.5617428851036818
Epoch: 44, plus 0 steps train_loss: 0.7225

#### test Acc: 0, NDCG: 0.12935077580251625 HIT: 0.2746078872196361

#### val Acc: 0, NDCG: 0.474002013589081 HIT: 0.5731359765129074
Epoch: 48, plus 0 steps train_loss: 0.7173

#### test Acc: 0, NDCG: 0.12963004893360466 HIT: 0.2817657638595006

#### val Acc: 0, NDCG: 0.4794859883956345 HIT: 0.577628246667372
Epoch: 52, plus 0 steps train_loss: 0.7192

#### test Acc: 0, NDCG: 0.1327156180726902 HIT: 0.29357626031527717

#### val Acc: 0, NDCG: 0.4754245028909079 HIT: 0.5669567287346593
Epoch: 56, plus 0 steps train_loss: 0.7202

#### test Acc: 0, NDCG: 0.139644884238734 HIT: 0.3059595522111722

#### val Acc: 0, NDCG: 0.4756242363769144 HIT: 0.571793668006771
Epoch: 60, plus 0 steps train_loss: 0.7219

#### test Acc: 0, NDCG: 0.1379051609702173 HIT: 0.2997017826914939

#### val Acc: 0, NDCG: 0.47843288534840944 HIT: 0.5718531792213288
Epoch: 64, plus 0 steps train_loss: 0.7101

#### test Acc: 0, NDCG: 0.1346840398030215 HIT: 0.2886897283643673

#### val Acc: 0, NDCG: 0.48554302144363204 HIT: 0.5823387246085484
Epoch: 68, plus 0 steps train_loss: 0.7074

#### test Acc: 0, NDCG: 0.13296847326029107 HIT: 0.28932534119763015

#### val Acc: 0, NDCG: 0.48051611580378467 HIT: 0.570367051946678
Epoch: 72, plus 0 steps train_loss: 0.7172

#### test Acc: 0, NDCG: 0.13608269288988084 HIT: 0.2907883252221752

#### val Acc: 0, NDCG: 0.4842442595810977 HIT: 0.5782506347862887
Epoch: 80, plus 0 steps train_loss: 0.7114

#### test Acc: 0, NDCG: 0.14530613016290572 HIT: 0.29962904676258995

#### val Acc: 0, NDCG: 0.49166508319517277 HIT: 0.5838438624100719
Epoch: 88, plus 0 steps train_loss: 0.7071

#### test Acc: 0, NDCG: 0.2663105179368663 HIT: 0.4162941705459162

#### val Acc: 0, NDCG: 0.5636254540130268 HIT: 0.6527892575645365
Epoch: 96, plus 0 steps train_loss: 0.703

#### test Acc: 0, NDCG: 0.36463766828560257 HIT: 0.5054907360876005

#### val Acc: 0, NDCG: 0.6270248099561484 HIT: 0.7147511769995768
Epoch: 104, plus 0 steps train_loss: 0.7074

#### test Acc: 0, NDCG: 0.2628939756632006 HIT: 0.41085798640499366

#### val Acc: 0, NDCG: 0.5712653958867755 HIT: 0.6600388806601777
Epoch: 112, plus 0 steps train_loss: 0.7096

#### test Acc: 0, NDCG: 0.27438323912873797 HIT: 0.423980209214981

#### val Acc: 0, NDCG: 0.5566031865354418 HIT: 0.6452908445302581
Epoch: 120, plus 0 steps train_loss: 0.709

#### test Acc: 0, NDCG: 0.26001169661910833 HIT: 0.4078898645789251

#### val Acc: 0, NDCG: 0.5658437051284996 HIT: 0.6567260897164621
Epoch: 128, plus 0 steps train_loss: 0.7032

#### test Acc: 0, NDCG: 0.283610216135843 HIT: 0.4395440449111299

#### val Acc: 0, NDCG: 0.5791633445866378 HIT: 0.6634087031845112
Epoch: 136, plus 0 steps train_loss: 0.7038

#### test Acc: 0, NDCG: 0.44676683056332567 HIT: 0.5869227412187897

#### val Acc: 0, NDCG: 0.6581539544083078 HIT: 0.7382366165890817
Epoch: 144, plus 0 steps train_loss: 0.7069

#### test Acc: 0, NDCG: 0.49225081336110355 HIT: 0.6192662597862887

#### val Acc: 0, NDCG: 0.6897136333322026 HIT: 0.7675930028036394
Epoch: 160, plus 0 steps train_loss: 0.7044

#### test Acc: 0, NDCG: 0.5339058754445889 HIT: 0.6588726261637748

#### val Acc: 0, NDCG: 0.7343064298618969 HIT: 0.8067455961701228
Epoch: 176, plus 0 steps train_loss: 0.7012

#### test Acc: 0, NDCG: 0.5608268053941359 HIT: 0.6785187658696572

#### val Acc: 0, NDCG: 0.7502099688232716 HIT: 0.8199273301946678
Epoch: 192, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.5757917308017858 HIT: 0.6907871680596699

#### val Acc: 0, NDCG: 0.7547811379177283 HIT: 0.8213308030046551
Epoch: 208, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.5832973569277747 HIT: 0.7002750740584004

#### val Acc: 0, NDCG: 0.7513548228721577 HIT: 0.8246072259839188
Epoch: 224, plus 0 steps train_loss: 0.7018

#### test Acc: 0, NDCG: 0.6192509552143296 HIT: 0.7306175280363945

#### val Acc: 0, NDCG: 0.7614210760332941 HIT: 0.8270025523698687
Epoch: 240, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.6012647752629322 HIT: 0.7135601261637748

#### val Acc: 0, NDCG: 0.7479667896875664 HIT: 0.8093095376639864
Epoch: 256, plus 0 steps train_loss: 0.7016

#### test Acc: 0, NDCG: 0.604238053146836 HIT: 0.7166373518831993

#### val Acc: 0, NDCG: 0.7694092606486086 HIT: 0.835468022640711
Epoch: 272, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.5800090154452759 HIT: 0.6925890353893356

#### val Acc: 0, NDCG: 0.7528291539725043 HIT: 0.8216333183453237
Epoch: 288, plus 0 steps train_loss: 0.6995

#### test Acc: 0, NDCG: 0.4292366845034823 HIT: 0.556180239631824

#### val Acc: 0, NDCG: 0.6456074486257845 HIT: 0.7226769136161659
Epoch: 304, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.505923791474813 HIT: 0.6277317300571308

#### val Acc: 0, NDCG: 0.6988838402305926 HIT: 0.7789670836859923
Epoch: 320, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.39489311522692183 HIT: 0.535348834902666

#### val Acc: 0, NDCG: 0.6191901738309216 HIT: 0.7050392774016081
Epoch: 352, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.5749554782447568 HIT: 0.6942933704506983

#### val Acc: 0, NDCG: 0.747191265486551 HIT: 0.8224912716885315
Epoch: 384, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.5409456676928244 HIT: 0.6586296220376641

#### val Acc: 0, NDCG: 0.722443912941687 HIT: 0.7942953541578502
Epoch: 416, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.2564007501732059 HIT: 0.39704229263647906

#### val Acc: 0, NDCG: 0.5466734331484626 HIT: 0.625131420598815
Epoch: 448, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.4909549893899233 HIT: 0.6162675558082945

#### val Acc: 0, NDCG: 0.6766377848607458 HIT: 0.7479526489102836
Epoch: 480, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.6346734636879602 HIT: 0.7345237780363945

#### val Acc: 0, NDCG: 0.7816662067832859 HIT: 0.838491522958104
Epoch: 512, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.6435487805250685 HIT: 0.742602425412611

#### val Acc: 0, NDCG: 0.7719547028358762 HIT: 0.8277646265340668
Epoch: 544, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.6493063008319901 HIT: 0.7414535283537875

#### val Acc: 0, NDCG: 0.8014138023150528 HIT: 0.8598477835378756
Epoch: 576, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.6416997219246608 HIT: 0.7364157387325434

#### val Acc: 0, NDCG: 0.779990046170263 HIT: 0.8352861828184511
Epoch: 608, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.638220222129882 HIT: 0.7357264004972492

#### val Acc: 0, NDCG: 0.7890315050606199 HIT: 0.8482265658061785
Epoch: 640, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.6267111072098335 HIT: 0.7238506070143885

#### val Acc: 0, NDCG: 0.7862283939647184 HIT: 0.84597092546551
Epoch: 704, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.626317460042583 HIT: 0.7262632908379179

#### val Acc: 0, NDCG: 0.7530185170305164 HIT: 0.8160938161235718
Epoch: 768, plus 0 steps train_loss: 0.6949

#### test Acc: 0, NDCG: 0.6001376993533343 HIT: 0.704694608283961

#### val Acc: 0, NDCG: 0.7632033284684206 HIT: 0.8209977055120609
Epoch: 832, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.6120894483028505 HIT: 0.7136444337177317

#### val Acc: 0, NDCG: 0.7644891858765316 HIT: 0.8252180424777825
Epoch: 896, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.592598113476137 HIT: 0.69939811018832

#### val Acc: 0, NDCG: 0.7526979299050955 HIT: 0.816208705829454
Epoch: 960, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.5863962915112808 HIT: 0.6961084624947101

#### val Acc: 0, NDCG: 0.7439658046461224 HIT: 0.8066555028036394
Epoch: 1017, plus 0 steps train_loss: 0.6967
Done: it took 90578.77308487892
max value of NDCG: 0.6493063008319901
max value of HIT: 0.742602425412611

After 20 validations
max value of NDCG: 0.6493063008319901
max value of HIT: 0.742602425412611
