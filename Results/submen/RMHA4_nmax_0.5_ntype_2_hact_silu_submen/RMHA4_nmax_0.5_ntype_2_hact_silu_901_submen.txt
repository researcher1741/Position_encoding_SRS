 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2
max_norm:             	0.5
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 12035791
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13003974309876037 HIT: 0.2886897283643673

#### val Acc: 0, NDCG: 0.4755762923723377 HIT: 0.5680080935251799
Epoch: 1, plus 0 steps train_loss: 0.8387

#### test Acc: 0, NDCG: 0.1339695481521097 HIT: 0.2894038629390605

#### val Acc: 0, NDCG: 0.4733888611527175 HIT: 0.5694958738891239
Epoch: 2, plus 0 steps train_loss: 0.8198

#### test Acc: 0, NDCG: 0.12597118487394257 HIT: 0.27814467176258995

#### val Acc: 0, NDCG: 0.4836128114570516 HIT: 0.5753668205141769
Epoch: 3, plus 0 steps train_loss: 0.7728

#### test Acc: 0, NDCG: 0.12688735920326666 HIT: 0.2839982609500635

#### val Acc: 0, NDCG: 0.48598100299250696 HIT: 0.5783944535548031
Epoch: 4, plus 0 steps train_loss: 0.7729

#### test Acc: 0, NDCG: 0.1293766634073833 HIT: 0.28489836807024965

#### val Acc: 0, NDCG: 0.4763058037092911 HIT: 0.5624437949640287
Epoch: 5, plus 0 steps train_loss: 0.7478

#### test Acc: 0, NDCG: 0.12421844662152175 HIT: 0.284312347915785

#### val Acc: 0, NDCG: 0.48488463941667925 HIT: 0.5867946267985612
Epoch: 6, plus 0 steps train_loss: 0.7495

#### test Acc: 0, NDCG: 0.12419148559343315 HIT: 0.2816161592784596

#### val Acc: 0, NDCG: 0.48553784697106 HIT: 0.5852109672556073
Epoch: 7, plus 0 steps train_loss: 0.7343

#### test Acc: 0, NDCG: 0.1241808038454663 HIT: 0.2833568623042742

#### val Acc: 0, NDCG: 0.47139879108637633 HIT: 0.5696107635950063
Epoch: 8, plus 0 steps train_loss: 0.7381

#### test Acc: 0, NDCG: 0.13152517078139248 HIT: 0.2896088460114261

#### val Acc: 0, NDCG: 0.4863334458705863 HIT: 0.5824478285019044
Epoch: 9, plus 0 steps train_loss: 0.7365

#### test Acc: 0, NDCG: 0.13817291893780143 HIT: 0.30388575169276344

#### val Acc: 0, NDCG: 0.4854213981293867 HIT: 0.5840314880448583
Epoch: 10, plus 0 steps train_loss: 0.7335

#### test Acc: 0, NDCG: 0.1330152776201187 HIT: 0.29396886902242914

#### val Acc: 0, NDCG: 0.4765682567453593 HIT: 0.5688123214663563
Epoch: 12, plus 0 steps train_loss: 0.7316

#### test Acc: 0, NDCG: 0.1279935876007494 HIT: 0.2813979514917478

#### val Acc: 0, NDCG: 0.4838310739904498 HIT: 0.5779059656686416
Epoch: 14, plus 0 steps train_loss: 0.7192

#### test Acc: 0, NDCG: 0.13431005443303087 HIT: 0.2996579758252222

#### val Acc: 0, NDCG: 0.47418644034085605 HIT: 0.5652623122090563
Epoch: 16, plus 0 steps train_loss: 0.7206

#### test Acc: 0, NDCG: 0.12510906761086193 HIT: 0.2837015314219213

#### val Acc: 0, NDCG: 0.4799973469534991 HIT: 0.5707042821625052
Epoch: 18, plus 0 steps train_loss: 0.7162

#### test Acc: 0, NDCG: 0.12949190782527747 HIT: 0.286719245926788

#### val Acc: 0, NDCG: 0.47654025386239385 HIT: 0.5692660944773592
Epoch: 20, plus 0 steps train_loss: 0.7174

#### test Acc: 0, NDCG: 0.1609062448427321 HIT: 0.313929095694033

#### val Acc: 0, NDCG: 0.4928224107969632 HIT: 0.5810749378438426
Epoch: 22, plus 0 steps train_loss: 0.7135

#### test Acc: 0, NDCG: 0.16827115668165585 HIT: 0.3266033313055438

#### val Acc: 0, NDCG: 0.497795200024722 HIT: 0.585343214399069
Epoch: 24, plus 0 steps train_loss: 0.7096

#### test Acc: 0, NDCG: 0.12310848217806625 HIT: 0.27834386902242914

#### val Acc: 0, NDCG: 0.4750111751290111 HIT: 0.5679585008463817
Epoch: 26, plus 0 steps train_loss: 0.7181

#### test Acc: 0, NDCG: 0.13996165925398776 HIT: 0.29824458447947527

#### val Acc: 0, NDCG: 0.49793650620040375 HIT: 0.5890560529517562
Epoch: 28, plus 0 steps train_loss: 0.7117

#### test Acc: 0, NDCG: 0.1745807880570967 HIT: 0.3356911896953026

#### val Acc: 0, NDCG: 0.49908784230322095 HIT: 0.5887725481379602
Epoch: 30, plus 0 steps train_loss: 0.7114

#### test Acc: 0, NDCG: 0.21484380564770192 HIT: 0.37107143329454084

#### val Acc: 0, NDCG: 0.5322775267183263 HIT: 0.6272779570461279
Epoch: 32, plus 0 steps train_loss: 0.7081

#### test Acc: 0, NDCG: 0.12372466329974564 HIT: 0.2765667980321625

#### val Acc: 0, NDCG: 0.4744189210424814 HIT: 0.5647242316440966
Epoch: 36, plus 0 steps train_loss: 0.7171

#### test Acc: 0, NDCG: 0.14144723651625687 HIT: 0.29500287637537026

#### val Acc: 0, NDCG: 0.4827075424722902 HIT: 0.5745931747249259
Epoch: 40, plus 0 steps train_loss: 0.7097

#### test Acc: 0, NDCG: 0.1328173947366267 HIT: 0.28683992144519677

#### val Acc: 0, NDCG: 0.4779791681485165 HIT: 0.5748229541366906
Epoch: 44, plus 0 steps train_loss: 0.709

#### test Acc: 0, NDCG: 0.17198977182598915 HIT: 0.32951772772958104

#### val Acc: 0, NDCG: 0.49887822434013224 HIT: 0.596571823423614
Epoch: 48, plus 0 steps train_loss: 0.7064

#### test Acc: 0, NDCG: 0.1385261788609175 HIT: 0.30124907426999575

#### val Acc: 0, NDCG: 0.48142070511804474 HIT: 0.5791697524333475
Epoch: 52, plus 0 steps train_loss: 0.7063

#### test Acc: 0, NDCG: 0.37253287731610873 HIT: 0.5169185423719848

#### val Acc: 0, NDCG: 0.6173282624456284 HIT: 0.7022091885315277
Epoch: 56, plus 0 steps train_loss: 0.7069

#### test Acc: 0, NDCG: 0.16385237917324483 HIT: 0.3214754483178163

#### val Acc: 0, NDCG: 0.5084860696550001 HIT: 0.6049587719530258
Epoch: 60, plus 0 steps train_loss: 0.7101

#### test Acc: 0, NDCG: 0.3597115390810227 HIT: 0.5101458355374524

#### val Acc: 0, NDCG: 0.609929673975628 HIT: 0.6958844688954718
Epoch: 64, plus 0 steps train_loss: 0.7028

#### test Acc: 0, NDCG: 0.3328803217485234 HIT: 0.47760890552264074

#### val Acc: 0, NDCG: 0.60545000585485 HIT: 0.6877636677422768
Epoch: 68, plus 0 steps train_loss: 0.7055

#### test Acc: 0, NDCG: 0.19603178673076627 HIT: 0.3509888780152349

#### val Acc: 0, NDCG: 0.5241198746458063 HIT: 0.6161873809775709
Epoch: 72, plus 0 steps train_loss: 0.7065

#### test Acc: 0, NDCG: 0.31839488615949096 HIT: 0.47286784542953875

#### val Acc: 0, NDCG: 0.5928160116994984 HIT: 0.6827085206834532
Epoch: 80, plus 0 steps train_loss: 0.706

#### test Acc: 0, NDCG: 0.31099700719507384 HIT: 0.4637378332628015

#### val Acc: 0, NDCG: 0.5790507958734361 HIT: 0.6660379417054592
Epoch: 88, plus 0 steps train_loss: 0.7033

#### test Acc: 0, NDCG: 0.40362359111173046 HIT: 0.5498555199957681

#### val Acc: 0, NDCG: 0.6355934946150749 HIT: 0.7197757419064749
Epoch: 96, plus 0 steps train_loss: 0.702

#### test Acc: 0, NDCG: 0.5212159039165277 HIT: 0.6413614512801523

#### val Acc: 0, NDCG: 0.7177217971892598 HIT: 0.7891005210537453
Epoch: 104, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.48392858855153187 HIT: 0.6144656884786288

#### val Acc: 0, NDCG: 0.6905507957893904 HIT: 0.7660209148857385
Epoch: 112, plus 0 steps train_loss: 0.6984

#### test Acc: 0, NDCG: 0.4648574444120165 HIT: 0.5964089941282268

#### val Acc: 0, NDCG: 0.6610768924788052 HIT: 0.7415378359077444
Epoch: 120, plus 0 steps train_loss: 0.7003

#### test Acc: 0, NDCG: 0.3960420808099209 HIT: 0.528934021900127

#### val Acc: 0, NDCG: 0.6298388881130729 HIT: 0.7111532281527718
Epoch: 128, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.5448327353227778 HIT: 0.6660800954824376

#### val Acc: 0, NDCG: 0.7148651169862665 HIT: 0.7837924513330512
Epoch: 136, plus 0 steps train_loss: 0.6984

#### test Acc: 0, NDCG: 0.5417055045608439 HIT: 0.6647377869763013

#### val Acc: 0, NDCG: 0.7059574365846808 HIT: 0.774528538933559
Epoch: 144, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.5486678912750245 HIT: 0.6606323397164621

#### val Acc: 0, NDCG: 0.7535824862465071 HIT: 0.8243179353575962
Epoch: 160, plus 0 steps train_loss: 0.6982

#### test Acc: 0, NDCG: 0.5708953597971191 HIT: 0.6904424989420228

#### val Acc: 0, NDCG: 0.7290737147665948 HIT: 0.8002522614261531
Epoch: 176, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.3996994318992634 HIT: 0.5426654081146848

#### val Acc: 0, NDCG: 0.6261209051563869 HIT: 0.7009511875793484
Epoch: 192, plus 0 steps train_loss: 0.6984

#### test Acc: 0, NDCG: 0.5038237552683603 HIT: 0.6307072907850191

#### val Acc: 0, NDCG: 0.7052240299396952 HIT: 0.7806424896847228
Epoch: 208, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.47017059535775957 HIT: 0.6077351354210749

#### val Acc: 0, NDCG: 0.6877324127122261 HIT: 0.761346804909014
Epoch: 224, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.44159384403056023 HIT: 0.5813584426576386

#### val Acc: 0, NDCG: 0.6586961648077055 HIT: 0.7366761002962336
Epoch: 240, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.5959857813581062 HIT: 0.7096960299407533

#### val Acc: 0, NDCG: 0.7398385769571943 HIT: 0.8117470178269149
Epoch: 256, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.5837442019610125 HIT: 0.691821175412611

#### val Acc: 0, NDCG: 0.7477829307080306 HIT: 0.8088441930279306
Epoch: 272, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.5928315860668771 HIT: 0.7039267483072366

#### val Acc: 0, NDCG: 0.7590184197965595 HIT: 0.8214630501481168
Epoch: 288, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.4893692592311674 HIT: 0.6194290890816758

#### val Acc: 0, NDCG: 0.6972204663153296 HIT: 0.7731804446148963
Epoch: 304, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.5250119646577444 HIT: 0.6401513899174778

#### val Acc: 0, NDCG: 0.7226310714366161 HIT: 0.795595508887008
Epoch: 320, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.5955913044413557 HIT: 0.7062972783537875

#### val Acc: 0, NDCG: 0.7585354691997673 HIT: 0.8220201412399492
Epoch: 352, plus 0 steps train_loss: 0.6933

#### test Acc: 0, NDCG: 0.6126565580713603 HIT: 0.7152165216356327

#### val Acc: 0, NDCG: 0.7758933133693272 HIT: 0.8405347413245874
Epoch: 384, plus 0 steps train_loss: 0.6877

#### test Acc: 0, NDCG: 0.5590559595870974 HIT: 0.6697392086330936

#### val Acc: 0, NDCG: 0.7438715408280824 HIT: 0.8104700063478629
Epoch: 416, plus 0 steps train_loss: 0.6808

#### test Acc: 0, NDCG: 0.4928627600536668 HIT: 0.615758404305967

#### val Acc: 0, NDCG: 0.7060893247985334 HIT: 0.7825286645683454
Epoch: 448, plus 0 steps train_loss: 0.6749

#### test Acc: 0, NDCG: 0.49740955754272254 HIT: 0.6293038179750318

#### val Acc: 0, NDCG: 0.7069724192982945 HIT: 0.7840585987092679
Epoch: 480, plus 0 steps train_loss: 0.6569

#### test Acc: 0, NDCG: 0.44271942120131413 HIT: 0.5817469186415574

#### val Acc: 0, NDCG: 0.6733693172987316 HIT: 0.7591275325327973
Epoch: 512, plus 0 steps train_loss: 0.6445

#### test Acc: 0, NDCG: 0.23531998347235603 HIT: 0.44134012642826914

#### val Acc: 0, NDCG: 0.5372590774985113 HIT: 0.6472133873783326
Epoch: 544, plus 0 steps train_loss: 0.613

#### test Acc: 0, NDCG: 0.2536536211304329 HIT: 0.4533250238044858

#### val Acc: 0, NDCG: 0.5464014351472817 HIT: 0.6519850296233601
Epoch: 576, plus 0 steps train_loss: 0.597

#### test Acc: 0, NDCG: 0.25998073416764994 HIT: 0.45994068715615744

#### val Acc: 0, NDCG: 0.5468791097923272 HIT: 0.6599851552581464
Epoch: 608, plus 0 steps train_loss: 0.5988

#### test Acc: 0, NDCG: 0.26681773664042013 HIT: 0.4716230691917055

#### val Acc: 0, NDCG: 0.5584050973842809 HIT: 0.6626755580829454
Epoch: 640, plus 0 steps train_loss: 0.6017

#### test Acc: 0, NDCG: 0.2730995540026942 HIT: 0.4760789713817181

#### val Acc: 0, NDCG: 0.5543103723006332 HIT: 0.6657469979898434
Epoch: 704, plus 0 steps train_loss: 0.5776

#### test Acc: 0, NDCG: 0.26890248407099077 HIT: 0.46936164303851036

#### val Acc: 0, NDCG: 0.5544410814683393 HIT: 0.6675067115425306
Epoch: 768, plus 0 steps train_loss: 0.5608

#### test Acc: 0, NDCG: 0.27056500719836346 HIT: 0.46912442472492594

#### val Acc: 0, NDCG: 0.5506880989884736 HIT: 0.6557706041049514
Epoch: 832, plus 0 steps train_loss: 0.5477

#### test Acc: 0, NDCG: 0.27300783204831697 HIT: 0.47822550782903095

#### val Acc: 0, NDCG: 0.5513558891764956 HIT: 0.6671752671392298
Epoch: 896, plus 0 steps train_loss: 0.588

#### test Acc: 0, NDCG: 0.2713577200811592 HIT: 0.4724140724185357

#### val Acc: 0, NDCG: 0.5543654657316273 HIT: 0.6614001996931866
Epoch: 960, plus 0 steps train_loss: 0.5502

#### test Acc: 0, NDCG: 0.26696532831583103 HIT: 0.46505699851883203

#### val Acc: 0, NDCG: 0.5615519543740779 HIT: 0.6697813624100719
Epoch: 1017, plus 0 steps train_loss: 0.5747
Done: it took 139789.3155283928
max value of NDCG: 0.6126565580713603
max value of HIT: 0.7152165216356327

After 20 validations
max value of NDCG: 0.6126565580713603
max value of HIT: 0.7152165216356327
