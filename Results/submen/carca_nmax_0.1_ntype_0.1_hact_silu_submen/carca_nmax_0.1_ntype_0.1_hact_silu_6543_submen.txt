 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	0.1
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11571301
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12914554269239212 HIT: 0.2830121931866272

#### val Acc: 0, NDCG: 0.48679928582116894 HIT: 0.5817279081146848
Epoch: 1, plus 0 steps train_loss: 0.7748

#### test Acc: 0, NDCG: 0.13234100908192326 HIT: 0.285884435833686

#### val Acc: 0, NDCG: 0.4770636422263271 HIT: 0.5708323965827338
Epoch: 2, plus 0 steps train_loss: 0.7911

#### test Acc: 0, NDCG: 0.13413667891154843 HIT: 0.2934671564219213

#### val Acc: 0, NDCG: 0.48063125751549096 HIT: 0.5761710484553533
Epoch: 3, plus 0 steps train_loss: 0.7777

#### test Acc: 0, NDCG: 0.12878299171394197 HIT: 0.28243195884468897

#### val Acc: 0, NDCG: 0.4824249090622023 HIT: 0.5776761862568769
Epoch: 4, plus 0 steps train_loss: 0.7874

#### test Acc: 0, NDCG: 0.13156448410456495 HIT: 0.2841610902454507

#### val Acc: 0, NDCG: 0.4947981039806597 HIT: 0.5879914634468895
Epoch: 5, plus 0 steps train_loss: 0.778

#### test Acc: 0, NDCG: 0.1345316548618647 HIT: 0.2896336423508252

#### val Acc: 0, NDCG: 0.4728216395968616 HIT: 0.5706084029834956
Epoch: 6, plus 0 steps train_loss: 0.7698

#### test Acc: 0, NDCG: 0.13597643637592802 HIT: 0.29393250105797714

#### val Acc: 0, NDCG: 0.47745651209365425 HIT: 0.5731359765129074
Epoch: 7, plus 0 steps train_loss: 0.7769

#### test Acc: 0, NDCG: 0.1333313950391267 HIT: 0.2951177660812526

#### val Acc: 0, NDCG: 0.4792106292242656 HIT: 0.5741757696783749
Epoch: 8, plus 0 steps train_loss: 0.7795

#### test Acc: 0, NDCG: 0.13783471856418372 HIT: 0.30144827152983494

#### val Acc: 0, NDCG: 0.47629636689034766 HIT: 0.5656623598180279
Epoch: 9, plus 0 steps train_loss: 0.7724

#### test Acc: 0, NDCG: 0.12763403074874255 HIT: 0.2865737740689801

#### val Acc: 0, NDCG: 0.48703702059571574 HIT: 0.5818064298561151
Epoch: 10, plus 0 steps train_loss: 0.7633

#### test Acc: 0, NDCG: 0.1332025884501188 HIT: 0.2940895445408379

#### val Acc: 0, NDCG: 0.4750090534227529 HIT: 0.5715085101036818
Epoch: 12, plus 0 steps train_loss: 0.7708

#### test Acc: 0, NDCG: 0.13249150197222803 HIT: 0.2828973034807448

#### val Acc: 0, NDCG: 0.4827219857889728 HIT: 0.5758321651502327
Epoch: 14, plus 0 steps train_loss: 0.7633

#### test Acc: 0, NDCG: 0.13368816472433526 HIT: 0.2922281659966145

#### val Acc: 0, NDCG: 0.4835578403818635 HIT: 0.5833421498095641
Epoch: 16, plus 0 steps train_loss: 0.7622

#### test Acc: 0, NDCG: 0.1351221185804531 HIT: 0.29306132300042315

#### val Acc: 0, NDCG: 0.46882123123381325 HIT: 0.5597302488891239
Epoch: 18, plus 0 steps train_loss: 0.7657

#### test Acc: 0, NDCG: 0.13346631380645266 HIT: 0.2933886346804909

#### val Acc: 0, NDCG: 0.4830085201956178 HIT: 0.5829801232543377
Epoch: 20, plus 0 steps train_loss: 0.7412

#### test Acc: 0, NDCG: 0.13353666112418844 HIT: 0.29236619895260263

#### val Acc: 0, NDCG: 0.4686934681072642 HIT: 0.5661144797397376
Epoch: 22, plus 0 steps train_loss: 0.7553

#### test Acc: 0, NDCG: 0.13461301635722545 HIT: 0.29016593710325855

#### val Acc: 0, NDCG: 0.47966853032831896 HIT: 0.5761346804909014
Epoch: 24, plus 0 steps train_loss: 0.7478

#### test Acc: 0, NDCG: 0.13440576330316187 HIT: 0.2867671855162928

#### val Acc: 0, NDCG: 0.4773139484475816 HIT: 0.5726342639123995
Epoch: 26, plus 0 steps train_loss: 0.7426

#### test Acc: 0, NDCG: 0.13198965660394857 HIT: 0.28822438372831144

#### val Acc: 0, NDCG: 0.48138855219122123 HIT: 0.5822486312420652
Epoch: 28, plus 0 steps train_loss: 0.7466

#### test Acc: 0, NDCG: 0.12984295296346127 HIT: 0.2831386545175624

#### val Acc: 0, NDCG: 0.48986305223634713 HIT: 0.5868557911024121
Epoch: 30, plus 0 steps train_loss: 0.7452

#### test Acc: 0, NDCG: 0.13833162955627176 HIT: 0.29436726354210746

#### val Acc: 0, NDCG: 0.4919720849749934 HIT: 0.5832330459162083
Epoch: 32, plus 0 steps train_loss: 0.7367

#### test Acc: 0, NDCG: 0.1318186895659872 HIT: 0.28463965959585275

#### val Acc: 0, NDCG: 0.4733227306272435 HIT: 0.5636001309246721
Epoch: 36, plus 0 steps train_loss: 0.731

#### test Acc: 0, NDCG: 0.1365106122583779 HIT: 0.2993149597968684

#### val Acc: 0, NDCG: 0.4786279685960566 HIT: 0.5702521622407957
Epoch: 40, plus 0 steps train_loss: 0.7294

#### test Acc: 0, NDCG: 0.12716104313991689 HIT: 0.2843239195408379

#### val Acc: 0, NDCG: 0.4834528978908126 HIT: 0.5825321360558613
Epoch: 44, plus 0 steps train_loss: 0.7196

#### test Acc: 0, NDCG: 0.1327091878984348 HIT: 0.283931310833686

#### val Acc: 0, NDCG: 0.47742100719528163 HIT: 0.5676997923719848
Epoch: 48, plus 0 steps train_loss: 0.7206

#### test Acc: 0, NDCG: 0.13068605498974464 HIT: 0.2900989869868811

#### val Acc: 0, NDCG: 0.47313297442724966 HIT: 0.5620222571942446
Epoch: 52, plus 0 steps train_loss: 0.7252

#### test Acc: 0, NDCG: 0.13009263452132533 HIT: 0.2889021503385527

#### val Acc: 0, NDCG: 0.47589685444626234 HIT: 0.5674757987727466
Epoch: 56, plus 0 steps train_loss: 0.7244

#### test Acc: 0, NDCG: 0.12681590004717294 HIT: 0.2787497024439272

#### val Acc: 0, NDCG: 0.4828733271010939 HIT: 0.5798227227041896
Epoch: 60, plus 0 steps train_loss: 0.718

#### test Acc: 0, NDCG: 0.13437323414886262 HIT: 0.28660435622090563

#### val Acc: 0, NDCG: 0.48126038699792323 HIT: 0.5869400986563691
Epoch: 64, plus 0 steps train_loss: 0.7171

#### test Acc: 0, NDCG: 0.13438986143512213 HIT: 0.28893273249047824

#### val Acc: 0, NDCG: 0.48605530383174067 HIT: 0.5770653697630131
Epoch: 68, plus 0 steps train_loss: 0.7194

#### test Acc: 0, NDCG: 0.15425323017673243 HIT: 0.3093756612357173

#### val Acc: 0, NDCG: 0.49468849764658124 HIT: 0.588094781527719
Epoch: 72, plus 0 steps train_loss: 0.7176

#### test Acc: 0, NDCG: 0.26572222726234906 HIT: 0.4066434352517985

#### val Acc: 0, NDCG: 0.5604014622945956 HIT: 0.6474200235399915
Epoch: 80, plus 0 steps train_loss: 0.7103

#### test Acc: 0, NDCG: 0.316776175210629 HIT: 0.45588896529834955

#### val Acc: 0, NDCG: 0.5968408039163027 HIT: 0.6848492713182396
Epoch: 88, plus 0 steps train_loss: 0.7089

#### test Acc: 0, NDCG: 0.37071405223301646 HIT: 0.5006711542530682

#### val Acc: 0, NDCG: 0.6246391222117547 HIT: 0.7041143739420228
Epoch: 96, plus 0 steps train_loss: 0.7073

#### test Acc: 0, NDCG: 0.3741051393317135 HIT: 0.5098011664198053

#### val Acc: 0, NDCG: 0.6068915889738392 HIT: 0.6859923825645365
Epoch: 104, plus 0 steps train_loss: 0.7007

#### test Acc: 0, NDCG: 0.31972526420802744 HIT: 0.45764289303851036

#### val Acc: 0, NDCG: 0.5890793386138021 HIT: 0.6711658246931866
Epoch: 112, plus 0 steps train_loss: 0.7039

#### test Acc: 0, NDCG: 0.36212889126647896 HIT: 0.5023581318768514

#### val Acc: 0, NDCG: 0.61598141008468 HIT: 0.6976499682606855
Epoch: 120, plus 0 steps train_loss: 0.7054

#### test Acc: 0, NDCG: 0.3861497273453588 HIT: 0.521676959902666

#### val Acc: 0, NDCG: 0.6336453362919299 HIT: 0.7122409609077444
Epoch: 128, plus 0 steps train_loss: 0.7047

#### test Acc: 0, NDCG: 0.4245514214126902 HIT: 0.5591004218683876

#### val Acc: 0, NDCG: 0.6662646958857062 HIT: 0.7422635421074905
Epoch: 136, plus 0 steps train_loss: 0.7037

#### test Acc: 0, NDCG: 0.45990816370699467 HIT: 0.5869169554062632

#### val Acc: 0, NDCG: 0.6917547404813627 HIT: 0.7652588407215405
Epoch: 144, plus 0 steps train_loss: 0.7067

#### test Acc: 0, NDCG: 0.4767430247376494 HIT: 0.6026303956834532

#### val Acc: 0, NDCG: 0.6975570159214626 HIT: 0.7715777745450698
Epoch: 160, plus 0 steps train_loss: 0.7017

#### test Acc: 0, NDCG: 0.4682712620526555 HIT: 0.5941417821625052

#### val Acc: 0, NDCG: 0.6718223995851696 HIT: 0.7464954506982648
Epoch: 176, plus 0 steps train_loss: 0.706

#### test Acc: 0, NDCG: 0.6125385632723291 HIT: 0.7157182342361404

#### val Acc: 0, NDCG: 0.7611512121545364 HIT: 0.8257619088552688
Epoch: 192, plus 0 steps train_loss: 0.6995

#### test Acc: 0, NDCG: 0.6387574865218244 HIT: 0.7454614433453237

#### val Acc: 0, NDCG: 0.7694849600355054 HIT: 0.8288887272534913
Epoch: 208, plus 0 steps train_loss: 0.7023

#### test Acc: 0, NDCG: 0.648621308355618 HIT: 0.7485270974396954

#### val Acc: 0, NDCG: 0.781689448947466 HIT: 0.8426027560304697
Epoch: 224, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.6105474756441498 HIT: 0.7055046220376641

#### val Acc: 0, NDCG: 0.7503880612396036 HIT: 0.8169707799936522
Epoch: 240, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.5513667324295349 HIT: 0.6646228972704189

#### val Acc: 0, NDCG: 0.734252590354448 HIT: 0.7986247950169276
Epoch: 256, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.6283785390756634 HIT: 0.7288330181443081

#### val Acc: 0, NDCG: 0.7684781053493095 HIT: 0.82963344398011
Epoch: 272, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.5301551684960355 HIT: 0.646615795598815

#### val Acc: 0, NDCG: 0.7221300742751794 HIT: 0.7916107371455777
Epoch: 288, plus 0 steps train_loss: 0.6984

#### test Acc: 0, NDCG: 0.5045716922189774 HIT: 0.6281970746931866

#### val Acc: 0, NDCG: 0.7069957232646203 HIT: 0.778471156898011
Epoch: 304, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.5328287020399578 HIT: 0.6522569628121032

#### val Acc: 0, NDCG: 0.6999635530406508 HIT: 0.7719951795916209
Epoch: 320, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.5413593864709026 HIT: 0.6621011095535336

#### val Acc: 0, NDCG: 0.7184136538469942 HIT: 0.792868738097757
Epoch: 352, plus 0 steps train_loss: 0.6949

#### test Acc: 0, NDCG: 0.5077230618500437 HIT: 0.6245627578819297

#### val Acc: 0, NDCG: 0.7103476830501472 HIT: 0.7876201795916209
Epoch: 384, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.48276400695773974 HIT: 0.6109826293377063

#### val Acc: 0, NDCG: 0.6834878570325622 HIT: 0.7605177806284384
Epoch: 416, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.5365380007555434 HIT: 0.659071823423614

#### val Acc: 0, NDCG: 0.7256577198398407 HIT: 0.7939680424777825
Epoch: 448, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.5217572463092611 HIT: 0.6470869260473974

#### val Acc: 0, NDCG: 0.710078870586353 HIT: 0.7805085894519679
Epoch: 480, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.5582144920272164 HIT: 0.6716063729898434

#### val Acc: 0, NDCG: 0.7307181611469298 HIT: 0.7978759455670758
Epoch: 512, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.5770679932788513 HIT: 0.6931271159542953

#### val Acc: 0, NDCG: 0.7561850272161635 HIT: 0.8210646556284384
Epoch: 544, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.6162885177541095 HIT: 0.7208634746614473

#### val Acc: 0, NDCG: 0.7687191545247685 HIT: 0.8276728800782903
Epoch: 576, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.6342344764178077 HIT: 0.7417370331675837

#### val Acc: 0, NDCG: 0.7775818011447123 HIT: 0.8368946387008042
Epoch: 608, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.6485956070921519 HIT: 0.7455474039885738

#### val Acc: 0, NDCG: 0.791236653015252 HIT: 0.8467387854422345
Epoch: 640, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.6644282347439443 HIT: 0.76518031898011

#### val Acc: 0, NDCG: 0.7914295718031932 HIT: 0.8546355929961913
Epoch: 704, plus 0 steps train_loss: 0.6972

#### test Acc: 0, NDCG: 0.6461193191569178 HIT: 0.7403467850719424

#### val Acc: 0, NDCG: 0.7810681685360534 HIT: 0.8350869855586119
Epoch: 768, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.6362645222998975 HIT: 0.7404310926258993

#### val Acc: 0, NDCG: 0.7809426785901376 HIT: 0.8397305133834109
Epoch: 832, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.6554185942746278 HIT: 0.7564487013330512

#### val Acc: 0, NDCG: 0.7904225219645342 HIT: 0.8496837640181972
Epoch: 896, plus 0 steps train_loss: 0.6941

#### test Acc: 0, NDCG: 0.6582476070005194 HIT: 0.7583654583685993

#### val Acc: 0, NDCG: 0.7995672529617649 HIT: 0.8523989631823953
Epoch: 960, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.62527095103691 HIT: 0.7237357173085062

#### val Acc: 0, NDCG: 0.7958171388166985 HIT: 0.8520237119128227
Epoch: 1017, plus 0 steps train_loss: 0.6936
Done: it took 81265.40978312492
max value of NDCG: 0.6644282347439443
max value of HIT: 0.76518031898011

After 20 validations
max value of NDCG: 0.6644282347439443
max value of HIT: 0.76518031898011
