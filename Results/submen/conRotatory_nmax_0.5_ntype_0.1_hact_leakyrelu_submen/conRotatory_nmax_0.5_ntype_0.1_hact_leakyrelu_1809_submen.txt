 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	0.5
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	rotatory
position_concatenation: 	True
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11889541
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12370229723782711 HIT: 0.2694130541155311

#### val Acc: 0, NDCG: 0.4748183317012732 HIT: 0.5702753054909014
Epoch: 1, plus 0 steps train_loss: 0.7752

#### test Acc: 0, NDCG: 0.12486138591136577 HIT: 0.2733978258569615

#### val Acc: 0, NDCG: 0.4849653233696756 HIT: 0.5797747831146848
Epoch: 2, plus 0 steps train_loss: 0.7835

#### test Acc: 0, NDCG: 0.12463072484443917 HIT: 0.2720670889758781

#### val Acc: 0, NDCG: 0.4840678832718859 HIT: 0.5848778697630131
Epoch: 3, plus 0 steps train_loss: 0.7818

#### test Acc: 0, NDCG: 0.1266511268392655 HIT: 0.278071935833686

#### val Acc: 0, NDCG: 0.49377888701565537 HIT: 0.5901495715192552
Epoch: 4, plus 0 steps train_loss: 0.7814

#### test Acc: 0, NDCG: 0.12247505378958795 HIT: 0.27405823502962334

#### val Acc: 0, NDCG: 0.4770941166505054 HIT: 0.5717573000423191
Epoch: 5, plus 0 steps train_loss: 0.7774

#### test Acc: 0, NDCG: 0.12420815434755947 HIT: 0.27663374814853997

#### val Acc: 0, NDCG: 0.4779961500138975 HIT: 0.5742311481696996
Epoch: 6, plus 0 steps train_loss: 0.7834

#### test Acc: 0, NDCG: 0.12421360278099189 HIT: 0.2789546855162928

#### val Acc: 0, NDCG: 0.4824558248765887 HIT: 0.5809542623254337
Epoch: 7, plus 0 steps train_loss: 0.7829

#### test Acc: 0, NDCG: 0.1176693141086355 HIT: 0.2669044911129919

#### val Acc: 0, NDCG: 0.48507071206287855 HIT: 0.583709962177317
Epoch: 8, plus 0 steps train_loss: 0.7572

#### test Acc: 0, NDCG: 0.12848324869844713 HIT: 0.2821773830935252

#### val Acc: 0, NDCG: 0.4780882274445448 HIT: 0.576866172503174
Epoch: 9, plus 0 steps train_loss: 0.7725

#### test Acc: 0, NDCG: 0.13055555023156873 HIT: 0.28876246429327124

#### val Acc: 0, NDCG: 0.4776021531513399 HIT: 0.5713456808082945
Epoch: 10, plus 0 steps train_loss: 0.7621

#### test Acc: 0, NDCG: 0.13137924014714336 HIT: 0.28757141345746934

#### val Acc: 0, NDCG: 0.48470207753067135 HIT: 0.5739881440435886
Epoch: 12, plus 0 steps train_loss: 0.7617

#### test Acc: 0, NDCG: 0.12138761399426536 HIT: 0.2785852200592467

#### val Acc: 0, NDCG: 0.47929151839413214 HIT: 0.5687090033855269
Epoch: 14, plus 0 steps train_loss: 0.7633

#### test Acc: 0, NDCG: 0.13154606306687788 HIT: 0.2853463552687262

#### val Acc: 0, NDCG: 0.47121228333498333 HIT: 0.5630984183241642
Epoch: 16, plus 0 steps train_loss: 0.7543

#### test Acc: 0, NDCG: 0.12944065140288336 HIT: 0.280762338658485

#### val Acc: 0, NDCG: 0.4814834058048092 HIT: 0.5785895180914092
Epoch: 18, plus 0 steps train_loss: 0.7525

#### test Acc: 0, NDCG: 0.12404491924062784 HIT: 0.26836747513753706

#### val Acc: 0, NDCG: 0.47434398336824435 HIT: 0.573231855691917
Epoch: 20, plus 0 steps train_loss: 0.7479

#### test Acc: 0, NDCG: 0.12928944955620367 HIT: 0.28493473603470165

#### val Acc: 0, NDCG: 0.4765755113163758 HIT: 0.5657888211489631
Epoch: 22, plus 0 steps train_loss: 0.7372

#### test Acc: 0, NDCG: 0.13026060135506728 HIT: 0.2854554591620821

#### val Acc: 0, NDCG: 0.4757139513052342 HIT: 0.5754759244075328
Epoch: 24, plus 0 steps train_loss: 0.7381

#### test Acc: 0, NDCG: 0.1322025825910598 HIT: 0.29273566440964877

#### val Acc: 0, NDCG: 0.46474510096218663 HIT: 0.554705683982226
Epoch: 26, plus 0 steps train_loss: 0.7438

#### test Acc: 0, NDCG: 0.1331878689943109 HIT: 0.29102389044646637

#### val Acc: 0, NDCG: 0.4764528299250133 HIT: 0.5617676814430808
Epoch: 28, plus 0 steps train_loss: 0.7391

#### test Acc: 0, NDCG: 0.13531144012795324 HIT: 0.2912230877063055

#### val Acc: 0, NDCG: 0.46752745672745744 HIT: 0.5539493956305543
Epoch: 30, plus 0 steps train_loss: 0.7356

#### test Acc: 0, NDCG: 0.1279440640498841 HIT: 0.2774917014917478

#### val Acc: 0, NDCG: 0.47039218786687315 HIT: 0.5618404173719848
Epoch: 32, plus 0 steps train_loss: 0.7284

#### test Acc: 0, NDCG: 0.13360472022808592 HIT: 0.2881516477994075

#### val Acc: 0, NDCG: 0.4713334493232509 HIT: 0.572052376481168
Epoch: 36, plus 0 steps train_loss: 0.7281

#### test Acc: 0, NDCG: 0.13430616908831983 HIT: 0.2925844067393144

#### val Acc: 0, NDCG: 0.4807162609203908 HIT: 0.574901475878121
Epoch: 40, plus 0 steps train_loss: 0.7198

#### test Acc: 0, NDCG: 0.13186557537746116 HIT: 0.2858364962441811

#### val Acc: 0, NDCG: 0.47256096991646135 HIT: 0.5748651079136691
Epoch: 44, plus 0 steps train_loss: 0.7283

#### test Acc: 0, NDCG: 0.1340152289187707 HIT: 0.29431932395260263

#### val Acc: 0, NDCG: 0.4803258438330337 HIT: 0.573660832363521
Epoch: 48, plus 0 steps train_loss: 0.7198

#### test Acc: 0, NDCG: 0.13080526403100626 HIT: 0.28455369895260263

#### val Acc: 0, NDCG: 0.4656559976082699 HIT: 0.5527104052052475
Epoch: 52, plus 0 steps train_loss: 0.7192

#### test Acc: 0, NDCG: 0.12734725807427535 HIT: 0.2805209876216674

#### val Acc: 0, NDCG: 0.4874632462340523 HIT: 0.5781415308929327
Epoch: 56, plus 0 steps train_loss: 0.7118

#### test Acc: 0, NDCG: 0.131750971499127 HIT: 0.2821658114684723

#### val Acc: 0, NDCG: 0.4757187739078759 HIT: 0.5680808294540838
Epoch: 60, plus 0 steps train_loss: 0.7093

#### test Acc: 0, NDCG: 0.12337720845292643 HIT: 0.2730953105162928

#### val Acc: 0, NDCG: 0.4725061603943574 HIT: 0.5598757207469318
Epoch: 64, plus 0 steps train_loss: 0.716

#### test Acc: 0, NDCG: 0.1281796237657081 HIT: 0.27266633384468897

#### val Acc: 0, NDCG: 0.48521373377070526 HIT: 0.5795276462653407
Epoch: 68, plus 0 steps train_loss: 0.7168

#### test Acc: 0, NDCG: 0.13360674629164834 HIT: 0.2936663536817605

#### val Acc: 0, NDCG: 0.4821620867701012 HIT: 0.5744171207151926
Epoch: 72, plus 0 steps train_loss: 0.711

#### test Acc: 0, NDCG: 0.14284160122104744 HIT: 0.2997860902454507

#### val Acc: 0, NDCG: 0.4939663793020915 HIT: 0.6039016213499789
Epoch: 80, plus 0 steps train_loss: 0.716

#### test Acc: 0, NDCG: 0.3165635052815925 HIT: 0.47414320381929753

#### val Acc: 0, NDCG: 0.5882786588906325 HIT: 0.6710261386479052
Epoch: 88, plus 0 steps train_loss: 0.7079

#### test Acc: 0, NDCG: 0.35800745502729187 HIT: 0.49742366033643676

#### val Acc: 0, NDCG: 0.6077429266466647 HIT: 0.6922443662716885
Epoch: 96, plus 0 steps train_loss: 0.7124

#### test Acc: 0, NDCG: 0.49130228646935226 HIT: 0.6142838486563691

#### val Acc: 0, NDCG: 0.7043525319104846 HIT: 0.7799589372619551
Epoch: 104, plus 0 steps train_loss: 0.709

#### test Acc: 0, NDCG: 0.3497366340670913 HIT: 0.4983733601354211

#### val Acc: 0, NDCG: 0.616296517126118 HIT: 0.6975656607067287
Epoch: 112, plus 0 steps train_loss: 0.7089

#### test Acc: 0, NDCG: 0.4385040616461079 HIT: 0.5684428560093102

#### val Acc: 0, NDCG: 0.6600283098728524 HIT: 0.7369306760473974
Epoch: 120, plus 0 steps train_loss: 0.71

#### test Acc: 0, NDCG: 0.5450992846389542 HIT: 0.6551713592361404

#### val Acc: 0, NDCG: 0.7300697321551323 HIT: 0.7996893845217943
Epoch: 128, plus 0 steps train_loss: 0.7087

#### test Acc: 0, NDCG: 0.5892827181289094 HIT: 0.6960720945302581

#### val Acc: 0, NDCG: 0.7572044008277227 HIT: 0.8204844212865002
Epoch: 136, plus 0 steps train_loss: 0.7036

#### test Acc: 0, NDCG: 0.5786415738946369 HIT: 0.6905268064959796

#### val Acc: 0, NDCG: 0.7620522060072293 HIT: 0.8207621402877698
Epoch: 144, plus 0 steps train_loss: 0.7054

#### test Acc: 0, NDCG: 0.6135634993096608 HIT: 0.7155363944138806

#### val Acc: 0, NDCG: 0.7732037498808446 HIT: 0.8351712931125688
Epoch: 160, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.5149800915734667 HIT: 0.6302708752115954

#### val Acc: 0, NDCG: 0.711066543482326 HIT: 0.7846024650867541
Epoch: 176, plus 0 steps train_loss: 0.7021

#### test Acc: 0, NDCG: 0.6233758049225505 HIT: 0.7217478774333475

#### val Acc: 0, NDCG: 0.7562069041452937 HIT: 0.813983647640711
Epoch: 192, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.6088660812655496 HIT: 0.7064063822471435

#### val Acc: 0, NDCG: 0.7781210075572083 HIT: 0.8356250661235718
Epoch: 208, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.6520083648505759 HIT: 0.7460358918747355

#### val Acc: 0, NDCG: 0.7816853943593597 HIT: 0.8433706160071943
Epoch: 224, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.662844903591959 HIT: 0.7541451214028777

#### val Acc: 0, NDCG: 0.775950867820746 HIT: 0.8317072444985188
Epoch: 240, plus 0 steps train_loss: 0.7028

#### test Acc: 0, NDCG: 0.6469047159380945 HIT: 0.7406666578501904

#### val Acc: 0, NDCG: 0.7759886294867531 HIT: 0.8341009177951756
Epoch: 256, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.6101535833333175 HIT: 0.7211106115107914

#### val Acc: 0, NDCG: 0.760872887399712 HIT: 0.8285076901713924
Epoch: 272, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.6358560844142326 HIT: 0.734064219212865

#### val Acc: 0, NDCG: 0.7875636345929017 HIT: 0.8439756466885315
Epoch: 288, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.5955949496900754 HIT: 0.7085223365425306

#### val Acc: 0, NDCG: 0.764034337482082 HIT: 0.8337083090880236
Epoch: 304, plus 0 steps train_loss: 0.7009

#### test Acc: 0, NDCG: 0.5961348950564767 HIT: 0.7050086952496826

#### val Acc: 0, NDCG: 0.7656829957465836 HIT: 0.8283448608760051
Epoch: 320, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.6290968203578382 HIT: 0.7369422476724502

#### val Acc: 0, NDCG: 0.7618703441656988 HIT: 0.8218019334532374
Epoch: 352, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.6097692594948289 HIT: 0.7188450526343632

#### val Acc: 0, NDCG: 0.7770133301995243 HIT: 0.8391387074164198
Epoch: 384, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.6110843373445031 HIT: 0.7267592176258993

#### val Acc: 0, NDCG: 0.7680301201920717 HIT: 0.8353895008992805
Epoch: 416, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.620044280515398 HIT: 0.7277204890499366

#### val Acc: 0, NDCG: 0.768177932114819 HIT: 0.8376203449005502
Epoch: 448, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.6087911189806675 HIT: 0.7116359302264071

#### val Acc: 0, NDCG: 0.7583582058657756 HIT: 0.819352881665256
Epoch: 480, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.6500927034323727 HIT: 0.7439199375793484

#### val Acc: 0, NDCG: 0.7944313614389934 HIT: 0.8448641821836649
Epoch: 512, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.6069753307701287 HIT: 0.7096828052264071

#### val Acc: 0, NDCG: 0.7696487587824627 HIT: 0.8350200354422345
Epoch: 544, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.6248528233210637 HIT: 0.7383209241430384

#### val Acc: 0, NDCG: 0.7822919232846198 HIT: 0.8479910005818875
Epoch: 576, plus 0 steps train_loss: 0.6944

#### test Acc: 0, NDCG: 0.6221592595224898 HIT: 0.737382795969107

#### val Acc: 0, NDCG: 0.7762876888154626 HIT: 0.8426754919593736
Epoch: 608, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.6232091086486181 HIT: 0.7278775325327973

#### val Acc: 0, NDCG: 0.767946121922321 HIT: 0.8370095284066865
Epoch: 640, plus 0 steps train_loss: 0.6984

#### test Acc: 0, NDCG: 0.6546046571468116 HIT: 0.7421908061785866

#### val Acc: 0, NDCG: 0.7833453902415025 HIT: 0.8392709545598815
Epoch: 704, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.6562074375945323 HIT: 0.7512001428269149

#### val Acc: 0, NDCG: 0.8116697314071574 HIT: 0.8664270789250952
Epoch: 768, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.6653748273117992 HIT: 0.7557114235082523

#### val Acc: 0, NDCG: 0.7984782220921351 HIT: 0.8543272918429963
Epoch: 832, plus 0 steps train_loss: 0.6941

#### test Acc: 0, NDCG: 0.6479913771420991 HIT: 0.7432727531210326

#### val Acc: 0, NDCG: 0.7898126990229735 HIT: 0.8457105639018198
Epoch: 896, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.6670930814961218 HIT: 0.7588308030046551

#### val Acc: 0, NDCG: 0.7909442682947616 HIT: 0.8468363177105375
Epoch: 960, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.6631486790437444 HIT: 0.7590605824164198

#### val Acc: 0, NDCG: 0.7861064977343714 HIT: 0.8426639203343208
Epoch: 1017, plus 0 steps train_loss: 0.6978
Done: it took 86630.556037426
max value of NDCG: 0.6670930814961218
max value of HIT: 0.7590605824164198

After 20 validations
max value of NDCG: 0.6670930814961218
max value of HIT: 0.7590605824164198
