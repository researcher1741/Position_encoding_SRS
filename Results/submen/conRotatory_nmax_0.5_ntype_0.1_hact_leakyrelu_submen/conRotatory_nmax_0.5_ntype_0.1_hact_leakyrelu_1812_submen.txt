 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	0.5
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	rotatory
position_concatenation: 	True
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11889541
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.11598503355969696 HIT: 0.2601012021265341

#### val Acc: 0, NDCG: 0.4884210684466935 HIT: 0.5874971897482014
Epoch: 1, plus 0 steps train_loss: 0.7636

#### test Acc: 0, NDCG: 0.11898770492467646 HIT: 0.26481168006771055

#### val Acc: 0, NDCG: 0.47883046613051855 HIT: 0.5748113825116378
Epoch: 2, plus 0 steps train_loss: 0.7686

#### test Acc: 0, NDCG: 0.11926708604391673 HIT: 0.26283375872831144

#### val Acc: 0, NDCG: 0.4921210107036982 HIT: 0.5837653406686416
Epoch: 3, plus 0 steps train_loss: 0.7539

#### test Acc: 0, NDCG: 0.11385228046151065 HIT: 0.2522523341620821

#### val Acc: 0, NDCG: 0.48128090784600785 HIT: 0.5795987291049514
Epoch: 4, plus 0 steps train_loss: 0.7614

#### test Acc: 0, NDCG: 0.11819446339809267 HIT: 0.2594176497037664

#### val Acc: 0, NDCG: 0.49805721883659826 HIT: 0.5937301629284808
Epoch: 5, plus 0 steps train_loss: 0.7608

#### test Acc: 0, NDCG: 0.11973277276363004 HIT: 0.2651927171498096

#### val Acc: 0, NDCG: 0.4924580187936375 HIT: 0.5923283432077867
Epoch: 6, plus 0 steps train_loss: 0.7578

#### test Acc: 0, NDCG: 0.12486859380301799 HIT: 0.28175419223444775

#### val Acc: 0, NDCG: 0.4788136099847651 HIT: 0.5751064589504867
Epoch: 7, plus 0 steps train_loss: 0.7473

#### test Acc: 0, NDCG: 0.1239294489564001 HIT: 0.27795126031527717

#### val Acc: 0, NDCG: 0.4818252567586924 HIT: 0.5764487674566229
Epoch: 8, plus 0 steps train_loss: 0.7564

#### test Acc: 0, NDCG: 0.12276909635328492 HIT: 0.2721340390922556

#### val Acc: 0, NDCG: 0.488090205124972 HIT: 0.584152163563267
Epoch: 9, plus 0 steps train_loss: 0.7488

#### test Acc: 0, NDCG: 0.12289087976491725 HIT: 0.2727027018091409

#### val Acc: 0, NDCG: 0.4763076831261774 HIT: 0.5714663563267033
Epoch: 10, plus 0 steps train_loss: 0.7612

#### test Acc: 0, NDCG: 0.1257760476934375 HIT: 0.2739722743863733

#### val Acc: 0, NDCG: 0.4822802185775173 HIT: 0.5750585193609818
Epoch: 12, plus 0 steps train_loss: 0.7553

#### test Acc: 0, NDCG: 0.12203000580779866 HIT: 0.2654224965615743

#### val Acc: 0, NDCG: 0.4887031927229059 HIT: 0.5851266597016505
Epoch: 14, plus 0 steps train_loss: 0.7546

#### test Acc: 0, NDCG: 0.11971398691236826 HIT: 0.26373551893779096

#### val Acc: 0, NDCG: 0.4858325107183066 HIT: 0.5840984381612356
Epoch: 16, plus 0 steps train_loss: 0.7487

#### test Acc: 0, NDCG: 0.12798504075196837 HIT: 0.28493473603470165

#### val Acc: 0, NDCG: 0.47902957102195043 HIT: 0.569852114631824
Epoch: 18, plus 0 steps train_loss: 0.7477

#### test Acc: 0, NDCG: 0.13129501369938976 HIT: 0.2973486100825222

#### val Acc: 0, NDCG: 0.4843777957813269 HIT: 0.5807186971011427
Epoch: 20, plus 0 steps train_loss: 0.7382

#### test Acc: 0, NDCG: 0.13683920676525047 HIT: 0.29524422741218787

#### val Acc: 0, NDCG: 0.4836937889472826 HIT: 0.5731169659860347
Epoch: 22, plus 0 steps train_loss: 0.7333

#### test Acc: 0, NDCG: 0.1258732078014381 HIT: 0.27648827629073214

#### val Acc: 0, NDCG: 0.47928425203430114 HIT: 0.5683395379284808
Epoch: 24, plus 0 steps train_loss: 0.7291

#### test Acc: 0, NDCG: 0.12321035509308605 HIT: 0.27599813531527717

#### val Acc: 0, NDCG: 0.46450383834350956 HIT: 0.5485859474185357
Epoch: 26, plus 0 steps train_loss: 0.7306

#### test Acc: 0, NDCG: 0.12733446537472817 HIT: 0.28697960749047824

#### val Acc: 0, NDCG: 0.4762592245680465 HIT: 0.5729177687261955
Epoch: 28, plus 0 steps train_loss: 0.734

#### test Acc: 0, NDCG: 0.11701150461989698 HIT: 0.26674000872831144

#### val Acc: 0, NDCG: 0.4839658010986052 HIT: 0.5817584902666102
Epoch: 30, plus 0 steps train_loss: 0.7265

#### test Acc: 0, NDCG: 0.12351894946991926 HIT: 0.27610145339610664

#### val Acc: 0, NDCG: 0.4938975634192417 HIT: 0.592872209585273
Epoch: 32, plus 0 steps train_loss: 0.7398

#### test Acc: 0, NDCG: 0.12707796668231733 HIT: 0.2878797146106644

#### val Acc: 0, NDCG: 0.47726669995732 HIT: 0.5702753054909014
Epoch: 36, plus 0 steps train_loss: 0.7262

#### test Acc: 0, NDCG: 0.12727745816213204 HIT: 0.283894942869234

#### val Acc: 0, NDCG: 0.4849815520100525 HIT: 0.581534496667372
Epoch: 40, plus 0 steps train_loss: 0.729

#### test Acc: 0, NDCG: 0.12729398591059538 HIT: 0.2814822590457046

#### val Acc: 0, NDCG: 0.4772369732098542 HIT: 0.5748708937261955
Epoch: 44, plus 0 steps train_loss: 0.7247

#### test Acc: 0, NDCG: 0.1386474541666969 HIT: 0.30182930861193397

#### val Acc: 0, NDCG: 0.47368953548546233 HIT: 0.5621850864896318
Epoch: 48, plus 0 steps train_loss: 0.7134

#### test Acc: 0, NDCG: 0.12447967023629548 HIT: 0.281143375740584

#### val Acc: 0, NDCG: 0.4777091313647483 HIT: 0.5714547847016505
Epoch: 52, plus 0 steps train_loss: 0.7181

#### test Acc: 0, NDCG: 0.13097347837188048 HIT: 0.29412012669276344

#### val Acc: 0, NDCG: 0.4667300499132567 HIT: 0.5540221315594583
Epoch: 56, plus 0 steps train_loss: 0.7174

#### test Acc: 0, NDCG: 0.13510147305386447 HIT: 0.3043395247037664

#### val Acc: 0, NDCG: 0.4733345726110749 HIT: 0.5653292623254337
Epoch: 60, plus 0 steps train_loss: 0.7174

#### test Acc: 0, NDCG: 0.1307079968942608 HIT: 0.2961402018091409

#### val Acc: 0, NDCG: 0.4687916256979869 HIT: 0.5669567287346593
Epoch: 64, plus 0 steps train_loss: 0.7171

#### test Acc: 0, NDCG: 0.13303499870242297 HIT: 0.2928505541155311

#### val Acc: 0, NDCG: 0.47633653249525937 HIT: 0.558956603099873
Epoch: 68, plus 0 steps train_loss: 0.716

#### test Acc: 0, NDCG: 0.13035497488239553 HIT: 0.2875044633410918

#### val Acc: 0, NDCG: 0.4768693385111362 HIT: 0.5714242025497249
Epoch: 72, plus 0 steps train_loss: 0.7204

#### test Acc: 0, NDCG: 0.1261402249896492 HIT: 0.283096500740584

#### val Acc: 0, NDCG: 0.4848715149734313 HIT: 0.5827619154676259
Epoch: 80, plus 0 steps train_loss: 0.71

#### test Acc: 0, NDCG: 0.1299356725581425 HIT: 0.2831634508569615

#### val Acc: 0, NDCG: 0.4813353034875572 HIT: 0.5833652930596699
Epoch: 88, plus 0 steps train_loss: 0.7097

#### test Acc: 0, NDCG: 0.13639510848724606 HIT: 0.29933810304697417

#### val Acc: 0, NDCG: 0.49011654400467547 HIT: 0.5883972968683876
Epoch: 96, plus 0 steps train_loss: 0.7083

#### test Acc: 0, NDCG: 0.1685196394917281 HIT: 0.32800515102623784

#### val Acc: 0, NDCG: 0.507926051173149 HIT: 0.6046273275497249
Epoch: 104, plus 0 steps train_loss: 0.7062

#### test Acc: 0, NDCG: 0.2288741236315204 HIT: 0.37049119895260263

#### val Acc: 0, NDCG: 0.5304785999828158 HIT: 0.622833626481168
Epoch: 112, plus 0 steps train_loss: 0.7081

#### test Acc: 0, NDCG: 0.25538409264276385 HIT: 0.4012742012272535

#### val Acc: 0, NDCG: 0.5573780705691951 HIT: 0.6550143157532797
Epoch: 120, plus 0 steps train_loss: 0.703

#### test Acc: 0, NDCG: 0.3983220383914581 HIT: 0.5249666075962759

#### val Acc: 0, NDCG: 0.6413302044689031 HIT: 0.7230827470376641
Epoch: 128, plus 0 steps train_loss: 0.7088

#### test Acc: 0, NDCG: 0.49800391930710086 HIT: 0.6106073780681338

#### val Acc: 0, NDCG: 0.7072293199528769 HIT: 0.7812037134997883
Epoch: 136, plus 0 steps train_loss: 0.7086

#### test Acc: 0, NDCG: 0.6392971262860433 HIT: 0.7360289158379179

#### val Acc: 0, NDCG: 0.7746975930747971 HIT: 0.8346695805120609
Epoch: 144, plus 0 steps train_loss: 0.7034

#### test Acc: 0, NDCG: 0.6487401581860216 HIT: 0.7409865306284384

#### val Acc: 0, NDCG: 0.8053981376090052 HIT: 0.8584269532903089
Epoch: 160, plus 0 steps train_loss: 0.7021

#### test Acc: 0, NDCG: 0.6950170214944713 HIT: 0.7835205181443081

#### val Acc: 0, NDCG: 0.8114720583701784 HIT: 0.8626720865954296
Epoch: 176, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.693076445383187 HIT: 0.7722728985928904

#### val Acc: 0, NDCG: 0.825181574896323 HIT: 0.8699217096910707
Epoch: 192, plus 0 steps train_loss: 0.7017

#### test Acc: 0, NDCG: 0.7062611871696687 HIT: 0.7900444350402032

#### val Acc: 0, NDCG: 0.823425545661891 HIT: 0.8690753279729159
Epoch: 208, plus 0 steps train_loss: 0.705

#### test Acc: 0, NDCG: 0.679970518336643 HIT: 0.7741954414409649

#### val Acc: 0, NDCG: 0.8119313361043146 HIT: 0.8612934101248414
Epoch: 224, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.5106385606286816 HIT: 0.6279863058082945

#### val Acc: 0, NDCG: 0.7103049260361648 HIT: 0.7755203925095218
Epoch: 240, plus 0 steps train_loss: 0.7007

#### test Acc: 0, NDCG: 0.6063605810823371 HIT: 0.7067816335167161

#### val Acc: 0, NDCG: 0.7685585851950393 HIT: 0.8245956543588658
Epoch: 256, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.4924254453354693 HIT: 0.6098758860558613

#### val Acc: 0, NDCG: 0.7097243306847405 HIT: 0.7750244657215405
Epoch: 272, plus 0 steps train_loss: 0.7017

#### test Acc: 0, NDCG: 0.7057425136686427 HIT: 0.7926083765340668

#### val Acc: 0, NDCG: 0.8175727397373309 HIT: 0.8645714861933982
Epoch: 288, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.7260659349686979 HIT: 0.8066976565806179

#### val Acc: 0, NDCG: 0.8227795698855994 HIT: 0.8726790626322471
Epoch: 304, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.7236885234901083 HIT: 0.8077200923085062

#### val Acc: 0, NDCG: 0.8210620950698446 HIT: 0.869335689536606
Epoch: 320, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.7132311422730809 HIT: 0.7931580287240796

#### val Acc: 0, NDCG: 0.8460166381225215 HIT: 0.8934319456199746
Epoch: 352, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.725705599448781 HIT: 0.8062744657215405

#### val Acc: 0, NDCG: 0.8459366150020035 HIT: 0.8917507538087177
Epoch: 384, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.7376663204904138 HIT: 0.8155268064959796

#### val Acc: 0, NDCG: 0.8377597246523745 HIT: 0.8840109897376217
Epoch: 416, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.7329859898528717 HIT: 0.8086871495450698

#### val Acc: 0, NDCG: 0.850226393603132 HIT: 0.8983416208209903
Epoch: 448, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.7193877574264391 HIT: 0.7986727346064325

#### val Acc: 0, NDCG: 0.8337646080834501 HIT: 0.8826438848920863
Epoch: 480, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.7079886943100901 HIT: 0.7873292358760051

#### val Acc: 0, NDCG: 0.8216432589235358 HIT: 0.8742032109606432
Epoch: 512, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.7185487207342582 HIT: 0.795976545969107

#### val Acc: 0, NDCG: 0.8270354938789544 HIT: 0.8732113573846805
Epoch: 544, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.7059660283187192 HIT: 0.7931522429115531

#### val Acc: 0, NDCG: 0.8327164913692069 HIT: 0.8822760725243335
Epoch: 576, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.6647863125725229 HIT: 0.7523854078501904

#### val Acc: 0, NDCG: 0.8059865461903081 HIT: 0.8592559775708845
Epoch: 608, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.4708708557893045 HIT: 0.5778886082310623

#### val Acc: 0, NDCG: 0.6918428242473253 HIT: 0.7594416194985188
Epoch: 640, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.7233782708065386 HIT: 0.7975602055120609

#### val Acc: 0, NDCG: 0.8418524560975322 HIT: 0.8869559683135845
Epoch: 704, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.7554651957415229 HIT: 0.8367797489949218

#### val Acc: 0, NDCG: 0.8504010205903451 HIT: 0.895499960325857
Epoch: 768, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.7255861162591216 HIT: 0.8071630012166737

#### val Acc: 0, NDCG: 0.830438243096205 HIT: 0.8789079030892932
Epoch: 832, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.6976901810303727 HIT: 0.7824559286394414

#### val Acc: 0, NDCG: 0.832066633595078 HIT: 0.8776556879496402
Epoch: 896, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.7140507642517019 HIT: 0.8010374788404571

#### val Acc: 0, NDCG: 0.8299746871689971 HIT: 0.8793426655734237
Epoch: 960, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.7132327343489839 HIT: 0.793751487780364

#### val Acc: 0, NDCG: 0.8300392727689997 HIT: 0.8731997857596276
Epoch: 1017, plus 0 steps train_loss: 0.6942
Done: it took 86781.8631734848
max value of NDCG: 0.7554651957415229
max value of HIT: 0.8367797489949218

After 20 validations
max value of NDCG: 0.7554651957415229
max value of HIT: 0.8367797489949218
