 The dataset SubMen contains 8331 users and 10000 items in total
average sequence length: {2.43}
ItemFeatures DF dimensions (10001, 2048)

#######  Training configuration
norm_type:            	2
max_norm:             	0.5
dataset:              	SubMen
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 16272
Number of steps in the Validation dataset: 17
Number of steps in the Test dataset: 17
Loading Model ...
Amount of model parameters 11571301
Loading scheduler and optimizer ...
Evaluation every 16 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13438472974800475 HIT: 0.2937027216462124

#### val Acc: 0, NDCG: 0.49253065594412804 HIT: 0.5929623029517562
Epoch: 1, plus 0 steps train_loss: 0.7743

#### test Acc: 0, NDCG: 0.12439299460523377 HIT: 0.2725035045493018

#### val Acc: 0, NDCG: 0.4864747083313135 HIT: 0.5878170625264495
Epoch: 2, plus 0 steps train_loss: 0.7684

#### test Acc: 0, NDCG: 0.12972079600158423 HIT: 0.2821658114684723

#### val Acc: 0, NDCG: 0.4792389501016494 HIT: 0.5719870794540838
Epoch: 3, plus 0 steps train_loss: 0.768

#### test Acc: 0, NDCG: 0.12787755637397058 HIT: 0.28757719926999575

#### val Acc: 0, NDCG: 0.4736104790413361 HIT: 0.5694826491747778
Epoch: 4, plus 0 steps train_loss: 0.7683

#### test Acc: 0, NDCG: 0.13250317050670132 HIT: 0.2903709201756242

#### val Acc: 0, NDCG: 0.4778890673942558 HIT: 0.5753304525497249
Epoch: 5, plus 0 steps train_loss: 0.7638

#### test Acc: 0, NDCG: 0.13437864770376967 HIT: 0.2931109156792213

#### val Acc: 0, NDCG: 0.4828529301969244 HIT: 0.5831487383622515
Epoch: 6, plus 0 steps train_loss: 0.7652

#### test Acc: 0, NDCG: 0.13347585803841608 HIT: 0.2953417596804909

#### val Acc: 0, NDCG: 0.48410774294073233 HIT: 0.5816188042213288
Epoch: 7, plus 0 steps train_loss: 0.7606

#### test Acc: 0, NDCG: 0.12942994206788674 HIT: 0.28719037637537026

#### val Acc: 0, NDCG: 0.49011874224089963 HIT: 0.5814981287029201
Epoch: 8, plus 0 steps train_loss: 0.7661

#### test Acc: 0, NDCG: 0.13631487721439378 HIT: 0.3005828792848075

#### val Acc: 0, NDCG: 0.478568255000969 HIT: 0.5783961066440966
Epoch: 9, plus 0 steps train_loss: 0.754

#### test Acc: 0, NDCG: 0.13854264323681445 HIT: 0.30608601354210746

#### val Acc: 0, NDCG: 0.4788899351388564 HIT: 0.5728814007617435
Epoch: 10, plus 0 steps train_loss: 0.7475

#### test Acc: 0, NDCG: 0.135954185603242 HIT: 0.30285174433982226

#### val Acc: 0, NDCG: 0.486946599792714 HIT: 0.5804219675730004
Epoch: 12, plus 0 steps train_loss: 0.7595

#### test Acc: 0, NDCG: 0.12171867304946797 HIT: 0.2765535733178163

#### val Acc: 0, NDCG: 0.4654574125546681 HIT: 0.5596996667371984
Epoch: 14, plus 0 steps train_loss: 0.7424

#### test Acc: 0, NDCG: 0.12690398836070474 HIT: 0.27332508992805754

#### val Acc: 0, NDCG: 0.481257293329026 HIT: 0.5789341872090563
Epoch: 16, plus 0 steps train_loss: 0.742

#### test Acc: 0, NDCG: 0.12330120761165766 HIT: 0.27345899016081254

#### val Acc: 0, NDCG: 0.47526157901197263 HIT: 0.5685040203131612
Epoch: 18, plus 0 steps train_loss: 0.7326

#### test Acc: 0, NDCG: 0.13217278797867307 HIT: 0.28449997355057133

#### val Acc: 0, NDCG: 0.48216246018250297 HIT: 0.5728028790203131
Epoch: 20, plus 0 steps train_loss: 0.7377

#### test Acc: 0, NDCG: 0.1327757296368339 HIT: 0.2897353073423614

#### val Acc: 0, NDCG: 0.4883408987383109 HIT: 0.5856341581146848
Epoch: 22, plus 0 steps train_loss: 0.7313

#### test Acc: 0, NDCG: 0.1428852323392761 HIT: 0.30745890420016925

#### val Acc: 0, NDCG: 0.4792788399746511 HIT: 0.5772835775497249
Epoch: 24, plus 0 steps train_loss: 0.7335

#### test Acc: 0, NDCG: 0.15738665626692824 HIT: 0.3205141768937791

#### val Acc: 0, NDCG: 0.495696324501872 HIT: 0.5827313333157004
Epoch: 26, plus 0 steps train_loss: 0.7219

#### test Acc: 0, NDCG: 0.17737091343389325 HIT: 0.33511674116589085

#### val Acc: 0, NDCG: 0.508913806313454 HIT: 0.5997234381612356
Epoch: 28, plus 0 steps train_loss: 0.7279

#### test Acc: 0, NDCG: 0.17169541577000408 HIT: 0.3350630157638595

#### val Acc: 0, NDCG: 0.5008277615014355 HIT: 0.594346765234871
Epoch: 30, plus 0 steps train_loss: 0.722

#### test Acc: 0, NDCG: 0.18198793081893558 HIT: 0.3472776925518409

#### val Acc: 0, NDCG: 0.5013296917328516 HIT: 0.5966098444773592
Epoch: 32, plus 0 steps train_loss: 0.7161

#### test Acc: 0, NDCG: 0.13501041342058007 HIT: 0.2884177951756242

#### val Acc: 0, NDCG: 0.4731848447479867 HIT: 0.5671195580300465
Epoch: 36, plus 0 steps train_loss: 0.7219

#### test Acc: 0, NDCG: 0.12094168471697021 HIT: 0.26732768197206935

#### val Acc: 0, NDCG: 0.4815918080576047 HIT: 0.5754701385950063
Epoch: 40, plus 0 steps train_loss: 0.7158

#### test Acc: 0, NDCG: 0.2007345559141572 HIT: 0.36328951544646637

#### val Acc: 0, NDCG: 0.514796359110715 HIT: 0.6109098934088024
Epoch: 44, plus 0 steps train_loss: 0.7187

#### test Acc: 0, NDCG: 0.36084239201497326 HIT: 0.5085621759944985

#### val Acc: 0, NDCG: 0.6071041446325387 HIT: 0.6978070117435464
Epoch: 48, plus 0 steps train_loss: 0.7078

#### test Acc: 0, NDCG: 0.5554386769028897 HIT: 0.6695325724714346

#### val Acc: 0, NDCG: 0.7449919679771109 HIT: 0.817079883887008
Epoch: 52, plus 0 steps train_loss: 0.7127

#### test Acc: 0, NDCG: 0.5757813738217876 HIT: 0.6830052502115954

#### val Acc: 0, NDCG: 0.7424573330543778 HIT: 0.8134992924777825
Epoch: 56, plus 0 steps train_loss: 0.7126

#### test Acc: 0, NDCG: 0.5866645648281598 HIT: 0.6907929538721964

#### val Acc: 0, NDCG: 0.7541765349312348 HIT: 0.8211431773698687
Epoch: 60, plus 0 steps train_loss: 0.7127

#### test Acc: 0, NDCG: 0.5742724263681084 HIT: 0.6818927211172239

#### val Acc: 0, NDCG: 0.7554820085667682 HIT: 0.8190867342890394
Epoch: 64, plus 0 steps train_loss: 0.7103

#### test Acc: 0, NDCG: 0.5504105596525464 HIT: 0.6735305689272112

#### val Acc: 0, NDCG: 0.7397237740200664 HIT: 0.8042965443821413
Epoch: 68, plus 0 steps train_loss: 0.7058

#### test Acc: 0, NDCG: 0.5491261513671344 HIT: 0.6679241165890817

#### val Acc: 0, NDCG: 0.7205759834376679 HIT: 0.7861439708527296
Epoch: 72, plus 0 steps train_loss: 0.7056

#### test Acc: 0, NDCG: 0.5130835719497204 HIT: 0.6477704784701651

#### val Acc: 0, NDCG: 0.6967953443111156 HIT: 0.7662085405205248
Epoch: 80, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.2850784257211506 HIT: 0.43748925491959373

#### val Acc: 0, NDCG: 0.5592096876420004 HIT: 0.6443675941599661
Epoch: 88, plus 0 steps train_loss: 0.7072

#### test Acc: 0, NDCG: 0.14510511276783486 HIT: 0.30001008384468897

#### val Acc: 0, NDCG: 0.4843328923979113 HIT: 0.5715027242911553
Epoch: 96, plus 0 steps train_loss: 0.706

#### test Acc: 0, NDCG: 0.43415270893051894 HIT: 0.5618098352200592

#### val Acc: 0, NDCG: 0.6713244292772352 HIT: 0.7461813637325434
Epoch: 104, plus 0 steps train_loss: 0.7039

#### test Acc: 0, NDCG: 0.40938989340406523 HIT: 0.5357720257617435

#### val Acc: 0, NDCG: 0.6483242004873092 HIT: 0.7329574759310199
Epoch: 112, plus 0 steps train_loss: 0.7025

#### test Acc: 0, NDCG: 0.19955682708348485 HIT: 0.3516856551523487

#### val Acc: 0, NDCG: 0.5369840356407795 HIT: 0.628693001481168
Epoch: 120, plus 0 steps train_loss: 0.702

#### test Acc: 0, NDCG: 0.16804365289869275 HIT: 0.3257321532479898

#### val Acc: 0, NDCG: 0.5041663594522683 HIT: 0.5968511955141769
Epoch: 128, plus 0 steps train_loss: 0.7064

#### test Acc: 0, NDCG: 0.15307451543622008 HIT: 0.3067885764917478

#### val Acc: 0, NDCG: 0.5071972815250746 HIT: 0.6015616734553533
Epoch: 136, plus 0 steps train_loss: 0.7027

#### test Acc: 0, NDCG: 0.23422742607668712 HIT: 0.39302693874312317

#### val Acc: 0, NDCG: 0.5257603749077078 HIT: 0.6181727412187897
Epoch: 144, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.5380963857510324 HIT: 0.6654750648011003

#### val Acc: 0, NDCG: 0.7348138510463338 HIT: 0.8098054644519679
Epoch: 160, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.5429019963220676 HIT: 0.6625416578501904

#### val Acc: 0, NDCG: 0.7322454177282164 HIT: 0.8048172675095218
Epoch: 176, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.3294624386854209 HIT: 0.47884789594794747

#### val Acc: 0, NDCG: 0.5835900644602292 HIT: 0.6765829983072366
Epoch: 192, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.5927385371897493 HIT: 0.703932534119763

#### val Acc: 0, NDCG: 0.7527107716324491 HIT: 0.8258958090880236
Epoch: 208, plus 0 steps train_loss: 0.7018

#### test Acc: 0, NDCG: 0.2545454270197448 HIT: 0.3994971302369869

#### val Acc: 0, NDCG: 0.5375668306179755 HIT: 0.6253975679750318
Epoch: 224, plus 0 steps train_loss: 0.6989

#### test Acc: 0, NDCG: 0.6046871685007531 HIT: 0.7143932831675837

#### val Acc: 0, NDCG: 0.7655267058126828 HIT: 0.8319965351248414
Epoch: 240, plus 0 steps train_loss: 0.7013

#### test Acc: 0, NDCG: 0.6199710795304466 HIT: 0.727787439166314

#### val Acc: 0, NDCG: 0.770562884063862 HIT: 0.831870073793906
Epoch: 256, plus 0 steps train_loss: 0.7024

#### test Acc: 0, NDCG: 0.33628775711435516 HIT: 0.4801480506771054

#### val Acc: 0, NDCG: 0.5944495525931534 HIT: 0.6830416181760475
Epoch: 272, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.3292688105352882 HIT: 0.48028195090986037

#### val Acc: 0, NDCG: 0.5983223144658314 HIT: 0.6835433307765553
Epoch: 288, plus 0 steps train_loss: 0.6982

#### test Acc: 0, NDCG: 0.6553598259545766 HIT: 0.7578753173931443

#### val Acc: 0, NDCG: 0.7761541055889252 HIT: 0.8408488282903089
Epoch: 304, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.6249136981053984 HIT: 0.7332657770842149

#### val Acc: 0, NDCG: 0.7743837577939228 HIT: 0.8404140658061785
Epoch: 320, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.6358228984102151 HIT: 0.7407509654041472

#### val Acc: 0, NDCG: 0.7841526251730326 HIT: 0.8456626243123149
Epoch: 352, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.6261501752860476 HIT: 0.7255987489420228

#### val Acc: 0, NDCG: 0.777664999532559 HIT: 0.8404868017350825
Epoch: 384, plus 0 steps train_loss: 0.6989

#### test Acc: 0, NDCG: 0.6501696290758496 HIT: 0.7454862396847228

#### val Acc: 0, NDCG: 0.7860962414698227 HIT: 0.8469321968895472
Epoch: 416, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.6559627234791952 HIT: 0.7568297384151502

#### val Acc: 0, NDCG: 0.7878274957044124 HIT: 0.8509111828184511
Epoch: 448, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.6248219601020178 HIT: 0.7291661156369023

#### val Acc: 0, NDCG: 0.7847013092034989 HIT: 0.8437152851248414
Epoch: 480, plus 0 steps train_loss: 0.6989

#### test Acc: 0, NDCG: 0.6329187641809648 HIT: 0.7354966210854845

#### val Acc: 0, NDCG: 0.7710564056347498 HIT: 0.8368946387008042
Epoch: 512, plus 0 steps train_loss: 0.6972

#### test Acc: 0, NDCG: 0.6129849670281414 HIT: 0.7204882233918747

#### val Acc: 0, NDCG: 0.7695301953930118 HIT: 0.8329098669593736
Epoch: 544, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.6230684802108337 HIT: 0.7284040414727042

#### val Acc: 0, NDCG: 0.7713703854843023 HIT: 0.8384303586542531
Epoch: 576, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.6409656409558577 HIT: 0.7440596236246297

#### val Acc: 0, NDCG: 0.78159074467657 HIT: 0.8377773883834109
Epoch: 608, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.6522034995244655 HIT: 0.749591686944562

#### val Acc: 0, NDCG: 0.7828798573088966 HIT: 0.8464974344054168
Epoch: 640, plus 0 steps train_loss: 0.6972

#### test Acc: 0, NDCG: 0.6393701434854021 HIT: 0.7390524161553111

#### val Acc: 0, NDCG: 0.7842415242585 HIT: 0.8462734408061785
Epoch: 704, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.6417976660562184 HIT: 0.7404674605903513

#### val Acc: 0, NDCG: 0.7923579735448807 HIT: 0.8545934392192128
Epoch: 768, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.6298286398916434 HIT: 0.7362892774016081

#### val Acc: 0, NDCG: 0.7804277061841287 HIT: 0.8421316255818875
Epoch: 832, plus 0 steps train_loss: 0.6942

#### test Acc: 0, NDCG: 0.631381738093893 HIT: 0.7338881652031316

#### val Acc: 0, NDCG: 0.7930079124546809 HIT: 0.8558456543588658
Epoch: 896, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.6425165254806032 HIT: 0.7495495331675837

#### val Acc: 0, NDCG: 0.7827684779587613 HIT: 0.8434433519360982
Epoch: 960, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.6488062719239757 HIT: 0.7528755488256453

#### val Acc: 0, NDCG: 0.7800415614947458 HIT: 0.8456320421603893
Epoch: 1017, plus 0 steps train_loss: 0.6963
Done: it took 78632.24401068687
max value of NDCG: 0.6559627234791952
max value of HIT: 0.7578753173931443

After 20 validations
max value of NDCG: 0.6559627234791952
max value of HIT: 0.7578753173931443
