 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	1.0
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
RMHA_decoder:         	False
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_encoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12742541271885258 HIT: 0.28078469669117645

#### val Acc: 0, NDCG: 0.1316665943898025 HIT: 0.2876780790441177
Epoch: 1, plus 0 steps train_loss: 0.7766

#### test Acc: 0, NDCG: 0.12323461842990693 HIT: 0.2759363511029412

#### val Acc: 0, NDCG: 0.12941928512290576 HIT: 0.2866268382352941
Epoch: 2, plus 0 steps train_loss: 0.7691

#### test Acc: 0, NDCG: 0.1273644594353816 HIT: 0.2823069852941177

#### val Acc: 0, NDCG: 0.13253989222983692 HIT: 0.28889590992647063
Epoch: 3, plus 0 steps train_loss: 0.7652

#### test Acc: 0, NDCG: 0.12863195534363409 HIT: 0.28120404411764705

#### val Acc: 0, NDCG: 0.12739306822161126 HIT: 0.2794864430147059
Epoch: 4, plus 0 steps train_loss: 0.7583

#### test Acc: 0, NDCG: 0.12774510514884097 HIT: 0.2804744944852941

#### val Acc: 0, NDCG: 0.12975290721702445 HIT: 0.2843060661764706
Epoch: 5, plus 0 steps train_loss: 0.7466

#### test Acc: 0, NDCG: 0.13353766223694713 HIT: 0.2922679227941177

#### val Acc: 0, NDCG: 0.12671420291029684 HIT: 0.2775677849264706
Epoch: 6, plus 0 steps train_loss: 0.7456

#### test Acc: 0, NDCG: 0.13132070720295924 HIT: 0.2923368566176471

#### val Acc: 0, NDCG: 0.1300451850747592 HIT: 0.28498965992647063
Epoch: 7, plus 0 steps train_loss: 0.7403

#### test Acc: 0, NDCG: 0.12850957282864903 HIT: 0.2821978400735294

#### val Acc: 0, NDCG: 0.13120345694888141 HIT: 0.28721852022058825
Epoch: 8, plus 0 steps train_loss: 0.7387

#### test Acc: 0, NDCG: 0.13245091879216866 HIT: 0.2900333180147059

#### val Acc: 0, NDCG: 0.12948373959185203 HIT: 0.28552389705882353
Epoch: 9, plus 0 steps train_loss: 0.7371

#### test Acc: 0, NDCG: 0.12491868079740635 HIT: 0.28141659007352937

#### val Acc: 0, NDCG: 0.13074078394312905 HIT: 0.28673023897058825
Epoch: 10, plus 0 steps train_loss: 0.7227

#### test Acc: 0, NDCG: 0.12614300243769444 HIT: 0.2772001378676471

#### val Acc: 0, NDCG: 0.12786334244465092 HIT: 0.2820369944852941
Epoch: 12, plus 0 steps train_loss: 0.7279

#### test Acc: 0, NDCG: 0.1283205182882399 HIT: 0.2816521139705882

#### val Acc: 0, NDCG: 0.1296005205526734 HIT: 0.28803423713235293
Epoch: 14, plus 0 steps train_loss: 0.7256

#### test Acc: 0, NDCG: 0.12883135652897174 HIT: 0.27960707720588235

#### val Acc: 0, NDCG: 0.1278730398681684 HIT: 0.2797104779411764
Epoch: 16, plus 0 steps train_loss: 0.7249

#### test Acc: 0, NDCG: 0.12857488892420157 HIT: 0.2855181525735294

#### val Acc: 0, NDCG: 0.13837208242994553 HIT: 0.2995461856617647
Epoch: 18, plus 0 steps train_loss: 0.7184

#### test Acc: 0, NDCG: 0.12956861115620927 HIT: 0.2907398897058823

#### val Acc: 0, NDCG: 0.1300848866494064 HIT: 0.28879250919117644
Epoch: 20, plus 0 steps train_loss: 0.7184

#### test Acc: 0, NDCG: 0.13247920745491687 HIT: 0.2889246323529412

#### val Acc: 0, NDCG: 0.12780005826034482 HIT: 0.28415670955882355
Epoch: 22, plus 0 steps train_loss: 0.7156

#### test Acc: 0, NDCG: 0.13090601360906165 HIT: 0.28935546875

#### val Acc: 0, NDCG: 0.12956778628365886 HIT: 0.28698874080882353
Epoch: 24, plus 0 steps train_loss: 0.7156

#### test Acc: 0, NDCG: 0.12931767249760792 HIT: 0.28336397058823526

#### val Acc: 0, NDCG: 0.13428659469161902 HIT: 0.29636374080882355
Epoch: 26, plus 0 steps train_loss: 0.713

#### test Acc: 0, NDCG: 0.12950628294222838 HIT: 0.28461626838235293

#### val Acc: 0, NDCG: 0.13293715284015603 HIT: 0.2884995404411764
Epoch: 28, plus 0 steps train_loss: 0.7081

#### test Acc: 0, NDCG: 0.1302530456034229 HIT: 0.28830422794117644

#### val Acc: 0, NDCG: 0.13249139857048964 HIT: 0.2891256893382353
Epoch: 30, plus 0 steps train_loss: 0.707

#### test Acc: 0, NDCG: 0.13357124839834883 HIT: 0.2938706341911764

#### val Acc: 0, NDCG: 0.12460251754033144 HIT: 0.27626378676470587
Epoch: 32, plus 0 steps train_loss: 0.705

#### test Acc: 0, NDCG: 0.1348137476411741 HIT: 0.29002182904411766

#### val Acc: 0, NDCG: 0.12982511250709095 HIT: 0.28178423713235295
Epoch: 36, plus 0 steps train_loss: 0.7101

#### test Acc: 0, NDCG: 0.12765422476687563 HIT: 0.28077895220588234

#### val Acc: 0, NDCG: 0.1344869755544525 HIT: 0.29488740808823527
Epoch: 40, plus 0 steps train_loss: 0.7069

#### test Acc: 0, NDCG: 0.131935822183026 HIT: 0.2905215992647059

#### val Acc: 0, NDCG: 0.1254169145146928 HIT: 0.2788775275735294
Epoch: 44, plus 0 steps train_loss: 0.7023

#### test Acc: 0, NDCG: 0.13056690112364064 HIT: 0.28924057904411765

#### val Acc: 0, NDCG: 0.13188861032697594 HIT: 0.2878044577205882
Epoch: 48, plus 0 steps train_loss: 0.704

#### test Acc: 0, NDCG: 0.12864311963972674 HIT: 0.28636833639705883

#### val Acc: 0, NDCG: 0.12914224417074033 HIT: 0.28259420955882353
Epoch: 52, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.13419024581000813 HIT: 0.2976275275735294

#### val Acc: 0, NDCG: 0.1280296077401843 HIT: 0.28430032169117647
Epoch: 56, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.1277749488499938 HIT: 0.27956686580882356

#### val Acc: 0, NDCG: 0.129003804696606 HIT: 0.2831973805147059
Epoch: 60, plus 0 steps train_loss: 0.7017

#### test Acc: 0, NDCG: 0.12814348075647092 HIT: 0.2837833180147059

#### val Acc: 0, NDCG: 0.13306274252668784 HIT: 0.2906709558823529
Epoch: 64, plus 0 steps train_loss: 0.701

#### test Acc: 0, NDCG: 0.13241833838148273 HIT: 0.29396254595588234

#### val Acc: 0, NDCG: 0.1277059109379564 HIT: 0.2802676930147059
Epoch: 68, plus 0 steps train_loss: 0.702

#### test Acc: 0, NDCG: 0.12839542888129718 HIT: 0.2841796875

#### val Acc: 0, NDCG: 0.1345866490071393 HIT: 0.29273322610294117
Epoch: 72, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.12969598049940984 HIT: 0.2902458639705882

#### val Acc: 0, NDCG: 0.13243810854098376 HIT: 0.2924115349264706
Epoch: 80, plus 0 steps train_loss: 0.7002

#### test Acc: 0, NDCG: 0.13587348041936015 HIT: 0.2981962316176471

#### val Acc: 0, NDCG: 0.13502052145892524 HIT: 0.29410041360294115
Epoch: 88, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.13218234070444657 HIT: 0.2927734375

#### val Acc: 0, NDCG: 0.1276685258137199 HIT: 0.27801585477941176
Epoch: 96, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.13877004024367018 HIT: 0.29761603860294117

#### val Acc: 0, NDCG: 0.14119788856560417 HIT: 0.29913258272058824
Epoch: 104, plus 0 steps train_loss: 0.6984

#### test Acc: 0, NDCG: 0.2567381629940132 HIT: 0.4163143382352941

#### val Acc: 0, NDCG: 0.2660822737166718 HIT: 0.4225298713235294
Epoch: 112, plus 0 steps train_loss: 0.6995

#### test Acc: 0, NDCG: 0.38002152940768297 HIT: 0.5283720128676471

#### val Acc: 0, NDCG: 0.39428188132318165 HIT: 0.54365234375
Epoch: 120, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.46117825352737885 HIT: 0.6006778492647059

#### val Acc: 0, NDCG: 0.47059306683647917 HIT: 0.6120232077205883
Epoch: 128, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.4821705539071184 HIT: 0.6183478860294118

#### val Acc: 0, NDCG: 0.4866381731518746 HIT: 0.6260052849264706
Epoch: 136, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.4851551718275108 HIT: 0.6254308363970588

#### val Acc: 0, NDCG: 0.5010647502772244 HIT: 0.6367015165441177
Epoch: 144, plus 0 steps train_loss: 0.6943

#### test Acc: 0, NDCG: 0.4300391365767936 HIT: 0.5733743106617647

#### val Acc: 0, NDCG: 0.43910585428695736 HIT: 0.5825597426470588
Epoch: 160, plus 0 steps train_loss: 0.6913

#### test Acc: 0, NDCG: 0.47835811135202616 HIT: 0.6124712775735295

#### val Acc: 0, NDCG: 0.48804357357984446 HIT: 0.6274758731617647
Epoch: 176, plus 0 steps train_loss: 0.6896

#### test Acc: 0, NDCG: 0.4473346014212615 HIT: 0.5943704044117647

#### val Acc: 0, NDCG: 0.4638648138667515 HIT: 0.6074965533088236
Epoch: 192, plus 0 steps train_loss: 0.6911

#### test Acc: 0, NDCG: 0.5075308159278685 HIT: 0.6391371783088236

#### val Acc: 0, NDCG: 0.5216027145350985 HIT: 0.6524988511029413
Epoch: 208, plus 0 steps train_loss: 0.6882

#### test Acc: 0, NDCG: 0.5070855519630055 HIT: 0.6415843290441177

#### val Acc: 0, NDCG: 0.5187056555185655 HIT: 0.6462545955882353
Epoch: 224, plus 0 steps train_loss: 0.6859

#### test Acc: 0, NDCG: 0.5161184043280059 HIT: 0.6486385569852942

#### val Acc: 0, NDCG: 0.5291243780085432 HIT: 0.6630744485294118
Epoch: 240, plus 0 steps train_loss: 0.6857

#### test Acc: 0, NDCG: 0.5211280745073683 HIT: 0.6531594669117646

#### val Acc: 0, NDCG: 0.5139506321596984 HIT: 0.6463062959558823
Epoch: 256, plus 0 steps train_loss: 0.6811

#### test Acc: 0, NDCG: 0.5215254021223263 HIT: 0.6494140625

#### val Acc: 0, NDCG: 0.5283172080153407 HIT: 0.6573184742647059
Epoch: 272, plus 0 steps train_loss: 0.6814

#### test Acc: 0, NDCG: 0.5096313976761824 HIT: 0.6411247702205882

#### val Acc: 0, NDCG: 0.5211605199904851 HIT: 0.6507008272058823
Epoch: 288, plus 0 steps train_loss: 0.6802

#### test Acc: 0, NDCG: 0.4987074653115363 HIT: 0.6422162224264706

#### val Acc: 0, NDCG: 0.5106950658236049 HIT: 0.6505687040441177
Epoch: 304, plus 0 steps train_loss: 0.6802

#### test Acc: 0, NDCG: 0.5104547676926804 HIT: 0.6386086856617647

#### val Acc: 0, NDCG: 0.5161709074091142 HIT: 0.6454388786764705
Epoch: 320, plus 0 steps train_loss: 0.6747

#### test Acc: 0, NDCG: 0.46327749767163395 HIT: 0.6211684283088236

#### val Acc: 0, NDCG: 0.4777031942611745 HIT: 0.6323529411764706
Epoch: 352, plus 0 steps train_loss: 0.6699

#### test Acc: 0, NDCG: 0.4450467091403665 HIT: 0.6143669577205882

#### val Acc: 0, NDCG: 0.4465024618200605 HIT: 0.6115291819852942
Epoch: 384, plus 0 steps train_loss: 0.6696

#### test Acc: 0, NDCG: 0.41512807909280064 HIT: 0.5851849724264706

#### val Acc: 0, NDCG: 0.4349946442604497 HIT: 0.6122127757352941
Epoch: 416, plus 0 steps train_loss: 0.6657

#### test Acc: 0, NDCG: 0.41440144087029324 HIT: 0.5892061121323529

#### val Acc: 0, NDCG: 0.43469265549269487 HIT: 0.6095932904411765
Epoch: 448, plus 0 steps train_loss: 0.6604

#### test Acc: 0, NDCG: 0.35089682921000176 HIT: 0.5550723805147059

#### val Acc: 0, NDCG: 0.364686619622032 HIT: 0.5623161764705882
Epoch: 480, plus 0 steps train_loss: 0.6611

#### test Acc: 0, NDCG: 0.34353471023004545 HIT: 0.5457778033088235

#### val Acc: 0, NDCG: 0.34536083089973324 HIT: 0.5445427389705882
Epoch: 512, plus 0 steps train_loss: 0.6474

#### test Acc: 0, NDCG: 0.30678336558976127 HIT: 0.5099034926470588

#### val Acc: 0, NDCG: 0.3110639998644229 HIT: 0.5123563878676471
Epoch: 544, plus 0 steps train_loss: 0.6591

#### test Acc: 0, NDCG: 0.27498835178169 HIT: 0.4894703584558823

#### val Acc: 0, NDCG: 0.2855810376238088 HIT: 0.4982019761029412
Epoch: 576, plus 0 steps train_loss: 0.6441

#### test Acc: 0, NDCG: 0.2563146344392284 HIT: 0.47019186580882355

#### val Acc: 0, NDCG: 0.2628966944493999 HIT: 0.4765567555147059
Epoch: 608, plus 0 steps train_loss: 0.6434

#### test Acc: 0, NDCG: 0.2590016587503695 HIT: 0.46775620404411766

#### val Acc: 0, NDCG: 0.262713907861866 HIT: 0.4745691636029412
Epoch: 640, plus 0 steps train_loss: 0.6324

#### test Acc: 0, NDCG: 0.26329252293553773 HIT: 0.4820657169117647

#### val Acc: 0, NDCG: 0.26413601965788197 HIT: 0.47947495404411766
Epoch: 704, plus 0 steps train_loss: 0.644

#### test Acc: 0, NDCG: 0.2629415745394418 HIT: 0.47922219669117644

#### val Acc: 0, NDCG: 0.27193457410166316 HIT: 0.4881376378676471
Epoch: 768, plus 0 steps train_loss: 0.6166

#### test Acc: 0, NDCG: 0.26757756828641044 HIT: 0.47808478860294124

#### val Acc: 0, NDCG: 0.26441482638503633 HIT: 0.4802274816176471
Epoch: 832, plus 0 steps train_loss: 0.6205

#### test Acc: 0, NDCG: 0.27142329796838177 HIT: 0.4938936121323529

#### val Acc: 0, NDCG: 0.2678163657993867 HIT: 0.47943474264705876
Epoch: 896, plus 0 steps train_loss: 0.6193

#### test Acc: 0, NDCG: 0.2672654646851059 HIT: 0.4745978860294118

#### val Acc: 0, NDCG: 0.2762357737071669 HIT: 0.4906824448529412
Epoch: 960, plus 0 steps train_loss: 0.6062

#### test Acc: 0, NDCG: 0.2633922364529696 HIT: 0.47629825367647055

#### val Acc: 0, NDCG: 0.2793985748432394 HIT: 0.49853515625
Epoch: 1013, plus 25 steps train_loss: 0.623
Done: it took 297616.662381649
max value of NDCG: 0.5215254021223263
max value of HIT: 0.6531594669117646

After 20 validations
max value of NDCG: 0.5215254021223263
max value of HIT: 0.6531594669117646
