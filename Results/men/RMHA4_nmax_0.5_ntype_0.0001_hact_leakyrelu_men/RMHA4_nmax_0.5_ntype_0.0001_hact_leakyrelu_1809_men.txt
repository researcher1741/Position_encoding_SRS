 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.0001
max_norm:             	0.5
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13143837781152334 HIT: 0.29246323529411766

#### val Acc: 0, NDCG: 0.1278180936437933 HIT: 0.27995749080882354
Epoch: 1, plus 0 steps train_loss: 0.762

#### test Acc: 0, NDCG: 0.1285810404131891 HIT: 0.2882869944852941

#### val Acc: 0, NDCG: 0.127257948818584 HIT: 0.2795209099264706
Epoch: 2, plus 0 steps train_loss: 0.7708

#### test Acc: 0, NDCG: 0.13438892254794715 HIT: 0.2960994944852941

#### val Acc: 0, NDCG: 0.12255831693216941 HIT: 0.2732364430147059
Epoch: 3, plus 0 steps train_loss: 0.7573

#### test Acc: 0, NDCG: 0.13217942862144771 HIT: 0.28895335477941175

#### val Acc: 0, NDCG: 0.13221069810601435 HIT: 0.28952780330882355
Epoch: 4, plus 0 steps train_loss: 0.756

#### test Acc: 0, NDCG: 0.13163448999518088 HIT: 0.2892578125

#### val Acc: 0, NDCG: 0.12797756940981322 HIT: 0.28330652573529413
Epoch: 5, plus 0 steps train_loss: 0.7406

#### test Acc: 0, NDCG: 0.132923334734462 HIT: 0.2913028492647059

#### val Acc: 0, NDCG: 0.13072858765040468 HIT: 0.2897805606617647
Epoch: 6, plus 0 steps train_loss: 0.7248

#### test Acc: 0, NDCG: 0.13367267441000294 HIT: 0.2870174632352941

#### val Acc: 0, NDCG: 0.12664219899200224 HIT: 0.27808478860294117
Epoch: 7, plus 0 steps train_loss: 0.7211

#### test Acc: 0, NDCG: 0.1519111128149979 HIT: 0.3086799172794118

#### val Acc: 0, NDCG: 0.15363120923029822 HIT: 0.3080767463235294
Epoch: 8, plus 0 steps train_loss: 0.7182

#### test Acc: 0, NDCG: 0.17103339965608305 HIT: 0.32368451286764705

#### val Acc: 0, NDCG: 0.18499757803298433 HIT: 0.33986098345588234
Epoch: 9, plus 0 steps train_loss: 0.7132

#### test Acc: 0, NDCG: 0.1698996206004429 HIT: 0.3225528492647059

#### val Acc: 0, NDCG: 0.18546193283370072 HIT: 0.34326171875
Epoch: 10, plus 0 steps train_loss: 0.707

#### test Acc: 0, NDCG: 0.22114439240891032 HIT: 0.37798138786764707

#### val Acc: 0, NDCG: 0.23367105553619547 HIT: 0.3835650275735294
Epoch: 12, plus 0 steps train_loss: 0.7082

#### test Acc: 0, NDCG: 0.24949813893089928 HIT: 0.39825942095588235

#### val Acc: 0, NDCG: 0.27245490311310955 HIT: 0.41799172794117645
Epoch: 14, plus 0 steps train_loss: 0.7077

#### test Acc: 0, NDCG: 0.3296438251405382 HIT: 0.4748104319852941

#### val Acc: 0, NDCG: 0.34141100986835693 HIT: 0.4807559742647059
Epoch: 16, plus 0 steps train_loss: 0.7027

#### test Acc: 0, NDCG: 0.3406729351911009 HIT: 0.4896484375

#### val Acc: 0, NDCG: 0.3528963896849089 HIT: 0.5001895680147059
Epoch: 18, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.4773054331286062 HIT: 0.6078986672794118

#### val Acc: 0, NDCG: 0.4892908347005684 HIT: 0.6154296875
Epoch: 20, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.5154419067919583 HIT: 0.6383961397058824

#### val Acc: 0, NDCG: 0.5212439158217396 HIT: 0.6427676930147059
Epoch: 22, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.5433679778185896 HIT: 0.6611787683823529

#### val Acc: 0, NDCG: 0.5548363688428986 HIT: 0.6690314797794118
Epoch: 24, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.5463545032862813 HIT: 0.6685776654411765

#### val Acc: 0, NDCG: 0.5426926701950918 HIT: 0.6665556066176471
Epoch: 26, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.4813138155703798 HIT: 0.6207146139705882

#### val Acc: 0, NDCG: 0.4918569159747155 HIT: 0.6259478400735294
Epoch: 28, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.4963590098446454 HIT: 0.6313074448529412

#### val Acc: 0, NDCG: 0.514418963623652 HIT: 0.6478458180147059
Epoch: 30, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.49701464535891704 HIT: 0.6336684283088235

#### val Acc: 0, NDCG: 0.5070448261071289 HIT: 0.6463350183823529
Epoch: 32, plus 0 steps train_loss: 0.701

#### test Acc: 0, NDCG: 0.48795711221732896 HIT: 0.6248736213235294

#### val Acc: 0, NDCG: 0.5065960885849774 HIT: 0.6343003216911764
Epoch: 36, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.47138617912714764 HIT: 0.6135799632352941

#### val Acc: 0, NDCG: 0.48287091681771355 HIT: 0.6241613051470588
Epoch: 40, plus 0 steps train_loss: 0.6927

#### test Acc: 0, NDCG: 0.4726362296862126 HIT: 0.6168141084558824

#### val Acc: 0, NDCG: 0.4827688675177578 HIT: 0.6244600183823529
Epoch: 44, plus 0 steps train_loss: 0.6921

#### test Acc: 0, NDCG: 0.21195052284645852 HIT: 0.4043428308823529

#### val Acc: 0, NDCG: 0.2293227134211297 HIT: 0.4224437040441177
Epoch: 48, plus 0 steps train_loss: 0.6791

#### test Acc: 0, NDCG: 0.23563148706898995 HIT: 0.44610523897058824

#### val Acc: 0, NDCG: 0.24730381100409296 HIT: 0.4540900735294118
Epoch: 52, plus 0 steps train_loss: 0.6736

#### test Acc: 0, NDCG: 0.21697644953530953 HIT: 0.4366785386029412

#### val Acc: 0, NDCG: 0.22550928997539216 HIT: 0.44309512867647055
Epoch: 56, plus 0 steps train_loss: 0.6609

#### test Acc: 0, NDCG: 0.22327751906252996 HIT: 0.4521369485294118

#### val Acc: 0, NDCG: 0.2300598148307434 HIT: 0.4530388327205882
Epoch: 60, plus 0 steps train_loss: 0.6542

#### test Acc: 0, NDCG: 0.22866235713173683 HIT: 0.45155101102941175

#### val Acc: 0, NDCG: 0.23577965586800714 HIT: 0.4603170955882353
Epoch: 64, plus 0 steps train_loss: 0.6459

#### test Acc: 0, NDCG: 0.23766130518641101 HIT: 0.4716394761029412

#### val Acc: 0, NDCG: 0.24518369090771142 HIT: 0.47857881433823535
Epoch: 68, plus 0 steps train_loss: 0.6302

#### test Acc: 0, NDCG: 0.2429566333451382 HIT: 0.4707088694852941

#### val Acc: 0, NDCG: 0.248576972652103 HIT: 0.47959558823529413
Epoch: 72, plus 0 steps train_loss: 0.6266

#### test Acc: 0, NDCG: 0.25494164884776344 HIT: 0.48976907169117645

#### val Acc: 0, NDCG: 0.2590727360072632 HIT: 0.4935029871323529
Epoch: 80, plus 0 steps train_loss: 0.6348

#### test Acc: 0, NDCG: 0.26074407128743954 HIT: 0.4972598805147059

#### val Acc: 0, NDCG: 0.27223804579970035 HIT: 0.5079446231617647
Epoch: 88, plus 0 steps train_loss: 0.6297

#### test Acc: 0, NDCG: 0.2706649265201387 HIT: 0.5096622242647059

#### val Acc: 0, NDCG: 0.2865959031459052 HIT: 0.5271254595588235
Epoch: 96, plus 0 steps train_loss: 0.6186

#### test Acc: 0, NDCG: 0.2827975761566789 HIT: 0.5344956341911764

#### val Acc: 0, NDCG: 0.2932934948261819 HIT: 0.5364315257352941
Epoch: 104, plus 0 steps train_loss: 0.6097

#### test Acc: 0, NDCG: 0.2912477927828655 HIT: 0.5333065257352941

#### val Acc: 0, NDCG: 0.30064288983971105 HIT: 0.5400965073529412
Epoch: 112, plus 0 steps train_loss: 0.6044

#### test Acc: 0, NDCG: 0.3042412043035665 HIT: 0.5492417279411764

#### val Acc: 0, NDCG: 0.3040187934745262 HIT: 0.5424287683823529
Epoch: 120, plus 0 steps train_loss: 0.5919

#### test Acc: 0, NDCG: 0.3007140375207894 HIT: 0.5373104319852942

#### val Acc: 0, NDCG: 0.3082013921784149 HIT: 0.5470415900735295
Epoch: 128, plus 0 steps train_loss: 0.5852

#### test Acc: 0, NDCG: 0.30684581580224646 HIT: 0.5502987132352941

#### val Acc: 0, NDCG: 0.3146089399921882 HIT: 0.5512235753676471
Epoch: 136, plus 0 steps train_loss: 0.6003

#### test Acc: 0, NDCG: 0.3073624088312663 HIT: 0.54638671875

#### val Acc: 0, NDCG: 0.31141029632154493 HIT: 0.5492015165441176
Epoch: 144, plus 0 steps train_loss: 0.5932

#### test Acc: 0, NDCG: 0.32187625464717196 HIT: 0.5679285386029412

#### val Acc: 0, NDCG: 0.3288692194811088 HIT: 0.5710305606617647
Epoch: 160, plus 0 steps train_loss: 0.5741

#### test Acc: 0, NDCG: 0.3221760114394915 HIT: 0.5644071691176471

#### val Acc: 0, NDCG: 0.33317789889112587 HIT: 0.5708467371323529
Epoch: 176, plus 0 steps train_loss: 0.5704

#### test Acc: 0, NDCG: 0.3274952314663619 HIT: 0.5688074448529412

#### val Acc: 0, NDCG: 0.33052928320249597 HIT: 0.5711397058823529
Epoch: 192, plus 0 steps train_loss: 0.5805

#### test Acc: 0, NDCG: 0.3297606887187272 HIT: 0.5771771599264706

#### val Acc: 0, NDCG: 0.33628618080396355 HIT: 0.5764935661764705
Epoch: 208, plus 0 steps train_loss: 0.584

#### test Acc: 0, NDCG: 0.3409266372591898 HIT: 0.5851390165441177

#### val Acc: 0, NDCG: 0.3489108719989874 HIT: 0.5870978860294118
Epoch: 224, plus 0 steps train_loss: 0.5664

#### test Acc: 0, NDCG: 0.33491053645040636 HIT: 0.5731789981617647

#### val Acc: 0, NDCG: 0.342108442652723 HIT: 0.5875919117647059
Epoch: 240, plus 0 steps train_loss: 0.5583

#### test Acc: 0, NDCG: 0.3436391945398092 HIT: 0.58359375

#### val Acc: 0, NDCG: 0.3581096859897568 HIT: 0.5960305606617646
Epoch: 256, plus 0 steps train_loss: 0.546

#### test Acc: 0, NDCG: 0.34795684272215005 HIT: 0.5848000919117646

#### val Acc: 0, NDCG: 0.3587828501194527 HIT: 0.6032169117647059
Epoch: 272, plus 0 steps train_loss: 0.5609

#### test Acc: 0, NDCG: 0.35323682936110995 HIT: 0.5922506893382353

#### val Acc: 0, NDCG: 0.36007757053638295 HIT: 0.6060604319852941
Epoch: 288, plus 0 steps train_loss: 0.5429

#### test Acc: 0, NDCG: 0.3583941900737325 HIT: 0.5970013786764705

#### val Acc: 0, NDCG: 0.3714903860547173 HIT: 0.6150505514705882
Epoch: 304, plus 0 steps train_loss: 0.5222

#### test Acc: 0, NDCG: 0.3584244735551728 HIT: 0.5964384191176471

#### val Acc: 0, NDCG: 0.3676382295190176 HIT: 0.6063246783088235
Epoch: 320, plus 0 steps train_loss: 0.537

#### test Acc: 0, NDCG: 0.36392089881039047 HIT: 0.6016716452205882

#### val Acc: 0, NDCG: 0.3760280421515893 HIT: 0.6154928768382353
Epoch: 352, plus 0 steps train_loss: 0.5478

#### test Acc: 0, NDCG: 0.3701459320432431 HIT: 0.6089499080882353

#### val Acc: 0, NDCG: 0.3914505456868171 HIT: 0.6272920496323529
Epoch: 384, plus 0 steps train_loss: 0.5325

#### test Acc: 0, NDCG: 0.37703003368005084 HIT: 0.6170266544117646

#### val Acc: 0, NDCG: 0.3894030465522451 HIT: 0.6275735294117647
Epoch: 416, plus 0 steps train_loss: 0.5223

#### test Acc: 0, NDCG: 0.37465586408135815 HIT: 0.6147863051470588

#### val Acc: 0, NDCG: 0.3918896178420234 HIT: 0.6336799172794118
Epoch: 448, plus 0 steps train_loss: 0.4968

#### test Acc: 0, NDCG: 0.37403748528632097 HIT: 0.6158030790441177

#### val Acc: 0, NDCG: 0.39908160004935567 HIT: 0.6365866268382353
Epoch: 480, plus 0 steps train_loss: 0.5022

#### test Acc: 0, NDCG: 0.38328950343691687 HIT: 0.6171243106617647

#### val Acc: 0, NDCG: 0.39761927173202793 HIT: 0.6371151194852941
Epoch: 512, plus 0 steps train_loss: 0.5346

#### test Acc: 0, NDCG: 0.3833340605308133 HIT: 0.6143784466911765

#### val Acc: 0, NDCG: 0.3979275422245315 HIT: 0.6405618106617647
Epoch: 544, plus 0 steps train_loss: 0.4994

#### test Acc: 0, NDCG: 0.38763602258322616 HIT: 0.6229549632352941

#### val Acc: 0, NDCG: 0.4024811232316348 HIT: 0.6455365349264706
Epoch: 576, plus 0 steps train_loss: 0.509

#### test Acc: 0, NDCG: 0.38533910955053613 HIT: 0.6231043198529412

#### val Acc: 0, NDCG: 0.40941970464691496 HIT: 0.6508042279411764
Epoch: 608, plus 0 steps train_loss: 0.4933

#### test Acc: 0, NDCG: 0.384354680594398 HIT: 0.6209903492647059

#### val Acc: 0, NDCG: 0.4048869262922364 HIT: 0.6459788602941177
Epoch: 640, plus 0 steps train_loss: 0.4811

#### test Acc: 0, NDCG: 0.3915696883639085 HIT: 0.6257352941176471

#### val Acc: 0, NDCG: 0.40618410265515237 HIT: 0.6519129136029412
Epoch: 704, plus 0 steps train_loss: 0.47

#### test Acc: 0, NDCG: 0.38837617262235347 HIT: 0.6228630514705882

#### val Acc: 0, NDCG: 0.40396243763256584 HIT: 0.6453929227941176
Epoch: 768, plus 0 steps train_loss: 0.4723

#### test Acc: 0, NDCG: 0.3926959727009874 HIT: 0.6334903492647059

#### val Acc: 0, NDCG: 0.40541469324581564 HIT: 0.6433708639705882
Epoch: 832, plus 0 steps train_loss: 0.4776

#### test Acc: 0, NDCG: 0.3926806556993967 HIT: 0.6285960477941177

#### val Acc: 0, NDCG: 0.3997408547101692 HIT: 0.6322495404411764
Epoch: 896, plus 0 steps train_loss: 0.4685

#### test Acc: 0, NDCG: 0.39432338385344023 HIT: 0.6295783547794118

#### val Acc: 0, NDCG: 0.40687777104369155 HIT: 0.6447954963235294
Epoch: 960, plus 0 steps train_loss: 0.471

#### test Acc: 0, NDCG: 0.391171345264576 HIT: 0.6255514705882353

#### val Acc: 0, NDCG: 0.40357581639935647 HIT: 0.6469094669117647
Epoch: 1013, plus 25 steps train_loss: 0.4784
Done: it took 285572.28854846954
max value of NDCG: 0.5463545032862813
max value of HIT: 0.6685776654411765

After 20 validations
max value of NDCG: 0.48795711221732896
max value of HIT: 0.6334903492647059
