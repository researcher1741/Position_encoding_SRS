 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	0.0001
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.1265290978606261 HIT: 0.28109489889705885

#### val Acc: 0, NDCG: 0.13214297914006948 HIT: 0.29593290441176473
Epoch: 1, plus 0 steps train_loss: 0.7463

#### test Acc: 0, NDCG: 0.13228989198596192 HIT: 0.29418658088235294

#### val Acc: 0, NDCG: 0.13402468320668737 HIT: 0.2931583180147059
Epoch: 2, plus 0 steps train_loss: 0.7305

#### test Acc: 0, NDCG: 0.1519089246701153 HIT: 0.3023782169117647

#### val Acc: 0, NDCG: 0.15055010891032872 HIT: 0.30236098345588236
Epoch: 3, plus 0 steps train_loss: 0.7125

#### test Acc: 0, NDCG: 0.14341845438118478 HIT: 0.2914407169117647

#### val Acc: 0, NDCG: 0.14083681866821063 HIT: 0.29069967830882354
Epoch: 4, plus 0 steps train_loss: 0.7092

#### test Acc: 0, NDCG: 0.14957213338569472 HIT: 0.30959329044117645

#### val Acc: 0, NDCG: 0.1520923187613346 HIT: 0.3178998161764706
Epoch: 5, plus 0 steps train_loss: 0.7078

#### test Acc: 0, NDCG: 0.18152751631520608 HIT: 0.3433880974264706

#### val Acc: 0, NDCG: 0.17865405015042263 HIT: 0.34216452205882353
Epoch: 6, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.19685861068673904 HIT: 0.3583352481617647

#### val Acc: 0, NDCG: 0.18678852843458826 HIT: 0.3440372242647059
Epoch: 7, plus 0 steps train_loss: 0.706

#### test Acc: 0, NDCG: 0.21967153262102287 HIT: 0.40197035845588236

#### val Acc: 0, NDCG: 0.21346177459176632 HIT: 0.3895737591911764
Epoch: 8, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.440704544343742 HIT: 0.5820772058823529

#### val Acc: 0, NDCG: 0.41741958956604847 HIT: 0.5663373161764705
Epoch: 9, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.39745253287711846 HIT: 0.5555376838235294

#### val Acc: 0, NDCG: 0.39117030517300616 HIT: 0.5526137408088235
Epoch: 10, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.22656299840326977 HIT: 0.45167738970588234

#### val Acc: 0, NDCG: 0.23187293661756841 HIT: 0.460546875
Epoch: 12, plus 0 steps train_loss: 0.6761

#### test Acc: 0, NDCG: 0.22589587628309635 HIT: 0.4545783547794118

#### val Acc: 0, NDCG: 0.2330704775951435 HIT: 0.47179457720588236
Epoch: 14, plus 0 steps train_loss: 0.6702

#### test Acc: 0, NDCG: 0.24315688879195774 HIT: 0.48817210477941175

#### val Acc: 0, NDCG: 0.2479416357739635 HIT: 0.49549632352941175
Epoch: 16, plus 0 steps train_loss: 0.6454

#### test Acc: 0, NDCG: 0.25255698848641184 HIT: 0.5024586397058823

#### val Acc: 0, NDCG: 0.2517761557724647 HIT: 0.5017980238970587
Epoch: 18, plus 0 steps train_loss: 0.6412

#### test Acc: 0, NDCG: 0.25404561692329164 HIT: 0.5090475643382353

#### val Acc: 0, NDCG: 0.24941991467447916 HIT: 0.4999655330882353
Epoch: 20, plus 0 steps train_loss: 0.6194

#### test Acc: 0, NDCG: 0.26689812902971083 HIT: 0.5229434742647059

#### val Acc: 0, NDCG: 0.27332772179446085 HIT: 0.5355985753676471
Epoch: 22, plus 0 steps train_loss: 0.6214

#### test Acc: 0, NDCG: 0.2642705417470674 HIT: 0.5176068474264706

#### val Acc: 0, NDCG: 0.2727876055095291 HIT: 0.5368910845588235
Epoch: 24, plus 0 steps train_loss: 0.6251

#### test Acc: 0, NDCG: 0.2724522395389418 HIT: 0.5265510110294118

#### val Acc: 0, NDCG: 0.2762148205849546 HIT: 0.5330480238970587
Epoch: 26, plus 0 steps train_loss: 0.6022

#### test Acc: 0, NDCG: 0.273355786762001 HIT: 0.5301700367647059

#### val Acc: 0, NDCG: 0.277184185487604 HIT: 0.5371208639705882
Epoch: 28, plus 0 steps train_loss: 0.624

#### test Acc: 0, NDCG: 0.27739737613277693 HIT: 0.5373563878676471

#### val Acc: 0, NDCG: 0.28335524496740944 HIT: 0.5407169117647059
Epoch: 30, plus 0 steps train_loss: 0.604

#### test Acc: 0, NDCG: 0.2822897672148784 HIT: 0.5407743566176471

#### val Acc: 0, NDCG: 0.2852832341521895 HIT: 0.5499138327205882
Epoch: 32, plus 0 steps train_loss: 0.6065

#### test Acc: 0, NDCG: 0.291496002764994 HIT: 0.5507869944852941

#### val Acc: 0, NDCG: 0.2928094205802563 HIT: 0.5575827205882353
Epoch: 36, plus 0 steps train_loss: 0.5994

#### test Acc: 0, NDCG: 0.2905516831395195 HIT: 0.5566693474264706

#### val Acc: 0, NDCG: 0.29089549013178073 HIT: 0.5521886488970588
Epoch: 40, plus 0 steps train_loss: 0.5941

#### test Acc: 0, NDCG: 0.2950592670844342 HIT: 0.5532169117647059

#### val Acc: 0, NDCG: 0.2972411387031333 HIT: 0.5621955422794118
Epoch: 44, plus 0 steps train_loss: 0.6012

#### test Acc: 0, NDCG: 0.2986093929522907 HIT: 0.5620002297794118

#### val Acc: 0, NDCG: 0.30050507993047193 HIT: 0.5658892463235294
Epoch: 48, plus 0 steps train_loss: 0.5941

#### test Acc: 0, NDCG: 0.2921908862594796 HIT: 0.5494657628676471

#### val Acc: 0, NDCG: 0.30214265557681075 HIT: 0.5640165441176471
Epoch: 52, plus 0 steps train_loss: 0.5898

#### test Acc: 0, NDCG: 0.3003184907942872 HIT: 0.5615579044117647

#### val Acc: 0, NDCG: 0.3072358059600062 HIT: 0.5762522977941177
Epoch: 56, plus 0 steps train_loss: 0.5889

#### test Acc: 0, NDCG: 0.3082106351970243 HIT: 0.5723230698529412

#### val Acc: 0, NDCG: 0.3085544998047921 HIT: 0.5756261488970588
Epoch: 60, plus 0 steps train_loss: 0.5798

#### test Acc: 0, NDCG: 0.3128328965061864 HIT: 0.5821346507352941

#### val Acc: 0, NDCG: 0.31557925454134916 HIT: 0.5814740349264705
Epoch: 64, plus 0 steps train_loss: 0.5886

#### test Acc: 0, NDCG: 0.3076011250776856 HIT: 0.5745404411764705

#### val Acc: 0, NDCG: 0.3159259824092795 HIT: 0.5840935202205882
Epoch: 68, plus 0 steps train_loss: 0.5611

#### test Acc: 0, NDCG: 0.3155457240500722 HIT: 0.5784524356617646

#### val Acc: 0, NDCG: 0.314772756451866 HIT: 0.5809742647058823
Epoch: 72, plus 0 steps train_loss: 0.5708

#### test Acc: 0, NDCG: 0.3185958738159739 HIT: 0.5831916360294118

#### val Acc: 0, NDCG: 0.3284624949282129 HIT: 0.5967026654411764
Epoch: 80, plus 0 steps train_loss: 0.5673

#### test Acc: 0, NDCG: 0.33209827767074435 HIT: 0.5988798253676471

#### val Acc: 0, NDCG: 0.3340586254369596 HIT: 0.6076401654411765
Epoch: 88, plus 0 steps train_loss: 0.5543

#### test Acc: 0, NDCG: 0.34181683083861575 HIT: 0.6141084558823529

#### val Acc: 0, NDCG: 0.3403537106902252 HIT: 0.6099437040441177
Epoch: 96, plus 0 steps train_loss: 0.5667

#### test Acc: 0, NDCG: 0.3361602099156271 HIT: 0.6049689797794118

#### val Acc: 0, NDCG: 0.3407917267110231 HIT: 0.6107996323529412
Epoch: 104, plus 0 steps train_loss: 0.5591

#### test Acc: 0, NDCG: 0.3402098346061672 HIT: 0.6104894301470588

#### val Acc: 0, NDCG: 0.3355785579415381 HIT: 0.6113625919117647
Epoch: 112, plus 0 steps train_loss: 0.5433

#### test Acc: 0, NDCG: 0.3477206296599141 HIT: 0.6149528952205883

#### val Acc: 0, NDCG: 0.35207761662999526 HIT: 0.6258501838235294
Epoch: 120, plus 0 steps train_loss: 0.5514

#### test Acc: 0, NDCG: 0.34945008311706793 HIT: 0.6186638327205882

#### val Acc: 0, NDCG: 0.3511942575061685 HIT: 0.6262120863970588
Epoch: 128, plus 0 steps train_loss: 0.5325

#### test Acc: 0, NDCG: 0.3541669828555585 HIT: 0.6290670955882354

#### val Acc: 0, NDCG: 0.35648195870394656 HIT: 0.6306123621323529
Epoch: 136, plus 0 steps train_loss: 0.5541

#### test Acc: 0, NDCG: 0.353795542788949 HIT: 0.6288258272058823

#### val Acc: 0, NDCG: 0.3539617600695124 HIT: 0.6210535386029412
Epoch: 144, plus 0 steps train_loss: 0.5464

#### test Acc: 0, NDCG: 0.3699467302481061 HIT: 0.6420726102941177

#### val Acc: 0, NDCG: 0.36902696914382693 HIT: 0.6424230238970587
Epoch: 160, plus 0 steps train_loss: 0.5365

#### test Acc: 0, NDCG: 0.369035778466268 HIT: 0.6414522058823529

#### val Acc: 0, NDCG: 0.3669831578968073 HIT: 0.6403837316176471
Epoch: 176, plus 0 steps train_loss: 0.5285

#### test Acc: 0, NDCG: 0.37288909538889714 HIT: 0.6381433823529412

#### val Acc: 0, NDCG: 0.3739826454934698 HIT: 0.6513384650735294
Epoch: 192, plus 0 steps train_loss: 0.5222

#### test Acc: 0, NDCG: 0.3762218068071036 HIT: 0.6455710018382353

#### val Acc: 0, NDCG: 0.3867010239172022 HIT: 0.6656077665441177
Epoch: 208, plus 0 steps train_loss: 0.5092

#### test Acc: 0, NDCG: 0.37879913204949767 HIT: 0.6554974724264706

#### val Acc: 0, NDCG: 0.38357293560066374 HIT: 0.6503274356617647
Epoch: 224, plus 0 steps train_loss: 0.5157

#### test Acc: 0, NDCG: 0.3897056147005899 HIT: 0.66123046875

#### val Acc: 0, NDCG: 0.3896802442720771 HIT: 0.6634478400735294
Epoch: 240, plus 0 steps train_loss: 0.5263

#### test Acc: 0, NDCG: 0.3893562051210462 HIT: 0.6587316176470588

#### val Acc: 0, NDCG: 0.39562377142650995 HIT: 0.6677676930147058
Epoch: 256, plus 0 steps train_loss: 0.5066

#### test Acc: 0, NDCG: 0.4030230358806929 HIT: 0.6767693014705882

#### val Acc: 0, NDCG: 0.3964094656864422 HIT: 0.6712545955882353
Epoch: 272, plus 0 steps train_loss: 0.4908

#### test Acc: 0, NDCG: 0.39308856302350537 HIT: 0.6592830882352941

#### val Acc: 0, NDCG: 0.4069799925066784 HIT: 0.6766831341911764
Epoch: 288, plus 0 steps train_loss: 0.4991

#### test Acc: 0, NDCG: 0.39965260970767486 HIT: 0.6737821691176471

#### val Acc: 0, NDCG: 0.40622244735750224 HIT: 0.67451171875
Epoch: 304, plus 0 steps train_loss: 0.4867

#### test Acc: 0, NDCG: 0.40357303636366704 HIT: 0.6739832261029413

#### val Acc: 0, NDCG: 0.4104235787123522 HIT: 0.6846392463235295
Epoch: 320, plus 0 steps train_loss: 0.493

#### test Acc: 0, NDCG: 0.4032988119617255 HIT: 0.66943359375

#### val Acc: 0, NDCG: 0.4119736390061369 HIT: 0.6775505514705882
Epoch: 352, plus 0 steps train_loss: 0.4873

#### test Acc: 0, NDCG: 0.41532392597708057 HIT: 0.6818991268382353

#### val Acc: 0, NDCG: 0.41214240850294487 HIT: 0.6867015165441177
Epoch: 384, plus 0 steps train_loss: 0.4698

#### test Acc: 0, NDCG: 0.42037881599412896 HIT: 0.6870576746323529

#### val Acc: 0, NDCG: 0.4273079733767554 HIT: 0.69638671875
Epoch: 416, plus 0 steps train_loss: 0.4748

#### test Acc: 0, NDCG: 0.418937469593007 HIT: 0.6881031709558824

#### val Acc: 0, NDCG: 0.42190632572658043 HIT: 0.6977251838235294
Epoch: 448, plus 0 steps train_loss: 0.4767

#### test Acc: 0, NDCG: 0.41725546825502724 HIT: 0.6792911305147059

#### val Acc: 0, NDCG: 0.4257470486108347 HIT: 0.6913775275735294
Epoch: 480, plus 0 steps train_loss: 0.462

#### test Acc: 0, NDCG: 0.42255790339545796 HIT: 0.6874080882352941

#### val Acc: 0, NDCG: 0.43221533629312114 HIT: 0.7000172334558823
Epoch: 512, plus 0 steps train_loss: 0.4786

#### test Acc: 0, NDCG: 0.42622246848626266 HIT: 0.6936925551470587

#### val Acc: 0, NDCG: 0.43128833461518823 HIT: 0.6963579963235295
Epoch: 544, plus 0 steps train_loss: 0.4666

#### test Acc: 0, NDCG: 0.4293456161188211 HIT: 0.6982192095588236

#### val Acc: 0, NDCG: 0.4341656475601937 HIT: 0.6986040900735294
Epoch: 576, plus 0 steps train_loss: 0.4508

#### test Acc: 0, NDCG: 0.4336939570710478 HIT: 0.7038890165441176

#### val Acc: 0, NDCG: 0.4363625869387267 HIT: 0.7020795036764705
Epoch: 608, plus 0 steps train_loss: 0.4563

#### test Acc: 0, NDCG: 0.43201421109527444 HIT: 0.6999827665441176

#### val Acc: 0, NDCG: 0.4367820865182919 HIT: 0.7023207720588236
Epoch: 640, plus 0 steps train_loss: 0.4529

#### test Acc: 0, NDCG: 0.42774171135836003 HIT: 0.6891831341911765

#### val Acc: 0, NDCG: 0.4370020184794094 HIT: 0.7056698069852941
Epoch: 704, plus 0 steps train_loss: 0.4475

#### test Acc: 0, NDCG: 0.4356767812661834 HIT: 0.6992359834558823

#### val Acc: 0, NDCG: 0.4408843810430877 HIT: 0.7047966452205883
Epoch: 768, plus 0 steps train_loss: 0.4426

#### test Acc: 0, NDCG: 0.4266698225531177 HIT: 0.6924919577205882

#### val Acc: 0, NDCG: 0.44177085456033743 HIT: 0.7050608915441177
Epoch: 832, plus 0 steps train_loss: 0.422

#### test Acc: 0, NDCG: 0.4316149433940136 HIT: 0.6975815716911764

#### val Acc: 0, NDCG: 0.43955039089957176 HIT: 0.7040498621323529
Epoch: 896, plus 0 steps train_loss: 0.4364

#### test Acc: 0, NDCG: 0.4315083297993958 HIT: 0.6929974724264706

#### val Acc: 0, NDCG: 0.4448465759601189 HIT: 0.7073701746323529
Epoch: 960, plus 0 steps train_loss: 0.4357

#### test Acc: 0, NDCG: 0.4302101104859741 HIT: 0.6894990808823529

#### val Acc: 0, NDCG: 0.4424427902561631 HIT: 0.7020565257352941
Epoch: 1013, plus 25 steps train_loss: 0.4471
Done: it took 486841.64315104485
max value of NDCG: 0.440704544343742
max value of HIT: 0.7038890165441176

After 20 validations
max value of NDCG: 0.4356767812661834
max value of HIT: 0.7038890165441176
