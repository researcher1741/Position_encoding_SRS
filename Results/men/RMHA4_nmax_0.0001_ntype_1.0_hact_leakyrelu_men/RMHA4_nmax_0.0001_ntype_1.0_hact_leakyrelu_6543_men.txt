 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	0.0001
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12732044181994573 HIT: 0.2840475643382353

#### val Acc: 0, NDCG: 0.13055330707684026 HIT: 0.2864085477941177
Epoch: 1, plus 0 steps train_loss: 0.7453

#### test Acc: 0, NDCG: 0.13179217099641707 HIT: 0.2911420036764706

#### val Acc: 0, NDCG: 0.1340207006571777 HIT: 0.29655905330882354
Epoch: 2, plus 0 steps train_loss: 0.7207

#### test Acc: 0, NDCG: 0.14451666875421743 HIT: 0.31331571691176474

#### val Acc: 0, NDCG: 0.14996148457472142 HIT: 0.32208754595588235
Epoch: 3, plus 0 steps train_loss: 0.7144

#### test Acc: 0, NDCG: 0.15729429672671946 HIT: 0.3311465992647059

#### val Acc: 0, NDCG: 0.16393382583156257 HIT: 0.3453412224264706
Epoch: 4, plus 0 steps train_loss: 0.7085

#### test Acc: 0, NDCG: 0.15577991189355103 HIT: 0.3335075827205882

#### val Acc: 0, NDCG: 0.15336947178419033 HIT: 0.33090533088235297
Epoch: 5, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.18349874643288658 HIT: 0.37678653492647063

#### val Acc: 0, NDCG: 0.18119919717906027 HIT: 0.37084673713235294
Epoch: 6, plus 0 steps train_loss: 0.703

#### test Acc: 0, NDCG: 0.18790552631061022 HIT: 0.39035500919117644

#### val Acc: 0, NDCG: 0.18987754279185526 HIT: 0.3876206341911764
Epoch: 7, plus 0 steps train_loss: 0.7002

#### test Acc: 0, NDCG: 0.18904113504288633 HIT: 0.3919577205882353

#### val Acc: 0, NDCG: 0.19771773391502184 HIT: 0.4007927389705882
Epoch: 8, plus 0 steps train_loss: 0.7012

#### test Acc: 0, NDCG: 0.19744865497442174 HIT: 0.4065027573529412

#### val Acc: 0, NDCG: 0.20064344507535475 HIT: 0.40637063419117647
Epoch: 9, plus 0 steps train_loss: 0.6915

#### test Acc: 0, NDCG: 0.2099522850823242 HIT: 0.41950252757352946

#### val Acc: 0, NDCG: 0.2137729247261977 HIT: 0.42718864889705876
Epoch: 10, plus 0 steps train_loss: 0.6859

#### test Acc: 0, NDCG: 0.2078007228709054 HIT: 0.42238051470588234

#### val Acc: 0, NDCG: 0.2107963811290953 HIT: 0.426171875
Epoch: 12, plus 0 steps train_loss: 0.6766

#### test Acc: 0, NDCG: 0.22201798588670116 HIT: 0.4406652113970588

#### val Acc: 0, NDCG: 0.2251057210944995 HIT: 0.4511833639705882
Epoch: 14, plus 0 steps train_loss: 0.6571

#### test Acc: 0, NDCG: 0.2211087200600864 HIT: 0.4510167738970588

#### val Acc: 0, NDCG: 0.2321785059414619 HIT: 0.46099494485294124
Epoch: 16, plus 0 steps train_loss: 0.6516

#### test Acc: 0, NDCG: 0.2396393866491966 HIT: 0.4722943474264706

#### val Acc: 0, NDCG: 0.2406885335238355 HIT: 0.46872127757352944
Epoch: 18, plus 0 steps train_loss: 0.6517

#### test Acc: 0, NDCG: 0.24522098804065445 HIT: 0.4815314797794118

#### val Acc: 0, NDCG: 0.2525055255557603 HIT: 0.4905790441176471
Epoch: 20, plus 0 steps train_loss: 0.6521

#### test Acc: 0, NDCG: 0.2520810202603835 HIT: 0.49717371323529413

#### val Acc: 0, NDCG: 0.2525504487757039 HIT: 0.4920553768382353
Epoch: 22, plus 0 steps train_loss: 0.6412

#### test Acc: 0, NDCG: 0.2574257103919362 HIT: 0.5009076286764705

#### val Acc: 0, NDCG: 0.25916039506426586 HIT: 0.5070772058823529
Epoch: 24, plus 0 steps train_loss: 0.6409

#### test Acc: 0, NDCG: 0.2606600475836883 HIT: 0.5112706801470588

#### val Acc: 0, NDCG: 0.2658768117949807 HIT: 0.5167279411764706
Epoch: 26, plus 0 steps train_loss: 0.635

#### test Acc: 0, NDCG: 0.2568327222964759 HIT: 0.5022231158088235

#### val Acc: 0, NDCG: 0.26119835660904717 HIT: 0.5144990808823529
Epoch: 28, plus 0 steps train_loss: 0.6324

#### test Acc: 0, NDCG: 0.26195239855232816 HIT: 0.5117359834558823

#### val Acc: 0, NDCG: 0.2637929898635493 HIT: 0.5203297334558823
Epoch: 30, plus 0 steps train_loss: 0.6237

#### test Acc: 0, NDCG: 0.26635275648517664 HIT: 0.5230124080882353

#### val Acc: 0, NDCG: 0.26887273298872866 HIT: 0.5200252757352941
Epoch: 32, plus 0 steps train_loss: 0.6122

#### test Acc: 0, NDCG: 0.2760698213188928 HIT: 0.5323414522058824

#### val Acc: 0, NDCG: 0.2778839141455063 HIT: 0.5266946231617646
Epoch: 36, plus 0 steps train_loss: 0.6141

#### test Acc: 0, NDCG: 0.2780674425510593 HIT: 0.5348403033088236

#### val Acc: 0, NDCG: 0.2837516164082145 HIT: 0.5432215073529412
Epoch: 40, plus 0 steps train_loss: 0.6075

#### test Acc: 0, NDCG: 0.28498076466043554 HIT: 0.5394875919117647

#### val Acc: 0, NDCG: 0.2827107775498763 HIT: 0.5325597426470587
Epoch: 44, plus 0 steps train_loss: 0.5985

#### test Acc: 0, NDCG: 0.28813196203974406 HIT: 0.5328067555147059

#### val Acc: 0, NDCG: 0.2859890016754167 HIT: 0.5387235753676471
Epoch: 48, plus 0 steps train_loss: 0.6167

#### test Acc: 0, NDCG: 0.2875334741455152 HIT: 0.5419577205882353

#### val Acc: 0, NDCG: 0.2957209855422338 HIT: 0.5531939338235294
Epoch: 52, plus 0 steps train_loss: 0.5985

#### test Acc: 0, NDCG: 0.29454321075873535 HIT: 0.5549977022058823

#### val Acc: 0, NDCG: 0.2996606435534049 HIT: 0.5567784926470588
Epoch: 56, plus 0 steps train_loss: 0.5964

#### test Acc: 0, NDCG: 0.2996627103734564 HIT: 0.5551470588235294

#### val Acc: 0, NDCG: 0.30297288775868964 HIT: 0.5666877297794117
Epoch: 60, plus 0 steps train_loss: 0.5881

#### test Acc: 0, NDCG: 0.29823346010551693 HIT: 0.5572380514705882

#### val Acc: 0, NDCG: 0.30245769657842714 HIT: 0.5629193474264705
Epoch: 64, plus 0 steps train_loss: 0.5912

#### test Acc: 0, NDCG: 0.30256327309242276 HIT: 0.56474609375

#### val Acc: 0, NDCG: 0.31005349370900864 HIT: 0.5719841452205883
Epoch: 68, plus 0 steps train_loss: 0.5971

#### test Acc: 0, NDCG: 0.30498420775733837 HIT: 0.5619542738970588

#### val Acc: 0, NDCG: 0.3166105355709711 HIT: 0.5833869485294118
Epoch: 72, plus 0 steps train_loss: 0.5856

#### test Acc: 0, NDCG: 0.3164233822724304 HIT: 0.5763786764705883

#### val Acc: 0, NDCG: 0.32321060703745175 HIT: 0.5850700827205882
Epoch: 80, plus 0 steps train_loss: 0.5935

#### test Acc: 0, NDCG: 0.3212770542094232 HIT: 0.5861845128676471

#### val Acc: 0, NDCG: 0.3287285551222571 HIT: 0.5908203125
Epoch: 88, plus 0 steps train_loss: 0.585

#### test Acc: 0, NDCG: 0.32726321380541307 HIT: 0.5876263786764706

#### val Acc: 0, NDCG: 0.3254987555597312 HIT: 0.5865406709558824
Epoch: 96, plus 0 steps train_loss: 0.562

#### test Acc: 0, NDCG: 0.3216026563660091 HIT: 0.5865406709558824

#### val Acc: 0, NDCG: 0.3420515897582501 HIT: 0.6063763786764705
Epoch: 104, plus 0 steps train_loss: 0.5507

#### test Acc: 0, NDCG: 0.3387432452974533 HIT: 0.6091624540441176

#### val Acc: 0, NDCG: 0.3435180107090248 HIT: 0.6071346507352942
Epoch: 112, plus 0 steps train_loss: 0.5819

#### test Acc: 0, NDCG: 0.336462435742306 HIT: 0.5994715073529412

#### val Acc: 0, NDCG: 0.3456654483007239 HIT: 0.6068474264705882
Epoch: 120, plus 0 steps train_loss: 0.5608

#### test Acc: 0, NDCG: 0.33794952008665186 HIT: 0.5996897977941177

#### val Acc: 0, NDCG: 0.3490407060367063 HIT: 0.6135799632352941
Epoch: 128, plus 0 steps train_loss: 0.5524

#### test Acc: 0, NDCG: 0.34718817464424384 HIT: 0.6123965992647059

#### val Acc: 0, NDCG: 0.3528446046753223 HIT: 0.6159237132352942
Epoch: 136, plus 0 steps train_loss: 0.5598

#### test Acc: 0, NDCG: 0.3555891849542384 HIT: 0.6175723805147059

#### val Acc: 0, NDCG: 0.3551034941558785 HIT: 0.6247414981617647
Epoch: 144, plus 0 steps train_loss: 0.5589

#### test Acc: 0, NDCG: 0.35224507748893996 HIT: 0.6210305606617647

#### val Acc: 0, NDCG: 0.356045674638153 HIT: 0.6187614889705882
Epoch: 160, plus 0 steps train_loss: 0.5416

#### test Acc: 0, NDCG: 0.3530067319232749 HIT: 0.6171185661764705

#### val Acc: 0, NDCG: 0.36338631580534314 HIT: 0.6293887867647059
Epoch: 176, plus 0 steps train_loss: 0.5346

#### test Acc: 0, NDCG: 0.36590082633403603 HIT: 0.6278435202205882

#### val Acc: 0, NDCG: 0.36938086814457705 HIT: 0.6348977481617647
Epoch: 192, plus 0 steps train_loss: 0.5433

#### test Acc: 0, NDCG: 0.36886481262832327 HIT: 0.6288373161764705

#### val Acc: 0, NDCG: 0.36991047400182947 HIT: 0.6381433823529412
Epoch: 208, plus 0 steps train_loss: 0.5304

#### test Acc: 0, NDCG: 0.37426011153696725 HIT: 0.6373506433823529

#### val Acc: 0, NDCG: 0.3731263098029897 HIT: 0.6357479319852941
Epoch: 224, plus 0 steps train_loss: 0.5326

#### test Acc: 0, NDCG: 0.37700038240491385 HIT: 0.6386603860294118

#### val Acc: 0, NDCG: 0.37875381448973117 HIT: 0.6419232536764705
Epoch: 240, plus 0 steps train_loss: 0.5247

#### test Acc: 0, NDCG: 0.38906711736312893 HIT: 0.6478515625

#### val Acc: 0, NDCG: 0.3890498716248414 HIT: 0.6479262408088236
Epoch: 256, plus 0 steps train_loss: 0.5208

#### test Acc: 0, NDCG: 0.3880302663112324 HIT: 0.6502814797794118

#### val Acc: 0, NDCG: 0.3936955795900109 HIT: 0.6529239430147059
Epoch: 272, plus 0 steps train_loss: 0.5133

#### test Acc: 0, NDCG: 0.3870788923073988 HIT: 0.6440142463235294

#### val Acc: 0, NDCG: 0.39424546702666163 HIT: 0.6569738051470588
Epoch: 288, plus 0 steps train_loss: 0.5097

#### test Acc: 0, NDCG: 0.39096046753791486 HIT: 0.6492761948529412

#### val Acc: 0, NDCG: 0.39618535444714953 HIT: 0.6534122242647059
Epoch: 304, plus 0 steps train_loss: 0.5063

#### test Acc: 0, NDCG: 0.3956203124996437 HIT: 0.65400390625

#### val Acc: 0, NDCG: 0.4006686220990326 HIT: 0.6585420496323529
Epoch: 320, plus 0 steps train_loss: 0.4937

#### test Acc: 0, NDCG: 0.39833908733707596 HIT: 0.6511374080882353

#### val Acc: 0, NDCG: 0.4000730740916628 HIT: 0.6609087775735294
Epoch: 352, plus 0 steps train_loss: 0.4963

#### test Acc: 0, NDCG: 0.4045428452746706 HIT: 0.6628274356617647

#### val Acc: 0, NDCG: 0.40891120838306094 HIT: 0.6700425091911765
Epoch: 384, plus 0 steps train_loss: 0.4952

#### test Acc: 0, NDCG: 0.4112748014693838 HIT: 0.6737764246323529

#### val Acc: 0, NDCG: 0.4207988134185935 HIT: 0.6845186121323529
Epoch: 416, plus 0 steps train_loss: 0.497

#### test Acc: 0, NDCG: 0.40553480250885343 HIT: 0.6624712775735294

#### val Acc: 0, NDCG: 0.4127476486741992 HIT: 0.6763499540441177
Epoch: 448, plus 0 steps train_loss: 0.4708

#### test Acc: 0, NDCG: 0.40662283155052875 HIT: 0.6636144301470588

#### val Acc: 0, NDCG: 0.4196910965513722 HIT: 0.6846966911764706
Epoch: 480, plus 0 steps train_loss: 0.4781

#### test Acc: 0, NDCG: 0.4154057130857346 HIT: 0.6739545036764706

#### val Acc: 0, NDCG: 0.4253724377814935 HIT: 0.6858513327205882
Epoch: 512, plus 0 steps train_loss: 0.4837

#### test Acc: 0, NDCG: 0.420420500824518 HIT: 0.6805089613970587

#### val Acc: 0, NDCG: 0.420569356025414 HIT: 0.6811293658088236
Epoch: 544, plus 0 steps train_loss: 0.4768

#### test Acc: 0, NDCG: 0.41177973965978965 HIT: 0.6695542279411765

#### val Acc: 0, NDCG: 0.42643592033495725 HIT: 0.6820657169117647
Epoch: 576, plus 0 steps train_loss: 0.4692

#### test Acc: 0, NDCG: 0.4176063834220984 HIT: 0.6740751378676471

#### val Acc: 0, NDCG: 0.4238173632968049 HIT: 0.6796128216911764
Epoch: 608, plus 0 steps train_loss: 0.4727

#### test Acc: 0, NDCG: 0.41362631918698556 HIT: 0.6747644761029412

#### val Acc: 0, NDCG: 0.4228017511567498 HIT: 0.6806123621323529
Epoch: 640, plus 0 steps train_loss: 0.4629

#### test Acc: 0, NDCG: 0.428104528415646 HIT: 0.6844324448529412

#### val Acc: 0, NDCG: 0.4300062222669229 HIT: 0.6908375459558823
Epoch: 704, plus 0 steps train_loss: 0.4603

#### test Acc: 0, NDCG: 0.426047732564889 HIT: 0.6794462316176471

#### val Acc: 0, NDCG: 0.4331789737305233 HIT: 0.6902171415441176
Epoch: 768, plus 0 steps train_loss: 0.4423

#### test Acc: 0, NDCG: 0.42478695331421257 HIT: 0.6837201286764706

#### val Acc: 0, NDCG: 0.4388835800928592 HIT: 0.6986213235294118
Epoch: 832, plus 0 steps train_loss: 0.4533

#### test Acc: 0, NDCG: 0.425047983075057 HIT: 0.6745749080882353

#### val Acc: 0, NDCG: 0.4364426774398953 HIT: 0.6929227941176471
Epoch: 896, plus 0 steps train_loss: 0.4446

#### test Acc: 0, NDCG: 0.4224081859337813 HIT: 0.6790613511029412

#### val Acc: 0, NDCG: 0.4366789705540047 HIT: 0.6898782169117647
Epoch: 960, plus 0 steps train_loss: 0.4604

#### test Acc: 0, NDCG: 0.42568157796314204 HIT: 0.6794002757352942

#### val Acc: 0, NDCG: 0.43987481474175666 HIT: 0.7004308363970588
Epoch: 1013, plus 25 steps train_loss: 0.4344
Done: it took 292084.4184117317
max value of NDCG: 0.428104528415646
max value of HIT: 0.6844324448529412

After 20 validations
max value of NDCG: 0.428104528415646
max value of HIT: 0.6844324448529412
