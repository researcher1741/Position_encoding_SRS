 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.01
max_norm:             	1.0
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12720848854019368 HIT: 0.2777630974264706

#### val Acc: 0, NDCG: 0.13162637564079527 HIT: 0.2932559742647059
Epoch: 1, plus 0 steps train_loss: 0.75

#### test Acc: 0, NDCG: 0.12506620306651756 HIT: 0.27515510110294117

#### val Acc: 0, NDCG: 0.12898022907242745 HIT: 0.2833926930147059
Epoch: 2, plus 0 steps train_loss: 0.7477

#### test Acc: 0, NDCG: 0.12970966651059562 HIT: 0.28984375

#### val Acc: 0, NDCG: 0.1335198310194335 HIT: 0.2940831801470588
Epoch: 3, plus 0 steps train_loss: 0.7386

#### test Acc: 0, NDCG: 0.1270884818323966 HIT: 0.2764303768382353

#### val Acc: 0, NDCG: 0.12880168501515696 HIT: 0.28296185661764706
Epoch: 4, plus 0 steps train_loss: 0.7216

#### test Acc: 0, NDCG: 0.13123023065912176 HIT: 0.2897518382352941

#### val Acc: 0, NDCG: 0.13377266297517104 HIT: 0.29135454963235297
Epoch: 5, plus 0 steps train_loss: 0.7133

#### test Acc: 0, NDCG: 0.15020758638684112 HIT: 0.3041187959558823

#### val Acc: 0, NDCG: 0.16225077763079215 HIT: 0.31994485294117647
Epoch: 6, plus 0 steps train_loss: 0.7093

#### test Acc: 0, NDCG: 0.14361679338072916 HIT: 0.2990579044117647

#### val Acc: 0, NDCG: 0.15916266270560142 HIT: 0.3154411764705882
Epoch: 7, plus 0 steps train_loss: 0.7067

#### test Acc: 0, NDCG: 0.15538263424984206 HIT: 0.30561236213235293

#### val Acc: 0, NDCG: 0.1697116439348611 HIT: 0.32194967830882354
Epoch: 8, plus 0 steps train_loss: 0.7039

#### test Acc: 0, NDCG: 0.17867449764583682 HIT: 0.3338982077205882

#### val Acc: 0, NDCG: 0.20690023776915956 HIT: 0.3603515625
Epoch: 9, plus 0 steps train_loss: 0.7071

#### test Acc: 0, NDCG: 0.16696410832012457 HIT: 0.3200482536764706

#### val Acc: 0, NDCG: 0.17684510476450116 HIT: 0.3283318014705882
Epoch: 10, plus 0 steps train_loss: 0.7047

#### test Acc: 0, NDCG: 0.19333853459133749 HIT: 0.3440487132352941

#### val Acc: 0, NDCG: 0.21604963154407 HIT: 0.37027803308823526
Epoch: 12, plus 0 steps train_loss: 0.7018

#### test Acc: 0, NDCG: 0.24860696434922464 HIT: 0.3973805147058823

#### val Acc: 0, NDCG: 0.2813126329425216 HIT: 0.43340992647058824
Epoch: 14, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.19097291665328647 HIT: 0.34499655330882356

#### val Acc: 0, NDCG: 0.2128554106527223 HIT: 0.36328125
Epoch: 16, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.1807007028519152 HIT: 0.3350241268382353

#### val Acc: 0, NDCG: 0.20123098043556104 HIT: 0.35529067095588235
Epoch: 18, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.2145848305516171 HIT: 0.3707375919117647

#### val Acc: 0, NDCG: 0.23525393189786473 HIT: 0.3851275275735294
Epoch: 20, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.2598240895806011 HIT: 0.4129308363970588

#### val Acc: 0, NDCG: 0.2830649753954098 HIT: 0.42767693014705876
Epoch: 22, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.31320522840557113 HIT: 0.46531479779411766

#### val Acc: 0, NDCG: 0.3312196223684235 HIT: 0.4758846507352941
Epoch: 24, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.314003601800091 HIT: 0.46702090992647055

#### val Acc: 0, NDCG: 0.3379264279939823 HIT: 0.48590303308823535
Epoch: 26, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.39227993980011727 HIT: 0.5287856158088236

#### val Acc: 0, NDCG: 0.4292928094209524 HIT: 0.5605526194852941
Epoch: 28, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.40054233579468645 HIT: 0.5356158088235294

#### val Acc: 0, NDCG: 0.4194552136440273 HIT: 0.5520335477941176
Epoch: 30, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.3301062009700934 HIT: 0.47150160845588235

#### val Acc: 0, NDCG: 0.34953014547610445 HIT: 0.4946231617647059
Epoch: 32, plus 0 steps train_loss: 0.6938

#### test Acc: 0, NDCG: 0.16761654622811706 HIT: 0.34638671875

#### val Acc: 0, NDCG: 0.17039832736507476 HIT: 0.34482996323529413
Epoch: 36, plus 0 steps train_loss: 0.693

#### test Acc: 0, NDCG: 0.19012260936223532 HIT: 0.38975183823529413

#### val Acc: 0, NDCG: 0.19065581097810808 HIT: 0.38745404411764706
Epoch: 40, plus 0 steps train_loss: 0.6928

#### test Acc: 0, NDCG: 0.19693404982723386 HIT: 0.39568014705882354

#### val Acc: 0, NDCG: 0.1969505252022728 HIT: 0.39388786764705885
Epoch: 44, plus 0 steps train_loss: 0.6852

#### test Acc: 0, NDCG: 0.2093654195188237 HIT: 0.41180491727941176

#### val Acc: 0, NDCG: 0.21620916127052398 HIT: 0.4176355698529412
Epoch: 48, plus 0 steps train_loss: 0.6815

#### test Acc: 0, NDCG: 0.27881842600917034 HIT: 0.4845818014705882

#### val Acc: 0, NDCG: 0.29828887179781605 HIT: 0.5003963694852941
Epoch: 52, plus 0 steps train_loss: 0.6812

#### test Acc: 0, NDCG: 0.2107451579785382 HIT: 0.4182502297794118

#### val Acc: 0, NDCG: 0.21384607012425993 HIT: 0.41741727941176465
Epoch: 56, plus 0 steps train_loss: 0.6663

#### test Acc: 0, NDCG: 0.23636613122658678 HIT: 0.46197725183823535

#### val Acc: 0, NDCG: 0.24367810100438086 HIT: 0.4650965073529412
Epoch: 60, plus 0 steps train_loss: 0.6534

#### test Acc: 0, NDCG: 0.24436481313126243 HIT: 0.47418428308823535

#### val Acc: 0, NDCG: 0.24431180668037986 HIT: 0.47653952205882355
Epoch: 64, plus 0 steps train_loss: 0.6393

#### test Acc: 0, NDCG: 0.24870955166299585 HIT: 0.4801125919117647

#### val Acc: 0, NDCG: 0.2532699502470444 HIT: 0.48376608455882353
Epoch: 68, plus 0 steps train_loss: 0.6339

#### test Acc: 0, NDCG: 0.26527790223187414 HIT: 0.49932789522058824

#### val Acc: 0, NDCG: 0.2589952601075559 HIT: 0.4927676930147059
Epoch: 72, plus 0 steps train_loss: 0.6328

#### test Acc: 0, NDCG: 0.27321468891006945 HIT: 0.5101447610294118

#### val Acc: 0, NDCG: 0.2771697744078793 HIT: 0.5139418658088235
Epoch: 80, plus 0 steps train_loss: 0.6335

#### test Acc: 0, NDCG: 0.2890082495693116 HIT: 0.5400677849264706

#### val Acc: 0, NDCG: 0.299237928736238 HIT: 0.5464269301470588
Epoch: 88, plus 0 steps train_loss: 0.6349

#### test Acc: 0, NDCG: 0.2991785368765342 HIT: 0.5513499540441177

#### val Acc: 0, NDCG: 0.3014404295200918 HIT: 0.5523380055147059
Epoch: 96, plus 0 steps train_loss: 0.6231

#### test Acc: 0, NDCG: 0.2976683097077155 HIT: 0.5510282628676471

#### val Acc: 0, NDCG: 0.30541965049129605 HIT: 0.5567727481617647
Epoch: 104, plus 0 steps train_loss: 0.6134

#### test Acc: 0, NDCG: 0.30873881382229873 HIT: 0.5583524816176471

#### val Acc: 0, NDCG: 0.317303842669976 HIT: 0.5677562040441176
Epoch: 112, plus 0 steps train_loss: 0.5959

#### test Acc: 0, NDCG: 0.31865460215462205 HIT: 0.5741498161764705

#### val Acc: 0, NDCG: 0.3303038610379837 HIT: 0.5843232996323529
Epoch: 120, plus 0 steps train_loss: 0.5985

#### test Acc: 0, NDCG: 0.32845846635189946 HIT: 0.5877355238970587

#### val Acc: 0, NDCG: 0.33533349819863917 HIT: 0.5942670036764706
Epoch: 128, plus 0 steps train_loss: 0.6011

#### test Acc: 0, NDCG: 0.3265473904053703 HIT: 0.5847713694852941

#### val Acc: 0, NDCG: 0.34027682406676846 HIT: 0.5937672334558823
Epoch: 136, plus 0 steps train_loss: 0.5721

#### test Acc: 0, NDCG: 0.3404213172385943 HIT: 0.5985121783088235

#### val Acc: 0, NDCG: 0.3335000853265461 HIT: 0.5905675551470588
Epoch: 144, plus 0 steps train_loss: 0.5771

#### test Acc: 0, NDCG: 0.3406615168961856 HIT: 0.5970990349264705

#### val Acc: 0, NDCG: 0.3436172904873932 HIT: 0.5995634191176471
Epoch: 160, plus 0 steps train_loss: 0.5674

#### test Acc: 0, NDCG: 0.34383537954167215 HIT: 0.6000402113970588

#### val Acc: 0, NDCG: 0.3550026057937331 HIT: 0.6121668198529412
Epoch: 176, plus 0 steps train_loss: 0.5728

#### test Acc: 0, NDCG: 0.3511300550058736 HIT: 0.6020680147058823

#### val Acc: 0, NDCG: 0.3620937369069728 HIT: 0.6198988970588235
Epoch: 192, plus 0 steps train_loss: 0.5486

#### test Acc: 0, NDCG: 0.3682941240839525 HIT: 0.6201573988970588

#### val Acc: 0, NDCG: 0.3629026430375157 HIT: 0.6199850643382353
Epoch: 208, plus 0 steps train_loss: 0.5445

#### test Acc: 0, NDCG: 0.3558958571511655 HIT: 0.6110466452205883

#### val Acc: 0, NDCG: 0.3735377586894151 HIT: 0.6294749540441177
Epoch: 224, plus 0 steps train_loss: 0.5485

#### test Acc: 0, NDCG: 0.36359015299217223 HIT: 0.6167624080882353

#### val Acc: 0, NDCG: 0.3813596985233083 HIT: 0.6301872702205882
Epoch: 240, plus 0 steps train_loss: 0.5438

#### test Acc: 0, NDCG: 0.36932735374106596 HIT: 0.6248391544117646

#### val Acc: 0, NDCG: 0.37656484489128406 HIT: 0.6350471047794117
Epoch: 256, plus 0 steps train_loss: 0.532

#### test Acc: 0, NDCG: 0.369691382063248 HIT: 0.6234375

#### val Acc: 0, NDCG: 0.38928782687291774 HIT: 0.6392578125
Epoch: 272, plus 0 steps train_loss: 0.5454

#### test Acc: 0, NDCG: 0.37811023470691707 HIT: 0.6273494944852941

#### val Acc: 0, NDCG: 0.38526408506806026 HIT: 0.6368566176470588
Epoch: 288, plus 0 steps train_loss: 0.5385

#### test Acc: 0, NDCG: 0.3775590986954268 HIT: 0.6335133272058824

#### val Acc: 0, NDCG: 0.3856389681017221 HIT: 0.6363855698529413
Epoch: 304, plus 0 steps train_loss: 0.5237

#### test Acc: 0, NDCG: 0.38575154990127103 HIT: 0.6403262867647059

#### val Acc: 0, NDCG: 0.38284561610958184 HIT: 0.6386661305147059
Epoch: 320, plus 0 steps train_loss: 0.5169

#### test Acc: 0, NDCG: 0.3842969695392399 HIT: 0.6350873161764705

#### val Acc: 0, NDCG: 0.3881373658305455 HIT: 0.6368795955882354
Epoch: 352, plus 0 steps train_loss: 0.5207

#### test Acc: 0, NDCG: 0.39239127468306045 HIT: 0.6368681066176471

#### val Acc: 0, NDCG: 0.39949668637159086 HIT: 0.6490981158088236
Epoch: 384, plus 0 steps train_loss: 0.5015

#### test Acc: 0, NDCG: 0.393869406410693 HIT: 0.644140625

#### val Acc: 0, NDCG: 0.4009837794169835 HIT: 0.6530215992647059
Epoch: 416, plus 0 steps train_loss: 0.5146

#### test Acc: 0, NDCG: 0.39763419940333206 HIT: 0.6460535386029412

#### val Acc: 0, NDCG: 0.4014072988917804 HIT: 0.6533375459558823
Epoch: 448, plus 0 steps train_loss: 0.512

#### test Acc: 0, NDCG: 0.3922787621288654 HIT: 0.6407571231617647

#### val Acc: 0, NDCG: 0.4053563171268418 HIT: 0.6557042738970588
Epoch: 480, plus 0 steps train_loss: 0.4927

#### test Acc: 0, NDCG: 0.3999599543563724 HIT: 0.6471909466911765

#### val Acc: 0, NDCG: 0.4045724449941268 HIT: 0.6591854319852941
Epoch: 512, plus 0 steps train_loss: 0.476

#### test Acc: 0, NDCG: 0.3982179740547814 HIT: 0.6449276194852941

#### val Acc: 0, NDCG: 0.40385046870643304 HIT: 0.6579388786764706
Epoch: 544, plus 0 steps train_loss: 0.4812

#### test Acc: 0, NDCG: 0.39896645701008177 HIT: 0.6487477022058823

#### val Acc: 0, NDCG: 0.4022837481920264 HIT: 0.6506778492647058
Epoch: 576, plus 0 steps train_loss: 0.4688

#### test Acc: 0, NDCG: 0.3922042372254619 HIT: 0.6403664981617647

#### val Acc: 0, NDCG: 0.4088675443114509 HIT: 0.6555721507352941
Epoch: 608, plus 0 steps train_loss: 0.493

#### test Acc: 0, NDCG: 0.4018981806797191 HIT: 0.6483226102941176

#### val Acc: 0, NDCG: 0.4102542022232468 HIT: 0.6588924632352942
Epoch: 640, plus 0 steps train_loss: 0.4868

#### test Acc: 0, NDCG: 0.40222696606472824 HIT: 0.6505572150735295

#### val Acc: 0, NDCG: 0.40472625274565804 HIT: 0.6530330882352942
Epoch: 704, plus 0 steps train_loss: 0.47

#### test Acc: 0, NDCG: 0.3982360420779116 HIT: 0.6492302389705882

#### val Acc: 0, NDCG: 0.41160132175536346 HIT: 0.6588350183823529
Epoch: 768, plus 0 steps train_loss: 0.4655

#### test Acc: 0, NDCG: 0.3997165578417746 HIT: 0.6459041819852941

#### val Acc: 0, NDCG: 0.40979029144529777 HIT: 0.6578871783088236
Epoch: 832, plus 0 steps train_loss: 0.4639

#### test Acc: 0, NDCG: 0.3967891386239143 HIT: 0.6410271139705882

#### val Acc: 0, NDCG: 0.41014960428001884 HIT: 0.6539579503676471
Epoch: 896, plus 0 steps train_loss: 0.4579

#### test Acc: 0, NDCG: 0.4047168007828549 HIT: 0.6527516084558823

#### val Acc: 0, NDCG: 0.40833800370511597 HIT: 0.6536477481617646
Epoch: 960, plus 0 steps train_loss: 0.4594

#### test Acc: 0, NDCG: 0.4013480578886047 HIT: 0.6451401654411765

#### val Acc: 0, NDCG: 0.40697152968923067 HIT: 0.6588177849264706
Epoch: 1013, plus 25 steps train_loss: 0.4668
Done: it took 301405.1383011341
max value of NDCG: 0.4047168007828549
max value of HIT: 0.6527516084558823

After 20 validations
max value of NDCG: 0.4047168007828549
max value of HIT: 0.6527516084558823
