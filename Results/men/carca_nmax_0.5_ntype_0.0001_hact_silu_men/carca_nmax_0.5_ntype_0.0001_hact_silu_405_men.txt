 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.0001
max_norm:             	0.5
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.1278110747931188 HIT: 0.28042279411764703

#### val Acc: 0, NDCG: 0.13075955774130654 HIT: 0.2924517463235294
Epoch: 1, plus 0 steps train_loss: 0.7593

#### test Acc: 0, NDCG: 0.1315014622468532 HIT: 0.29113625919117647

#### val Acc: 0, NDCG: 0.13211225904048313 HIT: 0.28841911764705885
Epoch: 2, plus 0 steps train_loss: 0.7526

#### test Acc: 0, NDCG: 0.12935501649155914 HIT: 0.28266314338235293

#### val Acc: 0, NDCG: 0.13157535955346067 HIT: 0.2879997702205882
Epoch: 3, plus 0 steps train_loss: 0.7483

#### test Acc: 0, NDCG: 0.1288005618632273 HIT: 0.2832950367647059

#### val Acc: 0, NDCG: 0.13166118977635566 HIT: 0.2911420036764706
Epoch: 4, plus 0 steps train_loss: 0.7421

#### test Acc: 0, NDCG: 0.12813807173279432 HIT: 0.2795783547794118

#### val Acc: 0, NDCG: 0.12783325623037245 HIT: 0.2810489430147059
Epoch: 5, plus 0 steps train_loss: 0.7326

#### test Acc: 0, NDCG: 0.13197199652928077 HIT: 0.29037224264705885

#### val Acc: 0, NDCG: 0.1313524895693347 HIT: 0.2877355238970588
Epoch: 6, plus 0 steps train_loss: 0.7349

#### test Acc: 0, NDCG: 0.12913607272308344 HIT: 0.28569048713235295

#### val Acc: 0, NDCG: 0.12942187768118513 HIT: 0.28428883272058825
Epoch: 7, plus 0 steps train_loss: 0.7314

#### test Acc: 0, NDCG: 0.13283573151635922 HIT: 0.2910271139705882

#### val Acc: 0, NDCG: 0.12955662950214342 HIT: 0.285546875
Epoch: 8, plus 0 steps train_loss: 0.7281

#### test Acc: 0, NDCG: 0.130141819802645 HIT: 0.2824161305147059

#### val Acc: 0, NDCG: 0.13190993867583928 HIT: 0.29226217830882356
Epoch: 9, plus 0 steps train_loss: 0.7213

#### test Acc: 0, NDCG: 0.13057738128652835 HIT: 0.2840877757352941

#### val Acc: 0, NDCG: 0.13139111664737502 HIT: 0.28965418198529413
Epoch: 10, plus 0 steps train_loss: 0.7216

#### test Acc: 0, NDCG: 0.12906741440980432 HIT: 0.2847943474264706

#### val Acc: 0, NDCG: 0.12857390615717687 HIT: 0.2866785386029412
Epoch: 12, plus 0 steps train_loss: 0.7194

#### test Acc: 0, NDCG: 0.12949337406840858 HIT: 0.2847598805147059

#### val Acc: 0, NDCG: 0.13096302243362812 HIT: 0.28763786764705884
Epoch: 14, plus 0 steps train_loss: 0.7196

#### test Acc: 0, NDCG: 0.13037724137371273 HIT: 0.2889993106617647

#### val Acc: 0, NDCG: 0.13242679354169432 HIT: 0.28923483455882354
Epoch: 16, plus 0 steps train_loss: 0.7132

#### test Acc: 0, NDCG: 0.1319624622906821 HIT: 0.2875919117647059

#### val Acc: 0, NDCG: 0.13197857646307534 HIT: 0.2929055606617647
Epoch: 18, plus 0 steps train_loss: 0.7096

#### test Acc: 0, NDCG: 0.12812983759438007 HIT: 0.2876034007352941

#### val Acc: 0, NDCG: 0.1321982101712667 HIT: 0.28840188419117646
Epoch: 20, plus 0 steps train_loss: 0.7155

#### test Acc: 0, NDCG: 0.12661140006770674 HIT: 0.27729204963235293

#### val Acc: 0, NDCG: 0.1328786423939592 HIT: 0.2941348805147059
Epoch: 22, plus 0 steps train_loss: 0.708

#### test Acc: 0, NDCG: 0.1340928059592604 HIT: 0.2930491727941177

#### val Acc: 0, NDCG: 0.13259422131254367 HIT: 0.29040670955882353
Epoch: 24, plus 0 steps train_loss: 0.7083

#### test Acc: 0, NDCG: 0.12822415358747846 HIT: 0.2861615349264706

#### val Acc: 0, NDCG: 0.1310272979876017 HIT: 0.2866842830882353
Epoch: 26, plus 0 steps train_loss: 0.7097

#### test Acc: 0, NDCG: 0.13370913072232013 HIT: 0.2924517463235294

#### val Acc: 0, NDCG: 0.13032234520786828 HIT: 0.2885684742647059
Epoch: 28, plus 0 steps train_loss: 0.7059

#### test Acc: 0, NDCG: 0.1328504537821447 HIT: 0.29197495404411766

#### val Acc: 0, NDCG: 0.13034550301973538 HIT: 0.2848115808823529
Epoch: 30, plus 0 steps train_loss: 0.7037

#### test Acc: 0, NDCG: 0.13283899680022135 HIT: 0.28835592830882356

#### val Acc: 0, NDCG: 0.13197057441294263 HIT: 0.29235983455882353
Epoch: 32, plus 0 steps train_loss: 0.7032

#### test Acc: 0, NDCG: 0.13155907907718953 HIT: 0.29246323529411766

#### val Acc: 0, NDCG: 0.12934796923124497 HIT: 0.2903377757352941
Epoch: 36, plus 0 steps train_loss: 0.7021

#### test Acc: 0, NDCG: 0.1285889780583889 HIT: 0.2833409926470588

#### val Acc: 0, NDCG: 0.13008088499818035 HIT: 0.28887867647058824
Epoch: 40, plus 0 steps train_loss: 0.7041

#### test Acc: 0, NDCG: 0.12990896367453025 HIT: 0.28673598345588236

#### val Acc: 0, NDCG: 0.1335020528717731 HIT: 0.28727022058823526
Epoch: 44, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.130602113413277 HIT: 0.2855641084558823

#### val Acc: 0, NDCG: 0.13031694818791506 HIT: 0.2868451286764706
Epoch: 48, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.13230343064264358 HIT: 0.2898954503676471

#### val Acc: 0, NDCG: 0.12957992774076035 HIT: 0.28195657169117644
Epoch: 52, plus 0 steps train_loss: 0.7017

#### test Acc: 0, NDCG: 0.13177951351518105 HIT: 0.2875057444852941

#### val Acc: 0, NDCG: 0.1284348176904066 HIT: 0.2834788602941177
Epoch: 56, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.13174402188173873 HIT: 0.2890739889705882

#### val Acc: 0, NDCG: 0.13234568487748039 HIT: 0.2869772518382353
Epoch: 60, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.1349685570766123 HIT: 0.2895565257352941

#### val Acc: 0, NDCG: 0.13744394558433437 HIT: 0.2940085018382353
Epoch: 64, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.13812673450068794 HIT: 0.2982019761029412

#### val Acc: 0, NDCG: 0.14229594463108725 HIT: 0.29564568014705883
Epoch: 68, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.20535238762200353 HIT: 0.3609317555147059

#### val Acc: 0, NDCG: 0.22541943931669084 HIT: 0.375390625
Epoch: 72, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.4964931658884015 HIT: 0.6166302849264705

#### val Acc: 0, NDCG: 0.5042294699391571 HIT: 0.6173828125
Epoch: 80, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.4652465045212577 HIT: 0.5854262408088236

#### val Acc: 0, NDCG: 0.48512227007345193 HIT: 0.6005284926470588
Epoch: 88, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.6327796817498279 HIT: 0.7261948529411765

#### val Acc: 0, NDCG: 0.6563226447252409 HIT: 0.7456456801470588
Epoch: 96, plus 0 steps train_loss: 0.6932

#### test Acc: 0, NDCG: 0.600407722244485 HIT: 0.6999080882352942

#### val Acc: 0, NDCG: 0.6024403246860727 HIT: 0.6993336397058824
Epoch: 104, plus 0 steps train_loss: 0.6953

#### test Acc: 0, NDCG: 0.6173438232541832 HIT: 0.7148839613970588

#### val Acc: 0, NDCG: 0.6223278370242155 HIT: 0.7155215992647059
Epoch: 112, plus 0 steps train_loss: 0.6938

#### test Acc: 0, NDCG: 0.6145894720804005 HIT: 0.7092945772058823

#### val Acc: 0, NDCG: 0.6325709084866401 HIT: 0.7284237132352941
Epoch: 120, plus 0 steps train_loss: 0.6941

#### test Acc: 0, NDCG: 0.4584494708701191 HIT: 0.5866842830882353

#### val Acc: 0, NDCG: 0.4828905852215807 HIT: 0.6099264705882353
Epoch: 128, plus 0 steps train_loss: 0.6923

#### test Acc: 0, NDCG: 0.6747559844920911 HIT: 0.7633329503676471

#### val Acc: 0, NDCG: 0.6781831592759803 HIT: 0.7636948529411764
Epoch: 136, plus 0 steps train_loss: 0.689

#### test Acc: 0, NDCG: 0.5693239596966487 HIT: 0.6764820772058824

#### val Acc: 0, NDCG: 0.5886677026261109 HIT: 0.6901079963235295
Epoch: 144, plus 0 steps train_loss: 0.6857

#### test Acc: 0, NDCG: 0.703270142984025 HIT: 0.7872931985294118

#### val Acc: 0, NDCG: 0.7262814528625443 HIT: 0.8013327205882353
Epoch: 160, plus 0 steps train_loss: 0.6861

#### test Acc: 0, NDCG: 0.6471626438165068 HIT: 0.7410500919117646

#### val Acc: 0, NDCG: 0.6710374300118264 HIT: 0.7631548713235294
Epoch: 176, plus 0 steps train_loss: 0.6831

#### test Acc: 0, NDCG: 0.5588179179754539 HIT: 0.6796645220588236

#### val Acc: 0, NDCG: 0.5854473374828344 HIT: 0.7042738970588236
Epoch: 192, plus 0 steps train_loss: 0.6834

#### test Acc: 0, NDCG: 0.6966493145043471 HIT: 0.7843577665441177

#### val Acc: 0, NDCG: 0.7180350678485363 HIT: 0.800390625
Epoch: 208, plus 0 steps train_loss: 0.6767

#### test Acc: 0, NDCG: 0.28629503858830324 HIT: 0.4748621323529412

#### val Acc: 0, NDCG: 0.31587715967489094 HIT: 0.5041762408088235
Epoch: 224, plus 0 steps train_loss: 0.6811

#### test Acc: 0, NDCG: 0.685744962862884 HIT: 0.7760799632352942

#### val Acc: 0, NDCG: 0.7042942786755683 HIT: 0.7905101102941177
Epoch: 240, plus 0 steps train_loss: 0.6765

#### test Acc: 0, NDCG: 0.632941225356186 HIT: 0.7449333639705882

#### val Acc: 0, NDCG: 0.650080095671273 HIT: 0.7540153952205882
Epoch: 256, plus 0 steps train_loss: 0.6712

#### test Acc: 0, NDCG: 0.3104306899397985 HIT: 0.50654296875

#### val Acc: 0, NDCG: 0.3498712395874398 HIT: 0.5492934283088236
Epoch: 272, plus 0 steps train_loss: 0.6739

#### test Acc: 0, NDCG: 0.2620484799430554 HIT: 0.47483340992647055

#### val Acc: 0, NDCG: 0.2731785558577913 HIT: 0.4876665900735294
Epoch: 288, plus 0 steps train_loss: 0.6626

#### test Acc: 0, NDCG: 0.2507341552005504 HIT: 0.47638442095588235

#### val Acc: 0, NDCG: 0.2551129793726964 HIT: 0.4770967371323529
Epoch: 304, plus 0 steps train_loss: 0.658

#### test Acc: 0, NDCG: 0.24562555195374253 HIT: 0.4654928768382353

#### val Acc: 0, NDCG: 0.245760617970792 HIT: 0.46380974264705876
Epoch: 320, plus 0 steps train_loss: 0.6555

#### test Acc: 0, NDCG: 0.24661296212788306 HIT: 0.46368336397058824

#### val Acc: 0, NDCG: 0.26017097747681833 HIT: 0.48247931985294124
Epoch: 352, plus 0 steps train_loss: 0.6362

#### test Acc: 0, NDCG: 0.25553440543648287 HIT: 0.47059972426470587

#### val Acc: 0, NDCG: 0.26105217003447445 HIT: 0.4777056525735294
Epoch: 384, plus 0 steps train_loss: 0.6569

#### test Acc: 0, NDCG: 0.263439248879828 HIT: 0.4854894301470588

#### val Acc: 0, NDCG: 0.26323109064791683 HIT: 0.4809914981617647
Epoch: 416, plus 0 steps train_loss: 0.64

#### test Acc: 0, NDCG: 0.2603446489377437 HIT: 0.4771254595588236

#### val Acc: 0, NDCG: 0.265897430395001 HIT: 0.4891256893382353
Epoch: 448, plus 0 steps train_loss: 0.6283

#### test Acc: 0, NDCG: 0.274170010519847 HIT: 0.4905101102941177

#### val Acc: 0, NDCG: 0.27968824158645633 HIT: 0.5065659466911765
Epoch: 480, plus 0 steps train_loss: 0.6386

#### test Acc: 0, NDCG: 0.2767721129765471 HIT: 0.5014016544117647

#### val Acc: 0, NDCG: 0.285601530753694 HIT: 0.5087258731617647
Epoch: 512, plus 0 steps train_loss: 0.6317

#### test Acc: 0, NDCG: 0.2838528684763819 HIT: 0.5120921415441176

#### val Acc: 0, NDCG: 0.28633000893850574 HIT: 0.5144875919117646
Epoch: 544, plus 0 steps train_loss: 0.6171

#### test Acc: 0, NDCG: 0.2858964759834976 HIT: 0.5154641544117646

#### val Acc: 0, NDCG: 0.29490950088614165 HIT: 0.5263959099264706
Epoch: 576, plus 0 steps train_loss: 0.6141

#### test Acc: 0, NDCG: 0.2858470601166273 HIT: 0.5216452205882354

#### val Acc: 0, NDCG: 0.2872066160491374 HIT: 0.5176987591911765
Epoch: 608, plus 0 steps train_loss: 0.6231

#### test Acc: 0, NDCG: 0.294211809969252 HIT: 0.5311868106617647

#### val Acc: 0, NDCG: 0.30216132398768636 HIT: 0.5399126838235294
Epoch: 640, plus 0 steps train_loss: 0.6262

#### test Acc: 0, NDCG: 0.29409137914969097 HIT: 0.5307100183823529

#### val Acc: 0, NDCG: 0.2977027599968759 HIT: 0.5322437959558823
Epoch: 704, plus 0 steps train_loss: 0.6155

#### test Acc: 0, NDCG: 0.2981204368509113 HIT: 0.5336109834558823

#### val Acc: 0, NDCG: 0.30151859747825516 HIT: 0.5322610294117647
Epoch: 768, plus 0 steps train_loss: 0.6052

#### test Acc: 0, NDCG: 0.30932157486157424 HIT: 0.5484317555147059

#### val Acc: 0, NDCG: 0.3071005887007641 HIT: 0.5411707261029413
Epoch: 832, plus 0 steps train_loss: 0.6185

#### test Acc: 0, NDCG: 0.30137961085641657 HIT: 0.5357996323529413

#### val Acc: 0, NDCG: 0.31126916793427073 HIT: 0.5494025735294118
Epoch: 896, plus 0 steps train_loss: 0.6097

#### test Acc: 0, NDCG: 0.3070985056320856 HIT: 0.5481732536764705

#### val Acc: 0, NDCG: 0.310382837469788 HIT: 0.5468577665441177
Epoch: 960, plus 0 steps train_loss: 0.603

#### test Acc: 0, NDCG: 0.3077738109835078 HIT: 0.5431812959558824

#### val Acc: 0, NDCG: 0.3190305820253224 HIT: 0.5582892922794118
Epoch: 1013, plus 25 steps train_loss: 0.601
Done: it took 295110.24117302895
max value of NDCG: 0.703270142984025
max value of HIT: 0.7872931985294118

After 20 validations
max value of NDCG: 0.703270142984025
max value of HIT: 0.7872931985294118
