 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	1.0
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
RMHA_decoder:         	False
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_encoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12823146263864632 HIT: 0.28537454044117644

#### val Acc: 0, NDCG: 0.12593100044230526 HIT: 0.2819967830882353
Epoch: 1, plus 0 steps train_loss: 0.7764

#### test Acc: 0, NDCG: 0.12956252010203764 HIT: 0.2857709099264706

#### val Acc: 0, NDCG: 0.12903782456125892 HIT: 0.2825769761029412
Epoch: 2, plus 0 steps train_loss: 0.7612

#### test Acc: 0, NDCG: 0.13297038361312155 HIT: 0.2908835018382353

#### val Acc: 0, NDCG: 0.13137236099706442 HIT: 0.2916360294117647
Epoch: 3, plus 0 steps train_loss: 0.7694

#### test Acc: 0, NDCG: 0.13098669683030711 HIT: 0.2922564338235294

#### val Acc: 0, NDCG: 0.1313215478801762 HIT: 0.29005629595588234
Epoch: 4, plus 0 steps train_loss: 0.7514

#### test Acc: 0, NDCG: 0.13287615503386607 HIT: 0.2888671875

#### val Acc: 0, NDCG: 0.13304765104429525 HIT: 0.29025735294117644
Epoch: 5, plus 0 steps train_loss: 0.7436

#### test Acc: 0, NDCG: 0.12795332871265705 HIT: 0.2827033547794118

#### val Acc: 0, NDCG: 0.1303070527995313 HIT: 0.2863568474264706
Epoch: 6, plus 0 steps train_loss: 0.7378

#### test Acc: 0, NDCG: 0.13078623089205424 HIT: 0.2918658088235294

#### val Acc: 0, NDCG: 0.12948151690826543 HIT: 0.2877412683823529
Epoch: 7, plus 0 steps train_loss: 0.7341

#### test Acc: 0, NDCG: 0.12711709437865767 HIT: 0.2811638327205882

#### val Acc: 0, NDCG: 0.12792493642845754 HIT: 0.28188763786764703
Epoch: 8, plus 0 steps train_loss: 0.7339

#### test Acc: 0, NDCG: 0.13311052869443865 HIT: 0.2947897518382353

#### val Acc: 0, NDCG: 0.1358455735325382 HIT: 0.2947150735294118
Epoch: 9, plus 0 steps train_loss: 0.7298

#### test Acc: 0, NDCG: 0.12788819999324894 HIT: 0.2831284466911764

#### val Acc: 0, NDCG: 0.13369395174998222 HIT: 0.2948586856617647
Epoch: 10, plus 0 steps train_loss: 0.7241

#### test Acc: 0, NDCG: 0.1348088366338158 HIT: 0.2964154411764706

#### val Acc: 0, NDCG: 0.12725723505494194 HIT: 0.2811121323529412
Epoch: 12, plus 0 steps train_loss: 0.722

#### test Acc: 0, NDCG: 0.12900047121370226 HIT: 0.2860696231617647

#### val Acc: 0, NDCG: 0.13065294253156998 HIT: 0.2882755055147059
Epoch: 14, plus 0 steps train_loss: 0.7195

#### test Acc: 0, NDCG: 0.128616038610942 HIT: 0.28274931066176473

#### val Acc: 0, NDCG: 0.13043584393370083 HIT: 0.2834788602941177
Epoch: 16, plus 0 steps train_loss: 0.7198

#### test Acc: 0, NDCG: 0.1279790259711413 HIT: 0.2818014705882353

#### val Acc: 0, NDCG: 0.1267113934288066 HIT: 0.27513786764705883
Epoch: 18, plus 0 steps train_loss: 0.717

#### test Acc: 0, NDCG: 0.12744905282339808 HIT: 0.2795783547794118

#### val Acc: 0, NDCG: 0.1289141958325512 HIT: 0.2838177849264706
Epoch: 20, plus 0 steps train_loss: 0.71

#### test Acc: 0, NDCG: 0.12784157071321672 HIT: 0.2796472886029412

#### val Acc: 0, NDCG: 0.1298417255936123 HIT: 0.2855755974264706
Epoch: 22, plus 0 steps train_loss: 0.7101

#### test Acc: 0, NDCG: 0.13064426482571173 HIT: 0.28792509191176474

#### val Acc: 0, NDCG: 0.1279835336961544 HIT: 0.2850988051470588
Epoch: 24, plus 0 steps train_loss: 0.7073

#### test Acc: 0, NDCG: 0.131704950075508 HIT: 0.2852366727941177

#### val Acc: 0, NDCG: 0.12462569322076375 HIT: 0.27668887867647063
Epoch: 26, plus 0 steps train_loss: 0.7062

#### test Acc: 0, NDCG: 0.13247430155004958 HIT: 0.2921875

#### val Acc: 0, NDCG: 0.129130862087189 HIT: 0.28664407169117645
Epoch: 28, plus 0 steps train_loss: 0.7035

#### test Acc: 0, NDCG: 0.12781512872200823 HIT: 0.2856732536764706

#### val Acc: 0, NDCG: 0.13367714501617559 HIT: 0.2945772058823529
Epoch: 30, plus 0 steps train_loss: 0.7052

#### test Acc: 0, NDCG: 0.12782333323950162 HIT: 0.28031364889705884

#### val Acc: 0, NDCG: 0.12859602817718777 HIT: 0.2820369944852941
Epoch: 32, plus 0 steps train_loss: 0.7025

#### test Acc: 0, NDCG: 0.13813286610401015 HIT: 0.3009937959558823

#### val Acc: 0, NDCG: 0.1271058048194909 HIT: 0.2795840992647059
Epoch: 36, plus 0 steps train_loss: 0.7024

#### test Acc: 0, NDCG: 0.13472796450790048 HIT: 0.29852366727941176

#### val Acc: 0, NDCG: 0.1278142377686186 HIT: 0.28399586397058824
Epoch: 40, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.14743173409387594 HIT: 0.30209673713235297

#### val Acc: 0, NDCG: 0.16057102906979337 HIT: 0.3203986672794118
Epoch: 44, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.1600286685205718 HIT: 0.3121380974264706

#### val Acc: 0, NDCG: 0.17171024246747357 HIT: 0.3250057444852941
Epoch: 48, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.1339051473697077 HIT: 0.2916302849264706

#### val Acc: 0, NDCG: 0.13510422373400763 HIT: 0.2944910386029412
Epoch: 52, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.13354256257481306 HIT: 0.29140625

#### val Acc: 0, NDCG: 0.1332690939497554 HIT: 0.29273322610294117
Epoch: 56, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.13734881453377665 HIT: 0.2958984375

#### val Acc: 0, NDCG: 0.13664805789391382 HIT: 0.29460592830882354
Epoch: 60, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.13834550758320252 HIT: 0.3018324908088236

#### val Acc: 0, NDCG: 0.13380782299939348 HIT: 0.2904469209558823
Epoch: 64, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.13285371228823234 HIT: 0.29048713235294116

#### val Acc: 0, NDCG: 0.1304820170060833 HIT: 0.28135340073529413
Epoch: 68, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.13431111747256824 HIT: 0.2923368566176471

#### val Acc: 0, NDCG: 0.13400116437319556 HIT: 0.28966567095588236
Epoch: 72, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.13332619180863906 HIT: 0.2918658088235294

#### val Acc: 0, NDCG: 0.13496757769457418 HIT: 0.29525505514705885
Epoch: 80, plus 0 steps train_loss: 0.6937

#### test Acc: 0, NDCG: 0.1423800298939851 HIT: 0.30528492647058825

#### val Acc: 0, NDCG: 0.14779427919653643 HIT: 0.3086684283088236
Epoch: 88, plus 0 steps train_loss: 0.6946

#### test Acc: 0, NDCG: 0.15389355151944692 HIT: 0.32494255514705883

#### val Acc: 0, NDCG: 0.15665006247127564 HIT: 0.33192784926470587
Epoch: 96, plus 0 steps train_loss: 0.6924

#### test Acc: 0, NDCG: 0.16899089901269027 HIT: 0.3534237132352941

#### val Acc: 0, NDCG: 0.1810632601560266 HIT: 0.36410845588235297
Epoch: 104, plus 0 steps train_loss: 0.6921

#### test Acc: 0, NDCG: 0.20758975494126847 HIT: 0.3925723805147059

#### val Acc: 0, NDCG: 0.22885294257828956 HIT: 0.40993795955882356
Epoch: 112, plus 0 steps train_loss: 0.6941

#### test Acc: 0, NDCG: 0.18072064909151062 HIT: 0.3724839154411764

#### val Acc: 0, NDCG: 0.18212760216346255 HIT: 0.3700884650735294
Epoch: 120, plus 0 steps train_loss: 0.689

#### test Acc: 0, NDCG: 0.19596768370703932 HIT: 0.39100988051470587

#### val Acc: 0, NDCG: 0.20097643677567842 HIT: 0.39724264705882356
Epoch: 128, plus 0 steps train_loss: 0.6827

#### test Acc: 0, NDCG: 0.1931445325834067 HIT: 0.3840647977941177

#### val Acc: 0, NDCG: 0.20070667976503104 HIT: 0.3845358455882353
Epoch: 136, plus 0 steps train_loss: 0.6806

#### test Acc: 0, NDCG: 0.22975203376345474 HIT: 0.4272805606617647

#### val Acc: 0, NDCG: 0.2326798825262319 HIT: 0.4259823069852941
Epoch: 144, plus 0 steps train_loss: 0.6711

#### test Acc: 0, NDCG: 0.19855998428266478 HIT: 0.3923713235294118

#### val Acc: 0, NDCG: 0.20347489903814475 HIT: 0.39681181066176474
Epoch: 160, plus 0 steps train_loss: 0.6613

#### test Acc: 0, NDCG: 0.20196978745371372 HIT: 0.4051987591911764

#### val Acc: 0, NDCG: 0.20233639940141632 HIT: 0.4013729319852941
Epoch: 176, plus 0 steps train_loss: 0.6593

#### test Acc: 0, NDCG: 0.20456948195654773 HIT: 0.41291360294117646

#### val Acc: 0, NDCG: 0.2086121866222018 HIT: 0.413671875
Epoch: 192, plus 0 steps train_loss: 0.6632

#### test Acc: 0, NDCG: 0.21238220103819588 HIT: 0.4069048713235294

#### val Acc: 0, NDCG: 0.21690465980474424 HIT: 0.4069278492647059
Epoch: 208, plus 0 steps train_loss: 0.6554

#### test Acc: 0, NDCG: 0.22192319019641915 HIT: 0.4248851102941177

#### val Acc: 0, NDCG: 0.23513429401564342 HIT: 0.43175551470588236
Epoch: 224, plus 0 steps train_loss: 0.6567

#### test Acc: 0, NDCG: 0.22276265607435622 HIT: 0.4291475183823529

#### val Acc: 0, NDCG: 0.22986588741672956 HIT: 0.4283777573529412
Epoch: 240, plus 0 steps train_loss: 0.6531

#### test Acc: 0, NDCG: 0.22911354736652378 HIT: 0.42917624080882355

#### val Acc: 0, NDCG: 0.24288275768975914 HIT: 0.44025160845588235
Epoch: 256, plus 0 steps train_loss: 0.6533

#### test Acc: 0, NDCG: 0.23811165445700871 HIT: 0.4461224724264706

#### val Acc: 0, NDCG: 0.2548224756695323 HIT: 0.4589786305147059
Epoch: 272, plus 0 steps train_loss: 0.6458

#### test Acc: 0, NDCG: 0.24510823328557668 HIT: 0.45184397977941176

#### val Acc: 0, NDCG: 0.268373160457348 HIT: 0.4703469669117647
Epoch: 288, plus 0 steps train_loss: 0.6416

#### test Acc: 0, NDCG: 0.25768196633904583 HIT: 0.4713579963235294

#### val Acc: 0, NDCG: 0.2786053757123354 HIT: 0.4830365349264706
Epoch: 304, plus 0 steps train_loss: 0.6502

#### test Acc: 0, NDCG: 0.285355689903353 HIT: 0.5004825367647059

#### val Acc: 0, NDCG: 0.2865057702903516 HIT: 0.4949563419117647
Epoch: 320, plus 0 steps train_loss: 0.6393

#### test Acc: 0, NDCG: 0.2905430957136391 HIT: 0.5088522518382353

#### val Acc: 0, NDCG: 0.2995704660425407 HIT: 0.5044749540441177
Epoch: 352, plus 0 steps train_loss: 0.6374

#### test Acc: 0, NDCG: 0.29574991359318553 HIT: 0.5050608915441177

#### val Acc: 0, NDCG: 0.3180785059507307 HIT: 0.5257238051470587
Epoch: 384, plus 0 steps train_loss: 0.6273

#### test Acc: 0, NDCG: 0.2818926252530286 HIT: 0.5057559742647059

#### val Acc: 0, NDCG: 0.29856994137810255 HIT: 0.5250517003676471
Epoch: 416, plus 0 steps train_loss: 0.6262

#### test Acc: 0, NDCG: 0.29584558534125105 HIT: 0.5260569852941177

#### val Acc: 0, NDCG: 0.31163185109969493 HIT: 0.5311638327205882
Epoch: 448, plus 0 steps train_loss: 0.6123

#### test Acc: 0, NDCG: 0.2926392178444847 HIT: 0.5226849724264706

#### val Acc: 0, NDCG: 0.3087965016392412 HIT: 0.5387925091911765
Epoch: 480, plus 0 steps train_loss: 0.613

#### test Acc: 0, NDCG: 0.3007029799809747 HIT: 0.5371208639705882

#### val Acc: 0, NDCG: 0.3079640011385804 HIT: 0.5388212316176471
Epoch: 512, plus 0 steps train_loss: 0.5991

#### test Acc: 0, NDCG: 0.2990992936089706 HIT: 0.5385627297794118

#### val Acc: 0, NDCG: 0.3103951995480761 HIT: 0.5402228860294118
Epoch: 544, plus 0 steps train_loss: 0.6147

#### test Acc: 0, NDCG: 0.29541455694247454 HIT: 0.5354836856617646

#### val Acc: 0, NDCG: 0.32061094812664964 HIT: 0.5501895680147059
Epoch: 576, plus 0 steps train_loss: 0.614

#### test Acc: 0, NDCG: 0.30410685083084155 HIT: 0.54794921875

#### val Acc: 0, NDCG: 0.31260931087780774 HIT: 0.5544577205882353
Epoch: 608, plus 0 steps train_loss: 0.6069

#### test Acc: 0, NDCG: 0.30287666792058693 HIT: 0.5462833180147059

#### val Acc: 0, NDCG: 0.3111621991086446 HIT: 0.5435374540441177
Epoch: 640, plus 0 steps train_loss: 0.6039

#### test Acc: 0, NDCG: 0.30049151902299753 HIT: 0.5455882352941177

#### val Acc: 0, NDCG: 0.31003986643996545 HIT: 0.5520967371323529
Epoch: 704, plus 0 steps train_loss: 0.611

#### test Acc: 0, NDCG: 0.30166098499710764 HIT: 0.5514590992647059

#### val Acc: 0, NDCG: 0.3132513075901885 HIT: 0.5607651654411765
Epoch: 768, plus 0 steps train_loss: 0.5982

#### test Acc: 0, NDCG: 0.3051516839673279 HIT: 0.5476217830882353

#### val Acc: 0, NDCG: 0.3107637063064167 HIT: 0.5554113051470588
Epoch: 832, plus 0 steps train_loss: 0.6043

#### test Acc: 0, NDCG: 0.30488403108011514 HIT: 0.5501378676470587

#### val Acc: 0, NDCG: 0.3187622316688753 HIT: 0.5526482077205882
Epoch: 896, plus 0 steps train_loss: 0.6047

#### test Acc: 0, NDCG: 0.30842133282215445 HIT: 0.5574850643382353

#### val Acc: 0, NDCG: 0.32035173930843946 HIT: 0.5686006433823529
Epoch: 960, plus 0 steps train_loss: 0.5849

#### test Acc: 0, NDCG: 0.3036784700271121 HIT: 0.5526941636029412

#### val Acc: 0, NDCG: 0.318109516415691 HIT: 0.5647690716911764
Epoch: 1013, plus 25 steps train_loss: 0.603
Done: it took 297636.1250257492
max value of NDCG: 0.30842133282215445
max value of HIT: 0.5574850643382353

After 20 validations
max value of NDCG: 0.30842133282215445
max value of HIT: 0.5574850643382353
