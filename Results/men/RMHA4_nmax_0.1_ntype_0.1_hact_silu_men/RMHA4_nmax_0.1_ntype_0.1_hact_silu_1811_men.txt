 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	0.1
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12438971719192951 HIT: 0.2773552389705882

#### val Acc: 0, NDCG: 0.12890709810673504 HIT: 0.28727022058823526
Epoch: 1, plus 0 steps train_loss: 0.7647

#### test Acc: 0, NDCG: 0.1273055864347934 HIT: 0.28352481617647063

#### val Acc: 0, NDCG: 0.1271731496081175 HIT: 0.28137063419117647
Epoch: 2, plus 0 steps train_loss: 0.7527

#### test Acc: 0, NDCG: 0.13378808788260896 HIT: 0.28929802389705883

#### val Acc: 0, NDCG: 0.12898264894338746 HIT: 0.28611557904411766
Epoch: 3, plus 0 steps train_loss: 0.7376

#### test Acc: 0, NDCG: 0.13113308450699473 HIT: 0.28923483455882354

#### val Acc: 0, NDCG: 0.13417470832123063 HIT: 0.29321001838235294
Epoch: 4, plus 0 steps train_loss: 0.7224

#### test Acc: 0, NDCG: 0.19060455614775257 HIT: 0.34621438419117645

#### val Acc: 0, NDCG: 0.19873023723139058 HIT: 0.3579963235294118
Epoch: 5, plus 0 steps train_loss: 0.7148

#### test Acc: 0, NDCG: 0.23132003014017766 HIT: 0.3837833180147059

#### val Acc: 0, NDCG: 0.2484062720255748 HIT: 0.3995059742647059
Epoch: 6, plus 0 steps train_loss: 0.7075

#### test Acc: 0, NDCG: 0.24619137214068476 HIT: 0.4016946231617647

#### val Acc: 0, NDCG: 0.26226507996907766 HIT: 0.4186695772058823
Epoch: 7, plus 0 steps train_loss: 0.7077

#### test Acc: 0, NDCG: 0.33828851538698146 HIT: 0.4813706341911764

#### val Acc: 0, NDCG: 0.3551604465733827 HIT: 0.4929285386029412
Epoch: 8, plus 0 steps train_loss: 0.7047

#### test Acc: 0, NDCG: 0.29269124057392004 HIT: 0.44152688419117647

#### val Acc: 0, NDCG: 0.3132911010069408 HIT: 0.4593175551470588
Epoch: 9, plus 0 steps train_loss: 0.7057

#### test Acc: 0, NDCG: 0.2674555835248987 HIT: 0.4188706341911764

#### val Acc: 0, NDCG: 0.29310778687664607 HIT: 0.43907973345588236
Epoch: 10, plus 0 steps train_loss: 0.706

#### test Acc: 0, NDCG: 0.25282782622275685 HIT: 0.4049115349264706

#### val Acc: 0, NDCG: 0.2763399867877835 HIT: 0.42131778492647054
Epoch: 12, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.28742494632579724 HIT: 0.43596622242647054

#### val Acc: 0, NDCG: 0.3152066444409253 HIT: 0.46335018382352944
Epoch: 14, plus 0 steps train_loss: 0.7032

#### test Acc: 0, NDCG: 0.2779708915161545 HIT: 0.4290383731617647

#### val Acc: 0, NDCG: 0.2922581151852056 HIT: 0.44240004595588234
Epoch: 16, plus 0 steps train_loss: 0.7

#### test Acc: 0, NDCG: 0.2540163878564764 HIT: 0.4073529411764706

#### val Acc: 0, NDCG: 0.2814337929765516 HIT: 0.4293485753676471
Epoch: 18, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.27540116865755976 HIT: 0.4243221507352941

#### val Acc: 0, NDCG: 0.3043999325943385 HIT: 0.45566980698529413
Epoch: 20, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.3275627002784168 HIT: 0.4710420496323529

#### val Acc: 0, NDCG: 0.344346857513584 HIT: 0.4890682444852941
Epoch: 22, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.24940693148397894 HIT: 0.40793313419117644

#### val Acc: 0, NDCG: 0.2570389639192642 HIT: 0.4075827205882353
Epoch: 24, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.31158354243671327 HIT: 0.4638212316176471

#### val Acc: 0, NDCG: 0.3389593830690998 HIT: 0.48448414522058825
Epoch: 26, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.21055696382213163 HIT: 0.3720703125

#### val Acc: 0, NDCG: 0.23272133790945032 HIT: 0.38724724264705884
Epoch: 28, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.19672731648890346 HIT: 0.35292394301470587

#### val Acc: 0, NDCG: 0.2179643901742358 HIT: 0.37734375
Epoch: 30, plus 0 steps train_loss: 0.6954

#### test Acc: 0, NDCG: 0.20198443344333797 HIT: 0.3614085477941177

#### val Acc: 0, NDCG: 0.22630907558245847 HIT: 0.37811351102941176
Epoch: 32, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.20790108595096496 HIT: 0.3680319393382353

#### val Acc: 0, NDCG: 0.23180672447515627 HIT: 0.39478400735294117
Epoch: 36, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.3038059010502957 HIT: 0.4527113970588236

#### val Acc: 0, NDCG: 0.32973811771140665 HIT: 0.4823701746323529
Epoch: 40, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.19488563861132677 HIT: 0.37216796875

#### val Acc: 0, NDCG: 0.2137602448766282 HIT: 0.38547219669117644
Epoch: 44, plus 0 steps train_loss: 0.6917

#### test Acc: 0, NDCG: 0.22161316684466642 HIT: 0.4083697150735294

#### val Acc: 0, NDCG: 0.24777620182162458 HIT: 0.43781594669117646
Epoch: 48, plus 0 steps train_loss: 0.6846

#### test Acc: 0, NDCG: 0.2366887595993176 HIT: 0.4410500919117647

#### val Acc: 0, NDCG: 0.25682636608152515 HIT: 0.45558938419117645
Epoch: 52, plus 0 steps train_loss: 0.6792

#### test Acc: 0, NDCG: 0.22960645610904012 HIT: 0.456640625

#### val Acc: 0, NDCG: 0.23578079338214758 HIT: 0.4497127757352941
Epoch: 56, plus 0 steps train_loss: 0.668

#### test Acc: 0, NDCG: 0.22498706887964476 HIT: 0.4498334099264706

#### val Acc: 0, NDCG: 0.23197335621058998 HIT: 0.4576171875
Epoch: 60, plus 0 steps train_loss: 0.6618

#### test Acc: 0, NDCG: 0.2254695130073256 HIT: 0.4458926930147059

#### val Acc: 0, NDCG: 0.23550581849946273 HIT: 0.4638154871323529
Epoch: 64, plus 0 steps train_loss: 0.6408

#### test Acc: 0, NDCG: 0.2359524667431901 HIT: 0.46368910845588235

#### val Acc: 0, NDCG: 0.24242787272758964 HIT: 0.4835305606617647
Epoch: 68, plus 0 steps train_loss: 0.6548

#### test Acc: 0, NDCG: 0.2485548630640552 HIT: 0.4874540441176471

#### val Acc: 0, NDCG: 0.2435298486191196 HIT: 0.47644186580882353
Epoch: 72, plus 0 steps train_loss: 0.6381

#### test Acc: 0, NDCG: 0.26418865665177443 HIT: 0.5097139246323529

#### val Acc: 0, NDCG: 0.2637497067773401 HIT: 0.5034811580882353
Epoch: 80, plus 0 steps train_loss: 0.6202

#### test Acc: 0, NDCG: 0.2654965222889609 HIT: 0.5053596047794118

#### val Acc: 0, NDCG: 0.2712769537608373 HIT: 0.514453125
Epoch: 88, plus 0 steps train_loss: 0.6212

#### test Acc: 0, NDCG: 0.28206562586260614 HIT: 0.5288602941176471

#### val Acc: 0, NDCG: 0.2868424950831437 HIT: 0.5309857536764706
Epoch: 96, plus 0 steps train_loss: 0.6032

#### test Acc: 0, NDCG: 0.28037315987691513 HIT: 0.5259765625

#### val Acc: 0, NDCG: 0.28497192734925786 HIT: 0.5274528952205882
Epoch: 104, plus 0 steps train_loss: 0.6073

#### test Acc: 0, NDCG: 0.29158190884071084 HIT: 0.5361443014705882

#### val Acc: 0, NDCG: 0.2991011684532354 HIT: 0.5406594669117647
Epoch: 112, plus 0 steps train_loss: 0.6166

#### test Acc: 0, NDCG: 0.29451669494751265 HIT: 0.5391544117647059

#### val Acc: 0, NDCG: 0.2960823119603386 HIT: 0.5355411305147059
Epoch: 120, plus 0 steps train_loss: 0.5932

#### test Acc: 0, NDCG: 0.30868495927832795 HIT: 0.5542509191176471

#### val Acc: 0, NDCG: 0.31147614459731077 HIT: 0.5577722886029413
Epoch: 128, plus 0 steps train_loss: 0.5949

#### test Acc: 0, NDCG: 0.30717813810668426 HIT: 0.5503331801470588

#### val Acc: 0, NDCG: 0.31652478849920845 HIT: 0.5589499080882353
Epoch: 136, plus 0 steps train_loss: 0.5889

#### test Acc: 0, NDCG: 0.3229793372444661 HIT: 0.5648092830882353

#### val Acc: 0, NDCG: 0.3181422756176424 HIT: 0.5554055606617647
Epoch: 144, plus 0 steps train_loss: 0.5909

#### test Acc: 0, NDCG: 0.326117916660312 HIT: 0.5685374540441177

#### val Acc: 0, NDCG: 0.33407519450978906 HIT: 0.5742359834558823
Epoch: 160, plus 0 steps train_loss: 0.5854

#### test Acc: 0, NDCG: 0.3350509060738986 HIT: 0.5816004136029412

#### val Acc: 0, NDCG: 0.3383515120484336 HIT: 0.5805319393382353
Epoch: 176, plus 0 steps train_loss: 0.5778

#### test Acc: 0, NDCG: 0.3350671583791661 HIT: 0.5842658547794117

#### val Acc: 0, NDCG: 0.3369325641321277 HIT: 0.5814165900735294
Epoch: 192, plus 0 steps train_loss: 0.5667

#### test Acc: 0, NDCG: 0.34042100354871185 HIT: 0.5867532169117646

#### val Acc: 0, NDCG: 0.35257270005238306 HIT: 0.5986960018382353
Epoch: 208, plus 0 steps train_loss: 0.5511

#### test Acc: 0, NDCG: 0.34437787632010314 HIT: 0.5906020220588235

#### val Acc: 0, NDCG: 0.35301929893382944 HIT: 0.5977194393382353
Epoch: 224, plus 0 steps train_loss: 0.5632

#### test Acc: 0, NDCG: 0.35276684265370467 HIT: 0.6030388327205882

#### val Acc: 0, NDCG: 0.3597354697276485 HIT: 0.6079676011029412
Epoch: 240, plus 0 steps train_loss: 0.5411

#### test Acc: 0, NDCG: 0.35668921627814326 HIT: 0.6036017922794118

#### val Acc: 0, NDCG: 0.3652940704293445 HIT: 0.6109489889705882
Epoch: 256, plus 0 steps train_loss: 0.5541

#### test Acc: 0, NDCG: 0.3587231901873492 HIT: 0.6108800551470588

#### val Acc: 0, NDCG: 0.37443335323195626 HIT: 0.6200999540441177
Epoch: 272, plus 0 steps train_loss: 0.5383

#### test Acc: 0, NDCG: 0.3652178615794689 HIT: 0.6100126378676471

#### val Acc: 0, NDCG: 0.365973820203349 HIT: 0.6068416819852941
Epoch: 288, plus 0 steps train_loss: 0.5399

#### test Acc: 0, NDCG: 0.36932161456358664 HIT: 0.6173081341911765

#### val Acc: 0, NDCG: 0.37424801626997173 HIT: 0.6258272058823529
Epoch: 304, plus 0 steps train_loss: 0.5392

#### test Acc: 0, NDCG: 0.37990170942909324 HIT: 0.6276252297794118

#### val Acc: 0, NDCG: 0.3833835463975583 HIT: 0.6356100643382353
Epoch: 320, plus 0 steps train_loss: 0.5268

#### test Acc: 0, NDCG: 0.38623379997230567 HIT: 0.6404526654411764

#### val Acc: 0, NDCG: 0.384008821857153 HIT: 0.6354090073529413
Epoch: 352, plus 0 steps train_loss: 0.5158

#### test Acc: 0, NDCG: 0.378648469241522 HIT: 0.6298081341911764

#### val Acc: 0, NDCG: 0.39148006154857223 HIT: 0.6414349724264705
Epoch: 384, plus 0 steps train_loss: 0.5349

#### test Acc: 0, NDCG: 0.38659014585768736 HIT: 0.6371208639705882

#### val Acc: 0, NDCG: 0.38915684188300903 HIT: 0.6416130514705882
Epoch: 416, plus 0 steps train_loss: 0.5179

#### test Acc: 0, NDCG: 0.38531731165312827 HIT: 0.6327952665441177

#### val Acc: 0, NDCG: 0.3942276161233883 HIT: 0.6409869025735294
Epoch: 448, plus 0 steps train_loss: 0.5139

#### test Acc: 0, NDCG: 0.3834539278292265 HIT: 0.6308421415441177

#### val Acc: 0, NDCG: 0.3946377159192573 HIT: 0.6440199908088236
Epoch: 480, plus 0 steps train_loss: 0.5003

#### test Acc: 0, NDCG: 0.39080129685248577 HIT: 0.6320025275735295

#### val Acc: 0, NDCG: 0.3990335838580019 HIT: 0.6514878216911765
Epoch: 512, plus 0 steps train_loss: 0.5142

#### test Acc: 0, NDCG: 0.39679181770748645 HIT: 0.6474494485294118

#### val Acc: 0, NDCG: 0.4016535137343865 HIT: 0.6552045036764705
Epoch: 544, plus 0 steps train_loss: 0.5006

#### test Acc: 0, NDCG: 0.3898051171412849 HIT: 0.6345013786764706

#### val Acc: 0, NDCG: 0.40174773013282283 HIT: 0.6492991727941176
Epoch: 576, plus 0 steps train_loss: 0.4805

#### test Acc: 0, NDCG: 0.3999639984341784 HIT: 0.6459673713235294

#### val Acc: 0, NDCG: 0.40594196368364954 HIT: 0.6513901654411764
Epoch: 608, plus 0 steps train_loss: 0.4782

#### test Acc: 0, NDCG: 0.39773767732283083 HIT: 0.6478170955882353

#### val Acc: 0, NDCG: 0.41495041390608306 HIT: 0.666015625
Epoch: 640, plus 0 steps train_loss: 0.4852

#### test Acc: 0, NDCG: 0.4022110771904943 HIT: 0.6513556985294118

#### val Acc: 0, NDCG: 0.410127784572685 HIT: 0.6570484834558823
Epoch: 704, plus 0 steps train_loss: 0.4843

#### test Acc: 0, NDCG: 0.3983734202723388 HIT: 0.6458697150735294

#### val Acc: 0, NDCG: 0.40280486403318055 HIT: 0.6466854319852942
Epoch: 768, plus 0 steps train_loss: 0.4868

#### test Acc: 0, NDCG: 0.40337995854043296 HIT: 0.6511833639705882

#### val Acc: 0, NDCG: 0.40531842989782574 HIT: 0.6567670036764706
Epoch: 832, plus 0 steps train_loss: 0.475

#### test Acc: 0, NDCG: 0.4078416893490518 HIT: 0.6512408088235294

#### val Acc: 0, NDCG: 0.4139084948425472 HIT: 0.6594611672794117
Epoch: 896, plus 0 steps train_loss: 0.4686

#### test Acc: 0, NDCG: 0.40073630782969244 HIT: 0.6411879595588236

#### val Acc: 0, NDCG: 0.4092774747051296 HIT: 0.6571518841911764
Epoch: 960, plus 0 steps train_loss: 0.4696

#### test Acc: 0, NDCG: 0.39502333906561304 HIT: 0.6452607996323529

#### val Acc: 0, NDCG: 0.40807097624327177 HIT: 0.6579503676470588
Epoch: 1013, plus 25 steps train_loss: 0.4614
Done: it took 274231.84490442276
max value of NDCG: 0.4078416893490518
max value of HIT: 0.6513556985294118

After 20 validations
max value of NDCG: 0.4078416893490518
max value of HIT: 0.6513556985294118
