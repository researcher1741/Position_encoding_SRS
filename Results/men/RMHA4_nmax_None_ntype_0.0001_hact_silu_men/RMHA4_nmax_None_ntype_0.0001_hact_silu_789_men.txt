 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.0001
max_norm:             	None
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13268930141658464 HIT: 0.29184283088235297

#### val Acc: 0, NDCG: 0.12968870771328156 HIT: 0.28566750919117645
Epoch: 1, plus 0 steps train_loss: 0.7626

#### test Acc: 0, NDCG: 0.12995986046407046 HIT: 0.2879595588235294

#### val Acc: 0, NDCG: 0.13292875537130827 HIT: 0.2888327205882353
Epoch: 2, plus 0 steps train_loss: 0.7574

#### test Acc: 0, NDCG: 0.1340708165042042 HIT: 0.29573759191176474

#### val Acc: 0, NDCG: 0.12942622095928588 HIT: 0.28388671875
Epoch: 3, plus 0 steps train_loss: 0.7454

#### test Acc: 0, NDCG: 0.13152166681623967 HIT: 0.28490349264705883

#### val Acc: 0, NDCG: 0.13315615434462152 HIT: 0.29391084558823527
Epoch: 4, plus 0 steps train_loss: 0.7378

#### test Acc: 0, NDCG: 0.13930235960684612 HIT: 0.3026424632352941

#### val Acc: 0, NDCG: 0.13142664817407798 HIT: 0.29037798713235297
Epoch: 5, plus 0 steps train_loss: 0.7352

#### test Acc: 0, NDCG: 0.12916113288351264 HIT: 0.2814510569852941

#### val Acc: 0, NDCG: 0.12973776078311963 HIT: 0.2889878216911764
Epoch: 6, plus 0 steps train_loss: 0.7224

#### test Acc: 0, NDCG: 0.13401261040778784 HIT: 0.29196920955882355

#### val Acc: 0, NDCG: 0.13693536626650132 HIT: 0.2992359834558823
Epoch: 7, plus 0 steps train_loss: 0.7152

#### test Acc: 0, NDCG: 0.14249050547058434 HIT: 0.29887408088235295

#### val Acc: 0, NDCG: 0.14525395194625362 HIT: 0.3034237132352941
Epoch: 8, plus 0 steps train_loss: 0.7078

#### test Acc: 0, NDCG: 0.1855878362493752 HIT: 0.34128561580882355

#### val Acc: 0, NDCG: 0.19449893339985005 HIT: 0.35129250919117644
Epoch: 9, plus 0 steps train_loss: 0.7047

#### test Acc: 0, NDCG: 0.23890300320307706 HIT: 0.3938534007352941

#### val Acc: 0, NDCG: 0.2526979731742637 HIT: 0.40309053308823534
Epoch: 10, plus 0 steps train_loss: 0.7095

#### test Acc: 0, NDCG: 0.26502657008025565 HIT: 0.4125459558823529

#### val Acc: 0, NDCG: 0.2887186026200086 HIT: 0.4352941176470588
Epoch: 12, plus 0 steps train_loss: 0.7059

#### test Acc: 0, NDCG: 0.18666307821331013 HIT: 0.3417049632352941

#### val Acc: 0, NDCG: 0.2093436354094839 HIT: 0.3638499540441177
Epoch: 14, plus 0 steps train_loss: 0.6995

#### test Acc: 0, NDCG: 0.186542031637373 HIT: 0.3436063878676471

#### val Acc: 0, NDCG: 0.21401423567563124 HIT: 0.37140969669117646
Epoch: 16, plus 0 steps train_loss: 0.7038

#### test Acc: 0, NDCG: 0.24381328979086306 HIT: 0.3955193014705882

#### val Acc: 0, NDCG: 0.26373853082443954 HIT: 0.41209214154411766
Epoch: 18, plus 0 steps train_loss: 0.7032

#### test Acc: 0, NDCG: 0.20357732610363738 HIT: 0.3622414981617647

#### val Acc: 0, NDCG: 0.2322520355034813 HIT: 0.3832433363970588
Epoch: 20, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.2216221182817142 HIT: 0.37861328125

#### val Acc: 0, NDCG: 0.24916251830781816 HIT: 0.4036592371323529
Epoch: 22, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.18834752185500436 HIT: 0.34670266544117645

#### val Acc: 0, NDCG: 0.20842169948668218 HIT: 0.36881318933823526
Epoch: 24, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.1678701588945773 HIT: 0.33089384191176474

#### val Acc: 0, NDCG: 0.1895934355747731 HIT: 0.3559627757352941
Epoch: 26, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.16523516175468944 HIT: 0.34906939338235293

#### val Acc: 0, NDCG: 0.1600207354644007 HIT: 0.3355928308823529
Epoch: 28, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.17114402848101187 HIT: 0.34874770220588236

#### val Acc: 0, NDCG: 0.17889955089552714 HIT: 0.35584788602941175
Epoch: 30, plus 0 steps train_loss: 0.6931

#### test Acc: 0, NDCG: 0.1784649346847566 HIT: 0.36654411764705885

#### val Acc: 0, NDCG: 0.18182727868977208 HIT: 0.36650390625
Epoch: 32, plus 0 steps train_loss: 0.6927

#### test Acc: 0, NDCG: 0.18160046661175042 HIT: 0.3766773897058823

#### val Acc: 0, NDCG: 0.19078999367924956 HIT: 0.3811580882352941
Epoch: 36, plus 0 steps train_loss: 0.6784

#### test Acc: 0, NDCG: 0.20079580230057043 HIT: 0.39881663602941175

#### val Acc: 0, NDCG: 0.2100921046816248 HIT: 0.4068761488970588
Epoch: 40, plus 0 steps train_loss: 0.6807

#### test Acc: 0, NDCG: 0.22943931953283916 HIT: 0.4430261948529412

#### val Acc: 0, NDCG: 0.24178286169839075 HIT: 0.45301585477941175
Epoch: 44, plus 0 steps train_loss: 0.6736

#### test Acc: 0, NDCG: 0.22521156978015427 HIT: 0.4503963694852941

#### val Acc: 0, NDCG: 0.23172845709826645 HIT: 0.45822610294117644
Epoch: 48, plus 0 steps train_loss: 0.6697

#### test Acc: 0, NDCG: 0.2301443605452848 HIT: 0.45615234375

#### val Acc: 0, NDCG: 0.23141569987120328 HIT: 0.46112132352941176
Epoch: 52, plus 0 steps train_loss: 0.646

#### test Acc: 0, NDCG: 0.23401292732078255 HIT: 0.4564165900735294

#### val Acc: 0, NDCG: 0.23107650158976237 HIT: 0.45842715992647054
Epoch: 56, plus 0 steps train_loss: 0.6427

#### test Acc: 0, NDCG: 0.2420275226535386 HIT: 0.4813189338235294

#### val Acc: 0, NDCG: 0.2466338233129742 HIT: 0.4799460018382353
Epoch: 60, plus 0 steps train_loss: 0.6497

#### test Acc: 0, NDCG: 0.25083135135869583 HIT: 0.48707490808823534

#### val Acc: 0, NDCG: 0.2556050631197405 HIT: 0.4905905330882353
Epoch: 64, plus 0 steps train_loss: 0.6442

#### test Acc: 0, NDCG: 0.25516827133416764 HIT: 0.4967888327205882

#### val Acc: 0, NDCG: 0.2584693798390005 HIT: 0.4993623621323529
Epoch: 68, plus 0 steps train_loss: 0.6349

#### test Acc: 0, NDCG: 0.25592541190036444 HIT: 0.49778837316176466

#### val Acc: 0, NDCG: 0.26114132847739113 HIT: 0.5031594669117647
Epoch: 72, plus 0 steps train_loss: 0.6276

#### test Acc: 0, NDCG: 0.27184370581440376 HIT: 0.5195484834558823

#### val Acc: 0, NDCG: 0.2778666425800863 HIT: 0.5248104319852941
Epoch: 80, plus 0 steps train_loss: 0.6217

#### test Acc: 0, NDCG: 0.27532507662686145 HIT: 0.5184225643382353

#### val Acc: 0, NDCG: 0.2801579045666059 HIT: 0.5188993566176471
Epoch: 88, plus 0 steps train_loss: 0.6195

#### test Acc: 0, NDCG: 0.2833038955629352 HIT: 0.5328182444852941

#### val Acc: 0, NDCG: 0.2810902936626479 HIT: 0.5287798713235294
Epoch: 96, plus 0 steps train_loss: 0.6084

#### test Acc: 0, NDCG: 0.2886954152407765 HIT: 0.5391084558823529

#### val Acc: 0, NDCG: 0.29073294158561624 HIT: 0.5376551011029412
Epoch: 104, plus 0 steps train_loss: 0.6031

#### test Acc: 0, NDCG: 0.30456135994618105 HIT: 0.5586626838235295

#### val Acc: 0, NDCG: 0.30414054794891526 HIT: 0.5568129595588236
Epoch: 112, plus 0 steps train_loss: 0.6039

#### test Acc: 0, NDCG: 0.30115172829352954 HIT: 0.5526654411764705

#### val Acc: 0, NDCG: 0.3060341139982275 HIT: 0.5568014705882354
Epoch: 120, plus 0 steps train_loss: 0.5892

#### test Acc: 0, NDCG: 0.3094741062469845 HIT: 0.5613625919117646

#### val Acc: 0, NDCG: 0.3111886903214976 HIT: 0.5625287224264706
Epoch: 128, plus 0 steps train_loss: 0.5824

#### test Acc: 0, NDCG: 0.3149983962539181 HIT: 0.5640165441176471

#### val Acc: 0, NDCG: 0.3202984444251197 HIT: 0.5722598805147059
Epoch: 136, plus 0 steps train_loss: 0.5855

#### test Acc: 0, NDCG: 0.31958696911700174 HIT: 0.57314453125

#### val Acc: 0, NDCG: 0.3256871081328209 HIT: 0.5797736672794118
Epoch: 144, plus 0 steps train_loss: 0.5944

#### test Acc: 0, NDCG: 0.3264722519091994 HIT: 0.5824620863970588

#### val Acc: 0, NDCG: 0.33345696236378886 HIT: 0.5876206341911765
Epoch: 160, plus 0 steps train_loss: 0.5719

#### test Acc: 0, NDCG: 0.33788375873265125 HIT: 0.5969496783088235

#### val Acc: 0, NDCG: 0.3343405708561645 HIT: 0.591796875
Epoch: 176, plus 0 steps train_loss: 0.5671

#### test Acc: 0, NDCG: 0.3491784407766526 HIT: 0.6087028952205882

#### val Acc: 0, NDCG: 0.3505722850937628 HIT: 0.60458984375
Epoch: 192, plus 0 steps train_loss: 0.5634

#### test Acc: 0, NDCG: 0.3508001108677857 HIT: 0.6020737591911764

#### val Acc: 0, NDCG: 0.3521170670162507 HIT: 0.6053136488970587
Epoch: 208, plus 0 steps train_loss: 0.5553

#### test Acc: 0, NDCG: 0.3436885707436984 HIT: 0.6006433823529412

#### val Acc: 0, NDCG: 0.35242422377506727 HIT: 0.6089786305147059
Epoch: 224, plus 0 steps train_loss: 0.55

#### test Acc: 0, NDCG: 0.35134796255567974 HIT: 0.6077493106617646

#### val Acc: 0, NDCG: 0.3654659537720139 HIT: 0.6171817555147059
Epoch: 240, plus 0 steps train_loss: 0.5574

#### test Acc: 0, NDCG: 0.35630226427887124 HIT: 0.6064395680147059

#### val Acc: 0, NDCG: 0.35106369219977757 HIT: 0.6014131433823529
Epoch: 256, plus 0 steps train_loss: 0.5422

#### test Acc: 0, NDCG: 0.35352080414690756 HIT: 0.6078814338235294

#### val Acc: 0, NDCG: 0.36369728893983744 HIT: 0.6266199448529413
Epoch: 272, plus 0 steps train_loss: 0.5314

#### test Acc: 0, NDCG: 0.3612001830694248 HIT: 0.6098575367647059

#### val Acc: 0, NDCG: 0.36850647493769056 HIT: 0.6260282628676471
Epoch: 288, plus 0 steps train_loss: 0.5381

#### test Acc: 0, NDCG: 0.36717747517188515 HIT: 0.61767578125

#### val Acc: 0, NDCG: 0.3702964159500461 HIT: 0.6244485294117647
Epoch: 304, plus 0 steps train_loss: 0.5413

#### test Acc: 0, NDCG: 0.36110294075345617 HIT: 0.6131606158088235

#### val Acc: 0, NDCG: 0.37659038098451536 HIT: 0.6340762867647058
Epoch: 320, plus 0 steps train_loss: 0.5379

#### test Acc: 0, NDCG: 0.36959497317793927 HIT: 0.6232823988970588

#### val Acc: 0, NDCG: 0.3832147442490971 HIT: 0.63681640625
Epoch: 352, plus 0 steps train_loss: 0.5153

#### test Acc: 0, NDCG: 0.3740871073564461 HIT: 0.6267061121323529

#### val Acc: 0, NDCG: 0.38014603968288807 HIT: 0.6356847426470588
Epoch: 384, plus 0 steps train_loss: 0.5063

#### test Acc: 0, NDCG: 0.3732078451567836 HIT: 0.6250172334558823

#### val Acc: 0, NDCG: 0.37977563449089236 HIT: 0.6375
Epoch: 416, plus 0 steps train_loss: 0.5156

#### test Acc: 0, NDCG: 0.37964418630745667 HIT: 0.6369485294117647

#### val Acc: 0, NDCG: 0.38637656133989984 HIT: 0.6385857077205882
Epoch: 448, plus 0 steps train_loss: 0.4978

#### test Acc: 0, NDCG: 0.37979685920403944 HIT: 0.6279411764705882

#### val Acc: 0, NDCG: 0.39169692133414447 HIT: 0.6468864889705882
Epoch: 480, plus 0 steps train_loss: 0.5158

#### test Acc: 0, NDCG: 0.37895261803875674 HIT: 0.6320542279411765

#### val Acc: 0, NDCG: 0.37880648899072916 HIT: 0.6324735753676471
Epoch: 512, plus 0 steps train_loss: 0.5015

#### test Acc: 0, NDCG: 0.38354169577374997 HIT: 0.6289694393382353

#### val Acc: 0, NDCG: 0.3840595732258359 HIT: 0.6300494025735295
Epoch: 544, plus 0 steps train_loss: 0.4939

#### test Acc: 0, NDCG: 0.3945326649135232 HIT: 0.6446576286764706

#### val Acc: 0, NDCG: 0.39220389909639175 HIT: 0.6454216452205882
Epoch: 576, plus 0 steps train_loss: 0.502

#### test Acc: 0, NDCG: 0.39049935705053673 HIT: 0.6401769301470588

#### val Acc: 0, NDCG: 0.3918727348491118 HIT: 0.6418715533088235
Epoch: 608, plus 0 steps train_loss: 0.4916

#### test Acc: 0, NDCG: 0.38981510629623156 HIT: 0.6384363511029412

#### val Acc: 0, NDCG: 0.3937680384080215 HIT: 0.6483628216911764
Epoch: 640, plus 0 steps train_loss: 0.472

#### test Acc: 0, NDCG: 0.382475405236051 HIT: 0.6236213235294118

#### val Acc: 0, NDCG: 0.3996659985657646 HIT: 0.6495576746323529
Epoch: 704, plus 0 steps train_loss: 0.4819

#### test Acc: 0, NDCG: 0.39119962725944973 HIT: 0.6383501838235295

#### val Acc: 0, NDCG: 0.39771923850188096 HIT: 0.64873046875
Epoch: 768, plus 0 steps train_loss: 0.443

#### test Acc: 0, NDCG: 0.38645871846428387 HIT: 0.6331801470588235

#### val Acc: 0, NDCG: 0.3991536506315261 HIT: 0.6487591911764705
Epoch: 832, plus 0 steps train_loss: 0.4601

#### test Acc: 0, NDCG: 0.3888189485617971 HIT: 0.6325827205882353

#### val Acc: 0, NDCG: 0.3984448601517123 HIT: 0.6475700827205882
Epoch: 896, plus 0 steps train_loss: 0.4524

#### test Acc: 0, NDCG: 0.3893876183235433 HIT: 0.6333409926470588

#### val Acc: 0, NDCG: 0.395941753548814 HIT: 0.6446691176470588
Epoch: 960, plus 0 steps train_loss: 0.4542

#### test Acc: 0, NDCG: 0.3902440250199416 HIT: 0.6319163602941177

#### val Acc: 0, NDCG: 0.3954828301845189 HIT: 0.6449678308823529
Epoch: 1013, plus 25 steps train_loss: 0.4612
Done: it took 346207.7522187233
max value of NDCG: 0.3945326649135232
max value of HIT: 0.6446576286764706

After 20 validations
max value of NDCG: 0.3945326649135232
max value of HIT: 0.6446576286764706
