 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	2.0
max_norm:             	0.1
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	rope
position_concatenation: 	False
RMHA_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_encoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50832991
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12424336444768395 HIT: 0.27568359375

#### val Acc: 0, NDCG: 0.12024780726620046 HIT: 0.26817555147058825
Epoch: 1, plus 0 steps train_loss: 0.7352

#### test Acc: 0, NDCG: 0.127606500356316 HIT: 0.2748334099264706

#### val Acc: 0, NDCG: 0.12628373142690702 HIT: 0.28275505514705884
Epoch: 2, plus 0 steps train_loss: 0.7353

#### test Acc: 0, NDCG: 0.13296829891589163 HIT: 0.2928768382352941

#### val Acc: 0, NDCG: 0.12656886903322198 HIT: 0.2786017922794118
Epoch: 3, plus 0 steps train_loss: 0.7296

#### test Acc: 0, NDCG: 0.1574347597815852 HIT: 0.31915785845588235

#### val Acc: 0, NDCG: 0.1572558198695581 HIT: 0.31591796875
Epoch: 4, plus 0 steps train_loss: 0.7188

#### test Acc: 0, NDCG: 0.2510186259463334 HIT: 0.4051470588235294

#### val Acc: 0, NDCG: 0.27543597762566663 HIT: 0.4245232077205882
Epoch: 5, plus 0 steps train_loss: 0.7087

#### test Acc: 0, NDCG: 0.2075676076709989 HIT: 0.36498736213235294

#### val Acc: 0, NDCG: 0.23207910908755064 HIT: 0.3841337316176471
Epoch: 6, plus 0 steps train_loss: 0.7162

#### test Acc: 0, NDCG: 0.3602334879187824 HIT: 0.49778837316176466

#### val Acc: 0, NDCG: 0.38224029929069775 HIT: 0.5150448069852941
Epoch: 7, plus 0 steps train_loss: 0.7112

#### test Acc: 0, NDCG: 0.28401163344029207 HIT: 0.4358915441176471

#### val Acc: 0, NDCG: 0.29928516756169476 HIT: 0.44201516544117647
Epoch: 8, plus 0 steps train_loss: 0.7056

#### test Acc: 0, NDCG: 0.1348433410900965 HIT: 0.2965992647058823

#### val Acc: 0, NDCG: 0.13510288379857013 HIT: 0.2983455882352941
Epoch: 9, plus 0 steps train_loss: 0.7061

#### test Acc: 0, NDCG: 0.13315109491770444 HIT: 0.29643267463235295

#### val Acc: 0, NDCG: 0.13543227953689013 HIT: 0.29703584558823526
Epoch: 10, plus 0 steps train_loss: 0.705

#### test Acc: 0, NDCG: 0.13536047314593563 HIT: 0.29642118566176473

#### val Acc: 0, NDCG: 0.13703520454606818 HIT: 0.29363511029411765
Epoch: 12, plus 0 steps train_loss: 0.7023

#### test Acc: 0, NDCG: 0.19215970683706401 HIT: 0.3403205422794118

#### val Acc: 0, NDCG: 0.206170500782068 HIT: 0.35158547794117645
Epoch: 14, plus 0 steps train_loss: 0.7013

#### test Acc: 0, NDCG: 0.1366179894834239 HIT: 0.30163717830882353

#### val Acc: 0, NDCG: 0.1423107674211748 HIT: 0.30485409007352937
Epoch: 16, plus 0 steps train_loss: 0.7015

#### test Acc: 0, NDCG: 0.1588137372362221 HIT: 0.34161879595588235

#### val Acc: 0, NDCG: 0.15709786430135939 HIT: 0.34099264705882354
Epoch: 18, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.16868728653608084 HIT: 0.3601505055147059

#### val Acc: 0, NDCG: 0.1661074653384429 HIT: 0.35307329963235295
Epoch: 20, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.17785528405233347 HIT: 0.3766659007352941

#### val Acc: 0, NDCG: 0.17844261783998888 HIT: 0.3708180147058823
Epoch: 22, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.2191524989988139 HIT: 0.40520450367647054

#### val Acc: 0, NDCG: 0.23567845006770702 HIT: 0.4114717371323529
Epoch: 24, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.33290969694646055 HIT: 0.5103343290441177

#### val Acc: 0, NDCG: 0.33373087412860447 HIT: 0.5042221966911764
Epoch: 26, plus 0 steps train_loss: 0.6885

#### test Acc: 0, NDCG: 0.30366595678420155 HIT: 0.47174862132352946

#### val Acc: 0, NDCG: 0.30547621126385477 HIT: 0.47275965073529413
Epoch: 28, plus 0 steps train_loss: 0.6752

#### test Acc: 0, NDCG: 0.1931667081862637 HIT: 0.3900390625

#### val Acc: 0, NDCG: 0.19992802122132 HIT: 0.40029296875
Epoch: 30, plus 0 steps train_loss: 0.6797

#### test Acc: 0, NDCG: 0.22732567908746631 HIT: 0.43458754595588234

#### val Acc: 0, NDCG: 0.23100321280017058 HIT: 0.43690257352941175
Epoch: 32, plus 0 steps train_loss: 0.6652

#### test Acc: 0, NDCG: 0.2974962250352803 HIT: 0.4952435661764706

#### val Acc: 0, NDCG: 0.3082319247562436 HIT: 0.5010454963235295
Epoch: 36, plus 0 steps train_loss: 0.6633

#### test Acc: 0, NDCG: 0.27274963234424604 HIT: 0.4945427389705882

#### val Acc: 0, NDCG: 0.2803736253802237 HIT: 0.5013212316176471
Epoch: 40, plus 0 steps train_loss: 0.6625

#### test Acc: 0, NDCG: 0.23591459862788683 HIT: 0.45205078125

#### val Acc: 0, NDCG: 0.2402545086234153 HIT: 0.45793887867647054
Epoch: 44, plus 0 steps train_loss: 0.6568

#### test Acc: 0, NDCG: 0.2226008323055732 HIT: 0.44142348345588234

#### val Acc: 0, NDCG: 0.22946716267124842 HIT: 0.4549977022058823
Epoch: 48, plus 0 steps train_loss: 0.6551

#### test Acc: 0, NDCG: 0.23509881779155192 HIT: 0.46217256433823534

#### val Acc: 0, NDCG: 0.23787419479168803 HIT: 0.4654986213235294
Epoch: 52, plus 0 steps train_loss: 0.651

#### test Acc: 0, NDCG: 0.2327096047233143 HIT: 0.4654641544117647

#### val Acc: 0, NDCG: 0.22809397749492985 HIT: 0.45086167279411765
Epoch: 56, plus 0 steps train_loss: 0.6433

#### test Acc: 0, NDCG: 0.2234068548841887 HIT: 0.4462545955882353

#### val Acc: 0, NDCG: 0.23289759278533925 HIT: 0.45220588235294124
Epoch: 60, plus 0 steps train_loss: 0.6446

#### test Acc: 0, NDCG: 0.2410101497989014 HIT: 0.4731904871323529

#### val Acc: 0, NDCG: 0.24813295557542533 HIT: 0.4805089613970588
Epoch: 64, plus 0 steps train_loss: 0.6439

#### test Acc: 0, NDCG: 0.2381055884323978 HIT: 0.4698586856617647

#### val Acc: 0, NDCG: 0.2425665796592905 HIT: 0.47324793198529413
Epoch: 68, plus 0 steps train_loss: 0.632

#### test Acc: 0, NDCG: 0.23616093379959424 HIT: 0.4730066636029412

#### val Acc: 0, NDCG: 0.24703872139105512 HIT: 0.4886776194852941
Epoch: 72, plus 0 steps train_loss: 0.6443

#### test Acc: 0, NDCG: 0.25113100557617146 HIT: 0.48976907169117645

#### val Acc: 0, NDCG: 0.26237125258306715 HIT: 0.5042509191176471
Epoch: 80, plus 0 steps train_loss: 0.6253

#### test Acc: 0, NDCG: 0.25561313792945395 HIT: 0.5029411764705882

#### val Acc: 0, NDCG: 0.26165512790188816 HIT: 0.5080997242647058
Epoch: 88, plus 0 steps train_loss: 0.6379

#### test Acc: 0, NDCG: 0.25132774139447916 HIT: 0.4906307444852941

#### val Acc: 0, NDCG: 0.25761882884574516 HIT: 0.5006893382352942
Epoch: 96, plus 0 steps train_loss: 0.6159

#### test Acc: 0, NDCG: 0.2726070490589846 HIT: 0.5116153492647059

#### val Acc: 0, NDCG: 0.27790718848041823 HIT: 0.5236557904411765
Epoch: 104, plus 0 steps train_loss: 0.5908

#### test Acc: 0, NDCG: 0.2866038671544885 HIT: 0.5115636488970587

#### val Acc: 0, NDCG: 0.2963549705126286 HIT: 0.5248793658088236
Epoch: 112, plus 0 steps train_loss: 0.5707

#### test Acc: 0, NDCG: 0.31270972188782575 HIT: 0.5149816176470587

#### val Acc: 0, NDCG: 0.32898800276923235 HIT: 0.5344209558823529
Epoch: 120, plus 0 steps train_loss: 0.5562

#### test Acc: 0, NDCG: 0.3301615695780383 HIT: 0.5201918658088236

#### val Acc: 0, NDCG: 0.34766823492348875 HIT: 0.5388901654411764
Epoch: 128, plus 0 steps train_loss: 0.5237

#### test Acc: 0, NDCG: 0.3327859830835505 HIT: 0.5132123161764706

#### val Acc: 0, NDCG: 0.3511665313133447 HIT: 0.5390452665441177
Epoch: 136, plus 0 steps train_loss: 0.5096

#### test Acc: 0, NDCG: 0.33168167291874656 HIT: 0.5139476102941176

#### val Acc: 0, NDCG: 0.3532153520126574 HIT: 0.5451516544117647
Epoch: 144, plus 0 steps train_loss: 0.4985

#### test Acc: 0, NDCG: 0.33706811759624633 HIT: 0.5099264705882354

#### val Acc: 0, NDCG: 0.3496698962351292 HIT: 0.5254308363970588
Epoch: 160, plus 0 steps train_loss: 0.4926

#### test Acc: 0, NDCG: 0.33649227084279765 HIT: 0.5030503216911765

#### val Acc: 0, NDCG: 0.35415131065773264 HIT: 0.5287511488970588
Epoch: 176, plus 0 steps train_loss: 0.4921

#### test Acc: 0, NDCG: 0.33520790785133214 HIT: 0.5005055147058823

#### val Acc: 0, NDCG: 0.36454372277559666 HIT: 0.5365808823529412
Epoch: 192, plus 0 steps train_loss: 0.4774

#### test Acc: 0, NDCG: 0.34923699997718155 HIT: 0.5137293198529412

#### val Acc: 0, NDCG: 0.3622344076155298 HIT: 0.5315199908088235
Epoch: 208, plus 0 steps train_loss: 0.4787

#### test Acc: 0, NDCG: 0.34409372566627683 HIT: 0.5102251838235294

#### val Acc: 0, NDCG: 0.362031596373266 HIT: 0.5363396139705883
Epoch: 224, plus 0 steps train_loss: 0.4851

#### test Acc: 0, NDCG: 0.3460495819301093 HIT: 0.5143095128676471

#### val Acc: 0, NDCG: 0.3699999806115356 HIT: 0.5460133272058824
Epoch: 240, plus 0 steps train_loss: 0.4629

#### test Acc: 0, NDCG: 0.3456371617795152 HIT: 0.5086052389705882

#### val Acc: 0, NDCG: 0.362797012292602 HIT: 0.5392693014705883
Epoch: 256, plus 0 steps train_loss: 0.4611

#### test Acc: 0, NDCG: 0.3476813518302612 HIT: 0.5146886488970588

#### val Acc: 0, NDCG: 0.3570217264883515 HIT: 0.5341624540441177
Epoch: 272, plus 0 steps train_loss: 0.4693

#### test Acc: 0, NDCG: 0.3506806101534471 HIT: 0.5153607536764706

#### val Acc: 0, NDCG: 0.36965409114218195 HIT: 0.5414924172794118
Epoch: 288, plus 0 steps train_loss: 0.4692

#### test Acc: 0, NDCG: 0.35064985573150625 HIT: 0.5229779411764706

#### val Acc: 0, NDCG: 0.36813858499500507 HIT: 0.5434627757352941
Epoch: 304, plus 0 steps train_loss: 0.4321

#### test Acc: 0, NDCG: 0.34993619140772375 HIT: 0.5189338235294118

#### val Acc: 0, NDCG: 0.36095865437586233 HIT: 0.5351907169117647
Epoch: 320, plus 0 steps train_loss: 0.4598

#### test Acc: 0, NDCG: 0.34731382307048875 HIT: 0.5218635110294118

#### val Acc: 0, NDCG: 0.35549278192108075 HIT: 0.5322897518382353
Epoch: 352, plus 0 steps train_loss: 0.4426

#### test Acc: 0, NDCG: 0.34073577004388705 HIT: 0.5112477022058823

#### val Acc: 0, NDCG: 0.35386984202310257 HIT: 0.5281537224264705
Epoch: 384, plus 0 steps train_loss: 0.4593

#### test Acc: 0, NDCG: 0.3471868647735935 HIT: 0.5170955882352941

#### val Acc: 0, NDCG: 0.3615389589274993 HIT: 0.5415670955882353
Epoch: 416, plus 0 steps train_loss: 0.4416

#### test Acc: 0, NDCG: 0.3542058651489919 HIT: 0.5258444393382353

#### val Acc: 0, NDCG: 0.3631784389148024 HIT: 0.5474149816176471
Epoch: 448, plus 0 steps train_loss: 0.4493

#### test Acc: 0, NDCG: 0.3456291673828085 HIT: 0.5199793198529412

#### val Acc: 0, NDCG: 0.36349764225839654 HIT: 0.5509018841911765
Epoch: 480, plus 0 steps train_loss: 0.4228

#### test Acc: 0, NDCG: 0.35024185084500914 HIT: 0.5230411305147059

#### val Acc: 0, NDCG: 0.35703138858473005 HIT: 0.5319450827205883
Epoch: 512, plus 0 steps train_loss: 0.4308

#### test Acc: 0, NDCG: 0.3446959693268121 HIT: 0.5188074448529412

#### val Acc: 0, NDCG: 0.3652599907962347 HIT: 0.5428136488970587
Epoch: 544, plus 0 steps train_loss: 0.4266

#### test Acc: 0, NDCG: 0.34447010045171667 HIT: 0.5155158547794118

#### val Acc: 0, NDCG: 0.35537341016461954 HIT: 0.5293715533088236
Epoch: 576, plus 0 steps train_loss: 0.4218

#### test Acc: 0, NDCG: 0.35052166758675096 HIT: 0.5196806066176471

#### val Acc: 0, NDCG: 0.3631635120638968 HIT: 0.5450367647058824
Epoch: 608, plus 0 steps train_loss: 0.4091

#### test Acc: 0, NDCG: 0.34656319396817176 HIT: 0.5133674172794118

#### val Acc: 0, NDCG: 0.36019480786496116 HIT: 0.5362247242647059
Epoch: 640, plus 0 steps train_loss: 0.3998

#### test Acc: 0, NDCG: 0.34087815686284356 HIT: 0.5079216452205882

#### val Acc: 0, NDCG: 0.3587659538771547 HIT: 0.5320599724264705
Epoch: 704, plus 0 steps train_loss: 0.4044

#### test Acc: 0, NDCG: 0.33793059387313107 HIT: 0.5021599264705883

#### val Acc: 0, NDCG: 0.3670272077091968 HIT: 0.5386776194852941
Epoch: 768, plus 0 steps train_loss: 0.3953

#### test Acc: 0, NDCG: 0.3437891630301172 HIT: 0.5135167738970587

#### val Acc: 0, NDCG: 0.3633251656190012 HIT: 0.5381089154411764
Epoch: 832, plus 0 steps train_loss: 0.3977

#### test Acc: 0, NDCG: 0.34968563844154615 HIT: 0.5206227022058824

#### val Acc: 0, NDCG: 0.35683147853601543 HIT: 0.5292509191176471
Epoch: 896, plus 0 steps train_loss: 0.3933

#### test Acc: 0, NDCG: 0.3499208681040728 HIT: 0.5181583180147059

#### val Acc: 0, NDCG: 0.35764204681137274 HIT: 0.5294921875
Epoch: 960, plus 0 steps train_loss: 0.3741

#### test Acc: 0, NDCG: 0.3434513155673701 HIT: 0.5131548713235294

#### val Acc: 0, NDCG: 0.37152514216763277 HIT: 0.5422736672794117
Epoch: 1013, plus 25 steps train_loss: 0.4047
Done: it took 305262.09970641136
max value of NDCG: 0.3602334879187824
max value of HIT: 0.5258444393382353

After 20 validations
max value of NDCG: 0.3542058651489919
max value of HIT: 0.5258444393382353
