 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	0.1
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12439348414733861 HIT: 0.27215073529411765

#### val Acc: 0, NDCG: 0.13002716746754245 HIT: 0.2847426470588236
Epoch: 1, plus 0 steps train_loss: 0.8356

#### test Acc: 0, NDCG: 0.12619008816856653 HIT: 0.2760052849264706

#### val Acc: 0, NDCG: 0.13169074023198402 HIT: 0.2911534926470588
Epoch: 2, plus 0 steps train_loss: 0.7997

#### test Acc: 0, NDCG: 0.12736108251553485 HIT: 0.28106617647058824

#### val Acc: 0, NDCG: 0.12967370694355185 HIT: 0.28869485294117647
Epoch: 3, plus 0 steps train_loss: 0.7684

#### test Acc: 0, NDCG: 0.12942977358787758 HIT: 0.28288143382352937

#### val Acc: 0, NDCG: 0.12903339258497531 HIT: 0.28537454044117644
Epoch: 4, plus 0 steps train_loss: 0.7667

#### test Acc: 0, NDCG: 0.13199743201432937 HIT: 0.29308938419117647

#### val Acc: 0, NDCG: 0.1295755411321467 HIT: 0.2828010110294118
Epoch: 5, plus 0 steps train_loss: 0.747

#### test Acc: 0, NDCG: 0.12868028797181724 HIT: 0.28651769301470587

#### val Acc: 0, NDCG: 0.12827063246084872 HIT: 0.28044002757352937
Epoch: 6, plus 0 steps train_loss: 0.7482

#### test Acc: 0, NDCG: 0.12933194365740963 HIT: 0.2855641084558823

#### val Acc: 0, NDCG: 0.1297825626096141 HIT: 0.28331801470588236
Epoch: 7, plus 0 steps train_loss: 0.7505

#### test Acc: 0, NDCG: 0.13430322155453298 HIT: 0.29658203125

#### val Acc: 0, NDCG: 0.13006531177995057 HIT: 0.28421415441176473
Epoch: 8, plus 0 steps train_loss: 0.7468

#### test Acc: 0, NDCG: 0.12669686078979608 HIT: 0.28247357536764706

#### val Acc: 0, NDCG: 0.12878158747089447 HIT: 0.28385225183823526
Epoch: 9, plus 0 steps train_loss: 0.7364

#### test Acc: 0, NDCG: 0.12504714280578874 HIT: 0.27387982536764705

#### val Acc: 0, NDCG: 0.12791659087291637 HIT: 0.28580537683823526
Epoch: 10, plus 0 steps train_loss: 0.7355

#### test Acc: 0, NDCG: 0.131628275079051 HIT: 0.2896943933823529

#### val Acc: 0, NDCG: 0.12702130283383392 HIT: 0.2811121323529412
Epoch: 12, plus 0 steps train_loss: 0.73

#### test Acc: 0, NDCG: 0.12953935258407526 HIT: 0.28199103860294117

#### val Acc: 0, NDCG: 0.13089189902736248 HIT: 0.2864947150735294
Epoch: 14, plus 0 steps train_loss: 0.7275

#### test Acc: 0, NDCG: 0.12576462433822413 HIT: 0.2790096507352941

#### val Acc: 0, NDCG: 0.13107659239924574 HIT: 0.28598345588235297
Epoch: 16, plus 0 steps train_loss: 0.715

#### test Acc: 0, NDCG: 0.12810121272681915 HIT: 0.28384650735294115

#### val Acc: 0, NDCG: 0.1264941512201217 HIT: 0.27724609375
Epoch: 18, plus 0 steps train_loss: 0.7155

#### test Acc: 0, NDCG: 0.1341699873787044 HIT: 0.29712201286764706

#### val Acc: 0, NDCG: 0.13220271912582857 HIT: 0.28790211397058824
Epoch: 20, plus 0 steps train_loss: 0.7177

#### test Acc: 0, NDCG: 0.13021553790609505 HIT: 0.2802159926470588

#### val Acc: 0, NDCG: 0.1261468434985108 HIT: 0.27961856617647063
Epoch: 22, plus 0 steps train_loss: 0.7171

#### test Acc: 0, NDCG: 0.13068255289286262 HIT: 0.2890510110294118

#### val Acc: 0, NDCG: 0.1296712565488581 HIT: 0.28588579963235294
Epoch: 24, plus 0 steps train_loss: 0.7188

#### test Acc: 0, NDCG: 0.13299499991298425 HIT: 0.2932329963235294

#### val Acc: 0, NDCG: 0.1258341605440753 HIT: 0.27897518382352937
Epoch: 26, plus 0 steps train_loss: 0.7132

#### test Acc: 0, NDCG: 0.12307440857607907 HIT: 0.27035271139705885

#### val Acc: 0, NDCG: 0.1311684434410656 HIT: 0.28520220588235295
Epoch: 28, plus 0 steps train_loss: 0.715

#### test Acc: 0, NDCG: 0.13449000121458468 HIT: 0.29626608455882353

#### val Acc: 0, NDCG: 0.1327212559817231 HIT: 0.29175091911764706
Epoch: 30, plus 0 steps train_loss: 0.7107

#### test Acc: 0, NDCG: 0.12997833253580246 HIT: 0.28129595588235295

#### val Acc: 0, NDCG: 0.1296953909476894 HIT: 0.28775850183823526
Epoch: 32, plus 0 steps train_loss: 0.7093

#### test Acc: 0, NDCG: 0.13326891493384926 HIT: 0.2945025275735294

#### val Acc: 0, NDCG: 0.13382215094218225 HIT: 0.29574333639705885
Epoch: 36, plus 0 steps train_loss: 0.7089

#### test Acc: 0, NDCG: 0.13139288325433113 HIT: 0.2889820772058823

#### val Acc: 0, NDCG: 0.13034657845435782 HIT: 0.2885454963235294
Epoch: 40, plus 0 steps train_loss: 0.7064

#### test Acc: 0, NDCG: 0.1312902603467426 HIT: 0.2870461856617647

#### val Acc: 0, NDCG: 0.1332243117985105 HIT: 0.2940889246323529
Epoch: 44, plus 0 steps train_loss: 0.7055

#### test Acc: 0, NDCG: 0.12985170491136602 HIT: 0.2854319852941177

#### val Acc: 0, NDCG: 0.1279025077443759 HIT: 0.2839499080882353
Epoch: 48, plus 0 steps train_loss: 0.7081

#### test Acc: 0, NDCG: 0.13204574745630732 HIT: 0.2867532169117647

#### val Acc: 0, NDCG: 0.13523872743045845 HIT: 0.29189453125
Epoch: 52, plus 0 steps train_loss: 0.7049

#### test Acc: 0, NDCG: 0.12765205808908836 HIT: 0.28336971507352937

#### val Acc: 0, NDCG: 0.13049220581609258 HIT: 0.2825022977941177
Epoch: 56, plus 0 steps train_loss: 0.7052

#### test Acc: 0, NDCG: 0.13530502238399653 HIT: 0.2957720588235294

#### val Acc: 0, NDCG: 0.1322561988264785 HIT: 0.28554113051470587
Epoch: 60, plus 0 steps train_loss: 0.7024

#### test Acc: 0, NDCG: 0.14541428095172365 HIT: 0.3041417738970588

#### val Acc: 0, NDCG: 0.14645257257436325 HIT: 0.3041704963235294
Epoch: 64, plus 0 steps train_loss: 0.702

#### test Acc: 0, NDCG: 0.1780980768992364 HIT: 0.34243451286764703

#### val Acc: 0, NDCG: 0.17911235922509555 HIT: 0.3356617647058823
Epoch: 68, plus 0 steps train_loss: 0.7

#### test Acc: 0, NDCG: 0.19041721821633636 HIT: 0.34846622242647063

#### val Acc: 0, NDCG: 0.20566359341283497 HIT: 0.3612534466911764
Epoch: 72, plus 0 steps train_loss: 0.7016

#### test Acc: 0, NDCG: 0.30096230508623556 HIT: 0.44988511029411765

#### val Acc: 0, NDCG: 0.3178320927813402 HIT: 0.46307444852941176
Epoch: 80, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.3552662461075459 HIT: 0.49621438419117647

#### val Acc: 0, NDCG: 0.38156337642953847 HIT: 0.5186063878676471
Epoch: 88, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.5166804068884655 HIT: 0.6431583180147059

#### val Acc: 0, NDCG: 0.5241447265588919 HIT: 0.6448012408088235
Epoch: 96, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.5786967736772763 HIT: 0.6961282169117646

#### val Acc: 0, NDCG: 0.5868752613423907 HIT: 0.6997529871323529
Epoch: 104, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.5786188189246895 HIT: 0.6951573988970587

#### val Acc: 0, NDCG: 0.5861074130629287 HIT: 0.7014246323529412
Epoch: 112, plus 0 steps train_loss: 0.6915

#### test Acc: 0, NDCG: 0.6071083138110174 HIT: 0.7157456341911764

#### val Acc: 0, NDCG: 0.6193508245424768 HIT: 0.7289292279411764
Epoch: 120, plus 0 steps train_loss: 0.6931

#### test Acc: 0, NDCG: 0.6109757687908706 HIT: 0.7174747242647059

#### val Acc: 0, NDCG: 0.6188755505019172 HIT: 0.7284352022058823
Epoch: 128, plus 0 steps train_loss: 0.6886

#### test Acc: 0, NDCG: 0.6164431864787381 HIT: 0.7215360753676471

#### val Acc: 0, NDCG: 0.6296915069451043 HIT: 0.7333754595588236
Epoch: 136, plus 0 steps train_loss: 0.6896

#### test Acc: 0, NDCG: 0.6215791254645053 HIT: 0.72880859375

#### val Acc: 0, NDCG: 0.6300957483615323 HIT: 0.7347886029411764
Epoch: 144, plus 0 steps train_loss: 0.6899

#### test Acc: 0, NDCG: 0.6324129645420069 HIT: 0.7384018841911765

#### val Acc: 0, NDCG: 0.6376240698027795 HIT: 0.7391256893382353
Epoch: 160, plus 0 steps train_loss: 0.6885

#### test Acc: 0, NDCG: 0.6308174492811663 HIT: 0.7358168658088236

#### val Acc: 0, NDCG: 0.6514403866957451 HIT: 0.7530503216911765
Epoch: 176, plus 0 steps train_loss: 0.6841

#### test Acc: 0, NDCG: 0.6491731488773296 HIT: 0.7470071231617647

#### val Acc: 0, NDCG: 0.6562902493386147 HIT: 0.7504365808823529
Epoch: 192, plus 0 steps train_loss: 0.687

#### test Acc: 0, NDCG: 0.6490474152793648 HIT: 0.7487017463235295

#### val Acc: 0, NDCG: 0.6490756858477067 HIT: 0.7493278952205882
Epoch: 208, plus 0 steps train_loss: 0.6794

#### test Acc: 0, NDCG: 0.6522759582556313 HIT: 0.7525045955882353

#### val Acc: 0, NDCG: 0.6638552202292258 HIT: 0.7574391084558824
Epoch: 224, plus 0 steps train_loss: 0.682

#### test Acc: 0, NDCG: 0.651362736456578 HIT: 0.7464786305147059

#### val Acc: 0, NDCG: 0.6589706661610042 HIT: 0.7586856617647059
Epoch: 240, plus 0 steps train_loss: 0.6822

#### test Acc: 0, NDCG: 0.6488562977141317 HIT: 0.7511833639705883

#### val Acc: 0, NDCG: 0.6585891593113333 HIT: 0.7524931066176471
Epoch: 256, plus 0 steps train_loss: 0.6715

#### test Acc: 0, NDCG: 0.6568080178120518 HIT: 0.7506721047794118

#### val Acc: 0, NDCG: 0.6567669133372104 HIT: 0.7530847886029413
Epoch: 272, plus 0 steps train_loss: 0.6807

#### test Acc: 0, NDCG: 0.6408938896328962 HIT: 0.7444393382352941

#### val Acc: 0, NDCG: 0.6504995005787426 HIT: 0.7453067555147059
Epoch: 288, plus 0 steps train_loss: 0.6777

#### test Acc: 0, NDCG: 0.6641464770728851 HIT: 0.7558536305147059

#### val Acc: 0, NDCG: 0.6801322482080926 HIT: 0.7690487132352941
Epoch: 304, plus 0 steps train_loss: 0.673

#### test Acc: 0, NDCG: 0.6670312159407836 HIT: 0.7602194393382353

#### val Acc: 0, NDCG: 0.6849573594958327 HIT: 0.7752125459558823
Epoch: 320, plus 0 steps train_loss: 0.6769

#### test Acc: 0, NDCG: 0.6578150944454173 HIT: 0.7560776654411765

#### val Acc: 0, NDCG: 0.6654394791484558 HIT: 0.7599781709558824
Epoch: 352, plus 0 steps train_loss: 0.6663

#### test Acc: 0, NDCG: 0.6549488030375199 HIT: 0.7545266544117647

#### val Acc: 0, NDCG: 0.6685530279046314 HIT: 0.7648552389705883
Epoch: 384, plus 0 steps train_loss: 0.6654

#### test Acc: 0, NDCG: 0.6734045022121363 HIT: 0.7673770680147058

#### val Acc: 0, NDCG: 0.6751269814546059 HIT: 0.7677274816176471
Epoch: 416, plus 0 steps train_loss: 0.6652

#### test Acc: 0, NDCG: 0.6506811727755867 HIT: 0.7571231617647058

#### val Acc: 0, NDCG: 0.658109470968647 HIT: 0.7614372702205883
Epoch: 448, plus 0 steps train_loss: 0.6655

#### test Acc: 0, NDCG: 0.6205195208279473 HIT: 0.7347771139705882

#### val Acc: 0, NDCG: 0.6327077425327754 HIT: 0.7419404871323529
Epoch: 480, plus 0 steps train_loss: 0.6663

#### test Acc: 0, NDCG: 0.5394672424331988 HIT: 0.6802332261029412

#### val Acc: 0, NDCG: 0.5632338133578798 HIT: 0.6910788143382354
Epoch: 512, plus 0 steps train_loss: 0.6605

#### test Acc: 0, NDCG: 0.4705449886949177 HIT: 0.6252068014705883

#### val Acc: 0, NDCG: 0.4884004173489994 HIT: 0.6379480698529412
Epoch: 544, plus 0 steps train_loss: 0.6552

#### test Acc: 0, NDCG: 0.5354555336716218 HIT: 0.6677274816176471

#### val Acc: 0, NDCG: 0.5646923992893154 HIT: 0.6898897058823529
Epoch: 576, plus 0 steps train_loss: 0.6591

#### test Acc: 0, NDCG: 0.5179011438534754 HIT: 0.6568301930147059

#### val Acc: 0, NDCG: 0.5448355851744623 HIT: 0.6793198529411765
Epoch: 608, plus 0 steps train_loss: 0.6558

#### test Acc: 0, NDCG: 0.5626865316986088 HIT: 0.6919577205882353

#### val Acc: 0, NDCG: 0.570913510226909 HIT: 0.6943589154411764
Epoch: 640, plus 0 steps train_loss: 0.6579

#### test Acc: 0, NDCG: 0.6126298130991261 HIT: 0.7225183823529412

#### val Acc: 0, NDCG: 0.6214890343648243 HIT: 0.728125
Epoch: 704, plus 0 steps train_loss: 0.6564

#### test Acc: 0, NDCG: 0.6455016329100712 HIT: 0.7478630514705882

#### val Acc: 0, NDCG: 0.665385785208941 HIT: 0.7609662224264706
Epoch: 768, plus 0 steps train_loss: 0.6531

#### test Acc: 0, NDCG: 0.6557481954862916 HIT: 0.7508214613970587

#### val Acc: 0, NDCG: 0.6589538198313614 HIT: 0.7562270220588235
Epoch: 832, plus 0 steps train_loss: 0.653

#### test Acc: 0, NDCG: 0.6515057310568764 HIT: 0.7475643382352941

#### val Acc: 0, NDCG: 0.6670691294099752 HIT: 0.7620174632352941
Epoch: 896, plus 0 steps train_loss: 0.6511

#### test Acc: 0, NDCG: 0.6603960877035032 HIT: 0.7561580882352941

#### val Acc: 0, NDCG: 0.6597074766335446 HIT: 0.7593405330882353
Epoch: 960, plus 0 steps train_loss: 0.6552

#### test Acc: 0, NDCG: 0.6567709283586637 HIT: 0.7569278492647059

#### val Acc: 0, NDCG: 0.6609427735590296 HIT: 0.7555319393382354
Epoch: 1013, plus 25 steps train_loss: 0.6525
Done: it took 282718.54823589325
max value of NDCG: 0.6734045022121363
max value of HIT: 0.7673770680147058

After 20 validations
max value of NDCG: 0.6734045022121363
max value of HIT: 0.7673770680147058
