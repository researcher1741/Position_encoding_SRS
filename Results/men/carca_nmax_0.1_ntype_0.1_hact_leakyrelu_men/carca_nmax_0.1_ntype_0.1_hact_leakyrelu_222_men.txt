 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	0.1
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
RMHA_decoder:         	False
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_encoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12737600498486162 HIT: 0.2819450827205882

#### val Acc: 0, NDCG: 0.12942126339801552 HIT: 0.2845760569852941
Epoch: 1, plus 0 steps train_loss: 0.7727

#### test Acc: 0, NDCG: 0.1271402384447495 HIT: 0.2790900735294118

#### val Acc: 0, NDCG: 0.12906351320691545 HIT: 0.28937844669117646
Epoch: 2, plus 0 steps train_loss: 0.7694

#### test Acc: 0, NDCG: 0.13480729318664078 HIT: 0.2971507352941177

#### val Acc: 0, NDCG: 0.12706955997903008 HIT: 0.2798483455882353
Epoch: 3, plus 0 steps train_loss: 0.7686

#### test Acc: 0, NDCG: 0.13305808597376867 HIT: 0.2885454963235294

#### val Acc: 0, NDCG: 0.1268855388242447 HIT: 0.2792164522058823
Epoch: 4, plus 0 steps train_loss: 0.7578

#### test Acc: 0, NDCG: 0.1305162168961094 HIT: 0.2857766544117647

#### val Acc: 0, NDCG: 0.13159368761857146 HIT: 0.28672449448529413
Epoch: 5, plus 0 steps train_loss: 0.745

#### test Acc: 0, NDCG: 0.130438195562366 HIT: 0.2876551011029412

#### val Acc: 0, NDCG: 0.1281550123219029 HIT: 0.2849666819852941
Epoch: 6, plus 0 steps train_loss: 0.7457

#### test Acc: 0, NDCG: 0.13013509756777275 HIT: 0.28191636029411765

#### val Acc: 0, NDCG: 0.1272739492432258 HIT: 0.2815257352941177
Epoch: 7, plus 0 steps train_loss: 0.745

#### test Acc: 0, NDCG: 0.12885955062672388 HIT: 0.2793026194852941

#### val Acc: 0, NDCG: 0.12916160131071447 HIT: 0.2859260110294118
Epoch: 8, plus 0 steps train_loss: 0.7449

#### test Acc: 0, NDCG: 0.13489488476584463 HIT: 0.2941521139705882

#### val Acc: 0, NDCG: 0.1240978530024734 HIT: 0.27653377757352937
Epoch: 9, plus 0 steps train_loss: 0.7367

#### test Acc: 0, NDCG: 0.12974938290040502 HIT: 0.2889763327205882

#### val Acc: 0, NDCG: 0.1292364049241085 HIT: 0.28623621323529413
Epoch: 10, plus 0 steps train_loss: 0.7269

#### test Acc: 0, NDCG: 0.1287500186343691 HIT: 0.2844784007352941

#### val Acc: 0, NDCG: 0.12775840449870007 HIT: 0.27967601102941175
Epoch: 12, plus 0 steps train_loss: 0.7237

#### test Acc: 0, NDCG: 0.1359366634763664 HIT: 0.294921875

#### val Acc: 0, NDCG: 0.12400427725686809 HIT: 0.2767693014705882
Epoch: 14, plus 0 steps train_loss: 0.725

#### test Acc: 0, NDCG: 0.13163678035375156 HIT: 0.2873334099264706

#### val Acc: 0, NDCG: 0.13305711962870514 HIT: 0.2897403492647059
Epoch: 16, plus 0 steps train_loss: 0.7273

#### test Acc: 0, NDCG: 0.1308218647302008 HIT: 0.2893439797794118

#### val Acc: 0, NDCG: 0.12880549704733654 HIT: 0.27990004595588236
Epoch: 18, plus 0 steps train_loss: 0.7166

#### test Acc: 0, NDCG: 0.1337567573717849 HIT: 0.2912396599264706

#### val Acc: 0, NDCG: 0.1325928103429012 HIT: 0.28680491727941176
Epoch: 20, plus 0 steps train_loss: 0.7177

#### test Acc: 0, NDCG: 0.12867490562821488 HIT: 0.2811868106617647

#### val Acc: 0, NDCG: 0.1283634767516509 HIT: 0.2867130055147059
Epoch: 22, plus 0 steps train_loss: 0.7117

#### test Acc: 0, NDCG: 0.1255776459698234 HIT: 0.276171875

#### val Acc: 0, NDCG: 0.13238932112998747 HIT: 0.2882295496323529
Epoch: 24, plus 0 steps train_loss: 0.7136

#### test Acc: 0, NDCG: 0.13051249489533498 HIT: 0.28761488970588234

#### val Acc: 0, NDCG: 0.1316900548988543 HIT: 0.29091796875
Epoch: 26, plus 0 steps train_loss: 0.7087

#### test Acc: 0, NDCG: 0.12658961730628188 HIT: 0.2777401194852941

#### val Acc: 0, NDCG: 0.1313170542703973 HIT: 0.28859719669117645
Epoch: 28, plus 0 steps train_loss: 0.7114

#### test Acc: 0, NDCG: 0.12622658085082317 HIT: 0.2793600643382353

#### val Acc: 0, NDCG: 0.13408861587619447 HIT: 0.2948414522058823
Epoch: 30, plus 0 steps train_loss: 0.7117

#### test Acc: 0, NDCG: 0.13485111440226244 HIT: 0.29477251838235297

#### val Acc: 0, NDCG: 0.13460437937053824 HIT: 0.2930434283088236
Epoch: 32, plus 0 steps train_loss: 0.707

#### test Acc: 0, NDCG: 0.12765932216936182 HIT: 0.28629365808823526

#### val Acc: 0, NDCG: 0.132595709258511 HIT: 0.28748851102941175
Epoch: 36, plus 0 steps train_loss: 0.7082

#### test Acc: 0, NDCG: 0.1298775237715768 HIT: 0.28439797794117644

#### val Acc: 0, NDCG: 0.13274472263283726 HIT: 0.2926700367647059
Epoch: 40, plus 0 steps train_loss: 0.7073

#### test Acc: 0, NDCG: 0.1252770072797483 HIT: 0.27750459558823526

#### val Acc: 0, NDCG: 0.1350931474458467 HIT: 0.2954733455882353
Epoch: 44, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.12932361449368657 HIT: 0.28450137867647063

#### val Acc: 0, NDCG: 0.12828713617960602 HIT: 0.2852366727941177
Epoch: 48, plus 0 steps train_loss: 0.7039

#### test Acc: 0, NDCG: 0.1301654162988623 HIT: 0.28594898897058824

#### val Acc: 0, NDCG: 0.13812705344764836 HIT: 0.29935661764705884
Epoch: 52, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.12703406836701497 HIT: 0.28205997242647063

#### val Acc: 0, NDCG: 0.13138944745010567 HIT: 0.28734489889705883
Epoch: 56, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.13178814152216012 HIT: 0.28967141544117647

#### val Acc: 0, NDCG: 0.12915590080102862 HIT: 0.28611557904411766
Epoch: 60, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.12872853746741952 HIT: 0.28525965073529413

#### val Acc: 0, NDCG: 0.12808186310103076 HIT: 0.28154296875
Epoch: 64, plus 0 steps train_loss: 0.7027

#### test Acc: 0, NDCG: 0.131414132512913 HIT: 0.28712660845588234

#### val Acc: 0, NDCG: 0.12969742183820399 HIT: 0.28485179227941176
Epoch: 68, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.13607960772576028 HIT: 0.2999425551470588

#### val Acc: 0, NDCG: 0.1301567181353241 HIT: 0.28477136948529413
Epoch: 72, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.12856078838989565 HIT: 0.28743681066176474

#### val Acc: 0, NDCG: 0.1332895893426398 HIT: 0.2954159007352941
Epoch: 80, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.13194451446430297 HIT: 0.29148092830882355

#### val Acc: 0, NDCG: 0.12635863179585988 HIT: 0.2788890165441177
Epoch: 88, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.12998707372553456 HIT: 0.28928079044117644

#### val Acc: 0, NDCG: 0.12660409128517525 HIT: 0.27702205882352937
Epoch: 96, plus 0 steps train_loss: 0.7

#### test Acc: 0, NDCG: 0.12863712814724168 HIT: 0.28748276654411764

#### val Acc: 0, NDCG: 0.13540356845361923 HIT: 0.29510569852941176
Epoch: 104, plus 0 steps train_loss: 0.7007

#### test Acc: 0, NDCG: 0.13218574164764244 HIT: 0.2883616727941177

#### val Acc: 0, NDCG: 0.13228888566168173 HIT: 0.28678193933823526
Epoch: 112, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.12690180942462548 HIT: 0.2821691176470588

#### val Acc: 0, NDCG: 0.13218654739580404 HIT: 0.2926700367647059
Epoch: 120, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.13348309500846517 HIT: 0.29356617647058825

#### val Acc: 0, NDCG: 0.12746644108268704 HIT: 0.28234145220588236
Epoch: 128, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.1268519186843388 HIT: 0.27996897977941176

#### val Acc: 0, NDCG: 0.13002504360632766 HIT: 0.28672449448529413
Epoch: 136, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.12979980615910117 HIT: 0.2830078125

#### val Acc: 0, NDCG: 0.12710396546320718 HIT: 0.2789349724264706
Epoch: 144, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.13861640448535253 HIT: 0.3008616727941177

#### val Acc: 0, NDCG: 0.1376078075689975 HIT: 0.2992359834558823
Epoch: 160, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.14218493584671826 HIT: 0.30450942095588235

#### val Acc: 0, NDCG: 0.14178472972653028 HIT: 0.30625
Epoch: 176, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.15368358710926025 HIT: 0.3270795036764706

#### val Acc: 0, NDCG: 0.15549658014065798 HIT: 0.32863051470588234
Epoch: 192, plus 0 steps train_loss: 0.6956

#### test Acc: 0, NDCG: 0.16131463088837725 HIT: 0.3401022518382353

#### val Acc: 0, NDCG: 0.15627363938879182 HIT: 0.3298770680147059
Epoch: 208, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.17623699174623148 HIT: 0.36435546875

#### val Acc: 0, NDCG: 0.18134612386789345 HIT: 0.36553883272058824
Epoch: 224, plus 0 steps train_loss: 0.6941

#### test Acc: 0, NDCG: 0.18091557930236823 HIT: 0.3729032628676471

#### val Acc: 0, NDCG: 0.1831935397579458 HIT: 0.3693646599264706
Epoch: 240, plus 0 steps train_loss: 0.6923

#### test Acc: 0, NDCG: 0.18880515174735044 HIT: 0.38446116727941176

#### val Acc: 0, NDCG: 0.18690922331424703 HIT: 0.3731387867647059
Epoch: 256, plus 0 steps train_loss: 0.6916

#### test Acc: 0, NDCG: 0.19167338908357828 HIT: 0.3900792738970588

#### val Acc: 0, NDCG: 0.19453596758399933 HIT: 0.3864889705882353
Epoch: 272, plus 0 steps train_loss: 0.6849

#### test Acc: 0, NDCG: 0.19908224334659075 HIT: 0.39503676470588234

#### val Acc: 0, NDCG: 0.1974454043722896 HIT: 0.3936293658088236
Epoch: 288, plus 0 steps train_loss: 0.688

#### test Acc: 0, NDCG: 0.19921225676744245 HIT: 0.40179802389705876

#### val Acc: 0, NDCG: 0.2116578936988756 HIT: 0.41589499080882353
Epoch: 304, plus 0 steps train_loss: 0.6868

#### test Acc: 0, NDCG: 0.2069816084759764 HIT: 0.4076171875

#### val Acc: 0, NDCG: 0.2066869832057033 HIT: 0.4052332261029412
Epoch: 320, plus 0 steps train_loss: 0.6822

#### test Acc: 0, NDCG: 0.22122746801053741 HIT: 0.42791245404411765

#### val Acc: 0, NDCG: 0.23113595529108166 HIT: 0.4345186121323529
Epoch: 352, plus 0 steps train_loss: 0.6831

#### test Acc: 0, NDCG: 0.2280239353555819 HIT: 0.4320829503676471

#### val Acc: 0, NDCG: 0.23360679567177192 HIT: 0.4393669577205882
Epoch: 384, plus 0 steps train_loss: 0.675

#### test Acc: 0, NDCG: 0.23316337565275685 HIT: 0.4263039981617647

#### val Acc: 0, NDCG: 0.2573290478923831 HIT: 0.45612362132352946
Epoch: 416, plus 0 steps train_loss: 0.6743

#### test Acc: 0, NDCG: 0.23609408902538234 HIT: 0.43674747242647055

#### val Acc: 0, NDCG: 0.24323199755022312 HIT: 0.45197035845588235
Epoch: 448, plus 0 steps train_loss: 0.6684

#### test Acc: 0, NDCG: 0.23665226148684587 HIT: 0.4383846507352941

#### val Acc: 0, NDCG: 0.24929668211197847 HIT: 0.4494140625
Epoch: 480, plus 0 steps train_loss: 0.667

#### test Acc: 0, NDCG: 0.24705824369201132 HIT: 0.4564051011029412

#### val Acc: 0, NDCG: 0.24339286554192302 HIT: 0.44053308823529413
Epoch: 512, plus 0 steps train_loss: 0.662

#### test Acc: 0, NDCG: 0.24044454588812747 HIT: 0.4486328125

#### val Acc: 0, NDCG: 0.25189573791920405 HIT: 0.46032858455882353
Epoch: 544, plus 0 steps train_loss: 0.6728

#### test Acc: 0, NDCG: 0.24326782095101268 HIT: 0.4474092371323529

#### val Acc: 0, NDCG: 0.2536575793632069 HIT: 0.4624885110294118
Epoch: 576, plus 0 steps train_loss: 0.6605

#### test Acc: 0, NDCG: 0.24038238385817143 HIT: 0.4452780330882353

#### val Acc: 0, NDCG: 0.25148760258839903 HIT: 0.4607364430147059
Epoch: 608, plus 0 steps train_loss: 0.6635

#### test Acc: 0, NDCG: 0.24046536659469164 HIT: 0.44169921875

#### val Acc: 0, NDCG: 0.25403967037992303 HIT: 0.4585305606617647
Epoch: 640, plus 0 steps train_loss: 0.6614

#### test Acc: 0, NDCG: 0.24949782130199916 HIT: 0.4532111672794118

#### val Acc: 0, NDCG: 0.25516152260611025 HIT: 0.45762293198529413
Epoch: 704, plus 0 steps train_loss: 0.661

#### test Acc: 0, NDCG: 0.24836884361988262 HIT: 0.4464326746323529

#### val Acc: 0, NDCG: 0.25639738125157274 HIT: 0.4635052849264706
Epoch: 768, plus 0 steps train_loss: 0.6502

#### test Acc: 0, NDCG: 0.24191898627189165 HIT: 0.4446920955882353

#### val Acc: 0, NDCG: 0.24614109524020372 HIT: 0.45334329044117644
Epoch: 832, plus 0 steps train_loss: 0.6497

#### test Acc: 0, NDCG: 0.24447875310382003 HIT: 0.4481560202205882

#### val Acc: 0, NDCG: 0.24816001062255838 HIT: 0.4549919577205882
Epoch: 896, plus 0 steps train_loss: 0.6527

#### test Acc: 0, NDCG: 0.23941017211803603 HIT: 0.44680032169117645

#### val Acc: 0, NDCG: 0.24936205257823355 HIT: 0.4549172794117647
Epoch: 960, plus 0 steps train_loss: 0.6417

#### test Acc: 0, NDCG: 0.241053100305007 HIT: 0.44347426470588236

#### val Acc: 0, NDCG: 0.25378570939177636 HIT: 0.4545036764705882
Epoch: 1013, plus 25 steps train_loss: 0.6591
Done: it took 299164.778614521
max value of NDCG: 0.24949782130199916
max value of HIT: 0.4564051011029412

After 20 validations
max value of NDCG: 0.24949782130199916
max value of HIT: 0.4564051011029412
