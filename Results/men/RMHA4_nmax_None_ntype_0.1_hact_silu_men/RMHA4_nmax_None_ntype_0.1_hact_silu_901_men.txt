 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	None
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13112461697111122 HIT: 0.2873391544117647

#### val Acc: 0, NDCG: 0.12609081629181013 HIT: 0.27736098345588234
Epoch: 1, plus 0 steps train_loss: 0.7876

#### test Acc: 0, NDCG: 0.12937133520738614 HIT: 0.28363970588235293

#### val Acc: 0, NDCG: 0.13002546391621816 HIT: 0.2881663602941177
Epoch: 2, plus 0 steps train_loss: 0.7566

#### test Acc: 0, NDCG: 0.12628075884736614 HIT: 0.27946346507352937

#### val Acc: 0, NDCG: 0.12806703517075332 HIT: 0.2860064338235294
Epoch: 3, plus 0 steps train_loss: 0.7378

#### test Acc: 0, NDCG: 0.12982957716358895 HIT: 0.2863396139705882

#### val Acc: 0, NDCG: 0.1345922706012869 HIT: 0.2950022977941177
Epoch: 4, plus 0 steps train_loss: 0.7215

#### test Acc: 0, NDCG: 0.1415923731484931 HIT: 0.30160271139705885

#### val Acc: 0, NDCG: 0.147195432265729 HIT: 0.30688189338235294
Epoch: 5, plus 0 steps train_loss: 0.711

#### test Acc: 0, NDCG: 0.19880885089339617 HIT: 0.36474609375

#### val Acc: 0, NDCG: 0.20603021771458363 HIT: 0.36024816176470587
Epoch: 6, plus 0 steps train_loss: 0.7094

#### test Acc: 0, NDCG: 0.22918075940873467 HIT: 0.38563304227941175

#### val Acc: 0, NDCG: 0.24241525341825998 HIT: 0.3943187040441177
Epoch: 7, plus 0 steps train_loss: 0.7099

#### test Acc: 0, NDCG: 0.2654513761533416 HIT: 0.4168485753676471

#### val Acc: 0, NDCG: 0.27908364457275103 HIT: 0.430859375
Epoch: 8, plus 0 steps train_loss: 0.7056

#### test Acc: 0, NDCG: 0.2553128966413971 HIT: 0.4096277573529412

#### val Acc: 0, NDCG: 0.26814973218966986 HIT: 0.42274816176470587
Epoch: 9, plus 0 steps train_loss: 0.7088

#### test Acc: 0, NDCG: 0.24856429008259565 HIT: 0.40369370404411764

#### val Acc: 0, NDCG: 0.26530565248534543 HIT: 0.41628561580882356
Epoch: 10, plus 0 steps train_loss: 0.7065

#### test Acc: 0, NDCG: 0.21351392176945713 HIT: 0.3734777113970588

#### val Acc: 0, NDCG: 0.2337062917434523 HIT: 0.3911879595588236
Epoch: 12, plus 0 steps train_loss: 0.7064

#### test Acc: 0, NDCG: 0.19954780930742594 HIT: 0.35920840992647063

#### val Acc: 0, NDCG: 0.2154466548870853 HIT: 0.3744829963235294
Epoch: 14, plus 0 steps train_loss: 0.7031

#### test Acc: 0, NDCG: 0.17521170212687132 HIT: 0.33918313419117646

#### val Acc: 0, NDCG: 0.1885008131676395 HIT: 0.3453469669117647
Epoch: 16, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.1740226998760106 HIT: 0.33758616727941176

#### val Acc: 0, NDCG: 0.19367569689265202 HIT: 0.35525045955882356
Epoch: 18, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.16565504704494632 HIT: 0.3328125

#### val Acc: 0, NDCG: 0.17770487271378696 HIT: 0.33930951286764705
Epoch: 20, plus 0 steps train_loss: 0.7003

#### test Acc: 0, NDCG: 0.19323766793271874 HIT: 0.3586224724264706

#### val Acc: 0, NDCG: 0.20893538922192664 HIT: 0.3661305147058823
Epoch: 22, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.162532892927921 HIT: 0.32982536764705883

#### val Acc: 0, NDCG: 0.17581218020078243 HIT: 0.3446633731617647
Epoch: 24, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.1544438924336518 HIT: 0.3223977481617647

#### val Acc: 0, NDCG: 0.16627196725556237 HIT: 0.33471392463235294
Epoch: 26, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.1519657670573872 HIT: 0.3228113511029412

#### val Acc: 0, NDCG: 0.16114555115024992 HIT: 0.33814338235294117
Epoch: 28, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.16296605730549715 HIT: 0.3429859834558823

#### val Acc: 0, NDCG: 0.15720041339796598 HIT: 0.3376665900735294
Epoch: 30, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.16495644915451815 HIT: 0.34653033088235297

#### val Acc: 0, NDCG: 0.16527324933957935 HIT: 0.34462890625
Epoch: 32, plus 0 steps train_loss: 0.693

#### test Acc: 0, NDCG: 0.18668819309770454 HIT: 0.38627068014705884

#### val Acc: 0, NDCG: 0.1836758237172719 HIT: 0.38040556066176473
Epoch: 36, plus 0 steps train_loss: 0.6925

#### test Acc: 0, NDCG: 0.2092418406690232 HIT: 0.4237879136029412

#### val Acc: 0, NDCG: 0.21009646437232693 HIT: 0.43292164522058824
Epoch: 40, plus 0 steps train_loss: 0.6725

#### test Acc: 0, NDCG: 0.21689736945094862 HIT: 0.4394473805147059

#### val Acc: 0, NDCG: 0.21911056791667677 HIT: 0.4474092371323529
Epoch: 44, plus 0 steps train_loss: 0.6596

#### test Acc: 0, NDCG: 0.22357923149369346 HIT: 0.4531996783088236

#### val Acc: 0, NDCG: 0.22308578583286445 HIT: 0.4521599264705882
Epoch: 48, plus 0 steps train_loss: 0.6523

#### test Acc: 0, NDCG: 0.22951515085977986 HIT: 0.45947265625

#### val Acc: 0, NDCG: 0.2323824367171221 HIT: 0.46389016544117645
Epoch: 52, plus 0 steps train_loss: 0.6522

#### test Acc: 0, NDCG: 0.2403036688274601 HIT: 0.4766486672794118

#### val Acc: 0, NDCG: 0.24690923839053336 HIT: 0.4842888327205882
Epoch: 56, plus 0 steps train_loss: 0.6425

#### test Acc: 0, NDCG: 0.24802664429723734 HIT: 0.4935029871323529

#### val Acc: 0, NDCG: 0.24917010124008004 HIT: 0.4855583639705882
Epoch: 60, plus 0 steps train_loss: 0.6295

#### test Acc: 0, NDCG: 0.24943706117354975 HIT: 0.4869140625

#### val Acc: 0, NDCG: 0.253178126785607 HIT: 0.4926642922794118
Epoch: 64, plus 0 steps train_loss: 0.6412

#### test Acc: 0, NDCG: 0.25932147953597895 HIT: 0.5087603400735294

#### val Acc: 0, NDCG: 0.25939573119930015 HIT: 0.5086339613970587
Epoch: 68, plus 0 steps train_loss: 0.6305

#### test Acc: 0, NDCG: 0.27015732862273756 HIT: 0.5201171875

#### val Acc: 0, NDCG: 0.2694676987733809 HIT: 0.5166417738970588
Epoch: 72, plus 0 steps train_loss: 0.6249

#### test Acc: 0, NDCG: 0.2791832941765931 HIT: 0.52578125

#### val Acc: 0, NDCG: 0.28473897203720877 HIT: 0.5345760569852941
Epoch: 80, plus 0 steps train_loss: 0.6142

#### test Acc: 0, NDCG: 0.2805300560219225 HIT: 0.5321576286764705

#### val Acc: 0, NDCG: 0.2790281536191902 HIT: 0.5295668658088235
Epoch: 88, plus 0 steps train_loss: 0.6255

#### test Acc: 0, NDCG: 0.2736839325958097 HIT: 0.5148092830882354

#### val Acc: 0, NDCG: 0.28893964817262774 HIT: 0.5398724724264705
Epoch: 96, plus 0 steps train_loss: 0.6171

#### test Acc: 0, NDCG: 0.2863752796682993 HIT: 0.5351275275735294

#### val Acc: 0, NDCG: 0.2951724470130828 HIT: 0.5415383731617647
Epoch: 104, plus 0 steps train_loss: 0.5993

#### test Acc: 0, NDCG: 0.29815056033881115 HIT: 0.5489889705882354

#### val Acc: 0, NDCG: 0.2927960192572175 HIT: 0.5410788143382353
Epoch: 112, plus 0 steps train_loss: 0.5827

#### test Acc: 0, NDCG: 0.30802680415259875 HIT: 0.5570657169117647

#### val Acc: 0, NDCG: 0.3119343991290425 HIT: 0.5635569852941177
Epoch: 120, plus 0 steps train_loss: 0.5808

#### test Acc: 0, NDCG: 0.3150599534492552 HIT: 0.5649758731617647

#### val Acc: 0, NDCG: 0.32255434554592266 HIT: 0.5780732996323529
Epoch: 128, plus 0 steps train_loss: 0.5765

#### test Acc: 0, NDCG: 0.31705366232383614 HIT: 0.5667911305147059

#### val Acc: 0, NDCG: 0.3193406100012283 HIT: 0.5705135569852942
Epoch: 136, plus 0 steps train_loss: 0.5816

#### test Acc: 0, NDCG: 0.3242498768411032 HIT: 0.5788717830882353

#### val Acc: 0, NDCG: 0.32877923571407786 HIT: 0.5851217830882354
Epoch: 144, plus 0 steps train_loss: 0.5589

#### test Acc: 0, NDCG: 0.3365641273593693 HIT: 0.5903894761029412

#### val Acc: 0, NDCG: 0.3385338306585875 HIT: 0.5912224264705882
Epoch: 160, plus 0 steps train_loss: 0.5604

#### test Acc: 0, NDCG: 0.3352672547323853 HIT: 0.5949908088235294

#### val Acc: 0, NDCG: 0.3375744029776342 HIT: 0.5959099264705883
Epoch: 176, plus 0 steps train_loss: 0.5621

#### test Acc: 0, NDCG: 0.35474014346772426 HIT: 0.6137005974264705

#### val Acc: 0, NDCG: 0.35346393875411086 HIT: 0.6057502297794117
Epoch: 192, plus 0 steps train_loss: 0.5669

#### test Acc: 0, NDCG: 0.35030685006222273 HIT: 0.6073127297794118

#### val Acc: 0, NDCG: 0.3552450212390177 HIT: 0.6121266084558823
Epoch: 208, plus 0 steps train_loss: 0.5704

#### test Acc: 0, NDCG: 0.34755376870758514 HIT: 0.5953871783088236

#### val Acc: 0, NDCG: 0.3597544059336765 HIT: 0.6173426011029413
Epoch: 224, plus 0 steps train_loss: 0.544

#### test Acc: 0, NDCG: 0.3615022096191333 HIT: 0.6192210477941177

#### val Acc: 0, NDCG: 0.3719613714220481 HIT: 0.6284696691176471
Epoch: 240, plus 0 steps train_loss: 0.5568

#### test Acc: 0, NDCG: 0.35856604118016433 HIT: 0.6088292738970588

#### val Acc: 0, NDCG: 0.3699282345483964 HIT: 0.6240521599264706
Epoch: 256, plus 0 steps train_loss: 0.5377

#### test Acc: 0, NDCG: 0.35967969110138165 HIT: 0.6087086397058823

#### val Acc: 0, NDCG: 0.3694221342143242 HIT: 0.6275677849264706
Epoch: 272, plus 0 steps train_loss: 0.5432

#### test Acc: 0, NDCG: 0.36311565617624336 HIT: 0.6215762867647059

#### val Acc: 0, NDCG: 0.37466771047437125 HIT: 0.6304859834558824
Epoch: 288, plus 0 steps train_loss: 0.536

#### test Acc: 0, NDCG: 0.36996120577265806 HIT: 0.6241555606617647

#### val Acc: 0, NDCG: 0.3776590348849177 HIT: 0.6342428768382353
Epoch: 304, plus 0 steps train_loss: 0.5225

#### test Acc: 0, NDCG: 0.37034527098059894 HIT: 0.6166475183823529

#### val Acc: 0, NDCG: 0.3717220040215635 HIT: 0.6294347426470588
Epoch: 320, plus 0 steps train_loss: 0.5258

#### test Acc: 0, NDCG: 0.3765808971691182 HIT: 0.6291762408088235

#### val Acc: 0, NDCG: 0.38609505549982304 HIT: 0.6389763327205882
Epoch: 352, plus 0 steps train_loss: 0.5322

#### test Acc: 0, NDCG: 0.3784941111575236 HIT: 0.6266716452205883

#### val Acc: 0, NDCG: 0.38830551520704604 HIT: 0.6431525735294118
Epoch: 384, plus 0 steps train_loss: 0.5164

#### test Acc: 0, NDCG: 0.3846028800143186 HIT: 0.6308306525735294

#### val Acc: 0, NDCG: 0.3887257825998941 HIT: 0.6425149356617647
Epoch: 416, plus 0 steps train_loss: 0.5032

#### test Acc: 0, NDCG: 0.37914936460140874 HIT: 0.6309168198529412

#### val Acc: 0, NDCG: 0.3937254913037382 HIT: 0.6471449908088236
Epoch: 448, plus 0 steps train_loss: 0.5116

#### test Acc: 0, NDCG: 0.3875172373719627 HIT: 0.6408777573529412

#### val Acc: 0, NDCG: 0.39533705541992337 HIT: 0.6501953125
Epoch: 480, plus 0 steps train_loss: 0.4927

#### test Acc: 0, NDCG: 0.39084788283107413 HIT: 0.6413315716911765

#### val Acc: 0, NDCG: 0.40001919589886387 HIT: 0.6528779871323529
Epoch: 512, plus 0 steps train_loss: 0.4969

#### test Acc: 0, NDCG: 0.3852898388995859 HIT: 0.6316004136029412

#### val Acc: 0, NDCG: 0.4050731286840327 HIT: 0.6501148897058824
Epoch: 544, plus 0 steps train_loss: 0.4837

#### test Acc: 0, NDCG: 0.390234357512418 HIT: 0.6405732996323529

#### val Acc: 0, NDCG: 0.3983688189821214 HIT: 0.6547449448529412
Epoch: 576, plus 0 steps train_loss: 0.4985

#### test Acc: 0, NDCG: 0.3921176868841129 HIT: 0.6465705422794118

#### val Acc: 0, NDCG: 0.39659017015156445 HIT: 0.6463235294117646
Epoch: 608, plus 0 steps train_loss: 0.4699

#### test Acc: 0, NDCG: 0.39500779740645026 HIT: 0.6466452205882354

#### val Acc: 0, NDCG: 0.40274454319047737 HIT: 0.6553940716911765
Epoch: 640, plus 0 steps train_loss: 0.4885

#### test Acc: 0, NDCG: 0.39176257684512744 HIT: 0.6372587316176471

#### val Acc: 0, NDCG: 0.40089241586426433 HIT: 0.6484547334558823
Epoch: 704, plus 0 steps train_loss: 0.4797

#### test Acc: 0, NDCG: 0.3828871598138847 HIT: 0.6267922794117646

#### val Acc: 0, NDCG: 0.40813991489632173 HIT: 0.6594669117647058
Epoch: 768, plus 0 steps train_loss: 0.4816

#### test Acc: 0, NDCG: 0.39200832001766417 HIT: 0.6356732536764705

#### val Acc: 0, NDCG: 0.4103908820403947 HIT: 0.6629767922794118
Epoch: 832, plus 0 steps train_loss: 0.4709

#### test Acc: 0, NDCG: 0.3901980758421852 HIT: 0.6351619944852941

#### val Acc: 0, NDCG: 0.40524709988468166 HIT: 0.6554113051470588
Epoch: 896, plus 0 steps train_loss: 0.4596

#### test Acc: 0, NDCG: 0.3953656369180728 HIT: 0.6397288602941177

#### val Acc: 0, NDCG: 0.4006192579805761 HIT: 0.6480641084558824
Epoch: 960, plus 0 steps train_loss: 0.4682

#### test Acc: 0, NDCG: 0.39910029266452185 HIT: 0.6425264246323529

#### val Acc: 0, NDCG: 0.40317971757788795 HIT: 0.6527975643382353
Epoch: 1013, plus 25 steps train_loss: 0.4446
Done: it took 272060.0764887333
max value of NDCG: 0.39910029266452185
max value of HIT: 0.6466452205882354

After 20 validations
max value of NDCG: 0.39910029266452185
max value of HIT: 0.6466452205882354
