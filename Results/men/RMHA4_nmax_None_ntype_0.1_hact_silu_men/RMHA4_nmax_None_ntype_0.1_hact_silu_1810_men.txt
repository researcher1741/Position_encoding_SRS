 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	None
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12777103791944364 HIT: 0.28107766544117646

#### val Acc: 0, NDCG: 0.12860007743095397 HIT: 0.28582835477941176
Epoch: 1, plus 0 steps train_loss: 0.7674

#### test Acc: 0, NDCG: 0.13167654873662954 HIT: 0.29105009191176473

#### val Acc: 0, NDCG: 0.1285828020046305 HIT: 0.2871783088235294
Epoch: 2, plus 0 steps train_loss: 0.7529

#### test Acc: 0, NDCG: 0.12709081126884592 HIT: 0.283203125

#### val Acc: 0, NDCG: 0.12869548881382176 HIT: 0.28407628676470587
Epoch: 3, plus 0 steps train_loss: 0.7411

#### test Acc: 0, NDCG: 0.12984510022161255 HIT: 0.2860466452205882

#### val Acc: 0, NDCG: 0.12716085718380418 HIT: 0.28123276654411766
Epoch: 4, plus 0 steps train_loss: 0.736

#### test Acc: 0, NDCG: 0.1339044724676543 HIT: 0.29636948529411766

#### val Acc: 0, NDCG: 0.13747563105749894 HIT: 0.29816176470588235
Epoch: 5, plus 0 steps train_loss: 0.7215

#### test Acc: 0, NDCG: 0.1397167007618943 HIT: 0.2954676011029412

#### val Acc: 0, NDCG: 0.14285446022559828 HIT: 0.3024356617647059
Epoch: 6, plus 0 steps train_loss: 0.7097

#### test Acc: 0, NDCG: 0.15862992094281703 HIT: 0.3175723805147059

#### val Acc: 0, NDCG: 0.16445952826447074 HIT: 0.32501148897058824
Epoch: 7, plus 0 steps train_loss: 0.7094

#### test Acc: 0, NDCG: 0.17290945152932055 HIT: 0.33675896139705885

#### val Acc: 0, NDCG: 0.17705717740596277 HIT: 0.3319738051470588
Epoch: 8, plus 0 steps train_loss: 0.7067

#### test Acc: 0, NDCG: 0.18911808702358351 HIT: 0.3431870404411764

#### val Acc: 0, NDCG: 0.19829072454049557 HIT: 0.3516946231617647
Epoch: 9, plus 0 steps train_loss: 0.703

#### test Acc: 0, NDCG: 0.2320801225071667 HIT: 0.3832261029411764

#### val Acc: 0, NDCG: 0.2568233022114409 HIT: 0.40851332720588235
Epoch: 10, plus 0 steps train_loss: 0.7056

#### test Acc: 0, NDCG: 0.2116771640470702 HIT: 0.36974379595588236

#### val Acc: 0, NDCG: 0.228013030842129 HIT: 0.38720703125
Epoch: 12, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.19966886139996579 HIT: 0.35744485294117645

#### val Acc: 0, NDCG: 0.21901209056706455 HIT: 0.3768899356617647
Epoch: 14, plus 0 steps train_loss: 0.7017

#### test Acc: 0, NDCG: 0.21820124220703607 HIT: 0.37495404411764705

#### val Acc: 0, NDCG: 0.23644688880798048 HIT: 0.38633386948529413
Epoch: 16, plus 0 steps train_loss: 0.7016

#### test Acc: 0, NDCG: 0.19660879605679452 HIT: 0.34716796875

#### val Acc: 0, NDCG: 0.2140733946659416 HIT: 0.3678883272058823
Epoch: 18, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.18090827651035774 HIT: 0.33744255514705884

#### val Acc: 0, NDCG: 0.19247241460822803 HIT: 0.3418772977941177
Epoch: 20, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.1850191126309046 HIT: 0.3385914522058823

#### val Acc: 0, NDCG: 0.19726290000204294 HIT: 0.34323874080882355
Epoch: 22, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.19106468958866107 HIT: 0.34321001838235293

#### val Acc: 0, NDCG: 0.208881440907716 HIT: 0.3591681985294118
Epoch: 24, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.20821398048454318 HIT: 0.36464269301470587

#### val Acc: 0, NDCG: 0.21988100457330134 HIT: 0.36945082720588235
Epoch: 26, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.20155292391059093 HIT: 0.3509823069852941

#### val Acc: 0, NDCG: 0.21880948793039812 HIT: 0.36821576286764707
Epoch: 28, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.3216496733626057 HIT: 0.4708409926470588

#### val Acc: 0, NDCG: 0.347772539318613 HIT: 0.4935719209558823
Epoch: 30, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.26036055852517126 HIT: 0.40862247242647054

#### val Acc: 0, NDCG: 0.2812732020913105 HIT: 0.4222886029411764
Epoch: 32, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.17079656799023776 HIT: 0.31205767463235295

#### val Acc: 0, NDCG: 0.1905513553428764 HIT: 0.33525390625
Epoch: 36, plus 0 steps train_loss: 0.6926

#### test Acc: 0, NDCG: 0.1684667316409621 HIT: 0.32348345588235294

#### val Acc: 0, NDCG: 0.18213499441910325 HIT: 0.3305376838235294
Epoch: 40, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.15272914388084324 HIT: 0.3286937040441177

#### val Acc: 0, NDCG: 0.16433548456905026 HIT: 0.34369829963235293
Epoch: 44, plus 0 steps train_loss: 0.6917

#### test Acc: 0, NDCG: 0.19021435721494856 HIT: 0.3859547334558823

#### val Acc: 0, NDCG: 0.19063080155414913 HIT: 0.3816980698529412
Epoch: 48, plus 0 steps train_loss: 0.6883

#### test Acc: 0, NDCG: 0.20473683836553297 HIT: 0.40802504595588235

#### val Acc: 0, NDCG: 0.20944803108295718 HIT: 0.4226102941176471
Epoch: 52, plus 0 steps train_loss: 0.6857

#### test Acc: 0, NDCG: 0.2100982082564658 HIT: 0.4226045496323529

#### val Acc: 0, NDCG: 0.21561929760987059 HIT: 0.43158318014705876
Epoch: 56, plus 0 steps train_loss: 0.6695

#### test Acc: 0, NDCG: 0.22838876484603138 HIT: 0.4576803768382353

#### val Acc: 0, NDCG: 0.22697610308460234 HIT: 0.4534696691176471
Epoch: 60, plus 0 steps train_loss: 0.6584

#### test Acc: 0, NDCG: 0.24299168504055985 HIT: 0.47454044117647054

#### val Acc: 0, NDCG: 0.2353199646055998 HIT: 0.4605870863970588
Epoch: 64, plus 0 steps train_loss: 0.6561

#### test Acc: 0, NDCG: 0.23738756197122962 HIT: 0.47067440257352944

#### val Acc: 0, NDCG: 0.24735265738073814 HIT: 0.47980813419117646
Epoch: 68, plus 0 steps train_loss: 0.6316

#### test Acc: 0, NDCG: 0.24647483477824692 HIT: 0.4795036764705882

#### val Acc: 0, NDCG: 0.2544647283834967 HIT: 0.48346162683823535
Epoch: 72, plus 0 steps train_loss: 0.6368

#### test Acc: 0, NDCG: 0.26384131826464025 HIT: 0.5055376838235295

#### val Acc: 0, NDCG: 0.27852995073061954 HIT: 0.5245059742647059
Epoch: 80, plus 0 steps train_loss: 0.6313

#### test Acc: 0, NDCG: 0.2846286786603791 HIT: 0.5284352022058824

#### val Acc: 0, NDCG: 0.29060854540599984 HIT: 0.5375574448529412
Epoch: 88, plus 0 steps train_loss: 0.6016

#### test Acc: 0, NDCG: 0.29126275716552424 HIT: 0.5477653952205882

#### val Acc: 0, NDCG: 0.29757070384340734 HIT: 0.5440716911764706
Epoch: 96, plus 0 steps train_loss: 0.6134

#### test Acc: 0, NDCG: 0.28520287977733105 HIT: 0.5318301930147059

#### val Acc: 0, NDCG: 0.30134578099063725 HIT: 0.54951171875
Epoch: 104, plus 0 steps train_loss: 0.6106

#### test Acc: 0, NDCG: 0.29472948521498793 HIT: 0.5449448529411764

#### val Acc: 0, NDCG: 0.30277699809391373 HIT: 0.5561580882352941
Epoch: 112, plus 0 steps train_loss: 0.5918

#### test Acc: 0, NDCG: 0.3030026293003101 HIT: 0.5514361213235295

#### val Acc: 0, NDCG: 0.3078084089544528 HIT: 0.5582318474264706
Epoch: 120, plus 0 steps train_loss: 0.595

#### test Acc: 0, NDCG: 0.305698320989947 HIT: 0.5558076746323529

#### val Acc: 0, NDCG: 0.3073468451045227 HIT: 0.5554457720588235
Epoch: 128, plus 0 steps train_loss: 0.5863

#### test Acc: 0, NDCG: 0.3117847111119952 HIT: 0.56259765625

#### val Acc: 0, NDCG: 0.3196896564730797 HIT: 0.5726792279411764
Epoch: 136, plus 0 steps train_loss: 0.5886

#### test Acc: 0, NDCG: 0.31876922435865007 HIT: 0.5654756433823529

#### val Acc: 0, NDCG: 0.3215916626930551 HIT: 0.5675264246323529
Epoch: 144, plus 0 steps train_loss: 0.587

#### test Acc: 0, NDCG: 0.3335240341270896 HIT: 0.5886776194852941

#### val Acc: 0, NDCG: 0.3366109311491089 HIT: 0.5912798713235294
Epoch: 160, plus 0 steps train_loss: 0.5771

#### test Acc: 0, NDCG: 0.3378754168029702 HIT: 0.5922162224264705

#### val Acc: 0, NDCG: 0.3407231165327471 HIT: 0.5938419117647059
Epoch: 176, plus 0 steps train_loss: 0.5615

#### test Acc: 0, NDCG: 0.3364111790602231 HIT: 0.5840762867647059

#### val Acc: 0, NDCG: 0.3477987045110445 HIT: 0.6005112591911764
Epoch: 192, plus 0 steps train_loss: 0.567

#### test Acc: 0, NDCG: 0.34195430047485964 HIT: 0.5953010110294118

#### val Acc: 0, NDCG: 0.3512174710557635 HIT: 0.6061178768382354
Epoch: 208, plus 0 steps train_loss: 0.5552

#### test Acc: 0, NDCG: 0.3510186176959819 HIT: 0.6016773897058824

#### val Acc: 0, NDCG: 0.3620623643736234 HIT: 0.6147173713235294
Epoch: 224, plus 0 steps train_loss: 0.5457

#### test Acc: 0, NDCG: 0.35786784420862616 HIT: 0.6118968290441177

#### val Acc: 0, NDCG: 0.3595904914090762 HIT: 0.6147920496323529
Epoch: 240, plus 0 steps train_loss: 0.5655

#### test Acc: 0, NDCG: 0.3593357512955551 HIT: 0.6094324448529412

#### val Acc: 0, NDCG: 0.370394587980803 HIT: 0.6262063419117647
Epoch: 256, plus 0 steps train_loss: 0.5331

#### test Acc: 0, NDCG: 0.37126258836981496 HIT: 0.6281537224264706

#### val Acc: 0, NDCG: 0.37715690576375954 HIT: 0.6328010110294118
Epoch: 272, plus 0 steps train_loss: 0.5195

#### test Acc: 0, NDCG: 0.36419386759271993 HIT: 0.6127527573529412

#### val Acc: 0, NDCG: 0.381237258325495 HIT: 0.6348747702205882
Epoch: 288, plus 0 steps train_loss: 0.5275

#### test Acc: 0, NDCG: 0.37188434740711174 HIT: 0.6265912224264706

#### val Acc: 0, NDCG: 0.3856641395669764 HIT: 0.6391888786764706
Epoch: 304, plus 0 steps train_loss: 0.5241

#### test Acc: 0, NDCG: 0.369724162989259 HIT: 0.6230353860294118

#### val Acc: 0, NDCG: 0.3790916429859114 HIT: 0.6399011948529412
Epoch: 320, plus 0 steps train_loss: 0.5286

#### test Acc: 0, NDCG: 0.37449500406081293 HIT: 0.6241957720588236

#### val Acc: 0, NDCG: 0.38294964879033977 HIT: 0.6425953584558823
Epoch: 352, plus 0 steps train_loss: 0.5262

#### test Acc: 0, NDCG: 0.38112154285517397 HIT: 0.6298828125

#### val Acc: 0, NDCG: 0.38571631114264054 HIT: 0.6411477481617647
Epoch: 384, plus 0 steps train_loss: 0.5051

#### test Acc: 0, NDCG: 0.3880494343973778 HIT: 0.6388269761029413

#### val Acc: 0, NDCG: 0.3944324614559766 HIT: 0.6453067555147058
Epoch: 416, plus 0 steps train_loss: 0.5075

#### test Acc: 0, NDCG: 0.38461569430991555 HIT: 0.6392750459558824

#### val Acc: 0, NDCG: 0.39317914916242963 HIT: 0.6501608455882353
Epoch: 448, plus 0 steps train_loss: 0.4992

#### test Acc: 0, NDCG: 0.379114452324563 HIT: 0.6295266544117647

#### val Acc: 0, NDCG: 0.3934786241304586 HIT: 0.6453297334558823
Epoch: 480, plus 0 steps train_loss: 0.4919

#### test Acc: 0, NDCG: 0.39282349295347624 HIT: 0.6435259650735294

#### val Acc: 0, NDCG: 0.4003794583746923 HIT: 0.6533375459558823
Epoch: 512, plus 0 steps train_loss: 0.4905

#### test Acc: 0, NDCG: 0.38837857873284914 HIT: 0.6422679227941177

#### val Acc: 0, NDCG: 0.3993244047488015 HIT: 0.6552102481617647
Epoch: 544, plus 0 steps train_loss: 0.4997

#### test Acc: 0, NDCG: 0.3919117076704251 HIT: 0.6411592371323529

#### val Acc: 0, NDCG: 0.39720706307500164 HIT: 0.6522001378676471
Epoch: 576, plus 0 steps train_loss: 0.4813

#### test Acc: 0, NDCG: 0.3994007416779733 HIT: 0.6443531709558823

#### val Acc: 0, NDCG: 0.4030832987544869 HIT: 0.6572150735294118
Epoch: 608, plus 0 steps train_loss: 0.472

#### test Acc: 0, NDCG: 0.3954256010140546 HIT: 0.6491957720588235

#### val Acc: 0, NDCG: 0.4072103283821396 HIT: 0.6617704503676471
Epoch: 640, plus 0 steps train_loss: 0.4812

#### test Acc: 0, NDCG: 0.39244541289312757 HIT: 0.6373563878676471

#### val Acc: 0, NDCG: 0.40794103705734697 HIT: 0.6610753676470588
Epoch: 704, plus 0 steps train_loss: 0.469

#### test Acc: 0, NDCG: 0.4040765674984524 HIT: 0.6492130055147058

#### val Acc: 0, NDCG: 0.40546957643763254 HIT: 0.6570484834558823
Epoch: 768, plus 0 steps train_loss: 0.4767

#### test Acc: 0, NDCG: 0.3917474072623627 HIT: 0.6381778492647059

#### val Acc: 0, NDCG: 0.41034028860706506 HIT: 0.6599379595588235
Epoch: 832, plus 0 steps train_loss: 0.4453

#### test Acc: 0, NDCG: 0.39757267342333324 HIT: 0.6443359375

#### val Acc: 0, NDCG: 0.4092891725849509 HIT: 0.6626436121323529
Epoch: 896, plus 0 steps train_loss: 0.4603

#### test Acc: 0, NDCG: 0.3960845335052386 HIT: 0.6440544577205882

#### val Acc: 0, NDCG: 0.4105059271293027 HIT: 0.6650390625
Epoch: 960, plus 0 steps train_loss: 0.4533

#### test Acc: 0, NDCG: 0.3924756639493968 HIT: 0.6287454044117646

#### val Acc: 0, NDCG: 0.40469084622968 HIT: 0.6525275735294118
Epoch: 1013, plus 25 steps train_loss: 0.4771
Done: it took 275093.4133605957
max value of NDCG: 0.4040765674984524
max value of HIT: 0.6492130055147058

After 20 validations
max value of NDCG: 0.4040765674984524
max value of HIT: 0.6492130055147058
