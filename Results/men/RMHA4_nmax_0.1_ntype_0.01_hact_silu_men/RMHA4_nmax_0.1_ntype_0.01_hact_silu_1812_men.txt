 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.01
max_norm:             	0.1
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.1284119919765429 HIT: 0.2858340992647059

#### val Acc: 0, NDCG: 0.12965555929995323 HIT: 0.2872012867647059
Epoch: 1, plus 0 steps train_loss: 0.7535

#### test Acc: 0, NDCG: 0.12820624305743114 HIT: 0.2820369944852941

#### val Acc: 0, NDCG: 0.13276347393785654 HIT: 0.2891314338235294
Epoch: 2, plus 0 steps train_loss: 0.7593

#### test Acc: 0, NDCG: 0.12462630471971439 HIT: 0.27612591911764706

#### val Acc: 0, NDCG: 0.1304031824774512 HIT: 0.2826171875
Epoch: 3, plus 0 steps train_loss: 0.7434

#### test Acc: 0, NDCG: 0.1285261146774161 HIT: 0.28129595588235295

#### val Acc: 0, NDCG: 0.12649674121932764 HIT: 0.2793543198529412
Epoch: 4, plus 0 steps train_loss: 0.7409

#### test Acc: 0, NDCG: 0.13182390851900938 HIT: 0.28986098345588235

#### val Acc: 0, NDCG: 0.12424325210833839 HIT: 0.275390625
Epoch: 5, plus 0 steps train_loss: 0.7259

#### test Acc: 0, NDCG: 0.1291386369224347 HIT: 0.28419692095588234

#### val Acc: 0, NDCG: 0.1309047702223634 HIT: 0.2848575367647059
Epoch: 6, plus 0 steps train_loss: 0.7189

#### test Acc: 0, NDCG: 0.13399917751024168 HIT: 0.2897403492647059

#### val Acc: 0, NDCG: 0.1484706545534089 HIT: 0.3116613051470588
Epoch: 7, plus 0 steps train_loss: 0.7101

#### test Acc: 0, NDCG: 0.13296695128676023 HIT: 0.28784466911764706

#### val Acc: 0, NDCG: 0.14904967297322053 HIT: 0.30680721507352937
Epoch: 8, plus 0 steps train_loss: 0.7053

#### test Acc: 0, NDCG: 0.14460350610384 HIT: 0.29860983455882356

#### val Acc: 0, NDCG: 0.16667205984241687 HIT: 0.32516084558823527
Epoch: 9, plus 0 steps train_loss: 0.7093

#### test Acc: 0, NDCG: 0.13744010158869355 HIT: 0.2946346507352941

#### val Acc: 0, NDCG: 0.14815092644014555 HIT: 0.30710592830882355
Epoch: 10, plus 0 steps train_loss: 0.7071

#### test Acc: 0, NDCG: 0.14081646075712853 HIT: 0.30220588235294116

#### val Acc: 0, NDCG: 0.15005713278945154 HIT: 0.3074276194852941
Epoch: 12, plus 0 steps train_loss: 0.7057

#### test Acc: 0, NDCG: 0.13777798639512745 HIT: 0.2901769301470588

#### val Acc: 0, NDCG: 0.15963839250465445 HIT: 0.3178079044117647
Epoch: 14, plus 0 steps train_loss: 0.707

#### test Acc: 0, NDCG: 0.15212837507073354 HIT: 0.30659466911764705

#### val Acc: 0, NDCG: 0.17347790227230378 HIT: 0.32816521139705884
Epoch: 16, plus 0 steps train_loss: 0.6995

#### test Acc: 0, NDCG: 0.1840766837366516 HIT: 0.33532858455882353

#### val Acc: 0, NDCG: 0.2022436610798472 HIT: 0.3568761488970588
Epoch: 18, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.14828592737215768 HIT: 0.2967830882352941

#### val Acc: 0, NDCG: 0.1664826559870971 HIT: 0.3270737591911764
Epoch: 20, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.16923981895404816 HIT: 0.32633272058823526

#### val Acc: 0, NDCG: 0.18623338099007697 HIT: 0.3377470128676471
Epoch: 22, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.17763890355270404 HIT: 0.32934283088235294

#### val Acc: 0, NDCG: 0.2063278687526359 HIT: 0.3622989430147059
Epoch: 24, plus 0 steps train_loss: 0.7003

#### test Acc: 0, NDCG: 0.23833229154174207 HIT: 0.39135454963235294

#### val Acc: 0, NDCG: 0.2535542569988789 HIT: 0.41017348345588234
Epoch: 26, plus 0 steps train_loss: 0.7002

#### test Acc: 0, NDCG: 0.2291167053783917 HIT: 0.3835650275735294

#### val Acc: 0, NDCG: 0.25294323231138416 HIT: 0.40452090992647055
Epoch: 28, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.1924521761070803 HIT: 0.3468807444852941

#### val Acc: 0, NDCG: 0.2189379471062308 HIT: 0.37076056985294115
Epoch: 30, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.18893866484088226 HIT: 0.33968290441176474

#### val Acc: 0, NDCG: 0.21532324509396017 HIT: 0.36876723345588236
Epoch: 32, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.20136120676276553 HIT: 0.36108111213235294

#### val Acc: 0, NDCG: 0.2191874257936747 HIT: 0.37761948529411765
Epoch: 36, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.3005116234334352 HIT: 0.4592256433823529

#### val Acc: 0, NDCG: 0.32414003700861416 HIT: 0.47971622242647055
Epoch: 40, plus 0 steps train_loss: 0.6914

#### test Acc: 0, NDCG: 0.3965496014597487 HIT: 0.5475758272058824

#### val Acc: 0, NDCG: 0.40644773509794474 HIT: 0.5533203125
Epoch: 44, plus 0 steps train_loss: 0.6776

#### test Acc: 0, NDCG: 0.2327140014627302 HIT: 0.4432846966911764

#### val Acc: 0, NDCG: 0.23651757650704458 HIT: 0.44835133272058825
Epoch: 48, plus 0 steps train_loss: 0.6703

#### test Acc: 0, NDCG: 0.20961570707466476 HIT: 0.43386374080882356

#### val Acc: 0, NDCG: 0.22200663567380605 HIT: 0.44752412683823534
Epoch: 52, plus 0 steps train_loss: 0.6604

#### test Acc: 0, NDCG: 0.22690989668978512 HIT: 0.45973690257352945

#### val Acc: 0, NDCG: 0.23438643958128735 HIT: 0.4677734375
Epoch: 56, plus 0 steps train_loss: 0.652

#### test Acc: 0, NDCG: 0.23478249588550743 HIT: 0.4719267003676471

#### val Acc: 0, NDCG: 0.24396594025767243 HIT: 0.4821001838235294
Epoch: 60, plus 0 steps train_loss: 0.6341

#### test Acc: 0, NDCG: 0.24909114231310658 HIT: 0.4961282169117647

#### val Acc: 0, NDCG: 0.2490816227066693 HIT: 0.4955135569852941
Epoch: 64, plus 0 steps train_loss: 0.6355

#### test Acc: 0, NDCG: 0.2538629744055817 HIT: 0.4974092371323529

#### val Acc: 0, NDCG: 0.2639712438626794 HIT: 0.5078469669117647
Epoch: 68, plus 0 steps train_loss: 0.6338

#### test Acc: 0, NDCG: 0.2608342320431518 HIT: 0.5046128216911765

#### val Acc: 0, NDCG: 0.26004503916118626 HIT: 0.5032628676470587
Epoch: 72, plus 0 steps train_loss: 0.6289

#### test Acc: 0, NDCG: 0.26276025561772637 HIT: 0.5122874540441177

#### val Acc: 0, NDCG: 0.26602778607226585 HIT: 0.5123334099264706
Epoch: 80, plus 0 steps train_loss: 0.62

#### test Acc: 0, NDCG: 0.27616732577703285 HIT: 0.5327550551470588

#### val Acc: 0, NDCG: 0.2744336865399054 HIT: 0.5241153492647059
Epoch: 88, plus 0 steps train_loss: 0.6291

#### test Acc: 0, NDCG: 0.2812265730483078 HIT: 0.5355526194852941

#### val Acc: 0, NDCG: 0.28493464795187096 HIT: 0.5416934742647059
Epoch: 96, plus 0 steps train_loss: 0.6151

#### test Acc: 0, NDCG: 0.2839167577069311 HIT: 0.53544921875

#### val Acc: 0, NDCG: 0.29052709257347054 HIT: 0.5499195772058824
Epoch: 104, plus 0 steps train_loss: 0.6137

#### test Acc: 0, NDCG: 0.2826020875370677 HIT: 0.5324793198529412

#### val Acc: 0, NDCG: 0.292551476247055 HIT: 0.5435087316176471
Epoch: 112, plus 0 steps train_loss: 0.5903

#### test Acc: 0, NDCG: 0.29135411448458964 HIT: 0.5422162224264706

#### val Acc: 0, NDCG: 0.30235688684165074 HIT: 0.5559110753676471
Epoch: 120, plus 0 steps train_loss: 0.5982

#### test Acc: 0, NDCG: 0.3020610310387459 HIT: 0.5540498621323529

#### val Acc: 0, NDCG: 0.3037179827892775 HIT: 0.559765625
Epoch: 128, plus 0 steps train_loss: 0.6111

#### test Acc: 0, NDCG: 0.3048491653990942 HIT: 0.5616957720588236

#### val Acc: 0, NDCG: 0.3147014911408113 HIT: 0.5677102481617646
Epoch: 136, plus 0 steps train_loss: 0.589

#### test Acc: 0, NDCG: 0.31670728788878627 HIT: 0.5702722886029412

#### val Acc: 0, NDCG: 0.313335286529919 HIT: 0.5693818933823529
Epoch: 144, plus 0 steps train_loss: 0.5906

#### test Acc: 0, NDCG: 0.32501396142461975 HIT: 0.5793141084558824

#### val Acc: 0, NDCG: 0.3238649812522334 HIT: 0.5797794117647059
Epoch: 160, plus 0 steps train_loss: 0.5758

#### test Acc: 0, NDCG: 0.3308716873164182 HIT: 0.5817670036764706

#### val Acc: 0, NDCG: 0.3407324650475834 HIT: 0.5907686121323529
Epoch: 176, plus 0 steps train_loss: 0.5779

#### test Acc: 0, NDCG: 0.33491465684511057 HIT: 0.5870863970588236

#### val Acc: 0, NDCG: 0.34523545238315023 HIT: 0.6030675551470588
Epoch: 192, plus 0 steps train_loss: 0.5583

#### test Acc: 0, NDCG: 0.353208866220408 HIT: 0.6044519761029412

#### val Acc: 0, NDCG: 0.35423127839983976 HIT: 0.6063246783088235
Epoch: 208, plus 0 steps train_loss: 0.5595

#### test Acc: 0, NDCG: 0.35053292068103536 HIT: 0.6015510110294118

#### val Acc: 0, NDCG: 0.36816133563629244 HIT: 0.6208639705882353
Epoch: 224, plus 0 steps train_loss: 0.5551

#### test Acc: 0, NDCG: 0.35407464450241516 HIT: 0.6047334558823529

#### val Acc: 0, NDCG: 0.3683699344383581 HIT: 0.6176011029411764
Epoch: 240, plus 0 steps train_loss: 0.5447

#### test Acc: 0, NDCG: 0.3631608952109505 HIT: 0.6078756893382353

#### val Acc: 0, NDCG: 0.37165690026144704 HIT: 0.6263729319852941
Epoch: 256, plus 0 steps train_loss: 0.5418

#### test Acc: 0, NDCG: 0.36136492474768434 HIT: 0.6079848345588236

#### val Acc: 0, NDCG: 0.3794262276023961 HIT: 0.6278894761029412
Epoch: 272, plus 0 steps train_loss: 0.5515

#### test Acc: 0, NDCG: 0.36929648428927864 HIT: 0.6195140165441176

#### val Acc: 0, NDCG: 0.3746717513188508 HIT: 0.622265625
Epoch: 288, plus 0 steps train_loss: 0.5581

#### test Acc: 0, NDCG: 0.3691606014208803 HIT: 0.6200080422794118

#### val Acc: 0, NDCG: 0.37748239326386607 HIT: 0.6254193474264705
Epoch: 304, plus 0 steps train_loss: 0.5309

#### test Acc: 0, NDCG: 0.3728640304120905 HIT: 0.6211971507352941

#### val Acc: 0, NDCG: 0.3778961864846071 HIT: 0.6254480698529412
Epoch: 320, plus 0 steps train_loss: 0.5205

#### test Acc: 0, NDCG: 0.3762546201505929 HIT: 0.6182272518382353

#### val Acc: 0, NDCG: 0.3840866055278476 HIT: 0.6315774356617647
Epoch: 352, plus 0 steps train_loss: 0.5275

#### test Acc: 0, NDCG: 0.3815198207145162 HIT: 0.6188821231617647

#### val Acc: 0, NDCG: 0.38453177863471005 HIT: 0.63046875
Epoch: 384, plus 0 steps train_loss: 0.5078

#### test Acc: 0, NDCG: 0.3866922939770286 HIT: 0.6262120863970588

#### val Acc: 0, NDCG: 0.3919224326659598 HIT: 0.6412166819852941
Epoch: 416, plus 0 steps train_loss: 0.5164

#### test Acc: 0, NDCG: 0.38738102618737347 HIT: 0.6286075367647059

#### val Acc: 0, NDCG: 0.3926577426784391 HIT: 0.6396829044117647
Epoch: 448, plus 0 steps train_loss: 0.5018

#### test Acc: 0, NDCG: 0.3848892483690244 HIT: 0.6254308363970588

#### val Acc: 0, NDCG: 0.3981869362048278 HIT: 0.6389878216911764
Epoch: 480, plus 0 steps train_loss: 0.484

#### test Acc: 0, NDCG: 0.39421353413827104 HIT: 0.6318014705882353

#### val Acc: 0, NDCG: 0.4023071974511943 HIT: 0.6459386488970588
Epoch: 512, plus 0 steps train_loss: 0.483

#### test Acc: 0, NDCG: 0.39094183797572246 HIT: 0.6334731158088236

#### val Acc: 0, NDCG: 0.39694792260315154 HIT: 0.6426068474264706
Epoch: 544, plus 0 steps train_loss: 0.4869

#### test Acc: 0, NDCG: 0.39166320454719483 HIT: 0.6331456801470587

#### val Acc: 0, NDCG: 0.40059581359221996 HIT: 0.6393324908088236
Epoch: 576, plus 0 steps train_loss: 0.4756

#### test Acc: 0, NDCG: 0.3861209554355896 HIT: 0.6300321691176471

#### val Acc: 0, NDCG: 0.4054378587190561 HIT: 0.6469496783088236
Epoch: 608, plus 0 steps train_loss: 0.4875

#### test Acc: 0, NDCG: 0.4023808079048477 HIT: 0.6436465992647059

#### val Acc: 0, NDCG: 0.40517392537378594 HIT: 0.6495921415441177
Epoch: 640, plus 0 steps train_loss: 0.4842

#### test Acc: 0, NDCG: 0.39371624132857497 HIT: 0.6345013786764706

#### val Acc: 0, NDCG: 0.4074248987985708 HIT: 0.6508559283088236
Epoch: 704, plus 0 steps train_loss: 0.4706

#### test Acc: 0, NDCG: 0.3977062123950504 HIT: 0.6404009650735294

#### val Acc: 0, NDCG: 0.411869772363984 HIT: 0.6512867647058823
Epoch: 768, plus 0 steps train_loss: 0.4612

#### test Acc: 0, NDCG: 0.3950513485917987 HIT: 0.6352366727941177

#### val Acc: 0, NDCG: 0.4173722378409049 HIT: 0.6535845588235294
Epoch: 832, plus 0 steps train_loss: 0.4607

#### test Acc: 0, NDCG: 0.3977060017425732 HIT: 0.6382869944852941

#### val Acc: 0, NDCG: 0.40998475430603853 HIT: 0.6462775735294117
Epoch: 896, plus 0 steps train_loss: 0.4547

#### test Acc: 0, NDCG: 0.3982964624555826 HIT: 0.6373563878676471

#### val Acc: 0, NDCG: 0.40766856496253656 HIT: 0.6497472426470587
Epoch: 960, plus 0 steps train_loss: 0.4631

#### test Acc: 0, NDCG: 0.39952710874729935 HIT: 0.6395450367647059

#### val Acc: 0, NDCG: 0.4078232859749843 HIT: 0.6521484375
Epoch: 1013, plus 25 steps train_loss: 0.47
Done: it took 298567.4259779453
max value of NDCG: 0.4023808079048477
max value of HIT: 0.6436465992647059

After 20 validations
max value of NDCG: 0.4023808079048477
max value of HIT: 0.6436465992647059
