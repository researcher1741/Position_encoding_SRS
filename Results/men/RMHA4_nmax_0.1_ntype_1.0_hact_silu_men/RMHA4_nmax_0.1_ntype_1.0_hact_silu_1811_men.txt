 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	0.1
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13520223416941363 HIT: 0.29653607536764703

#### val Acc: 0, NDCG: 0.14293275861820295 HIT: 0.31036305147058824
Epoch: 1, plus 0 steps train_loss: 0.717

#### test Acc: 0, NDCG: 0.15196643327835635 HIT: 0.28465073529411766

#### val Acc: 0, NDCG: 0.18692275588277157 HIT: 0.3266544117647059
Epoch: 2, plus 0 steps train_loss: 0.7043

#### test Acc: 0, NDCG: 0.1672975499166197 HIT: 0.3094956341911764

#### val Acc: 0, NDCG: 0.21302625902300476 HIT: 0.355078125
Epoch: 3, plus 0 steps train_loss: 0.7055

#### test Acc: 0, NDCG: 0.14647097871861875 HIT: 0.31456801470588236

#### val Acc: 0, NDCG: 0.15705415956074878 HIT: 0.3218462775735294
Epoch: 4, plus 0 steps train_loss: 0.7044

#### test Acc: 0, NDCG: 0.17343015132533884 HIT: 0.34330193014705884

#### val Acc: 0, NDCG: 0.1956967354563355 HIT: 0.3588062959558823
Epoch: 5, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.17949964760216225 HIT: 0.3731330422794118

#### val Acc: 0, NDCG: 0.18722651024554632 HIT: 0.38215188419117646
Epoch: 6, plus 0 steps train_loss: 0.6926

#### test Acc: 0, NDCG: 0.1986882206939811 HIT: 0.4030215992647059

#### val Acc: 0, NDCG: 0.18861892273888078 HIT: 0.38899931066176474
Epoch: 7, plus 0 steps train_loss: 0.6735

#### test Acc: 0, NDCG: 0.21640872228059313 HIT: 0.4434053308823529

#### val Acc: 0, NDCG: 0.21930208499954412 HIT: 0.4407858455882353
Epoch: 8, plus 0 steps train_loss: 0.6584

#### test Acc: 0, NDCG: 0.22620527651002637 HIT: 0.4517003676470588

#### val Acc: 0, NDCG: 0.2276983523902806 HIT: 0.4545840992647059
Epoch: 9, plus 0 steps train_loss: 0.6634

#### test Acc: 0, NDCG: 0.2250904385752225 HIT: 0.4577263327205882

#### val Acc: 0, NDCG: 0.23431209297094724 HIT: 0.47267348345588234
Epoch: 10, plus 0 steps train_loss: 0.658

#### test Acc: 0, NDCG: 0.24773088833812335 HIT: 0.4974264705882353

#### val Acc: 0, NDCG: 0.2533154804587312 HIT: 0.50263671875
Epoch: 12, plus 0 steps train_loss: 0.6389

#### test Acc: 0, NDCG: 0.25372106428300767 HIT: 0.5027458639705882

#### val Acc: 0, NDCG: 0.26081073369220636 HIT: 0.5124655330882353
Epoch: 14, plus 0 steps train_loss: 0.625

#### test Acc: 0, NDCG: 0.2623506132097262 HIT: 0.51474609375

#### val Acc: 0, NDCG: 0.2728973807645031 HIT: 0.5208467371323529
Epoch: 16, plus 0 steps train_loss: 0.6285

#### test Acc: 0, NDCG: 0.25709317806951354 HIT: 0.5074678308823529

#### val Acc: 0, NDCG: 0.2649633807547888 HIT: 0.5209903492647059
Epoch: 18, plus 0 steps train_loss: 0.603

#### test Acc: 0, NDCG: 0.2630014858677586 HIT: 0.5171185661764706

#### val Acc: 0, NDCG: 0.27359515745367546 HIT: 0.52568359375
Epoch: 20, plus 0 steps train_loss: 0.6158

#### test Acc: 0, NDCG: 0.27099629299846545 HIT: 0.5315085018382353

#### val Acc: 0, NDCG: 0.27747904199374235 HIT: 0.5355009191176471
Epoch: 22, plus 0 steps train_loss: 0.6143

#### test Acc: 0, NDCG: 0.2753056312250596 HIT: 0.5331916360294118

#### val Acc: 0, NDCG: 0.2838932977426046 HIT: 0.5383501838235294
Epoch: 24, plus 0 steps train_loss: 0.6102

#### test Acc: 0, NDCG: 0.2817495795132633 HIT: 0.5423081341911764

#### val Acc: 0, NDCG: 0.28735444719190434 HIT: 0.5450080422794118
Epoch: 26, plus 0 steps train_loss: 0.6056

#### test Acc: 0, NDCG: 0.29800558594805926 HIT: 0.56376953125

#### val Acc: 0, NDCG: 0.3057572723788202 HIT: 0.5699046415441177
Epoch: 28, plus 0 steps train_loss: 0.5866

#### test Acc: 0, NDCG: 0.29531410715336537 HIT: 0.5587201286764706

#### val Acc: 0, NDCG: 0.3041463761196458 HIT: 0.5678423713235294
Epoch: 30, plus 0 steps train_loss: 0.5995

#### test Acc: 0, NDCG: 0.3107990949969906 HIT: 0.5706973805147059

#### val Acc: 0, NDCG: 0.3197401056243324 HIT: 0.5791877297794118
Epoch: 32, plus 0 steps train_loss: 0.5877

#### test Acc: 0, NDCG: 0.3324697678152651 HIT: 0.5963809742647059

#### val Acc: 0, NDCG: 0.3267289197858897 HIT: 0.5788200827205883
Epoch: 36, plus 0 steps train_loss: 0.5816

#### test Acc: 0, NDCG: 0.3408955722055057 HIT: 0.5968577665441177

#### val Acc: 0, NDCG: 0.3475347877253678 HIT: 0.6016888786764706
Epoch: 40, plus 0 steps train_loss: 0.5651

#### test Acc: 0, NDCG: 0.35469961014127654 HIT: 0.6091911764705882

#### val Acc: 0, NDCG: 0.36365182968700044 HIT: 0.6167394301470588
Epoch: 44, plus 0 steps train_loss: 0.5333

#### test Acc: 0, NDCG: 0.35097072747190194 HIT: 0.5942957261029412

#### val Acc: 0, NDCG: 0.3692468023696556 HIT: 0.6135627297794117
Epoch: 48, plus 0 steps train_loss: 0.5337

#### test Acc: 0, NDCG: 0.3574464625146396 HIT: 0.5874138327205882

#### val Acc: 0, NDCG: 0.37293108056605023 HIT: 0.6168887867647059
Epoch: 52, plus 0 steps train_loss: 0.5482

#### test Acc: 0, NDCG: 0.3602099101044533 HIT: 0.5941463694852941

#### val Acc: 0, NDCG: 0.3727895734419262 HIT: 0.6101275275735294
Epoch: 56, plus 0 steps train_loss: 0.5169

#### test Acc: 0, NDCG: 0.3585227021415575 HIT: 0.5895967371323529

#### val Acc: 0, NDCG: 0.3719596123844825 HIT: 0.6074620863970588
Epoch: 60, plus 0 steps train_loss: 0.5185

#### test Acc: 0, NDCG: 0.36261957019702806 HIT: 0.5939625459558824

#### val Acc: 0, NDCG: 0.3720152274780523 HIT: 0.6071920955882353
Epoch: 64, plus 0 steps train_loss: 0.4941

#### test Acc: 0, NDCG: 0.3631303247965273 HIT: 0.5942325367647059

#### val Acc: 0, NDCG: 0.36674454803125894 HIT: 0.6027228860294118
Epoch: 68, plus 0 steps train_loss: 0.5005

#### test Acc: 0, NDCG: 0.3678680099167666 HIT: 0.5992072610294118

#### val Acc: 0, NDCG: 0.3689020438297668 HIT: 0.6061236213235295
Epoch: 72, plus 0 steps train_loss: 0.4852

#### test Acc: 0, NDCG: 0.3602218794209215 HIT: 0.5833122702205882

#### val Acc: 0, NDCG: 0.37071585247371047 HIT: 0.5988683363970588
Epoch: 80, plus 0 steps train_loss: 0.4682

#### test Acc: 0, NDCG: 0.3577071526899285 HIT: 0.5857651654411764

#### val Acc: 0, NDCG: 0.36703588877369203 HIT: 0.6102481617647059
Epoch: 88, plus 0 steps train_loss: 0.4867

#### test Acc: 0, NDCG: 0.36224650191926505 HIT: 0.5830365349264706

#### val Acc: 0, NDCG: 0.3694286346935742 HIT: 0.5999368106617646
Epoch: 96, plus 0 steps train_loss: 0.4575

#### test Acc: 0, NDCG: 0.35318100155578797 HIT: 0.5766486672794118

#### val Acc: 0, NDCG: 0.37180322006245403 HIT: 0.6020335477941177
Epoch: 104, plus 0 steps train_loss: 0.4643

#### test Acc: 0, NDCG: 0.3539431121866339 HIT: 0.5768037683823529

#### val Acc: 0, NDCG: 0.3694475604390896 HIT: 0.6015452665441177
Epoch: 112, plus 0 steps train_loss: 0.4709

#### test Acc: 0, NDCG: 0.34610576452743713 HIT: 0.5703642003676471

#### val Acc: 0, NDCG: 0.3693567225739871 HIT: 0.6044117647058823
Epoch: 120, plus 0 steps train_loss: 0.4446

#### test Acc: 0, NDCG: 0.3515770073159147 HIT: 0.5753561580882354

#### val Acc: 0, NDCG: 0.3665053658503132 HIT: 0.6002068014705882
Epoch: 128, plus 0 steps train_loss: 0.4515

#### test Acc: 0, NDCG: 0.353260423818532 HIT: 0.5812040441176471

#### val Acc: 0, NDCG: 0.3687934731093619 HIT: 0.6128619025735295
Epoch: 136, plus 0 steps train_loss: 0.447

#### test Acc: 0, NDCG: 0.3512505149466653 HIT: 0.5784639246323529

#### val Acc: 0, NDCG: 0.35999717191745917 HIT: 0.5925608915441176
Epoch: 144, plus 0 steps train_loss: 0.4244

#### test Acc: 0, NDCG: 0.34433321171931874 HIT: 0.5718864889705882

#### val Acc: 0, NDCG: 0.35692899895125446 HIT: 0.5910788143382353
Epoch: 160, plus 0 steps train_loss: 0.4361

#### test Acc: 0, NDCG: 0.3392849165236047 HIT: 0.5730698529411764

#### val Acc: 0, NDCG: 0.35211183862237705 HIT: 0.5962488511029412
Epoch: 176, plus 0 steps train_loss: 0.4228

#### test Acc: 0, NDCG: 0.33543040054494994 HIT: 0.5621783088235295

#### val Acc: 0, NDCG: 0.3525396428772337 HIT: 0.5918543198529412
Epoch: 192, plus 0 steps train_loss: 0.4054

#### test Acc: 0, NDCG: 0.3344796011897867 HIT: 0.5679572610294118

#### val Acc: 0, NDCG: 0.35027995158247516 HIT: 0.5964269301470588
Epoch: 208, plus 0 steps train_loss: 0.4158

#### test Acc: 0, NDCG: 0.33710033684189655 HIT: 0.5719956341911765

#### val Acc: 0, NDCG: 0.3443719824587915 HIT: 0.5829963235294118
Epoch: 224, plus 0 steps train_loss: 0.4273

#### test Acc: 0, NDCG: 0.3330846593234858 HIT: 0.5688189338235294

#### val Acc: 0, NDCG: 0.34592068833478146 HIT: 0.5906422334558823
Epoch: 240, plus 0 steps train_loss: 0.4055

#### test Acc: 0, NDCG: 0.3306570826597771 HIT: 0.5684283088235295

#### val Acc: 0, NDCG: 0.347609800486981 HIT: 0.5878044577205882
Epoch: 256, plus 0 steps train_loss: 0.414

#### test Acc: 0, NDCG: 0.32413417800312827 HIT: 0.556640625

#### val Acc: 0, NDCG: 0.3439610803193104 HIT: 0.5864487591911764
Epoch: 272, plus 0 steps train_loss: 0.3989

#### test Acc: 0, NDCG: 0.33176646093683265 HIT: 0.5635627297794118

#### val Acc: 0, NDCG: 0.334835009250682 HIT: 0.5811178768382353
Epoch: 288, plus 0 steps train_loss: 0.4086

#### test Acc: 0, NDCG: 0.32924584983241584 HIT: 0.5602711397058824

#### val Acc: 0, NDCG: 0.34651577719226284 HIT: 0.59365234375
Epoch: 304, plus 0 steps train_loss: 0.4025

#### test Acc: 0, NDCG: 0.34399586243044233 HIT: 0.5722943474264706

#### val Acc: 0, NDCG: 0.35152537461309086 HIT: 0.5962028952205882
Epoch: 320, plus 0 steps train_loss: 0.3901

#### test Acc: 0, NDCG: 0.3352269083663818 HIT: 0.5744600183823529

#### val Acc: 0, NDCG: 0.3379049858331903 HIT: 0.5838924632352941
Epoch: 352, plus 0 steps train_loss: 0.3735

#### test Acc: 0, NDCG: 0.3338927349800255 HIT: 0.5701918658088235

#### val Acc: 0, NDCG: 0.34469718908413816 HIT: 0.5894129136029412
Epoch: 384, plus 0 steps train_loss: 0.3985

#### test Acc: 0, NDCG: 0.33731155418052045 HIT: 0.5765969669117647

#### val Acc: 0, NDCG: 0.3424273515238223 HIT: 0.5852998621323529
Epoch: 416, plus 0 steps train_loss: 0.3756

#### test Acc: 0, NDCG: 0.3228978341262374 HIT: 0.5547277113970588

#### val Acc: 0, NDCG: 0.3434514871843506 HIT: 0.5851102941176471
Epoch: 448, plus 0 steps train_loss: 0.3677

#### test Acc: 0, NDCG: 0.32207954394391136 HIT: 0.5550149356617646

#### val Acc: 0, NDCG: 0.34381131133609577 HIT: 0.5946461397058823
Epoch: 480, plus 0 steps train_loss: 0.3582

#### test Acc: 0, NDCG: 0.3380115710849289 HIT: 0.5779584099264705

#### val Acc: 0, NDCG: 0.3432263546047051 HIT: 0.5920955882352941
Epoch: 512, plus 0 steps train_loss: 0.377

#### test Acc: 0, NDCG: 0.3349645097113178 HIT: 0.5760110294117646

#### val Acc: 0, NDCG: 0.3458755955323613 HIT: 0.5935834099264705
Epoch: 544, plus 0 steps train_loss: 0.3582

#### test Acc: 0, NDCG: 0.33026632113411714 HIT: 0.5616038602941177

#### val Acc: 0, NDCG: 0.3455828620689807 HIT: 0.5881204044117647
Epoch: 576, plus 0 steps train_loss: 0.3506

#### test Acc: 0, NDCG: 0.34216197555576583 HIT: 0.5777516084558824

#### val Acc: 0, NDCG: 0.3567039268847886 HIT: 0.5969956341911764
Epoch: 608, plus 0 steps train_loss: 0.3472

#### test Acc: 0, NDCG: 0.34342407064704333 HIT: 0.5725413602941176

#### val Acc: 0, NDCG: 0.3554814860103667 HIT: 0.5967830882352941
Epoch: 640, plus 0 steps train_loss: 0.3532

#### test Acc: 0, NDCG: 0.3481913930544012 HIT: 0.5664177389705882

#### val Acc: 0, NDCG: 0.36461809408116747 HIT: 0.5981675091911764
Epoch: 704, plus 0 steps train_loss: 0.3248

#### test Acc: 0, NDCG: 0.34801840991342237 HIT: 0.5698299632352941

#### val Acc: 0, NDCG: 0.3578260136794865 HIT: 0.5765510110294118
Epoch: 768, plus 0 steps train_loss: 0.3098

#### test Acc: 0, NDCG: 0.3532670194819719 HIT: 0.5632123161764706

#### val Acc: 0, NDCG: 0.3608609886769362 HIT: 0.5781939338235295
Epoch: 832, plus 0 steps train_loss: 0.3027

#### test Acc: 0, NDCG: 0.36083844007986143 HIT: 0.5653147977941176

#### val Acc: 0, NDCG: 0.36612198890431497 HIT: 0.5798196231617647
Epoch: 896, plus 0 steps train_loss: 0.3061

#### test Acc: 0, NDCG: 0.3560832779693207 HIT: 0.5578527113970588

#### val Acc: 0, NDCG: 0.36474136320822403 HIT: 0.5786937040441177
Epoch: 960, plus 0 steps train_loss: 0.2814

#### test Acc: 0, NDCG: 0.3514109439739507 HIT: 0.5518267463235295

#### val Acc: 0, NDCG: 0.3643482359729863 HIT: 0.5777171415441177
Epoch: 1013, plus 25 steps train_loss: 0.2841
Done: it took 289415.6556017399
max value of NDCG: 0.3678680099167666
max value of HIT: 0.6091911764705882

After 20 validations
max value of NDCG: 0.3678680099167666
max value of HIT: 0.6091911764705882
