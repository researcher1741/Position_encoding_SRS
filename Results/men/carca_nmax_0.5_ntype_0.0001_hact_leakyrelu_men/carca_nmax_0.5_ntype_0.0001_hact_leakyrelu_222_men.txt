 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.0001
max_norm:             	0.5
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
RMHA_decoder:         	False
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_encoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12727720615954924 HIT: 0.28128446691176473

#### val Acc: 0, NDCG: 0.13104767224762714 HIT: 0.28527113970588236
Epoch: 1, plus 0 steps train_loss: 0.7753

#### test Acc: 0, NDCG: 0.1285886212976297 HIT: 0.2796989889705882

#### val Acc: 0, NDCG: 0.12939217064747013 HIT: 0.28938419117647063
Epoch: 2, plus 0 steps train_loss: 0.774

#### test Acc: 0, NDCG: 0.12632220797273286 HIT: 0.2806353400735294

#### val Acc: 0, NDCG: 0.13088732200619752 HIT: 0.28483455882352937
Epoch: 3, plus 0 steps train_loss: 0.763

#### test Acc: 0, NDCG: 0.1314825574105391 HIT: 0.2876780790441177

#### val Acc: 0, NDCG: 0.13007609110742102 HIT: 0.28394416360294117
Epoch: 4, plus 0 steps train_loss: 0.7672

#### test Acc: 0, NDCG: 0.13265818938430168 HIT: 0.29323874080882356

#### val Acc: 0, NDCG: 0.12593501563949464 HIT: 0.2760914522058823
Epoch: 5, plus 0 steps train_loss: 0.7517

#### test Acc: 0, NDCG: 0.13267988716030396 HIT: 0.2891429227941177

#### val Acc: 0, NDCG: 0.13067892153287325 HIT: 0.2880112591911764
Epoch: 6, plus 0 steps train_loss: 0.7416

#### test Acc: 0, NDCG: 0.13352550291499257 HIT: 0.2914981617647059

#### val Acc: 0, NDCG: 0.12870682962551522 HIT: 0.2866785386029412
Epoch: 7, plus 0 steps train_loss: 0.7427

#### test Acc: 0, NDCG: 0.13169826085667408 HIT: 0.28596047794117646

#### val Acc: 0, NDCG: 0.12784500205316196 HIT: 0.28025620404411766
Epoch: 8, plus 0 steps train_loss: 0.7406

#### test Acc: 0, NDCG: 0.12775467709426613 HIT: 0.27892348345588236

#### val Acc: 0, NDCG: 0.12595888859299245 HIT: 0.27368451286764706
Epoch: 9, plus 0 steps train_loss: 0.733

#### test Acc: 0, NDCG: 0.13163727632365338 HIT: 0.2870404411764706

#### val Acc: 0, NDCG: 0.1311909661745423 HIT: 0.2881778492647059
Epoch: 10, plus 0 steps train_loss: 0.7287

#### test Acc: 0, NDCG: 0.13444407436041947 HIT: 0.2954216452205882

#### val Acc: 0, NDCG: 0.13090279339868802 HIT: 0.2850700827205882
Epoch: 12, plus 0 steps train_loss: 0.7237

#### test Acc: 0, NDCG: 0.13008935440006691 HIT: 0.2855181525735294

#### val Acc: 0, NDCG: 0.13196306670382654 HIT: 0.28944738051470587
Epoch: 14, plus 0 steps train_loss: 0.7246

#### test Acc: 0, NDCG: 0.1313170435406991 HIT: 0.28970588235294115

#### val Acc: 0, NDCG: 0.1355478240162009 HIT: 0.29287109375
Epoch: 16, plus 0 steps train_loss: 0.7184

#### test Acc: 0, NDCG: 0.13109060271822853 HIT: 0.28512178308823527

#### val Acc: 0, NDCG: 0.13072618387804275 HIT: 0.2866268382352941
Epoch: 18, plus 0 steps train_loss: 0.7182

#### test Acc: 0, NDCG: 0.13073294764688295 HIT: 0.28721277573529413

#### val Acc: 0, NDCG: 0.12558262362970035 HIT: 0.27780905330882355
Epoch: 20, plus 0 steps train_loss: 0.7122

#### test Acc: 0, NDCG: 0.12433230063488934 HIT: 0.2747587316176471

#### val Acc: 0, NDCG: 0.1287726046632088 HIT: 0.28255974264705885
Epoch: 22, plus 0 steps train_loss: 0.7146

#### test Acc: 0, NDCG: 0.12561781504822436 HIT: 0.2787454044117647

#### val Acc: 0, NDCG: 0.13134059569263115 HIT: 0.28797104779411764
Epoch: 24, plus 0 steps train_loss: 0.7113

#### test Acc: 0, NDCG: 0.12601127121199313 HIT: 0.2754480698529412

#### val Acc: 0, NDCG: 0.13264418004000933 HIT: 0.2912281709558823
Epoch: 26, plus 0 steps train_loss: 0.7098

#### test Acc: 0, NDCG: 0.12835691360899446 HIT: 0.2828469669117647

#### val Acc: 0, NDCG: 0.12690876527035846 HIT: 0.27857306985294117
Epoch: 28, plus 0 steps train_loss: 0.7088

#### test Acc: 0, NDCG: 0.12815360712165866 HIT: 0.2865349264705882

#### val Acc: 0, NDCG: 0.13217243736676126 HIT: 0.28683938419117644
Epoch: 30, plus 0 steps train_loss: 0.7123

#### test Acc: 0, NDCG: 0.12707593742577722 HIT: 0.2797564338235294

#### val Acc: 0, NDCG: 0.12663155829988498 HIT: 0.28218635110294116
Epoch: 32, plus 0 steps train_loss: 0.7112

#### test Acc: 0, NDCG: 0.13117813739158754 HIT: 0.2848747702205882

#### val Acc: 0, NDCG: 0.1286269128808894 HIT: 0.28413947610294116
Epoch: 36, plus 0 steps train_loss: 0.7097

#### test Acc: 0, NDCG: 0.13260195916513437 HIT: 0.2889303768382353

#### val Acc: 0, NDCG: 0.13397725676717895 HIT: 0.29237132352941175
Epoch: 40, plus 0 steps train_loss: 0.7031

#### test Acc: 0, NDCG: 0.13126960514811853 HIT: 0.28679342830882354

#### val Acc: 0, NDCG: 0.13410451224415795 HIT: 0.2949505974264706
Epoch: 44, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.12582572238544143 HIT: 0.27509765625

#### val Acc: 0, NDCG: 0.1304981953670151 HIT: 0.29069393382352937
Epoch: 48, plus 0 steps train_loss: 0.7028

#### test Acc: 0, NDCG: 0.12834501312139873 HIT: 0.2797909007352941

#### val Acc: 0, NDCG: 0.1324270821037719 HIT: 0.29097541360294116
Epoch: 52, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.12881761548368018 HIT: 0.27996323529411765

#### val Acc: 0, NDCG: 0.1252139898561336 HIT: 0.27522403492647063
Epoch: 56, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.1316730662314683 HIT: 0.28566750919117645

#### val Acc: 0, NDCG: 0.12817802284091012 HIT: 0.2858455882352941
Epoch: 60, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.12974954986851828 HIT: 0.2796989889705882

#### val Acc: 0, NDCG: 0.13078543312318552 HIT: 0.28700022977941175
Epoch: 64, plus 0 steps train_loss: 0.7018

#### test Acc: 0, NDCG: 0.13107548084919113 HIT: 0.27994025735294115

#### val Acc: 0, NDCG: 0.1348600027408794 HIT: 0.29005629595588234
Epoch: 68, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.13113661673244423 HIT: 0.2864889705882353

#### val Acc: 0, NDCG: 0.12418810741863559 HIT: 0.2689108455882353
Epoch: 72, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.1261531580740825 HIT: 0.27463235294117644

#### val Acc: 0, NDCG: 0.13283381264633093 HIT: 0.2880170036764706
Epoch: 80, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.13425487906073857 HIT: 0.28525965073529413

#### val Acc: 0, NDCG: 0.1341934643125818 HIT: 0.28657513786764705
Epoch: 88, plus 0 steps train_loss: 0.6995

#### test Acc: 0, NDCG: 0.1370730101584536 HIT: 0.293359375

#### val Acc: 0, NDCG: 0.13909825820264615 HIT: 0.29233111213235297
Epoch: 96, plus 0 steps train_loss: 0.6953

#### test Acc: 0, NDCG: 0.14718205423613112 HIT: 0.2988568474264706

#### val Acc: 0, NDCG: 0.1562233999098301 HIT: 0.3088235294117647
Epoch: 104, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.1594372355673494 HIT: 0.31351102941176473

#### val Acc: 0, NDCG: 0.16348602654899358 HIT: 0.3168198529411764
Epoch: 112, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.28375291356291754 HIT: 0.43933823529411764

#### val Acc: 0, NDCG: 0.29334122304104626 HIT: 0.44883386948529413
Epoch: 120, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.2831059548248178 HIT: 0.44338809742647056

#### val Acc: 0, NDCG: 0.29080794861662573 HIT: 0.44622012867647054
Epoch: 128, plus 0 steps train_loss: 0.6954

#### test Acc: 0, NDCG: 0.35312555183472105 HIT: 0.5129193474264706

#### val Acc: 0, NDCG: 0.3698534607547599 HIT: 0.5248046875
Epoch: 136, plus 0 steps train_loss: 0.6918

#### test Acc: 0, NDCG: 0.3911112464806645 HIT: 0.5438074448529412

#### val Acc: 0, NDCG: 0.4044552067573167 HIT: 0.5564682904411764
Epoch: 144, plus 0 steps train_loss: 0.691

#### test Acc: 0, NDCG: 0.3459660063625202 HIT: 0.5031824448529412

#### val Acc: 0, NDCG: 0.36153255022853903 HIT: 0.51572265625
Epoch: 160, plus 0 steps train_loss: 0.6903

#### test Acc: 0, NDCG: 0.5189409409386622 HIT: 0.6480813419117647

#### val Acc: 0, NDCG: 0.5352187116979062 HIT: 0.6603860294117647
Epoch: 176, plus 0 steps train_loss: 0.6907

#### test Acc: 0, NDCG: 0.5540451232634683 HIT: 0.6816865808823529

#### val Acc: 0, NDCG: 0.561520513496409 HIT: 0.6842141544117647
Epoch: 192, plus 0 steps train_loss: 0.6902

#### test Acc: 0, NDCG: 0.5627875209722155 HIT: 0.6861500459558824

#### val Acc: 0, NDCG: 0.5721289775893104 HIT: 0.6907858455882353
Epoch: 208, plus 0 steps train_loss: 0.6847

#### test Acc: 0, NDCG: 0.5489698374824816 HIT: 0.6792738970588236

#### val Acc: 0, NDCG: 0.5690219978489975 HIT: 0.6914407169117647
Epoch: 224, plus 0 steps train_loss: 0.6844

#### test Acc: 0, NDCG: 0.5597586143720636 HIT: 0.68291015625

#### val Acc: 0, NDCG: 0.5610383434773961 HIT: 0.6866785386029413
Epoch: 240, plus 0 steps train_loss: 0.685

#### test Acc: 0, NDCG: 0.5592068861375221 HIT: 0.6807272518382353

#### val Acc: 0, NDCG: 0.5705716443921316 HIT: 0.6943301930147059
Epoch: 256, plus 0 steps train_loss: 0.681

#### test Acc: 0, NDCG: 0.5433353188974178 HIT: 0.6684914981617647

#### val Acc: 0, NDCG: 0.5548390029195414 HIT: 0.6822150735294118
Epoch: 272, plus 0 steps train_loss: 0.6786

#### test Acc: 0, NDCG: 0.5198352560732344 HIT: 0.6547449448529412

#### val Acc: 0, NDCG: 0.527761684309369 HIT: 0.6580135569852941
Epoch: 288, plus 0 steps train_loss: 0.6795

#### test Acc: 0, NDCG: 0.5116539955333654 HIT: 0.6471564797794118

#### val Acc: 0, NDCG: 0.5178231663145795 HIT: 0.6590073529411764
Epoch: 304, plus 0 steps train_loss: 0.6799

#### test Acc: 0, NDCG: 0.5223716244532253 HIT: 0.66103515625

#### val Acc: 0, NDCG: 0.5327889009593358 HIT: 0.6666762408088236
Epoch: 320, plus 0 steps train_loss: 0.6722

#### test Acc: 0, NDCG: 0.5653124007086214 HIT: 0.6879653033088236

#### val Acc: 0, NDCG: 0.5780419954004758 HIT: 0.6983111213235295
Epoch: 352, plus 0 steps train_loss: 0.6698

#### test Acc: 0, NDCG: 0.4773568804362937 HIT: 0.6249540441176471

#### val Acc: 0, NDCG: 0.49230762870495975 HIT: 0.6326286764705882
Epoch: 384, plus 0 steps train_loss: 0.667

#### test Acc: 0, NDCG: 0.49088022406354437 HIT: 0.6335822610294117

#### val Acc: 0, NDCG: 0.5102833606323008 HIT: 0.6457548253676471
Epoch: 416, plus 0 steps train_loss: 0.666

#### test Acc: 0, NDCG: 0.442089150253078 HIT: 0.5954388786764706

#### val Acc: 0, NDCG: 0.45715477567825874 HIT: 0.6034064797794118
Epoch: 448, plus 0 steps train_loss: 0.6598

#### test Acc: 0, NDCG: 0.5442874463106838 HIT: 0.6703584558823529

#### val Acc: 0, NDCG: 0.5535499926170324 HIT: 0.6804457720588235
Epoch: 480, plus 0 steps train_loss: 0.6592

#### test Acc: 0, NDCG: 0.4627837978817122 HIT: 0.6117072610294118

#### val Acc: 0, NDCG: 0.47698859799298293 HIT: 0.6188591452205883
Epoch: 512, plus 0 steps train_loss: 0.6522

#### test Acc: 0, NDCG: 0.4263116743196034 HIT: 0.5760397518382353

#### val Acc: 0, NDCG: 0.448113523527997 HIT: 0.5984087775735294
Epoch: 544, plus 0 steps train_loss: 0.6661

#### test Acc: 0, NDCG: 0.41810548322725116 HIT: 0.5684914981617647

#### val Acc: 0, NDCG: 0.449611620084638 HIT: 0.5990981158088236
Epoch: 576, plus 0 steps train_loss: 0.6555

#### test Acc: 0, NDCG: 0.39115134392277595 HIT: 0.5523380055147059

#### val Acc: 0, NDCG: 0.4286894454566007 HIT: 0.5842026654411765
Epoch: 608, plus 0 steps train_loss: 0.6575

#### test Acc: 0, NDCG: 0.41138145641680246 HIT: 0.5683134191176471

#### val Acc: 0, NDCG: 0.4315012253994982 HIT: 0.5860236672794118
Epoch: 640, plus 0 steps train_loss: 0.6537

#### test Acc: 0, NDCG: 0.3405460295260557 HIT: 0.51318359375

#### val Acc: 0, NDCG: 0.358532819863272 HIT: 0.5262408088235294
Epoch: 704, plus 0 steps train_loss: 0.6599

#### test Acc: 0, NDCG: 0.3350238126279549 HIT: 0.49732881433823534

#### val Acc: 0, NDCG: 0.37315587282022233 HIT: 0.5436121323529413
Epoch: 768, plus 0 steps train_loss: 0.648

#### test Acc: 0, NDCG: 0.3155460906179116 HIT: 0.4913028492647059

#### val Acc: 0, NDCG: 0.33226714069270075 HIT: 0.5015739889705882
Epoch: 832, plus 0 steps train_loss: 0.6452

#### test Acc: 0, NDCG: 0.31514031990553737 HIT: 0.4912166819852941

#### val Acc: 0, NDCG: 0.3293761172404638 HIT: 0.5062327665441176
Epoch: 896, plus 0 steps train_loss: 0.6525

#### test Acc: 0, NDCG: 0.30767639736061536 HIT: 0.4787109375

#### val Acc: 0, NDCG: 0.3307897275839764 HIT: 0.5068818933823529
Epoch: 960, plus 0 steps train_loss: 0.6375

#### test Acc: 0, NDCG: 0.3055365268679099 HIT: 0.4861787683823529

#### val Acc: 0, NDCG: 0.33663427351954206 HIT: 0.5071461397058823
Epoch: 1013, plus 25 steps train_loss: 0.6483
Done: it took 298603.2595973015
max value of NDCG: 0.5653124007086214
max value of HIT: 0.6879653033088236

After 20 validations
max value of NDCG: 0.5653124007086214
max value of HIT: 0.6879653033088236
