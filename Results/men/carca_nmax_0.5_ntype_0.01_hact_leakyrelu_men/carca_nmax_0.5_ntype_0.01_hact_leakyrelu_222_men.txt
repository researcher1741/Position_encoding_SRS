 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.01
max_norm:             	0.5
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
RMHA_decoder:         	False
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_encoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12807218137697146 HIT: 0.28149126838235294

#### val Acc: 0, NDCG: 0.13026261594971628 HIT: 0.28547794117647063
Epoch: 1, plus 0 steps train_loss: 0.7758

#### test Acc: 0, NDCG: 0.12562072524967338 HIT: 0.28289866727941176

#### val Acc: 0, NDCG: 0.1297860970102686 HIT: 0.2856732536764706
Epoch: 2, plus 0 steps train_loss: 0.769

#### test Acc: 0, NDCG: 0.12929320677928563 HIT: 0.2816693474264706

#### val Acc: 0, NDCG: 0.12890017379485427 HIT: 0.28269761029411766
Epoch: 3, plus 0 steps train_loss: 0.7598

#### test Acc: 0, NDCG: 0.13235351806156287 HIT: 0.28786764705882356

#### val Acc: 0, NDCG: 0.13486452665129348 HIT: 0.2983283547794118
Epoch: 4, plus 0 steps train_loss: 0.7624

#### test Acc: 0, NDCG: 0.13054824049098346 HIT: 0.2859317555147059

#### val Acc: 0, NDCG: 0.13109447160431303 HIT: 0.2922909007352941
Epoch: 5, plus 0 steps train_loss: 0.7584

#### test Acc: 0, NDCG: 0.12936976621666765 HIT: 0.2878619025735294

#### val Acc: 0, NDCG: 0.13506514316701207 HIT: 0.29232536764705885
Epoch: 6, plus 0 steps train_loss: 0.7452

#### test Acc: 0, NDCG: 0.12962606249555744 HIT: 0.2837028952205882

#### val Acc: 0, NDCG: 0.13395761346219495 HIT: 0.29508272058823526
Epoch: 7, plus 0 steps train_loss: 0.7367

#### test Acc: 0, NDCG: 0.12966640279831856 HIT: 0.2832146139705882

#### val Acc: 0, NDCG: 0.1342962023571152 HIT: 0.29068244485294115
Epoch: 8, plus 0 steps train_loss: 0.7441

#### test Acc: 0, NDCG: 0.13482278082446728 HIT: 0.29340533088235293

#### val Acc: 0, NDCG: 0.1336722232870428 HIT: 0.2904526654411764
Epoch: 9, plus 0 steps train_loss: 0.7349

#### test Acc: 0, NDCG: 0.13135658192253868 HIT: 0.29021139705882354

#### val Acc: 0, NDCG: 0.13098342929547457 HIT: 0.28680491727941176
Epoch: 10, plus 0 steps train_loss: 0.73

#### test Acc: 0, NDCG: 0.13256693668988842 HIT: 0.29431295955882353

#### val Acc: 0, NDCG: 0.12674885708247768 HIT: 0.2776309742647059
Epoch: 12, plus 0 steps train_loss: 0.7302

#### test Acc: 0, NDCG: 0.12990675915968367 HIT: 0.28812614889705884

#### val Acc: 0, NDCG: 0.13161765441687817 HIT: 0.2868508731617647
Epoch: 14, plus 0 steps train_loss: 0.7256

#### test Acc: 0, NDCG: 0.12889466266031463 HIT: 0.2827435661764706

#### val Acc: 0, NDCG: 0.13267957167981062 HIT: 0.28875804227941176
Epoch: 16, plus 0 steps train_loss: 0.7222

#### test Acc: 0, NDCG: 0.12471335575737652 HIT: 0.27974494485294116

#### val Acc: 0, NDCG: 0.13119746258531412 HIT: 0.28624770220588236
Epoch: 18, plus 0 steps train_loss: 0.7194

#### test Acc: 0, NDCG: 0.1276931977929993 HIT: 0.27945197610294115

#### val Acc: 0, NDCG: 0.1269421366367142 HIT: 0.27975068933823527
Epoch: 20, plus 0 steps train_loss: 0.7163

#### test Acc: 0, NDCG: 0.1300983756762457 HIT: 0.28569623161764707

#### val Acc: 0, NDCG: 0.1341897091791257 HIT: 0.29689223345588234
Epoch: 22, plus 0 steps train_loss: 0.7165

#### test Acc: 0, NDCG: 0.13076716066981656 HIT: 0.28840188419117646

#### val Acc: 0, NDCG: 0.13049402366561696 HIT: 0.28657513786764705
Epoch: 24, plus 0 steps train_loss: 0.7138

#### test Acc: 0, NDCG: 0.13348793302011144 HIT: 0.29145220588235293

#### val Acc: 0, NDCG: 0.13270273254238976 HIT: 0.2919634650735294
Epoch: 26, plus 0 steps train_loss: 0.712

#### test Acc: 0, NDCG: 0.12699199253131968 HIT: 0.2813763786764706

#### val Acc: 0, NDCG: 0.12828031251119051 HIT: 0.2824333639705882
Epoch: 28, plus 0 steps train_loss: 0.7108

#### test Acc: 0, NDCG: 0.13191573900837392 HIT: 0.2921357996323529

#### val Acc: 0, NDCG: 0.13100574569123263 HIT: 0.2902688419117647
Epoch: 30, plus 0 steps train_loss: 0.7098

#### test Acc: 0, NDCG: 0.13273806902368904 HIT: 0.28873506433823526

#### val Acc: 0, NDCG: 0.12987952749082504 HIT: 0.28401309742647063
Epoch: 32, plus 0 steps train_loss: 0.7032

#### test Acc: 0, NDCG: 0.12974595390152827 HIT: 0.2877240349264706

#### val Acc: 0, NDCG: 0.12654972725149977 HIT: 0.2811178768382353
Epoch: 36, plus 0 steps train_loss: 0.7061

#### test Acc: 0, NDCG: 0.12789451748237554 HIT: 0.2821518841911764

#### val Acc: 0, NDCG: 0.12956403831328414 HIT: 0.28519646139705884
Epoch: 40, plus 0 steps train_loss: 0.7029

#### test Acc: 0, NDCG: 0.1355215586188128 HIT: 0.29851217830882354

#### val Acc: 0, NDCG: 0.12674439911073812 HIT: 0.2829733455882353
Epoch: 44, plus 0 steps train_loss: 0.7055

#### test Acc: 0, NDCG: 0.12651302481993804 HIT: 0.2765797334558823

#### val Acc: 0, NDCG: 0.13467338956047661 HIT: 0.2946461397058823
Epoch: 48, plus 0 steps train_loss: 0.7016

#### test Acc: 0, NDCG: 0.14384531323428618 HIT: 0.2988970588235294

#### val Acc: 0, NDCG: 0.15360212105470888 HIT: 0.31532628676470587
Epoch: 52, plus 0 steps train_loss: 0.7027

#### test Acc: 0, NDCG: 0.16706199932793506 HIT: 0.3196001838235294

#### val Acc: 0, NDCG: 0.17847382906915182 HIT: 0.33403607536764707
Epoch: 56, plus 0 steps train_loss: 0.7013

#### test Acc: 0, NDCG: 0.23707127570938083 HIT: 0.39889131433823527

#### val Acc: 0, NDCG: 0.23113085481321116 HIT: 0.3875631893382353
Epoch: 60, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.23208545847210543 HIT: 0.38997012867647063

#### val Acc: 0, NDCG: 0.24512107939041244 HIT: 0.4017176011029412
Epoch: 64, plus 0 steps train_loss: 0.7003

#### test Acc: 0, NDCG: 0.3127659722870194 HIT: 0.4729377297794118

#### val Acc: 0, NDCG: 0.3231435962551491 HIT: 0.4741325827205882
Epoch: 68, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.38297016050179233 HIT: 0.5335018382352941

#### val Acc: 0, NDCG: 0.3856534771120282 HIT: 0.5366613051470588
Epoch: 72, plus 0 steps train_loss: 0.6995

#### test Acc: 0, NDCG: 0.435502505567538 HIT: 0.5807157628676471

#### val Acc: 0, NDCG: 0.44431988423937946 HIT: 0.5871610753676471
Epoch: 80, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.5143930022077379 HIT: 0.63974609375

#### val Acc: 0, NDCG: 0.5228726895723435 HIT: 0.6467945772058823
Epoch: 88, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.45318733885904267 HIT: 0.5959386488970588

#### val Acc: 0, NDCG: 0.4629645858252907 HIT: 0.5970645680147059
Epoch: 96, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.5205578654539673 HIT: 0.642578125

#### val Acc: 0, NDCG: 0.533700998740823 HIT: 0.6580710018382353
Epoch: 104, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.462313883138331 HIT: 0.6038660386029412

#### val Acc: 0, NDCG: 0.47540020275444766 HIT: 0.6105870863970588
Epoch: 112, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.5202780232592453 HIT: 0.6426642922794118

#### val Acc: 0, NDCG: 0.5304066000820616 HIT: 0.6519071691176471
Epoch: 120, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.5231550033245737 HIT: 0.6482651654411764

#### val Acc: 0, NDCG: 0.5282106734782609 HIT: 0.6486615349264706
Epoch: 128, plus 0 steps train_loss: 0.6928

#### test Acc: 0, NDCG: 0.5321360088761985 HIT: 0.6479664522058823

#### val Acc: 0, NDCG: 0.5362311879268907 HIT: 0.6571001838235294
Epoch: 136, plus 0 steps train_loss: 0.6909

#### test Acc: 0, NDCG: 0.5326594262030805 HIT: 0.6602596507352941

#### val Acc: 0, NDCG: 0.5336324930290094 HIT: 0.6541302849264705
Epoch: 144, plus 0 steps train_loss: 0.6898

#### test Acc: 0, NDCG: 0.4645835051256936 HIT: 0.6063419117647059

#### val Acc: 0, NDCG: 0.47143607667864024 HIT: 0.6061868106617647
Epoch: 160, plus 0 steps train_loss: 0.6902

#### test Acc: 0, NDCG: 0.46370154778226186 HIT: 0.6066061580882354

#### val Acc: 0, NDCG: 0.4673286555534526 HIT: 0.6029296875
Epoch: 176, plus 0 steps train_loss: 0.6868

#### test Acc: 0, NDCG: 0.4700206614460562 HIT: 0.6107536764705882

#### val Acc: 0, NDCG: 0.4722595705761933 HIT: 0.6069450827205882
Epoch: 192, plus 0 steps train_loss: 0.69

#### test Acc: 0, NDCG: 0.4717293454815209 HIT: 0.6151769301470588

#### val Acc: 0, NDCG: 0.48533774873604774 HIT: 0.6225700827205882
Epoch: 208, plus 0 steps train_loss: 0.6874

#### test Acc: 0, NDCG: 0.4771314251250093 HIT: 0.6170151654411764

#### val Acc: 0, NDCG: 0.48489359471523646 HIT: 0.6229664522058823
Epoch: 224, plus 0 steps train_loss: 0.6827

#### test Acc: 0, NDCG: 0.4902393939161069 HIT: 0.62587890625

#### val Acc: 0, NDCG: 0.48691930122432636 HIT: 0.6187155330882353
Epoch: 240, plus 0 steps train_loss: 0.6803

#### test Acc: 0, NDCG: 0.4742536973948458 HIT: 0.6094152113970588

#### val Acc: 0, NDCG: 0.483262687308547 HIT: 0.6167451746323529
Epoch: 256, plus 0 steps train_loss: 0.6832

#### test Acc: 0, NDCG: 0.4754517158912737 HIT: 0.6159237132352942

#### val Acc: 0, NDCG: 0.48642463337736314 HIT: 0.6233513327205882
Epoch: 272, plus 0 steps train_loss: 0.6824

#### test Acc: 0, NDCG: 0.4742707446970206 HIT: 0.6126838235294118

#### val Acc: 0, NDCG: 0.4861604110833414 HIT: 0.6241383272058824
Epoch: 288, plus 0 steps train_loss: 0.6799

#### test Acc: 0, NDCG: 0.4700394194683377 HIT: 0.6032571231617647

#### val Acc: 0, NDCG: 0.5002973321017206 HIT: 0.6402918198529413
Epoch: 304, plus 0 steps train_loss: 0.6765

#### test Acc: 0, NDCG: 0.47906724954296004 HIT: 0.6158145680147059

#### val Acc: 0, NDCG: 0.4807880875712397 HIT: 0.6198988970588235
Epoch: 320, plus 0 steps train_loss: 0.6732

#### test Acc: 0, NDCG: 0.486213915275017 HIT: 0.6173023897058824

#### val Acc: 0, NDCG: 0.493866960343922 HIT: 0.6261833639705883
Epoch: 352, plus 0 steps train_loss: 0.6701

#### test Acc: 0, NDCG: 0.4794988608015481 HIT: 0.6178021599264706

#### val Acc: 0, NDCG: 0.49856976949456167 HIT: 0.6278664981617647
Epoch: 384, plus 0 steps train_loss: 0.6682

#### test Acc: 0, NDCG: 0.49031081467495785 HIT: 0.6221737132352941

#### val Acc: 0, NDCG: 0.5101379172800815 HIT: 0.6380572150735294
Epoch: 416, plus 0 steps train_loss: 0.6719

#### test Acc: 0, NDCG: 0.4969987531335961 HIT: 0.6305319393382354

#### val Acc: 0, NDCG: 0.4949825110098932 HIT: 0.6306755514705882
Epoch: 448, plus 0 steps train_loss: 0.6604

#### test Acc: 0, NDCG: 0.49406464767895064 HIT: 0.6316636029411764

#### val Acc: 0, NDCG: 0.5013769868934539 HIT: 0.6371438419117647
Epoch: 480, plus 0 steps train_loss: 0.6621

#### test Acc: 0, NDCG: 0.39788164723816727 HIT: 0.5581456801470588

#### val Acc: 0, NDCG: 0.41588499585683997 HIT: 0.5709386488970588
Epoch: 512, plus 0 steps train_loss: 0.656

#### test Acc: 0, NDCG: 0.3490917318880588 HIT: 0.5209731158088236

#### val Acc: 0, NDCG: 0.3636557014775204 HIT: 0.5310029871323529
Epoch: 544, plus 0 steps train_loss: 0.6643

#### test Acc: 0, NDCG: 0.4364940235276067 HIT: 0.5899586397058824

#### val Acc: 0, NDCG: 0.4501738824895476 HIT: 0.5997357536764706
Epoch: 576, plus 0 steps train_loss: 0.6518

#### test Acc: 0, NDCG: 0.48960003330809554 HIT: 0.6236557904411765

#### val Acc: 0, NDCG: 0.5001064469812687 HIT: 0.6303423713235294
Epoch: 608, plus 0 steps train_loss: 0.6675

#### test Acc: 0, NDCG: 0.476525467173221 HIT: 0.6155732996323529

#### val Acc: 0, NDCG: 0.48705341061222873 HIT: 0.62568359375
Epoch: 640, plus 0 steps train_loss: 0.6616

#### test Acc: 0, NDCG: 0.4025871725414495 HIT: 0.5604204963235294

#### val Acc: 0, NDCG: 0.41108603529366716 HIT: 0.5630974264705882
Epoch: 704, plus 0 steps train_loss: 0.6547

#### test Acc: 0, NDCG: 0.34854486367227533 HIT: 0.5073874080882353

#### val Acc: 0, NDCG: 0.38581453982563274 HIT: 0.5509708180147059
Epoch: 768, plus 0 steps train_loss: 0.6457

#### test Acc: 0, NDCG: 0.31536724878575273 HIT: 0.48431181066176465

#### val Acc: 0, NDCG: 0.33542327338343914 HIT: 0.5089671415441177
Epoch: 832, plus 0 steps train_loss: 0.6472

#### test Acc: 0, NDCG: 0.32812108571469023 HIT: 0.49997702205882355

#### val Acc: 0, NDCG: 0.3444052267674095 HIT: 0.5107421875
Epoch: 896, plus 0 steps train_loss: 0.6547

#### test Acc: 0, NDCG: 0.29783439601603456 HIT: 0.4704905790441177

#### val Acc: 0, NDCG: 0.31805407114128237 HIT: 0.4890912224264706
Epoch: 960, plus 0 steps train_loss: 0.6459

#### test Acc: 0, NDCG: 0.3031262129162815 HIT: 0.47487936580882356

#### val Acc: 0, NDCG: 0.32956806466036215 HIT: 0.49827090992647055
Epoch: 1013, plus 25 steps train_loss: 0.6535
Done: it took 298997.36674165726
max value of NDCG: 0.5326594262030805
max value of HIT: 0.6602596507352941

After 20 validations
max value of NDCG: 0.5326594262030805
max value of HIT: 0.6602596507352941
