 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.01
max_norm:             	0.5
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
RMHA_decoder:         	False
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_encoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.1293005804510338 HIT: 0.28193359375

#### val Acc: 0, NDCG: 0.13205783943501112 HIT: 0.2911592371323529
Epoch: 1, plus 0 steps train_loss: 0.7611

#### test Acc: 0, NDCG: 0.12416814893144243 HIT: 0.2824276194852941

#### val Acc: 0, NDCG: 0.13005521702418024 HIT: 0.2869198069852941
Epoch: 2, plus 0 steps train_loss: 0.7637

#### test Acc: 0, NDCG: 0.12986533464665034 HIT: 0.28316865808823527

#### val Acc: 0, NDCG: 0.12572429391665813 HIT: 0.28091681985294115
Epoch: 3, plus 0 steps train_loss: 0.7593

#### test Acc: 0, NDCG: 0.13085722064249733 HIT: 0.2864947150735294

#### val Acc: 0, NDCG: 0.1318101935356229 HIT: 0.29172219669117644
Epoch: 4, plus 0 steps train_loss: 0.7504

#### test Acc: 0, NDCG: 0.13060675327220161 HIT: 0.2874655330882353

#### val Acc: 0, NDCG: 0.13282917985048176 HIT: 0.28841911764705885
Epoch: 5, plus 0 steps train_loss: 0.7447

#### test Acc: 0, NDCG: 0.12959097459967786 HIT: 0.28582835477941176

#### val Acc: 0, NDCG: 0.1311596656275184 HIT: 0.29264705882352937
Epoch: 6, plus 0 steps train_loss: 0.7358

#### test Acc: 0, NDCG: 0.1283927875015582 HIT: 0.27960133272058824

#### val Acc: 0, NDCG: 0.13405055656049913 HIT: 0.29482421875
Epoch: 7, plus 0 steps train_loss: 0.7293

#### test Acc: 0, NDCG: 0.12753080755392338 HIT: 0.27953814338235294

#### val Acc: 0, NDCG: 0.13342531272930688 HIT: 0.29126838235294117
Epoch: 8, plus 0 steps train_loss: 0.7283

#### test Acc: 0, NDCG: 0.12869790571962086 HIT: 0.2857421875

#### val Acc: 0, NDCG: 0.13062521918162218 HIT: 0.2868221507352941
Epoch: 9, plus 0 steps train_loss: 0.7249

#### test Acc: 0, NDCG: 0.1288001243483828 HIT: 0.28658088235294116

#### val Acc: 0, NDCG: 0.1319475026534627 HIT: 0.28693704044117646
Epoch: 10, plus 0 steps train_loss: 0.7264

#### test Acc: 0, NDCG: 0.12771211370177754 HIT: 0.2796587775735294

#### val Acc: 0, NDCG: 0.13094114051523376 HIT: 0.29019990808823526
Epoch: 12, plus 0 steps train_loss: 0.7216

#### test Acc: 0, NDCG: 0.13128305149664093 HIT: 0.2883444393382353

#### val Acc: 0, NDCG: 0.13001235629556548 HIT: 0.2875
Epoch: 14, plus 0 steps train_loss: 0.7196

#### test Acc: 0, NDCG: 0.12880889302963164 HIT: 0.28435776654411765

#### val Acc: 0, NDCG: 0.12898958164588142 HIT: 0.28435202205882354
Epoch: 16, plus 0 steps train_loss: 0.7157

#### test Acc: 0, NDCG: 0.13192065478555767 HIT: 0.29013671875

#### val Acc: 0, NDCG: 0.13154369015008918 HIT: 0.28956801470588234
Epoch: 18, plus 0 steps train_loss: 0.7177

#### test Acc: 0, NDCG: 0.1292069526359154 HIT: 0.2864315257352941

#### val Acc: 0, NDCG: 0.1288784575982273 HIT: 0.28157743566176474
Epoch: 20, plus 0 steps train_loss: 0.7077

#### test Acc: 0, NDCG: 0.13274270798971882 HIT: 0.2903952205882353

#### val Acc: 0, NDCG: 0.12474386697556494 HIT: 0.2735294117647059
Epoch: 22, plus 0 steps train_loss: 0.71

#### test Acc: 0, NDCG: 0.13042052914107885 HIT: 0.28797104779411764

#### val Acc: 0, NDCG: 0.12985573699097888 HIT: 0.2873908547794118
Epoch: 24, plus 0 steps train_loss: 0.7116

#### test Acc: 0, NDCG: 0.13216920692941356 HIT: 0.2916417738970588

#### val Acc: 0, NDCG: 0.1319712472487822 HIT: 0.29233111213235297
Epoch: 26, plus 0 steps train_loss: 0.7108

#### test Acc: 0, NDCG: 0.13002961369653668 HIT: 0.2831341911764706

#### val Acc: 0, NDCG: 0.1328335496626199 HIT: 0.28716107536764707
Epoch: 28, plus 0 steps train_loss: 0.7099

#### test Acc: 0, NDCG: 0.12773483876935915 HIT: 0.2791590073529412

#### val Acc: 0, NDCG: 0.13030576390978005 HIT: 0.2882755055147059
Epoch: 30, plus 0 steps train_loss: 0.7073

#### test Acc: 0, NDCG: 0.13125971384312218 HIT: 0.29069967830882354

#### val Acc: 0, NDCG: 0.12950142755196825 HIT: 0.28218060661764705
Epoch: 32, plus 0 steps train_loss: 0.7071

#### test Acc: 0, NDCG: 0.1337824567143195 HIT: 0.29154986213235295

#### val Acc: 0, NDCG: 0.13580761638814673 HIT: 0.2917911305147059
Epoch: 36, plus 0 steps train_loss: 0.7059

#### test Acc: 0, NDCG: 0.13166435850108246 HIT: 0.2901252297794118

#### val Acc: 0, NDCG: 0.12967591929643432 HIT: 0.28205997242647063
Epoch: 40, plus 0 steps train_loss: 0.7036

#### test Acc: 0, NDCG: 0.12897878310832517 HIT: 0.28728745404411765

#### val Acc: 0, NDCG: 0.1311482172187034 HIT: 0.2894071691176471
Epoch: 44, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.1292398101397809 HIT: 0.2856560202205882

#### val Acc: 0, NDCG: 0.1301706011726403 HIT: 0.28011259191176474
Epoch: 48, plus 0 steps train_loss: 0.7035

#### test Acc: 0, NDCG: 0.13195680611412605 HIT: 0.2917624080882353

#### val Acc: 0, NDCG: 0.12813253864894214 HIT: 0.28510454963235293
Epoch: 52, plus 0 steps train_loss: 0.7045

#### test Acc: 0, NDCG: 0.13211765583447183 HIT: 0.2875402113970588

#### val Acc: 0, NDCG: 0.1289026286740454 HIT: 0.28490923713235294
Epoch: 56, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.12874140085055485 HIT: 0.2857881433823529

#### val Acc: 0, NDCG: 0.12974762484348085 HIT: 0.28412798713235293
Epoch: 60, plus 0 steps train_loss: 0.7026

#### test Acc: 0, NDCG: 0.13086570481226872 HIT: 0.2839499080882353

#### val Acc: 0, NDCG: 0.12640119610245748 HIT: 0.27716567095588235
Epoch: 64, plus 0 steps train_loss: 0.7026

#### test Acc: 0, NDCG: 0.1299154398022862 HIT: 0.28882697610294117

#### val Acc: 0, NDCG: 0.1343024056110842 HIT: 0.29236557904411764
Epoch: 68, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.1310560180144575 HIT: 0.29294577205882355

#### val Acc: 0, NDCG: 0.12967673918198644 HIT: 0.2873678768382353
Epoch: 72, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.1350440941933735 HIT: 0.29427274816176474

#### val Acc: 0, NDCG: 0.1344802436414671 HIT: 0.2961799172794118
Epoch: 80, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.1328670935536159 HIT: 0.2889705882352941

#### val Acc: 0, NDCG: 0.1344810451876812 HIT: 0.2911477481617647
Epoch: 88, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.13091265521002832 HIT: 0.2869083180147059

#### val Acc: 0, NDCG: 0.13054930413542482 HIT: 0.2875057444852941
Epoch: 96, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.12950300143903354 HIT: 0.28839039522058824

#### val Acc: 0, NDCG: 0.1309362640558555 HIT: 0.28955078125
Epoch: 104, plus 0 steps train_loss: 0.6989

#### test Acc: 0, NDCG: 0.1303155543397177 HIT: 0.2855009191176471

#### val Acc: 0, NDCG: 0.1359406799424888 HIT: 0.2932444852941177
Epoch: 112, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.13716923195994893 HIT: 0.2979951746323529

#### val Acc: 0, NDCG: 0.14049598990430395 HIT: 0.30953584558823527
Epoch: 120, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.13697384041766703 HIT: 0.29985064338235295

#### val Acc: 0, NDCG: 0.1404110287998825 HIT: 0.3060719209558823
Epoch: 128, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.1334814995446097 HIT: 0.2931583180147059

#### val Acc: 0, NDCG: 0.13606569489848572 HIT: 0.29658203125
Epoch: 136, plus 0 steps train_loss: 0.6982

#### test Acc: 0, NDCG: 0.1340450395758725 HIT: 0.29347426470588234

#### val Acc: 0, NDCG: 0.13882174566279132 HIT: 0.2998851102941177
Epoch: 144, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.2509533134898381 HIT: 0.40964499080882355

#### val Acc: 0, NDCG: 0.27663244057027836 HIT: 0.43278952205882354
Epoch: 160, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.45886029145481855 HIT: 0.5958754595588236

#### val Acc: 0, NDCG: 0.46906951747516146 HIT: 0.6018439797794117
Epoch: 176, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.5244011306345182 HIT: 0.6475183823529412

#### val Acc: 0, NDCG: 0.5434947503116418 HIT: 0.6686293658088236
Epoch: 192, plus 0 steps train_loss: 0.6933

#### test Acc: 0, NDCG: 0.6336411945890705 HIT: 0.7333065257352941

#### val Acc: 0, NDCG: 0.6504542727079143 HIT: 0.7503733915441176
Epoch: 208, plus 0 steps train_loss: 0.6901

#### test Acc: 0, NDCG: 0.6380676897660454 HIT: 0.7387867647058823

#### val Acc: 0, NDCG: 0.6508413827801941 HIT: 0.7534811580882353
Epoch: 224, plus 0 steps train_loss: 0.6879

#### test Acc: 0, NDCG: 0.6516911866443371 HIT: 0.7512867647058823

#### val Acc: 0, NDCG: 0.6493111114984421 HIT: 0.7531479779411765
Epoch: 240, plus 0 steps train_loss: 0.6856

#### test Acc: 0, NDCG: 0.5156321033302017 HIT: 0.6423138786764706

#### val Acc: 0, NDCG: 0.5357880332562073 HIT: 0.66240234375
Epoch: 256, plus 0 steps train_loss: 0.6858

#### test Acc: 0, NDCG: 0.23727619266149472 HIT: 0.4243623621323529

#### val Acc: 0, NDCG: 0.24857881076463362 HIT: 0.4335420496323529
Epoch: 272, plus 0 steps train_loss: 0.6812

#### test Acc: 0, NDCG: 0.3341409723501244 HIT: 0.4921932444852941

#### val Acc: 0, NDCG: 0.36989893128005213 HIT: 0.5240693933823529
Epoch: 288, plus 0 steps train_loss: 0.6849

#### test Acc: 0, NDCG: 0.24243986867688258 HIT: 0.4382755055147059

#### val Acc: 0, NDCG: 0.25088988917363425 HIT: 0.43889590992647054
Epoch: 304, plus 0 steps train_loss: 0.6743

#### test Acc: 0, NDCG: 0.24873428910528766 HIT: 0.4452665441176471

#### val Acc: 0, NDCG: 0.26418383556267616 HIT: 0.45607766544117645
Epoch: 320, plus 0 steps train_loss: 0.6772

#### test Acc: 0, NDCG: 0.2916179486864374 HIT: 0.4868910845588236

#### val Acc: 0, NDCG: 0.30984479869101567 HIT: 0.5026079963235295
Epoch: 352, plus 0 steps train_loss: 0.6666

#### test Acc: 0, NDCG: 0.2988435873839899 HIT: 0.5026137408088236

#### val Acc: 0, NDCG: 0.3155667597332291 HIT: 0.5067670036764705
Epoch: 384, plus 0 steps train_loss: 0.6497

#### test Acc: 0, NDCG: 0.28342947743059294 HIT: 0.48342141544117645

#### val Acc: 0, NDCG: 0.3001258402994669 HIT: 0.49661075367647056
Epoch: 416, plus 0 steps train_loss: 0.6553

#### test Acc: 0, NDCG: 0.27357464659986375 HIT: 0.4840418198529412

#### val Acc: 0, NDCG: 0.28867708029015093 HIT: 0.49725413602941176
Epoch: 448, plus 0 steps train_loss: 0.6429

#### test Acc: 0, NDCG: 0.2811993805182999 HIT: 0.5030158547794118

#### val Acc: 0, NDCG: 0.2850022565422795 HIT: 0.4986270680147059
Epoch: 480, plus 0 steps train_loss: 0.6429

#### test Acc: 0, NDCG: 0.28816079854192533 HIT: 0.5037568933823529

#### val Acc: 0, NDCG: 0.2943392888341432 HIT: 0.5072782628676471
Epoch: 512, plus 0 steps train_loss: 0.6393

#### test Acc: 0, NDCG: 0.28651884731884353 HIT: 0.5066119025735294

#### val Acc: 0, NDCG: 0.29570766696282325 HIT: 0.5096852022058823
Epoch: 544, plus 0 steps train_loss: 0.6292

#### test Acc: 0, NDCG: 0.3136439380128467 HIT: 0.5320886948529412

#### val Acc: 0, NDCG: 0.3315226563127607 HIT: 0.5385512408088236
Epoch: 576, plus 0 steps train_loss: 0.6233

#### test Acc: 0, NDCG: 0.3034096371831166 HIT: 0.5171530330882353

#### val Acc: 0, NDCG: 0.3182784496076082 HIT: 0.5239659926470588
Epoch: 608, plus 0 steps train_loss: 0.6158

#### test Acc: 0, NDCG: 0.30242981982083494 HIT: 0.5202320772058824

#### val Acc: 0, NDCG: 0.31761764468618003 HIT: 0.5298770680147059
Epoch: 640, plus 0 steps train_loss: 0.6216

#### test Acc: 0, NDCG: 0.3024611821683405 HIT: 0.5230009191176471

#### val Acc: 0, NDCG: 0.3199126436416906 HIT: 0.5360409007352941
Epoch: 704, plus 0 steps train_loss: 0.6173

#### test Acc: 0, NDCG: 0.30301738053334715 HIT: 0.53076171875

#### val Acc: 0, NDCG: 0.3119110180450717 HIT: 0.5351045496323529
Epoch: 768, plus 0 steps train_loss: 0.6101

#### test Acc: 0, NDCG: 0.30118740378689934 HIT: 0.5201573988970588

#### val Acc: 0, NDCG: 0.3124669349687283 HIT: 0.5311810661764705
Epoch: 832, plus 0 steps train_loss: 0.6186

#### test Acc: 0, NDCG: 0.29566534328639105 HIT: 0.5188591452205882

#### val Acc: 0, NDCG: 0.31287538603820425 HIT: 0.5385340073529412
Epoch: 896, plus 0 steps train_loss: 0.6225

#### test Acc: 0, NDCG: 0.29887399571803475 HIT: 0.5216739430147059

#### val Acc: 0, NDCG: 0.3141032325213259 HIT: 0.5398839613970587
Epoch: 960, plus 0 steps train_loss: 0.6169

#### test Acc: 0, NDCG: 0.29657100015345217 HIT: 0.5208812040441176

#### val Acc: 0, NDCG: 0.30530097692490404 HIT: 0.5281709558823529
Epoch: 1013, plus 25 steps train_loss: 0.6164
Done: it took 299016.0564944744
max value of NDCG: 0.6516911866443371
max value of HIT: 0.7512867647058823

After 20 validations
max value of NDCG: 0.6516911866443371
max value of HIT: 0.7512867647058823
