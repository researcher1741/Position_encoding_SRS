 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	0.5
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13715074985540548 HIT: 0.2954216452205882

#### val Acc: 0, NDCG: 0.1415077144747325 HIT: 0.3045438878676471
Epoch: 1, plus 0 steps train_loss: 0.7181

#### test Acc: 0, NDCG: 0.15264089318267127 HIT: 0.31245978860294116

#### val Acc: 0, NDCG: 0.17298990704920514 HIT: 0.32726332720588236
Epoch: 2, plus 0 steps train_loss: 0.71

#### test Acc: 0, NDCG: 0.15780144097416596 HIT: 0.3340705422794118

#### val Acc: 0, NDCG: 0.16819819370636918 HIT: 0.3483513327205882
Epoch: 3, plus 0 steps train_loss: 0.7061

#### test Acc: 0, NDCG: 0.14755252779788944 HIT: 0.31092601102941175

#### val Acc: 0, NDCG: 0.15706428301235187 HIT: 0.3267520680147059
Epoch: 4, plus 0 steps train_loss: 0.7054

#### test Acc: 0, NDCG: 0.20894301830837342 HIT: 0.39370978860294115

#### val Acc: 0, NDCG: 0.234134016104209 HIT: 0.4182674632352941
Epoch: 5, plus 0 steps train_loss: 0.7032

#### test Acc: 0, NDCG: 0.18952402538083038 HIT: 0.3940142463235294

#### val Acc: 0, NDCG: 0.1994903255930735 HIT: 0.40565831801470587
Epoch: 6, plus 0 steps train_loss: 0.6906

#### test Acc: 0, NDCG: 0.19764205217149983 HIT: 0.4134248621323529

#### val Acc: 0, NDCG: 0.19992631629236404 HIT: 0.41784811580882353
Epoch: 7, plus 0 steps train_loss: 0.6808

#### test Acc: 0, NDCG: 0.2227204735773717 HIT: 0.45221162683823535

#### val Acc: 0, NDCG: 0.2190554496044664 HIT: 0.4513614430147059
Epoch: 8, plus 0 steps train_loss: 0.6615

#### test Acc: 0, NDCG: 0.23760752741590502 HIT: 0.47954963235294124

#### val Acc: 0, NDCG: 0.2288711630613148 HIT: 0.46784237132352946
Epoch: 9, plus 0 steps train_loss: 0.6554

#### test Acc: 0, NDCG: 0.24928730212689665 HIT: 0.4994715073529412

#### val Acc: 0, NDCG: 0.24331512679127587 HIT: 0.49102711397058824
Epoch: 10, plus 0 steps train_loss: 0.654

#### test Acc: 0, NDCG: 0.24761585470180142 HIT: 0.4929630055147059

#### val Acc: 0, NDCG: 0.25036238094044466 HIT: 0.49945427389705876
Epoch: 12, plus 0 steps train_loss: 0.642

#### test Acc: 0, NDCG: 0.25350425610478666 HIT: 0.5072035845588235

#### val Acc: 0, NDCG: 0.24875924914436628 HIT: 0.4986155790441177
Epoch: 14, plus 0 steps train_loss: 0.641

#### test Acc: 0, NDCG: 0.2655667003543012 HIT: 0.5245806525735295

#### val Acc: 0, NDCG: 0.2675942450875095 HIT: 0.5243393841911764
Epoch: 16, plus 0 steps train_loss: 0.6218

#### test Acc: 0, NDCG: 0.26424951154968335 HIT: 0.5226332720588236

#### val Acc: 0, NDCG: 0.272291029976219 HIT: 0.5370749080882353
Epoch: 18, plus 0 steps train_loss: 0.6232

#### test Acc: 0, NDCG: 0.2737144562531283 HIT: 0.5357077205882353

#### val Acc: 0, NDCG: 0.2811116735522795 HIT: 0.5464384191176471
Epoch: 20, plus 0 steps train_loss: 0.6131

#### test Acc: 0, NDCG: 0.28016415874136064 HIT: 0.5437385110294117

#### val Acc: 0, NDCG: 0.2851230516132797 HIT: 0.551171875
Epoch: 22, plus 0 steps train_loss: 0.6174

#### test Acc: 0, NDCG: 0.2818348340803636 HIT: 0.5430089613970588

#### val Acc: 0, NDCG: 0.2882394945930718 HIT: 0.5543543198529413
Epoch: 24, plus 0 steps train_loss: 0.6099

#### test Acc: 0, NDCG: 0.28975269902064527 HIT: 0.5520335477941176

#### val Acc: 0, NDCG: 0.2954366342248599 HIT: 0.5630457261029412
Epoch: 26, plus 0 steps train_loss: 0.6038

#### test Acc: 0, NDCG: 0.2993908352567789 HIT: 0.5634823069852941

#### val Acc: 0, NDCG: 0.30038592505765155 HIT: 0.5668255974264705
Epoch: 28, plus 0 steps train_loss: 0.6004

#### test Acc: 0, NDCG: 0.3096462013413127 HIT: 0.5724437040441177

#### val Acc: 0, NDCG: 0.3177959601701818 HIT: 0.5738338694852941
Epoch: 30, plus 0 steps train_loss: 0.5929

#### test Acc: 0, NDCG: 0.3131587840764994 HIT: 0.5733168658088236

#### val Acc: 0, NDCG: 0.32797831506335645 HIT: 0.5911879595588235
Epoch: 32, plus 0 steps train_loss: 0.5766

#### test Acc: 0, NDCG: 0.35137128421863784 HIT: 0.5825482536764706

#### val Acc: 0, NDCG: 0.3653612185360402 HIT: 0.6039636948529412
Epoch: 36, plus 0 steps train_loss: 0.5529

#### test Acc: 0, NDCG: 0.36203056851582455 HIT: 0.5731330422794118

#### val Acc: 0, NDCG: 0.370144224717192 HIT: 0.5883386948529412
Epoch: 40, plus 0 steps train_loss: 0.5052

#### test Acc: 0, NDCG: 0.35406144845234727 HIT: 0.5645565257352941

#### val Acc: 0, NDCG: 0.37143522021480024 HIT: 0.5947840073529412
Epoch: 44, plus 0 steps train_loss: 0.4667

#### test Acc: 0, NDCG: 0.3489028748261773 HIT: 0.5578412224264706

#### val Acc: 0, NDCG: 0.36287518380444267 HIT: 0.5853056066176471
Epoch: 48, plus 0 steps train_loss: 0.4916

#### test Acc: 0, NDCG: 0.3521476772131096 HIT: 0.5620232077205882

#### val Acc: 0, NDCG: 0.36513635591723215 HIT: 0.5804974724264705
Epoch: 52, plus 0 steps train_loss: 0.4971

#### test Acc: 0, NDCG: 0.34404346329729807 HIT: 0.5529813878676471

#### val Acc: 0, NDCG: 0.3633931723872351 HIT: 0.5763959099264706
Epoch: 56, plus 0 steps train_loss: 0.4837

#### test Acc: 0, NDCG: 0.34519584777247253 HIT: 0.5582605698529413

#### val Acc: 0, NDCG: 0.3635143536525732 HIT: 0.5832778033088235
Epoch: 60, plus 0 steps train_loss: 0.4559

#### test Acc: 0, NDCG: 0.34861571534047797 HIT: 0.5571806066176471

#### val Acc: 0, NDCG: 0.36552151475642275 HIT: 0.5810891544117647
Epoch: 64, plus 0 steps train_loss: 0.449

#### test Acc: 0, NDCG: 0.34988328309797195 HIT: 0.5586741727941177

#### val Acc: 0, NDCG: 0.3721098707722209 HIT: 0.5859489889705882
Epoch: 68, plus 0 steps train_loss: 0.4528

#### test Acc: 0, NDCG: 0.36140485526567445 HIT: 0.5703699448529412

#### val Acc: 0, NDCG: 0.3633856997156785 HIT: 0.5759018841911765
Epoch: 72, plus 0 steps train_loss: 0.4281

#### test Acc: 0, NDCG: 0.35942626783389053 HIT: 0.5623161764705882

#### val Acc: 0, NDCG: 0.36432946789042986 HIT: 0.5731675091911764
Epoch: 80, plus 0 steps train_loss: 0.4473

#### test Acc: 0, NDCG: 0.3467070588467807 HIT: 0.5453584558823529

#### val Acc: 0, NDCG: 0.36280475294117626 HIT: 0.57138671875
Epoch: 88, plus 0 steps train_loss: 0.4602

#### test Acc: 0, NDCG: 0.34565449400611736 HIT: 0.5439223345588236

#### val Acc: 0, NDCG: 0.3589970991850821 HIT: 0.5600643382352941
Epoch: 96, plus 0 steps train_loss: 0.4521

#### test Acc: 0, NDCG: 0.35153592252436894 HIT: 0.5446346507352942

#### val Acc: 0, NDCG: 0.3639082771370466 HIT: 0.5607364430147059
Epoch: 104, plus 0 steps train_loss: 0.4628

#### test Acc: 0, NDCG: 0.34350249105096076 HIT: 0.5357881433823529

#### val Acc: 0, NDCG: 0.3594671717171297 HIT: 0.5596507352941177
Epoch: 112, plus 0 steps train_loss: 0.4167

#### test Acc: 0, NDCG: 0.34448882467580705 HIT: 0.5336454503676471

#### val Acc: 0, NDCG: 0.3582629361636987 HIT: 0.5466394761029412
Epoch: 120, plus 0 steps train_loss: 0.4103

#### test Acc: 0, NDCG: 0.3464105852153684 HIT: 0.5324505974264706

#### val Acc: 0, NDCG: 0.3637528972783275 HIT: 0.5571116727941177
Epoch: 128, plus 0 steps train_loss: 0.4449

#### test Acc: 0, NDCG: 0.33991485740227656 HIT: 0.5241555606617647

#### val Acc: 0, NDCG: 0.3665601999009558 HIT: 0.5560087316176471
Epoch: 136, plus 0 steps train_loss: 0.407

#### test Acc: 0, NDCG: 0.3473266907713458 HIT: 0.5399643841911764

#### val Acc: 0, NDCG: 0.3560329159777572 HIT: 0.5482709099264705
Epoch: 144, plus 0 steps train_loss: 0.4187

#### test Acc: 0, NDCG: 0.3443778905880376 HIT: 0.5328239889705882

#### val Acc: 0, NDCG: 0.3660329480913742 HIT: 0.5548598345588236
Epoch: 160, plus 0 steps train_loss: 0.3847

#### test Acc: 0, NDCG: 0.3486810957605563 HIT: 0.53232421875

#### val Acc: 0, NDCG: 0.365713233656744 HIT: 0.5563648897058824
Epoch: 176, plus 0 steps train_loss: 0.3971

#### test Acc: 0, NDCG: 0.3437344251227199 HIT: 0.5256089154411765

#### val Acc: 0, NDCG: 0.36344132754583514 HIT: 0.5511776194852941
Epoch: 192, plus 0 steps train_loss: 0.3848

#### test Acc: 0, NDCG: 0.35600179332332926 HIT: 0.5337488511029412

#### val Acc: 0, NDCG: 0.36583678590248675 HIT: 0.5518899356617647
Epoch: 208, plus 0 steps train_loss: 0.3786

#### test Acc: 0, NDCG: 0.35332377069597065 HIT: 0.5330422794117646

#### val Acc: 0, NDCG: 0.3741961504871834 HIT: 0.5570255055147059
Epoch: 224, plus 0 steps train_loss: 0.3786

#### test Acc: 0, NDCG: 0.35763878746825395 HIT: 0.5382352941176471

#### val Acc: 0, NDCG: 0.37226824624286164 HIT: 0.5565027573529412
Epoch: 240, plus 0 steps train_loss: 0.3766

#### test Acc: 0, NDCG: 0.34884154315355254 HIT: 0.5260914522058824

#### val Acc: 0, NDCG: 0.3660777886091159 HIT: 0.5535041360294117
Epoch: 256, plus 0 steps train_loss: 0.3408

#### test Acc: 0, NDCG: 0.34889105560897804 HIT: 0.5266371783088235

#### val Acc: 0, NDCG: 0.37325119785525496 HIT: 0.5564797794117646
Epoch: 272, plus 0 steps train_loss: 0.3631

#### test Acc: 0, NDCG: 0.35218297534141585 HIT: 0.5288545496323529

#### val Acc: 0, NDCG: 0.3715957577701846 HIT: 0.5538947610294118
Epoch: 288, plus 0 steps train_loss: 0.3411

#### test Acc: 0, NDCG: 0.352506043147365 HIT: 0.5345530790441176

#### val Acc: 0, NDCG: 0.36025878714196946 HIT: 0.5420266544117647
Epoch: 304, plus 0 steps train_loss: 0.3346

#### test Acc: 0, NDCG: 0.34908909620836137 HIT: 0.5208812040441176

#### val Acc: 0, NDCG: 0.3655842094453962 HIT: 0.5442095588235294
Epoch: 320, plus 0 steps train_loss: 0.3101

#### test Acc: 0, NDCG: 0.34501975004892105 HIT: 0.51787109375

#### val Acc: 0, NDCG: 0.3593255298239114 HIT: 0.5375114889705882
Epoch: 352, plus 0 steps train_loss: 0.2894

#### test Acc: 0, NDCG: 0.35125101874632414 HIT: 0.5251436121323529

#### val Acc: 0, NDCG: 0.3618405662774852 HIT: 0.5364430147058823
Epoch: 384, plus 0 steps train_loss: 0.2895

#### test Acc: 0, NDCG: 0.3452302288968281 HIT: 0.5167853860294118

#### val Acc: 0, NDCG: 0.36123318340096217 HIT: 0.5368566176470588
Epoch: 416, plus 0 steps train_loss: 0.2931

#### test Acc: 0, NDCG: 0.3385918738714412 HIT: 0.5089901194852942

#### val Acc: 0, NDCG: 0.3601855716917051 HIT: 0.5354721966911764
Epoch: 448, plus 0 steps train_loss: 0.2825

#### test Acc: 0, NDCG: 0.3420120040892385 HIT: 0.5136086856617647

#### val Acc: 0, NDCG: 0.3638471520241875 HIT: 0.5373161764705883
Epoch: 480, plus 0 steps train_loss: 0.2549

#### test Acc: 0, NDCG: 0.34902757777879 HIT: 0.5189682904411764

#### val Acc: 0, NDCG: 0.36423246106376866 HIT: 0.5458237591911764
Epoch: 512, plus 0 steps train_loss: 0.2593

#### test Acc: 0, NDCG: 0.3398849136326892 HIT: 0.5073988970588236

#### val Acc: 0, NDCG: 0.36398866191784635 HIT: 0.5391371783088236
Epoch: 544, plus 0 steps train_loss: 0.2579

#### test Acc: 0, NDCG: 0.3441204337488271 HIT: 0.5140797334558823

#### val Acc: 0, NDCG: 0.36157043212113926 HIT: 0.5352251838235295
Epoch: 576, plus 0 steps train_loss: 0.2483

#### test Acc: 0, NDCG: 0.33329244114630086 HIT: 0.5075942095588235

#### val Acc: 0, NDCG: 0.3576405455359436 HIT: 0.5350356158088235
Epoch: 608, plus 0 steps train_loss: 0.2552

#### test Acc: 0, NDCG: 0.34934220056224724 HIT: 0.5191521139705882

#### val Acc: 0, NDCG: 0.35772865110434166 HIT: 0.5324793198529412
Epoch: 640, plus 0 steps train_loss: 0.253

#### test Acc: 0, NDCG: 0.34307591348413957 HIT: 0.5149816176470587

#### val Acc: 0, NDCG: 0.35584187673384815 HIT: 0.5313763786764706
Epoch: 704, plus 0 steps train_loss: 0.2545

#### test Acc: 0, NDCG: 0.3384707935360443 HIT: 0.5077090992647059

#### val Acc: 0, NDCG: 0.363373879938302 HIT: 0.5393152573529412
Epoch: 768, plus 0 steps train_loss: 0.2454

#### test Acc: 0, NDCG: 0.3327567961002291 HIT: 0.5018210018382353

#### val Acc: 0, NDCG: 0.3589695352051495 HIT: 0.5294577205882354
Epoch: 832, plus 0 steps train_loss: 0.2301

#### test Acc: 0, NDCG: 0.33589638874650996 HIT: 0.5091796875

#### val Acc: 0, NDCG: 0.3584675051775257 HIT: 0.5345990349264705
Epoch: 896, plus 0 steps train_loss: 0.225

#### test Acc: 0, NDCG: 0.34186411231840175 HIT: 0.5131031709558823

#### val Acc: 0, NDCG: 0.35536043361781533 HIT: 0.5335477941176471
Epoch: 960, plus 0 steps train_loss: 0.2286

#### test Acc: 0, NDCG: 0.3351805717361092 HIT: 0.5031364889705883

#### val Acc: 0, NDCG: 0.3493765019941611 HIT: 0.5282111672794118
Epoch: 1013, plus 25 steps train_loss: 0.2553
Done: it took 292279.61937880516
max value of NDCG: 0.36203056851582455
max value of HIT: 0.5825482536764706

After 20 validations
max value of NDCG: 0.36203056851582455
max value of HIT: 0.5825482536764706
