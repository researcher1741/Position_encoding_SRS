 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	None
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
RMHA_decoder:         	False
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_encoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12760972090839012 HIT: 0.2815142463235294

#### val Acc: 0, NDCG: 0.12991747880128307 HIT: 0.2875689338235294
Epoch: 1, plus 0 steps train_loss: 0.7774

#### test Acc: 0, NDCG: 0.128563376490277 HIT: 0.2816636029411764

#### val Acc: 0, NDCG: 0.12777935283745118 HIT: 0.28427734375
Epoch: 2, plus 0 steps train_loss: 0.7718

#### test Acc: 0, NDCG: 0.13295747118652051 HIT: 0.29357766544117647

#### val Acc: 0, NDCG: 0.12803950978194314 HIT: 0.2851447610294118
Epoch: 3, plus 0 steps train_loss: 0.7739

#### test Acc: 0, NDCG: 0.12928706249784871 HIT: 0.2872472426470588

#### val Acc: 0, NDCG: 0.12701886158674186 HIT: 0.28414522058823527
Epoch: 4, plus 0 steps train_loss: 0.7495

#### test Acc: 0, NDCG: 0.1284899838630998 HIT: 0.2844381893382353

#### val Acc: 0, NDCG: 0.12502583143066373 HIT: 0.278125
Epoch: 5, plus 0 steps train_loss: 0.7483

#### test Acc: 0, NDCG: 0.12866027148230885 HIT: 0.2855583639705882

#### val Acc: 0, NDCG: 0.13262739921270042 HIT: 0.29259535845588236
Epoch: 6, plus 0 steps train_loss: 0.7418

#### test Acc: 0, NDCG: 0.12778853007001156 HIT: 0.28072725183823527

#### val Acc: 0, NDCG: 0.13413218084210304 HIT: 0.2922679227941177
Epoch: 7, plus 0 steps train_loss: 0.7391

#### test Acc: 0, NDCG: 0.13335243244842396 HIT: 0.2900390625

#### val Acc: 0, NDCG: 0.12495090541506079 HIT: 0.27543658088235295
Epoch: 8, plus 0 steps train_loss: 0.7402

#### test Acc: 0, NDCG: 0.13001297231239076 HIT: 0.2829388786764706

#### val Acc: 0, NDCG: 0.12826198679728476 HIT: 0.2863625919117647
Epoch: 9, plus 0 steps train_loss: 0.7378

#### test Acc: 0, NDCG: 0.1331200572136491 HIT: 0.29019416360294115

#### val Acc: 0, NDCG: 0.13218837811967948 HIT: 0.2877872242647059
Epoch: 10, plus 0 steps train_loss: 0.7319

#### test Acc: 0, NDCG: 0.12980947362097067 HIT: 0.28517348345588234

#### val Acc: 0, NDCG: 0.12509712153633798 HIT: 0.27443704044117645
Epoch: 12, plus 0 steps train_loss: 0.7286

#### test Acc: 0, NDCG: 0.1317422059459734 HIT: 0.2899528952205882

#### val Acc: 0, NDCG: 0.13136293350898567 HIT: 0.2905158547794118
Epoch: 14, plus 0 steps train_loss: 0.722

#### test Acc: 0, NDCG: 0.12653321338182982 HIT: 0.2778262867647059

#### val Acc: 0, NDCG: 0.129660330875978 HIT: 0.28608685661764705
Epoch: 16, plus 0 steps train_loss: 0.7169

#### test Acc: 0, NDCG: 0.13192849625321082 HIT: 0.2911477481617647

#### val Acc: 0, NDCG: 0.13199477177229552 HIT: 0.28880974264705883
Epoch: 18, plus 0 steps train_loss: 0.7174

#### test Acc: 0, NDCG: 0.12740001078193075 HIT: 0.2808306525735294

#### val Acc: 0, NDCG: 0.1255198030422539 HIT: 0.2792164522058823
Epoch: 20, plus 0 steps train_loss: 0.7124

#### test Acc: 0, NDCG: 0.12826846914028764 HIT: 0.2800149356617647

#### val Acc: 0, NDCG: 0.1341045849887145 HIT: 0.29392233455882355
Epoch: 22, plus 0 steps train_loss: 0.713

#### test Acc: 0, NDCG: 0.1319486505774884 HIT: 0.29125689338235294

#### val Acc: 0, NDCG: 0.12813122702998875 HIT: 0.28141659007352937
Epoch: 24, plus 0 steps train_loss: 0.7104

#### test Acc: 0, NDCG: 0.12871737734920535 HIT: 0.2865923713235294

#### val Acc: 0, NDCG: 0.1335903871593379 HIT: 0.29272173713235294
Epoch: 26, plus 0 steps train_loss: 0.7127

#### test Acc: 0, NDCG: 0.12689565099698957 HIT: 0.2804630055147059

#### val Acc: 0, NDCG: 0.13104802150446357 HIT: 0.28568474264705884
Epoch: 28, plus 0 steps train_loss: 0.7092

#### test Acc: 0, NDCG: 0.12505201677806072 HIT: 0.27892922794117647

#### val Acc: 0, NDCG: 0.12929798613795823 HIT: 0.28629940257352937
Epoch: 30, plus 0 steps train_loss: 0.7083

#### test Acc: 0, NDCG: 0.13284337976208566 HIT: 0.28742532169117646

#### val Acc: 0, NDCG: 0.1315647288219375 HIT: 0.28405905330882353
Epoch: 32, plus 0 steps train_loss: 0.7098

#### test Acc: 0, NDCG: 0.13163888127108617 HIT: 0.29264131433823526

#### val Acc: 0, NDCG: 0.13511425485812362 HIT: 0.29287109375
Epoch: 36, plus 0 steps train_loss: 0.7083

#### test Acc: 0, NDCG: 0.13591045264833124 HIT: 0.2943761488970588

#### val Acc: 0, NDCG: 0.12884549165634068 HIT: 0.28747702205882353
Epoch: 40, plus 0 steps train_loss: 0.7062

#### test Acc: 0, NDCG: 0.13774091310628683 HIT: 0.2977653952205882

#### val Acc: 0, NDCG: 0.13129788541783066 HIT: 0.2855813419117647
Epoch: 44, plus 0 steps train_loss: 0.705

#### test Acc: 0, NDCG: 0.13094463555609762 HIT: 0.28771829044117647

#### val Acc: 0, NDCG: 0.12821134197704673 HIT: 0.2849551930147059
Epoch: 48, plus 0 steps train_loss: 0.7009

#### test Acc: 0, NDCG: 0.13277569018948338 HIT: 0.29183708639705885

#### val Acc: 0, NDCG: 0.1281591040388186 HIT: 0.2835994944852941
Epoch: 52, plus 0 steps train_loss: 0.7035

#### test Acc: 0, NDCG: 0.1304099582690264 HIT: 0.2888729319852941

#### val Acc: 0, NDCG: 0.13426274459672707 HIT: 0.2939338235294118
Epoch: 56, plus 0 steps train_loss: 0.7032

#### test Acc: 0, NDCG: 0.12747808005552413 HIT: 0.28031364889705884

#### val Acc: 0, NDCG: 0.1307710065374919 HIT: 0.28540326286764706
Epoch: 60, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.12974912445972317 HIT: 0.2851505055147059

#### val Acc: 0, NDCG: 0.13385306560072566 HIT: 0.2922736672794118
Epoch: 64, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.1301249962866143 HIT: 0.2848977481617647

#### val Acc: 0, NDCG: 0.13285061224483258 HIT: 0.29181985294117646
Epoch: 68, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.1318454524363302 HIT: 0.28959099264705884

#### val Acc: 0, NDCG: 0.13143655227380913 HIT: 0.2873334099264706
Epoch: 72, plus 0 steps train_loss: 0.7008

#### test Acc: 0, NDCG: 0.128708567468582 HIT: 0.2848690257352941

#### val Acc: 0, NDCG: 0.1343939421562253 HIT: 0.29746668198529413
Epoch: 80, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.1317154000766781 HIT: 0.29389361213235293

#### val Acc: 0, NDCG: 0.13432599933722178 HIT: 0.2885052849264706
Epoch: 88, plus 0 steps train_loss: 0.7002

#### test Acc: 0, NDCG: 0.13095380348141278 HIT: 0.28736213235294117

#### val Acc: 0, NDCG: 0.12798722151820022 HIT: 0.28432904411764703
Epoch: 96, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.13147907455588795 HIT: 0.2877355238970588

#### val Acc: 0, NDCG: 0.13592139470033565 HIT: 0.2962545955882353
Epoch: 104, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.13511295843811 HIT: 0.29070542279411765

#### val Acc: 0, NDCG: 0.1345815372882529 HIT: 0.2917164522058823
Epoch: 112, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.13112938259729776 HIT: 0.2914407169117647

#### val Acc: 0, NDCG: 0.12807785111904393 HIT: 0.28428883272058825
Epoch: 120, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.1405089089741974 HIT: 0.3088694852941177

#### val Acc: 0, NDCG: 0.1381481715565091 HIT: 0.3017578125
Epoch: 128, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.14441968149185175 HIT: 0.31330422794117646

#### val Acc: 0, NDCG: 0.1460288207086744 HIT: 0.31232192095588235
Epoch: 136, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.1524058926222296 HIT: 0.32069738051470587

#### val Acc: 0, NDCG: 0.15243413625266564 HIT: 0.32669462316176473
Epoch: 144, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.13257376467937895 HIT: 0.2811695772058823

#### val Acc: 0, NDCG: 0.13106598825187227 HIT: 0.2765912224264706
Epoch: 160, plus 0 steps train_loss: 0.6925

#### test Acc: 0, NDCG: 0.16908129972280958 HIT: 0.3469439338235294

#### val Acc: 0, NDCG: 0.16526826865425143 HIT: 0.3433478860294118
Epoch: 176, plus 0 steps train_loss: 0.6892

#### test Acc: 0, NDCG: 0.18020378405242637 HIT: 0.3660098805147059

#### val Acc: 0, NDCG: 0.1881880601459128 HIT: 0.37579848345588235
Epoch: 192, plus 0 steps train_loss: 0.6792

#### test Acc: 0, NDCG: 0.1978349921442434 HIT: 0.3908375459558823

#### val Acc: 0, NDCG: 0.20625401844459032 HIT: 0.401953125
Epoch: 208, plus 0 steps train_loss: 0.6833

#### test Acc: 0, NDCG: 0.2559574317215752 HIT: 0.44659352022058824

#### val Acc: 0, NDCG: 0.25697196478426654 HIT: 0.44256089154411765
Epoch: 224, plus 0 steps train_loss: 0.6579

#### test Acc: 0, NDCG: 0.22803793776352954 HIT: 0.4245634191176471

#### val Acc: 0, NDCG: 0.24041548422446007 HIT: 0.4398494944852941
Epoch: 240, plus 0 steps train_loss: 0.6604

#### test Acc: 0, NDCG: 0.23004235226287711 HIT: 0.43775850183823534

#### val Acc: 0, NDCG: 0.23772005899172172 HIT: 0.4357536764705882
Epoch: 256, plus 0 steps train_loss: 0.661

#### test Acc: 0, NDCG: 0.244160369062454 HIT: 0.44500229779411765

#### val Acc: 0, NDCG: 0.24915779627475096 HIT: 0.4466279871323529
Epoch: 272, plus 0 steps train_loss: 0.657

#### test Acc: 0, NDCG: 0.22167751947424427 HIT: 0.4371725643382353

#### val Acc: 0, NDCG: 0.23503575807046725 HIT: 0.4502355238970588
Epoch: 288, plus 0 steps train_loss: 0.6547

#### test Acc: 0, NDCG: 0.22859048479242064 HIT: 0.44855813419117646

#### val Acc: 0, NDCG: 0.23345613058653608 HIT: 0.4514131433823529
Epoch: 304, plus 0 steps train_loss: 0.6559

#### test Acc: 0, NDCG: 0.24867330419859268 HIT: 0.4621553308823529

#### val Acc: 0, NDCG: 0.25476356911864523 HIT: 0.4681238511029412
Epoch: 320, plus 0 steps train_loss: 0.6472

#### test Acc: 0, NDCG: 0.2509335412459122 HIT: 0.4708295036764706

#### val Acc: 0, NDCG: 0.2580644194747845 HIT: 0.47605124080882355
Epoch: 352, plus 0 steps train_loss: 0.6424

#### test Acc: 0, NDCG: 0.26638529420151824 HIT: 0.48767807904411764

#### val Acc: 0, NDCG: 0.26926165087239873 HIT: 0.4807444852941177
Epoch: 384, plus 0 steps train_loss: 0.6401

#### test Acc: 0, NDCG: 0.2578940721883881 HIT: 0.4816061580882353

#### val Acc: 0, NDCG: 0.2706388882845646 HIT: 0.48835018382352946
Epoch: 416, plus 0 steps train_loss: 0.6498

#### test Acc: 0, NDCG: 0.25128816698977274 HIT: 0.48671875

#### val Acc: 0, NDCG: 0.25926551514145724 HIT: 0.49299172794117646
Epoch: 448, plus 0 steps train_loss: 0.6371

#### test Acc: 0, NDCG: 0.26009054810820675 HIT: 0.4983455882352941

#### val Acc: 0, NDCG: 0.26877292672516184 HIT: 0.5048540900735294
Epoch: 480, plus 0 steps train_loss: 0.6294

#### test Acc: 0, NDCG: 0.27372554089041895 HIT: 0.5151309742647059

#### val Acc: 0, NDCG: 0.2855820576122225 HIT: 0.5171932444852941
Epoch: 512, plus 0 steps train_loss: 0.6393

#### test Acc: 0, NDCG: 0.26736998734016604 HIT: 0.49989659926470587

#### val Acc: 0, NDCG: 0.27676673007687747 HIT: 0.5057387408088235
Epoch: 544, plus 0 steps train_loss: 0.6214

#### test Acc: 0, NDCG: 0.2647561331881032 HIT: 0.5064453125

#### val Acc: 0, NDCG: 0.2757108765855819 HIT: 0.5107536764705882
Epoch: 576, plus 0 steps train_loss: 0.6304

#### test Acc: 0, NDCG: 0.2715662151376797 HIT: 0.5083352481617647

#### val Acc: 0, NDCG: 0.2829499726534912 HIT: 0.51923828125
Epoch: 608, plus 0 steps train_loss: 0.6116

#### test Acc: 0, NDCG: 0.2673300080401617 HIT: 0.5128274356617647

#### val Acc: 0, NDCG: 0.2786281618121854 HIT: 0.5246840533088235
Epoch: 640, plus 0 steps train_loss: 0.6312

#### test Acc: 0, NDCG: 0.27812267678303715 HIT: 0.5255687040441177

#### val Acc: 0, NDCG: 0.2856855093764825 HIT: 0.5303308823529412
Epoch: 704, plus 0 steps train_loss: 0.6314

#### test Acc: 0, NDCG: 0.2699618447857124 HIT: 0.5181870404411765

#### val Acc: 0, NDCG: 0.2810428633114418 HIT: 0.5282341452205882
Epoch: 768, plus 0 steps train_loss: 0.6278

#### test Acc: 0, NDCG: 0.27841627183161255 HIT: 0.5169462316176471

#### val Acc: 0, NDCG: 0.2792192121956475 HIT: 0.5200654871323529
Epoch: 832, plus 0 steps train_loss: 0.6136

#### test Acc: 0, NDCG: 0.2810543401756731 HIT: 0.5223862591911764

#### val Acc: 0, NDCG: 0.2818581151104629 HIT: 0.5255916819852942
Epoch: 896, plus 0 steps train_loss: 0.614

#### test Acc: 0, NDCG: 0.28639816847875565 HIT: 0.5335535386029412

#### val Acc: 0, NDCG: 0.2928067164281149 HIT: 0.5400965073529412
Epoch: 960, plus 0 steps train_loss: 0.6073

#### test Acc: 0, NDCG: 0.28243402942124285 HIT: 0.5263154871323529

#### val Acc: 0, NDCG: 0.29216662346515376 HIT: 0.5388327205882353
Epoch: 1013, plus 25 steps train_loss: 0.5988
Done: it took 284077.2734146118
max value of NDCG: 0.28639816847875565
max value of HIT: 0.5335535386029412

After 20 validations
max value of NDCG: 0.28639816847875565
max value of HIT: 0.5335535386029412
