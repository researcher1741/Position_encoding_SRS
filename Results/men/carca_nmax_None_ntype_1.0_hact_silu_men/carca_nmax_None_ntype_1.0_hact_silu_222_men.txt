 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	None
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
RMHA_decoder:         	False
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_encoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12946526961095772 HIT: 0.29022288602941176

#### val Acc: 0, NDCG: 0.12452802978752486 HIT: 0.27837201286764707
Epoch: 1, plus 0 steps train_loss: 0.7743

#### test Acc: 0, NDCG: 0.1318658059376258 HIT: 0.28852826286764705

#### val Acc: 0, NDCG: 0.1313077105023879 HIT: 0.2892865349264706
Epoch: 2, plus 0 steps train_loss: 0.7654

#### test Acc: 0, NDCG: 0.13152259767418834 HIT: 0.28916590073529413

#### val Acc: 0, NDCG: 0.1323544572227217 HIT: 0.2876665900735294
Epoch: 3, plus 0 steps train_loss: 0.7623

#### test Acc: 0, NDCG: 0.13064117223398464 HIT: 0.2887637867647059

#### val Acc: 0, NDCG: 0.12525510922759378 HIT: 0.28232996323529413
Epoch: 4, plus 0 steps train_loss: 0.7459

#### test Acc: 0, NDCG: 0.1344769207253705 HIT: 0.29299172794117645

#### val Acc: 0, NDCG: 0.13430544478572404 HIT: 0.2948931525735294
Epoch: 5, plus 0 steps train_loss: 0.7312

#### test Acc: 0, NDCG: 0.1305849810585575 HIT: 0.2883501838235294

#### val Acc: 0, NDCG: 0.129056785847873 HIT: 0.28259420955882353
Epoch: 6, plus 0 steps train_loss: 0.7433

#### test Acc: 0, NDCG: 0.1344771310037382 HIT: 0.29474379595588235

#### val Acc: 0, NDCG: 0.13016300900597214 HIT: 0.2855870863970588
Epoch: 7, plus 0 steps train_loss: 0.734

#### test Acc: 0, NDCG: 0.13256109315250655 HIT: 0.2875919117647059

#### val Acc: 0, NDCG: 0.13386935555976204 HIT: 0.2937327665441177
Epoch: 8, plus 0 steps train_loss: 0.7392

#### test Acc: 0, NDCG: 0.13041622386809526 HIT: 0.2896139705882353

#### val Acc: 0, NDCG: 0.13030760599430843 HIT: 0.2867474724264706
Epoch: 9, plus 0 steps train_loss: 0.7274

#### test Acc: 0, NDCG: 0.13396771418321254 HIT: 0.29361787683823526

#### val Acc: 0, NDCG: 0.1299296841526433 HIT: 0.28349609375
Epoch: 10, plus 0 steps train_loss: 0.7268

#### test Acc: 0, NDCG: 0.13245690722401154 HIT: 0.2906652113970588

#### val Acc: 0, NDCG: 0.12751244812391097 HIT: 0.28151999080882356
Epoch: 12, plus 0 steps train_loss: 0.7242

#### test Acc: 0, NDCG: 0.1324849680248366 HIT: 0.28986098345588235

#### val Acc: 0, NDCG: 0.1301944991774594 HIT: 0.28430032169117647
Epoch: 14, plus 0 steps train_loss: 0.7144

#### test Acc: 0, NDCG: 0.13256781454975936 HIT: 0.29086626838235297

#### val Acc: 0, NDCG: 0.13254839549976988 HIT: 0.2942325367647059
Epoch: 16, plus 0 steps train_loss: 0.715

#### test Acc: 0, NDCG: 0.13553752439733097 HIT: 0.2963005514705882

#### val Acc: 0, NDCG: 0.13251821891556498 HIT: 0.28882697610294117
Epoch: 18, plus 0 steps train_loss: 0.7104

#### test Acc: 0, NDCG: 0.13176744098900542 HIT: 0.28763786764705884

#### val Acc: 0, NDCG: 0.13258340272938826 HIT: 0.28907973345588234
Epoch: 20, plus 0 steps train_loss: 0.7072

#### test Acc: 0, NDCG: 0.12210997040027027 HIT: 0.2712603400735294

#### val Acc: 0, NDCG: 0.13185627710260783 HIT: 0.29243451286764705
Epoch: 22, plus 0 steps train_loss: 0.7104

#### test Acc: 0, NDCG: 0.13191849635078656 HIT: 0.2911017922794118

#### val Acc: 0, NDCG: 0.1278573536800479 HIT: 0.27653952205882354
Epoch: 24, plus 0 steps train_loss: 0.7076

#### test Acc: 0, NDCG: 0.12520480534429201 HIT: 0.27835477941176473

#### val Acc: 0, NDCG: 0.1265422430108915 HIT: 0.27815372242647063
Epoch: 26, plus 0 steps train_loss: 0.7073

#### test Acc: 0, NDCG: 0.13160257979911946 HIT: 0.2896312040441177

#### val Acc: 0, NDCG: 0.13579247885765833 HIT: 0.2939395680147059
Epoch: 28, plus 0 steps train_loss: 0.704

#### test Acc: 0, NDCG: 0.13045945930940792 HIT: 0.28728745404411765

#### val Acc: 0, NDCG: 0.12877244813852523 HIT: 0.2793658088235294
Epoch: 30, plus 0 steps train_loss: 0.7036

#### test Acc: 0, NDCG: 0.13105077322040398 HIT: 0.2893267463235294

#### val Acc: 0, NDCG: 0.13207914476393018 HIT: 0.2886316636029412
Epoch: 32, plus 0 steps train_loss: 0.7025

#### test Acc: 0, NDCG: 0.12812785659673914 HIT: 0.28249655330882356

#### val Acc: 0, NDCG: 0.13289169109428978 HIT: 0.2896197150735294
Epoch: 36, plus 0 steps train_loss: 0.7012

#### test Acc: 0, NDCG: 0.1323411588953817 HIT: 0.28812040441176473

#### val Acc: 0, NDCG: 0.12814391910631975 HIT: 0.2809857536764706
Epoch: 40, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.1296289723928317 HIT: 0.2860638786764706

#### val Acc: 0, NDCG: 0.136136582660372 HIT: 0.29595013786764707
Epoch: 44, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.12793145768285824 HIT: 0.2824850643382353

#### val Acc: 0, NDCG: 0.12947600264917292 HIT: 0.2850183823529412
Epoch: 48, plus 0 steps train_loss: 0.6984

#### test Acc: 0, NDCG: 0.13156893504677683 HIT: 0.29210707720588236

#### val Acc: 0, NDCG: 0.1316763194471881 HIT: 0.2851677389705882
Epoch: 52, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.1313975505733877 HIT: 0.2884363511029412

#### val Acc: 0, NDCG: 0.13207991944188927 HIT: 0.2913660386029412
Epoch: 56, plus 0 steps train_loss: 0.6972

#### test Acc: 0, NDCG: 0.13442000406863913 HIT: 0.29574908088235297

#### val Acc: 0, NDCG: 0.13319999745473698 HIT: 0.2906594669117647
Epoch: 60, plus 0 steps train_loss: 0.6976

#### test Acc: 0, NDCG: 0.13045374446121247 HIT: 0.2867474724264706

#### val Acc: 0, NDCG: 0.128044921218394 HIT: 0.2857709099264706
Epoch: 64, plus 0 steps train_loss: 0.6982

#### test Acc: 0, NDCG: 0.1350448146183953 HIT: 0.29508272058823526

#### val Acc: 0, NDCG: 0.1368015163521928 HIT: 0.29409466911764703
Epoch: 68, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.13496571801301355 HIT: 0.2966739430147059

#### val Acc: 0, NDCG: 0.12753356830910545 HIT: 0.2851505055147059
Epoch: 72, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.13234735511427786 HIT: 0.29056181066176473

#### val Acc: 0, NDCG: 0.1336253641775857 HIT: 0.2952837775735294
Epoch: 80, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.13302587834425345 HIT: 0.29194623161764705

#### val Acc: 0, NDCG: 0.14158991903350435 HIT: 0.3102022058823529
Epoch: 88, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.13564769794735382 HIT: 0.29476102941176474

#### val Acc: 0, NDCG: 0.1353958883871986 HIT: 0.29881089154411766
Epoch: 96, plus 0 steps train_loss: 0.6954

#### test Acc: 0, NDCG: 0.14288101081991916 HIT: 0.30994944852941175

#### val Acc: 0, NDCG: 0.14424536001366925 HIT: 0.3135627297794118
Epoch: 104, plus 0 steps train_loss: 0.695

#### test Acc: 0, NDCG: 0.15964164765689745 HIT: 0.33903952205882354

#### val Acc: 0, NDCG: 0.15843983044728888 HIT: 0.335546875
Epoch: 112, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.2528026643462516 HIT: 0.42068014705882356

#### val Acc: 0, NDCG: 0.26878047657980575 HIT: 0.4316750919117647
Epoch: 120, plus 0 steps train_loss: 0.6935

#### test Acc: 0, NDCG: 0.18538512467816542 HIT: 0.37710822610294115

#### val Acc: 0, NDCG: 0.18995172117831366 HIT: 0.3756318933823529
Epoch: 128, plus 0 steps train_loss: 0.6926

#### test Acc: 0, NDCG: 0.1870318774648799 HIT: 0.38668428308823527

#### val Acc: 0, NDCG: 0.18532626721738787 HIT: 0.3735294117647059
Epoch: 136, plus 0 steps train_loss: 0.688

#### test Acc: 0, NDCG: 0.1882029982290969 HIT: 0.38159466911764706

#### val Acc: 0, NDCG: 0.19708414383360215 HIT: 0.3967658547794118
Epoch: 144, plus 0 steps train_loss: 0.6865

#### test Acc: 0, NDCG: 0.20630519575666711 HIT: 0.4119198069852941

#### val Acc: 0, NDCG: 0.2044075983742432 HIT: 0.4036075367647059
Epoch: 160, plus 0 steps train_loss: 0.6841

#### test Acc: 0, NDCG: 0.22620527918487054 HIT: 0.4351964613970588

#### val Acc: 0, NDCG: 0.22633872405186292 HIT: 0.4242704503676471
Epoch: 176, plus 0 steps train_loss: 0.6771

#### test Acc: 0, NDCG: 0.23123064376440539 HIT: 0.4366038602941177

#### val Acc: 0, NDCG: 0.25125690944294277 HIT: 0.45399241727941175
Epoch: 192, plus 0 steps train_loss: 0.6683

#### test Acc: 0, NDCG: 0.25033385557520854 HIT: 0.45209099264705876

#### val Acc: 0, NDCG: 0.2625297288008325 HIT: 0.4672794117647059
Epoch: 208, plus 0 steps train_loss: 0.6609

#### test Acc: 0, NDCG: 0.24816907758180604 HIT: 0.465625

#### val Acc: 0, NDCG: 0.2672521924763931 HIT: 0.4789694393382353
Epoch: 224, plus 0 steps train_loss: 0.6599

#### test Acc: 0, NDCG: 0.25437326902798074 HIT: 0.4636603860294118

#### val Acc: 0, NDCG: 0.2649053379511101 HIT: 0.4666590073529412
Epoch: 240, plus 0 steps train_loss: 0.6509

#### test Acc: 0, NDCG: 0.25240177142311176 HIT: 0.46591796875

#### val Acc: 0, NDCG: 0.2582514803989949 HIT: 0.46995059742647055
Epoch: 256, plus 0 steps train_loss: 0.6548

#### test Acc: 0, NDCG: 0.26229008777995333 HIT: 0.48561580882352945

#### val Acc: 0, NDCG: 0.2738210835907797 HIT: 0.4906709558823529
Epoch: 272, plus 0 steps train_loss: 0.6472

#### test Acc: 0, NDCG: 0.25917555127348213 HIT: 0.4692727481617647

#### val Acc: 0, NDCG: 0.2650646454154647 HIT: 0.4708639705882353
Epoch: 288, plus 0 steps train_loss: 0.647

#### test Acc: 0, NDCG: 0.27414769178462206 HIT: 0.4930836397058823

#### val Acc: 0, NDCG: 0.28828760177326396 HIT: 0.5020852481617647
Epoch: 304, plus 0 steps train_loss: 0.6466

#### test Acc: 0, NDCG: 0.2725667445717841 HIT: 0.5012178308823529

#### val Acc: 0, NDCG: 0.2794918058852335 HIT: 0.4994370404411764
Epoch: 320, plus 0 steps train_loss: 0.6423

#### test Acc: 0, NDCG: 0.28136595609374326 HIT: 0.5136891084558823

#### val Acc: 0, NDCG: 0.29027889556311337 HIT: 0.5204216452205882
Epoch: 352, plus 0 steps train_loss: 0.6394

#### test Acc: 0, NDCG: 0.27946649043225313 HIT: 0.5152401194852941

#### val Acc: 0, NDCG: 0.2848943276339105 HIT: 0.5146484375
Epoch: 384, plus 0 steps train_loss: 0.6251

#### test Acc: 0, NDCG: 0.27916027942229044 HIT: 0.5164636948529412

#### val Acc: 0, NDCG: 0.288480876335241 HIT: 0.5233168658088235
Epoch: 416, plus 0 steps train_loss: 0.6306

#### test Acc: 0, NDCG: 0.2823854600958353 HIT: 0.5213177849264705

#### val Acc: 0, NDCG: 0.2897967757077896 HIT: 0.5248448988970588
Epoch: 448, plus 0 steps train_loss: 0.6082

#### test Acc: 0, NDCG: 0.2910220114765397 HIT: 0.5331916360294118

#### val Acc: 0, NDCG: 0.2970772700029499 HIT: 0.5344267003676471
Epoch: 480, plus 0 steps train_loss: 0.6206

#### test Acc: 0, NDCG: 0.2946210749761221 HIT: 0.5338809742647059

#### val Acc: 0, NDCG: 0.2968701348993962 HIT: 0.5381721047794118
Epoch: 512, plus 0 steps train_loss: 0.6058

#### test Acc: 0, NDCG: 0.29709597944306365 HIT: 0.5442153033088235

#### val Acc: 0, NDCG: 0.30077703168555237 HIT: 0.5431123621323529
Epoch: 544, plus 0 steps train_loss: 0.618

#### test Acc: 0, NDCG: 0.2964176068806037 HIT: 0.5422621783088235

#### val Acc: 0, NDCG: 0.30710775162434034 HIT: 0.5496266084558823
Epoch: 576, plus 0 steps train_loss: 0.612

#### test Acc: 0, NDCG: 0.30068456939871147 HIT: 0.5424230238970588

#### val Acc: 0, NDCG: 0.30814324633986007 HIT: 0.5494944852941177
Epoch: 608, plus 0 steps train_loss: 0.6154

#### test Acc: 0, NDCG: 0.3028340509232854 HIT: 0.5439625459558823

#### val Acc: 0, NDCG: 0.3018710820142548 HIT: 0.53525390625
Epoch: 640, plus 0 steps train_loss: 0.6013

#### test Acc: 0, NDCG: 0.30805173345245457 HIT: 0.5531422334558823

#### val Acc: 0, NDCG: 0.3124503955921312 HIT: 0.5520105698529412
Epoch: 704, plus 0 steps train_loss: 0.6104

#### test Acc: 0, NDCG: 0.30490511081618543 HIT: 0.5471277573529412

#### val Acc: 0, NDCG: 0.3107248072794039 HIT: 0.5523667279411765
Epoch: 768, plus 0 steps train_loss: 0.596

#### test Acc: 0, NDCG: 0.30443030277941174 HIT: 0.5417049632352942

#### val Acc: 0, NDCG: 0.30599698140781084 HIT: 0.5470358455882354
Epoch: 832, plus 0 steps train_loss: 0.6034

#### test Acc: 0, NDCG: 0.3097508435234596 HIT: 0.5567153033088236

#### val Acc: 0, NDCG: 0.3085254604030027 HIT: 0.5511603860294118
Epoch: 896, plus 0 steps train_loss: 0.6033

#### test Acc: 0, NDCG: 0.3084996184542363 HIT: 0.5468118106617647

#### val Acc: 0, NDCG: 0.320842040569988 HIT: 0.5729262408088236
Epoch: 960, plus 0 steps train_loss: 0.585

#### test Acc: 0, NDCG: 0.30881575192185406 HIT: 0.5471852022058823

#### val Acc: 0, NDCG: 0.318066624341837 HIT: 0.5621610753676471
Epoch: 1013, plus 25 steps train_loss: 0.6044
Done: it took 297620.98982167244
max value of NDCG: 0.3097508435234596
max value of HIT: 0.5567153033088236

After 20 validations
max value of NDCG: 0.3097508435234596
max value of HIT: 0.5567153033088236
