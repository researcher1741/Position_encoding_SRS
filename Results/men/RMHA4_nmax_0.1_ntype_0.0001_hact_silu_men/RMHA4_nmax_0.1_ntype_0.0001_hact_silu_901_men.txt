 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.0001
max_norm:             	0.1
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13213855019936557 HIT: 0.29397977941176473

#### val Acc: 0, NDCG: 0.1334988684330918 HIT: 0.28994140625
Epoch: 1, plus 0 steps train_loss: 0.7549

#### test Acc: 0, NDCG: 0.13281234302452125 HIT: 0.28637982536764706

#### val Acc: 0, NDCG: 0.1329096199675396 HIT: 0.2913660386029412
Epoch: 2, plus 0 steps train_loss: 0.754

#### test Acc: 0, NDCG: 0.13425687615534754 HIT: 0.29384191176470587

#### val Acc: 0, NDCG: 0.12879894644803275 HIT: 0.2839556525735294
Epoch: 3, plus 0 steps train_loss: 0.7434

#### test Acc: 0, NDCG: 0.13055349379859704 HIT: 0.28714384191176473

#### val Acc: 0, NDCG: 0.1269210996656741 HIT: 0.28157169117647063
Epoch: 4, plus 0 steps train_loss: 0.7356

#### test Acc: 0, NDCG: 0.12537557006065564 HIT: 0.2796415441176471

#### val Acc: 0, NDCG: 0.1300174180510158 HIT: 0.28347311580882356
Epoch: 5, plus 0 steps train_loss: 0.7243

#### test Acc: 0, NDCG: 0.1285049202984911 HIT: 0.28295036764705883

#### val Acc: 0, NDCG: 0.13100942864790951 HIT: 0.2882180606617647
Epoch: 6, plus 0 steps train_loss: 0.7182

#### test Acc: 0, NDCG: 0.13005140582413421 HIT: 0.2813189338235294

#### val Acc: 0, NDCG: 0.13296218794467263 HIT: 0.2918543198529412
Epoch: 7, plus 0 steps train_loss: 0.7065

#### test Acc: 0, NDCG: 0.1428046836647372 HIT: 0.3053653492647059

#### val Acc: 0, NDCG: 0.15072874486899496 HIT: 0.30367647058823527
Epoch: 8, plus 0 steps train_loss: 0.7101

#### test Acc: 0, NDCG: 0.15501724146255988 HIT: 0.3155158547794118

#### val Acc: 0, NDCG: 0.16189878676303332 HIT: 0.31591796875
Epoch: 9, plus 0 steps train_loss: 0.7042

#### test Acc: 0, NDCG: 0.1848446274740841 HIT: 0.33577090992647063

#### val Acc: 0, NDCG: 0.21293506857498962 HIT: 0.3643267463235294
Epoch: 10, plus 0 steps train_loss: 0.7049

#### test Acc: 0, NDCG: 0.23565142439625922 HIT: 0.3853400735294118

#### val Acc: 0, NDCG: 0.25237623414140503 HIT: 0.4030732996323529
Epoch: 12, plus 0 steps train_loss: 0.7026

#### test Acc: 0, NDCG: 0.28004410211189523 HIT: 0.4313074448529412

#### val Acc: 0, NDCG: 0.29936818495052664 HIT: 0.44947725183823534
Epoch: 14, plus 0 steps train_loss: 0.7042

#### test Acc: 0, NDCG: 0.3372539349870938 HIT: 0.4834731158088236

#### val Acc: 0, NDCG: 0.3533883141635335 HIT: 0.4986615349264706
Epoch: 16, plus 0 steps train_loss: 0.7032

#### test Acc: 0, NDCG: 0.4712178043265105 HIT: 0.6080422794117647

#### val Acc: 0, NDCG: 0.4907580015862855 HIT: 0.6238740808823529
Epoch: 18, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.3737984344883124 HIT: 0.5187729779411765

#### val Acc: 0, NDCG: 0.3966990696355816 HIT: 0.5345473345588235
Epoch: 20, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.4126793871503491 HIT: 0.5532284007352941

#### val Acc: 0, NDCG: 0.4311406266244423 HIT: 0.5663947610294118
Epoch: 22, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.3945462697941987 HIT: 0.5332605698529412

#### val Acc: 0, NDCG: 0.4250739229486952 HIT: 0.5634880514705882
Epoch: 24, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.35358668262247683 HIT: 0.5008616727941176

#### val Acc: 0, NDCG: 0.3884032072249391 HIT: 0.5288200827205882
Epoch: 26, plus 0 steps train_loss: 0.6984

#### test Acc: 0, NDCG: 0.39419491139803475 HIT: 0.5366670496323529

#### val Acc: 0, NDCG: 0.4219402523901968 HIT: 0.5560776654411764
Epoch: 28, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.3157491019857971 HIT: 0.4642233455882353

#### val Acc: 0, NDCG: 0.3348906038351399 HIT: 0.47833180147058824
Epoch: 30, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.41640497594004744 HIT: 0.5541360294117647

#### val Acc: 0, NDCG: 0.4401053507312498 HIT: 0.5712086397058823
Epoch: 32, plus 0 steps train_loss: 0.6962

#### test Acc: 0, NDCG: 0.532965575138536 HIT: 0.6602022058823529

#### val Acc: 0, NDCG: 0.5449717795751806 HIT: 0.6719324448529412
Epoch: 36, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.5059936405826277 HIT: 0.6408432904411765

#### val Acc: 0, NDCG: 0.5248382484493803 HIT: 0.6534811580882354
Epoch: 40, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.47046256387747026 HIT: 0.61015625

#### val Acc: 0, NDCG: 0.47679518230755463 HIT: 0.6184110753676471
Epoch: 44, plus 0 steps train_loss: 0.6888

#### test Acc: 0, NDCG: 0.3964832800234178 HIT: 0.5509650735294118

#### val Acc: 0, NDCG: 0.41685491980427125 HIT: 0.5635225183823529
Epoch: 48, plus 0 steps train_loss: 0.6839

#### test Acc: 0, NDCG: 0.19990542213375756 HIT: 0.4156135110294118

#### val Acc: 0, NDCG: 0.1979497954938652 HIT: 0.4108340992647059
Epoch: 52, plus 0 steps train_loss: 0.6736

#### test Acc: 0, NDCG: 0.21792581835563712 HIT: 0.4451746323529412

#### val Acc: 0, NDCG: 0.2210723046912571 HIT: 0.44752412683823534
Epoch: 56, plus 0 steps train_loss: 0.6616

#### test Acc: 0, NDCG: 0.2231642012820984 HIT: 0.4492302389705882

#### val Acc: 0, NDCG: 0.22848019350464419 HIT: 0.45733570772058824
Epoch: 60, plus 0 steps train_loss: 0.6484

#### test Acc: 0, NDCG: 0.22215816732988897 HIT: 0.4499138327205882

#### val Acc: 0, NDCG: 0.23436742524512882 HIT: 0.4695140165441177
Epoch: 64, plus 0 steps train_loss: 0.6497

#### test Acc: 0, NDCG: 0.24535177011109513 HIT: 0.4885799632352941

#### val Acc: 0, NDCG: 0.24260816722472808 HIT: 0.48150850183823535
Epoch: 68, plus 0 steps train_loss: 0.6441

#### test Acc: 0, NDCG: 0.2530993240847684 HIT: 0.49988511029411764

#### val Acc: 0, NDCG: 0.24995198411796865 HIT: 0.4899816176470588
Epoch: 72, plus 0 steps train_loss: 0.6402

#### test Acc: 0, NDCG: 0.2656405907453891 HIT: 0.5114832261029412

#### val Acc: 0, NDCG: 0.26106453631558735 HIT: 0.5089211856617647
Epoch: 80, plus 0 steps train_loss: 0.6253

#### test Acc: 0, NDCG: 0.2705476891092332 HIT: 0.5237074908088235

#### val Acc: 0, NDCG: 0.27284062231393597 HIT: 0.5277113970588235
Epoch: 88, plus 0 steps train_loss: 0.6262

#### test Acc: 0, NDCG: 0.2734538744839544 HIT: 0.5207375919117647

#### val Acc: 0, NDCG: 0.2821458301323796 HIT: 0.5289177389705882
Epoch: 96, plus 0 steps train_loss: 0.6189

#### test Acc: 0, NDCG: 0.2806467867315888 HIT: 0.52724609375

#### val Acc: 0, NDCG: 0.2885384695696769 HIT: 0.5337890625
Epoch: 104, plus 0 steps train_loss: 0.602

#### test Acc: 0, NDCG: 0.2875110405501593 HIT: 0.5352079503676471

#### val Acc: 0, NDCG: 0.288658660900262 HIT: 0.5400218290441177
Epoch: 112, plus 0 steps train_loss: 0.5924

#### test Acc: 0, NDCG: 0.2970218784439132 HIT: 0.5483972886029412

#### val Acc: 0, NDCG: 0.3023408156388279 HIT: 0.5524126838235295
Epoch: 120, plus 0 steps train_loss: 0.5878

#### test Acc: 0, NDCG: 0.29865133682632666 HIT: 0.5482823988970588

#### val Acc: 0, NDCG: 0.31268097859343313 HIT: 0.5677447150735294
Epoch: 128, plus 0 steps train_loss: 0.5817

#### test Acc: 0, NDCG: 0.30234875100176295 HIT: 0.5529469209558824

#### val Acc: 0, NDCG: 0.3086229524907528 HIT: 0.5523552389705882
Epoch: 136, plus 0 steps train_loss: 0.6057

#### test Acc: 0, NDCG: 0.3106956274857887 HIT: 0.5568129595588236

#### val Acc: 0, NDCG: 0.31104913082528707 HIT: 0.5580997242647059
Epoch: 144, plus 0 steps train_loss: 0.5747

#### test Acc: 0, NDCG: 0.3177893391007124 HIT: 0.5624253216911764

#### val Acc: 0, NDCG: 0.3221666811556442 HIT: 0.5688936121323529
Epoch: 160, plus 0 steps train_loss: 0.5762

#### test Acc: 0, NDCG: 0.3273185252538033 HIT: 0.5699276194852941

#### val Acc: 0, NDCG: 0.3319357298831152 HIT: 0.5822782628676471
Epoch: 176, plus 0 steps train_loss: 0.5766

#### test Acc: 0, NDCG: 0.33492713535163665 HIT: 0.5825827205882353

#### val Acc: 0, NDCG: 0.34253652794213724 HIT: 0.5945714613970587
Epoch: 192, plus 0 steps train_loss: 0.5741

#### test Acc: 0, NDCG: 0.3405332509951055 HIT: 0.5890682444852942

#### val Acc: 0, NDCG: 0.34154935328812797 HIT: 0.5839671415441177
Epoch: 208, plus 0 steps train_loss: 0.5698

#### test Acc: 0, NDCG: 0.33699999865980784 HIT: 0.5813189338235294

#### val Acc: 0, NDCG: 0.34600681981267756 HIT: 0.5899701286764706
Epoch: 224, plus 0 steps train_loss: 0.5472

#### test Acc: 0, NDCG: 0.35217516402558274 HIT: 0.6008444393382353

#### val Acc: 0, NDCG: 0.3561990311555402 HIT: 0.6005112591911764
Epoch: 240, plus 0 steps train_loss: 0.5547

#### test Acc: 0, NDCG: 0.35375680539215265 HIT: 0.5994255514705882

#### val Acc: 0, NDCG: 0.3576346108781157 HIT: 0.6024241727941176
Epoch: 256, plus 0 steps train_loss: 0.5497

#### test Acc: 0, NDCG: 0.35062778996812116 HIT: 0.5904067095588236

#### val Acc: 0, NDCG: 0.3601581237923602 HIT: 0.6040785845588236
Epoch: 272, plus 0 steps train_loss: 0.5643

#### test Acc: 0, NDCG: 0.35888960112479423 HIT: 0.6061982996323529

#### val Acc: 0, NDCG: 0.36405523059541384 HIT: 0.6090016084558824
Epoch: 288, plus 0 steps train_loss: 0.5409

#### test Acc: 0, NDCG: 0.3648250986664848 HIT: 0.6058134191176471

#### val Acc: 0, NDCG: 0.367240618044387 HIT: 0.6149356617647059
Epoch: 304, plus 0 steps train_loss: 0.531

#### test Acc: 0, NDCG: 0.36320495236255396 HIT: 0.6070484834558824

#### val Acc: 0, NDCG: 0.3633679020169868 HIT: 0.6116383272058823
Epoch: 320, plus 0 steps train_loss: 0.536

#### test Acc: 0, NDCG: 0.3657607525353396 HIT: 0.6137178308823529

#### val Acc: 0, NDCG: 0.37772808227916405 HIT: 0.6252642463235294
Epoch: 352, plus 0 steps train_loss: 0.5316

#### test Acc: 0, NDCG: 0.3729775685891672 HIT: 0.6224896599264705

#### val Acc: 0, NDCG: 0.38280459161390856 HIT: 0.6306640625
Epoch: 384, plus 0 steps train_loss: 0.5135

#### test Acc: 0, NDCG: 0.37698175517779176 HIT: 0.6240119485294118

#### val Acc: 0, NDCG: 0.3871570112265594 HIT: 0.6357249540441177
Epoch: 416, plus 0 steps train_loss: 0.5178

#### test Acc: 0, NDCG: 0.37607167927118657 HIT: 0.6254308363970588

#### val Acc: 0, NDCG: 0.3848569401265861 HIT: 0.6370002297794117
Epoch: 448, plus 0 steps train_loss: 0.5106

#### test Acc: 0, NDCG: 0.3880505054958394 HIT: 0.6370921415441176

#### val Acc: 0, NDCG: 0.38947943767572873 HIT: 0.6460363051470588
Epoch: 480, plus 0 steps train_loss: 0.4967

#### test Acc: 0, NDCG: 0.38379723314784864 HIT: 0.6311580882352941

#### val Acc: 0, NDCG: 0.3898786834458765 HIT: 0.6394129136029412
Epoch: 512, plus 0 steps train_loss: 0.4972

#### test Acc: 0, NDCG: 0.380638819677252 HIT: 0.6275448069852941

#### val Acc: 0, NDCG: 0.3930017711830889 HIT: 0.6442842371323529
Epoch: 544, plus 0 steps train_loss: 0.4831

#### test Acc: 0, NDCG: 0.38513167456352393 HIT: 0.6298023897058823

#### val Acc: 0, NDCG: 0.3852868033925339 HIT: 0.6343520220588236
Epoch: 576, plus 0 steps train_loss: 0.4982

#### test Acc: 0, NDCG: 0.38943375909872235 HIT: 0.6386891084558823

#### val Acc: 0, NDCG: 0.39498217575261096 HIT: 0.6428136488970588
Epoch: 608, plus 0 steps train_loss: 0.4864

#### test Acc: 0, NDCG: 0.3894632022816936 HIT: 0.6341050091911764

#### val Acc: 0, NDCG: 0.3964311537098681 HIT: 0.6379078584558824
Epoch: 640, plus 0 steps train_loss: 0.4913

#### test Acc: 0, NDCG: 0.38662377995802677 HIT: 0.6340992647058823

#### val Acc: 0, NDCG: 0.3995010873283153 HIT: 0.64814453125
Epoch: 704, plus 0 steps train_loss: 0.4866

#### test Acc: 0, NDCG: 0.3829615899747419 HIT: 0.6276482077205883

#### val Acc: 0, NDCG: 0.40446689427394056 HIT: 0.6567784926470588
Epoch: 768, plus 0 steps train_loss: 0.4842

#### test Acc: 0, NDCG: 0.38807411922581864 HIT: 0.6361098345588235

#### val Acc: 0, NDCG: 0.4031365337817589 HIT: 0.6517061121323529
Epoch: 832, plus 0 steps train_loss: 0.4806

#### test Acc: 0, NDCG: 0.3857613950711082 HIT: 0.6303825827205882

#### val Acc: 0, NDCG: 0.39943268707807894 HIT: 0.6484949448529412
Epoch: 896, plus 0 steps train_loss: 0.4549

#### test Acc: 0, NDCG: 0.38873300535422733 HIT: 0.6356904871323529

#### val Acc: 0, NDCG: 0.39719898274347293 HIT: 0.6431181066176471
Epoch: 960, plus 0 steps train_loss: 0.4631

#### test Acc: 0, NDCG: 0.39240834617943526 HIT: 0.6370346966911764

#### val Acc: 0, NDCG: 0.3971195940828484 HIT: 0.6468864889705882
Epoch: 1013, plus 25 steps train_loss: 0.445
Done: it took 301140.90081834793
max value of NDCG: 0.532965575138536
max value of HIT: 0.6602022058823529

After 20 validations
max value of NDCG: 0.532965575138536
max value of HIT: 0.6602022058823529
