 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	0.0001
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13253506194606424 HIT: 0.2922736672794118

#### val Acc: 0, NDCG: 0.1279386842224246 HIT: 0.28161764705882353
Epoch: 1, plus 0 steps train_loss: 0.7763

#### test Acc: 0, NDCG: 0.13435237963943186 HIT: 0.2938821231617647

#### val Acc: 0, NDCG: 0.12526838593701017 HIT: 0.27701631433823526
Epoch: 2, plus 0 steps train_loss: 0.7523

#### test Acc: 0, NDCG: 0.1328322602065168 HIT: 0.2933134191176471

#### val Acc: 0, NDCG: 0.13315002963895495 HIT: 0.29237132352941175
Epoch: 3, plus 0 steps train_loss: 0.7356

#### test Acc: 0, NDCG: 0.17468488149969252 HIT: 0.32257582720588235

#### val Acc: 0, NDCG: 0.18599398451907592 HIT: 0.34048713235294115
Epoch: 4, plus 0 steps train_loss: 0.72

#### test Acc: 0, NDCG: 0.2654428935412545 HIT: 0.4192957261029412

#### val Acc: 0, NDCG: 0.2785455397341682 HIT: 0.4303021599264706
Epoch: 5, plus 0 steps train_loss: 0.7116

#### test Acc: 0, NDCG: 0.3071048210856613 HIT: 0.4550264246323529

#### val Acc: 0, NDCG: 0.3287590859748642 HIT: 0.4793026194852941
Epoch: 6, plus 0 steps train_loss: 0.7157

#### test Acc: 0, NDCG: 0.3393622261039074 HIT: 0.4850643382352941

#### val Acc: 0, NDCG: 0.3515860660815951 HIT: 0.49075137867647056
Epoch: 7, plus 0 steps train_loss: 0.7067

#### test Acc: 0, NDCG: 0.37153612744888564 HIT: 0.5150103400735294

#### val Acc: 0, NDCG: 0.3861607778707112 HIT: 0.5274011948529412
Epoch: 8, plus 0 steps train_loss: 0.7069

#### test Acc: 0, NDCG: 0.3239213053207514 HIT: 0.47340877757352945

#### val Acc: 0, NDCG: 0.34859655628944675 HIT: 0.49230813419117647
Epoch: 9, plus 0 steps train_loss: 0.7035

#### test Acc: 0, NDCG: 0.2241202674804279 HIT: 0.37570657169117644

#### val Acc: 0, NDCG: 0.24349477505323508 HIT: 0.39184283088235294
Epoch: 10, plus 0 steps train_loss: 0.7019

#### test Acc: 0, NDCG: 0.2555051325262123 HIT: 0.40858226102941175

#### val Acc: 0, NDCG: 0.28632845500024673 HIT: 0.4349034926470588
Epoch: 12, plus 0 steps train_loss: 0.703

#### test Acc: 0, NDCG: 0.23530423451224433 HIT: 0.3783490349264706

#### val Acc: 0, NDCG: 0.277483727331966 HIT: 0.4210248161764706
Epoch: 14, plus 0 steps train_loss: 0.7039

#### test Acc: 0, NDCG: 0.29557081098791876 HIT: 0.4432042738970588

#### val Acc: 0, NDCG: 0.3270083933908321 HIT: 0.4721622242647059
Epoch: 16, plus 0 steps train_loss: 0.701

#### test Acc: 0, NDCG: 0.2828979135744524 HIT: 0.4269186580882353

#### val Acc: 0, NDCG: 0.3143864647270934 HIT: 0.45749080882352944
Epoch: 18, plus 0 steps train_loss: 0.7004

#### test Acc: 0, NDCG: 0.251927699365384 HIT: 0.39896599264705884

#### val Acc: 0, NDCG: 0.28560642363411975 HIT: 0.43161190257352944
Epoch: 20, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.21677089002033895 HIT: 0.36665900735294116

#### val Acc: 0, NDCG: 0.24980043155549456 HIT: 0.39740923713235293
Epoch: 22, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.20071579344668744 HIT: 0.35166015625

#### val Acc: 0, NDCG: 0.2360677523592623 HIT: 0.37895795036764707
Epoch: 24, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.2149951220645892 HIT: 0.361328125

#### val Acc: 0, NDCG: 0.24524254237957752 HIT: 0.39256089154411766
Epoch: 26, plus 0 steps train_loss: 0.6982

#### test Acc: 0, NDCG: 0.2285871578564163 HIT: 0.37722311580882356

#### val Acc: 0, NDCG: 0.2567161423028169 HIT: 0.40294692095588236
Epoch: 28, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.25072291825001153 HIT: 0.39994255514705884

#### val Acc: 0, NDCG: 0.2854641316568199 HIT: 0.43537454044117646
Epoch: 30, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.18393429901723163 HIT: 0.34196920955882354

#### val Acc: 0, NDCG: 0.21568189061732856 HIT: 0.3706916360294118
Epoch: 32, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.25268137500543086 HIT: 0.41120174632352946

#### val Acc: 0, NDCG: 0.28364378816581437 HIT: 0.4388844209558823
Epoch: 36, plus 0 steps train_loss: 0.6911

#### test Acc: 0, NDCG: 0.3238378201568471 HIT: 0.4801815257352941

#### val Acc: 0, NDCG: 0.3631134403685384 HIT: 0.5182502297794118
Epoch: 40, plus 0 steps train_loss: 0.6895

#### test Acc: 0, NDCG: 0.3676888301733382 HIT: 0.5352309283088236

#### val Acc: 0, NDCG: 0.3820577786121494 HIT: 0.5488625919117647
Epoch: 44, plus 0 steps train_loss: 0.6773

#### test Acc: 0, NDCG: 0.21034282579361277 HIT: 0.4291475183823529

#### val Acc: 0, NDCG: 0.21712917273048743 HIT: 0.4372185202205882
Epoch: 48, plus 0 steps train_loss: 0.6717

#### test Acc: 0, NDCG: 0.21636864210737428 HIT: 0.4373104319852941

#### val Acc: 0, NDCG: 0.22226955476874824 HIT: 0.45419921875
Epoch: 52, plus 0 steps train_loss: 0.6681

#### test Acc: 0, NDCG: 0.22532981331437235 HIT: 0.4599092371323529

#### val Acc: 0, NDCG: 0.22742357353007572 HIT: 0.45745634191176465
Epoch: 56, plus 0 steps train_loss: 0.6521

#### test Acc: 0, NDCG: 0.22949800437817736 HIT: 0.4539464613970588

#### val Acc: 0, NDCG: 0.23153477401451722 HIT: 0.461328125
Epoch: 60, plus 0 steps train_loss: 0.652

#### test Acc: 0, NDCG: 0.2324902745373189 HIT: 0.4610811121323529

#### val Acc: 0, NDCG: 0.2361760309674783 HIT: 0.4691061580882353
Epoch: 64, plus 0 steps train_loss: 0.6373

#### test Acc: 0, NDCG: 0.2412864317554853 HIT: 0.4745691636029412

#### val Acc: 0, NDCG: 0.2435027148417052 HIT: 0.47645335477941175
Epoch: 68, plus 0 steps train_loss: 0.6511

#### test Acc: 0, NDCG: 0.25305466586974484 HIT: 0.4901826746323529

#### val Acc: 0, NDCG: 0.2507571573698781 HIT: 0.4840877757352941
Epoch: 72, plus 0 steps train_loss: 0.6389

#### test Acc: 0, NDCG: 0.26495467205136125 HIT: 0.5099954044117647

#### val Acc: 0, NDCG: 0.2703534586145843 HIT: 0.5099034926470588
Epoch: 80, plus 0 steps train_loss: 0.6207

#### test Acc: 0, NDCG: 0.27320873271020496 HIT: 0.5210880055147059

#### val Acc: 0, NDCG: 0.27996288041053335 HIT: 0.5201746323529413
Epoch: 88, plus 0 steps train_loss: 0.6219

#### test Acc: 0, NDCG: 0.2872225058091872 HIT: 0.5356158088235294

#### val Acc: 0, NDCG: 0.287068430901505 HIT: 0.5321748621323529
Epoch: 96, plus 0 steps train_loss: 0.5886

#### test Acc: 0, NDCG: 0.29477367488058975 HIT: 0.5458180147058823

#### val Acc: 0, NDCG: 0.2981303640927221 HIT: 0.5420209099264706
Epoch: 104, plus 0 steps train_loss: 0.6116

#### test Acc: 0, NDCG: 0.298718649609014 HIT: 0.5450482536764706

#### val Acc: 0, NDCG: 0.3047181016203337 HIT: 0.5512982536764706
Epoch: 112, plus 0 steps train_loss: 0.6108

#### test Acc: 0, NDCG: 0.3061499014844403 HIT: 0.5551183363970588

#### val Acc: 0, NDCG: 0.31131182143186137 HIT: 0.5625
Epoch: 120, plus 0 steps train_loss: 0.5865

#### test Acc: 0, NDCG: 0.3112319692507212 HIT: 0.5567899816176471

#### val Acc: 0, NDCG: 0.31539462422632875 HIT: 0.56298828125
Epoch: 128, plus 0 steps train_loss: 0.5879

#### test Acc: 0, NDCG: 0.31703613782992845 HIT: 0.5722139246323529

#### val Acc: 0, NDCG: 0.3249653945090704 HIT: 0.5748736213235295
Epoch: 136, plus 0 steps train_loss: 0.5748

#### test Acc: 0, NDCG: 0.3226819582090473 HIT: 0.5717313878676471

#### val Acc: 0, NDCG: 0.3255922333617961 HIT: 0.5783088235294118
Epoch: 144, plus 0 steps train_loss: 0.5819

#### test Acc: 0, NDCG: 0.31708302981846737 HIT: 0.5697093290441176

#### val Acc: 0, NDCG: 0.32722170976625775 HIT: 0.5868106617647059
Epoch: 160, plus 0 steps train_loss: 0.5693

#### test Acc: 0, NDCG: 0.3322652946367051 HIT: 0.5893841911764706

#### val Acc: 0, NDCG: 0.33706306496835836 HIT: 0.5955652573529412
Epoch: 176, plus 0 steps train_loss: 0.5739

#### test Acc: 0, NDCG: 0.331673321382829 HIT: 0.5876034007352942

#### val Acc: 0, NDCG: 0.34169285268890465 HIT: 0.5954331341911765
Epoch: 192, plus 0 steps train_loss: 0.55

#### test Acc: 0, NDCG: 0.3356041901639742 HIT: 0.5891027113970588

#### val Acc: 0, NDCG: 0.35011788681704126 HIT: 0.6089786305147059
Epoch: 208, plus 0 steps train_loss: 0.5413

#### test Acc: 0, NDCG: 0.34551166377532067 HIT: 0.5996897977941177

#### val Acc: 0, NDCG: 0.34554589062447033 HIT: 0.6010857077205882
Epoch: 224, plus 0 steps train_loss: 0.5648

#### test Acc: 0, NDCG: 0.34608172003189025 HIT: 0.6038488051470587

#### val Acc: 0, NDCG: 0.35650235151272913 HIT: 0.6180893841911764
Epoch: 240, plus 0 steps train_loss: 0.5352

#### test Acc: 0, NDCG: 0.3635152142201452 HIT: 0.62197265625

#### val Acc: 0, NDCG: 0.36632335393290816 HIT: 0.62529296875
Epoch: 256, plus 0 steps train_loss: 0.5398

#### test Acc: 0, NDCG: 0.3708776274335845 HIT: 0.6293083639705882

#### val Acc: 0, NDCG: 0.3689988316930014 HIT: 0.6238511029411764
Epoch: 272, plus 0 steps train_loss: 0.5292

#### test Acc: 0, NDCG: 0.3649578796509206 HIT: 0.6110179227941177

#### val Acc: 0, NDCG: 0.3667683855801732 HIT: 0.6189912683823529
Epoch: 288, plus 0 steps train_loss: 0.5303

#### test Acc: 0, NDCG: 0.36610944002808005 HIT: 0.6181985294117647

#### val Acc: 0, NDCG: 0.37199150178953155 HIT: 0.6246553308823529
Epoch: 304, plus 0 steps train_loss: 0.5363

#### test Acc: 0, NDCG: 0.3806438107660903 HIT: 0.6299172794117647

#### val Acc: 0, NDCG: 0.3793617034532153 HIT: 0.6363223805147059
Epoch: 320, plus 0 steps train_loss: 0.5101

#### test Acc: 0, NDCG: 0.37956068155716716 HIT: 0.6349379595588236

#### val Acc: 0, NDCG: 0.38527109234442103 HIT: 0.6422564338235295
Epoch: 352, plus 0 steps train_loss: 0.5123

#### test Acc: 0, NDCG: 0.37764697840595685 HIT: 0.6263384650735294

#### val Acc: 0, NDCG: 0.3854592071000926 HIT: 0.6434283088235294
Epoch: 384, plus 0 steps train_loss: 0.5164

#### test Acc: 0, NDCG: 0.38579488820817637 HIT: 0.6377182904411764

#### val Acc: 0, NDCG: 0.3896967884765871 HIT: 0.6473460477941176
Epoch: 416, plus 0 steps train_loss: 0.5007

#### test Acc: 0, NDCG: 0.3771202972104136 HIT: 0.6349609375

#### val Acc: 0, NDCG: 0.3879414899961161 HIT: 0.6455365349264706
Epoch: 448, plus 0 steps train_loss: 0.5043

#### test Acc: 0, NDCG: 0.3784892422330569 HIT: 0.6244370404411764

#### val Acc: 0, NDCG: 0.3940029049013697 HIT: 0.6515682444852942
Epoch: 480, plus 0 steps train_loss: 0.4802

#### test Acc: 0, NDCG: 0.38616688855447434 HIT: 0.6353975183823529

#### val Acc: 0, NDCG: 0.3941951973538116 HIT: 0.6434340533088235
Epoch: 512, plus 0 steps train_loss: 0.4997

#### test Acc: 0, NDCG: 0.39363839338132844 HIT: 0.6448414522058823

#### val Acc: 0, NDCG: 0.3961078246907165 HIT: 0.6513269761029412
Epoch: 544, plus 0 steps train_loss: 0.4827

#### test Acc: 0, NDCG: 0.38387355101382786 HIT: 0.6295783547794118

#### val Acc: 0, NDCG: 0.3959116295388517 HIT: 0.6471105238970588
Epoch: 576, plus 0 steps train_loss: 0.465

#### test Acc: 0, NDCG: 0.39245590039632733 HIT: 0.6334903492647059

#### val Acc: 0, NDCG: 0.40010610603742425 HIT: 0.6500517003676471
Epoch: 608, plus 0 steps train_loss: 0.4572

#### test Acc: 0, NDCG: 0.3901889258084873 HIT: 0.6328182444852941

#### val Acc: 0, NDCG: 0.40298310855510316 HIT: 0.6516256893382353
Epoch: 640, plus 0 steps train_loss: 0.4842

#### test Acc: 0, NDCG: 0.39332212483166046 HIT: 0.6375229779411764

#### val Acc: 0, NDCG: 0.4079927991880912 HIT: 0.6559397977941177
Epoch: 704, plus 0 steps train_loss: 0.4789

#### test Acc: 0, NDCG: 0.3915235166567821 HIT: 0.6365119485294117

#### val Acc: 0, NDCG: 0.3937673908122561 HIT: 0.6388786764705883
Epoch: 768, plus 0 steps train_loss: 0.4716

#### test Acc: 0, NDCG: 0.3947057337216925 HIT: 0.6388959099264706

#### val Acc: 0, NDCG: 0.40178187994697934 HIT: 0.6484949448529412
Epoch: 832, plus 0 steps train_loss: 0.4601

#### test Acc: 0, NDCG: 0.39934734662393084 HIT: 0.6406824448529412

#### val Acc: 0, NDCG: 0.40237221896774233 HIT: 0.6541704963235294
Epoch: 896, plus 0 steps train_loss: 0.464

#### test Acc: 0, NDCG: 0.398767646786448 HIT: 0.6403722426470588

#### val Acc: 0, NDCG: 0.40227220594635005 HIT: 0.6504997702205882
Epoch: 960, plus 0 steps train_loss: 0.4471

#### test Acc: 0, NDCG: 0.3919022436273979 HIT: 0.6337948069852941

#### val Acc: 0, NDCG: 0.4050612072244049 HIT: 0.6545496323529412
Epoch: 1013, plus 25 steps train_loss: 0.4631
Done: it took 275316.9189386368
max value of NDCG: 0.39934734662393084
max value of HIT: 0.6448414522058823

After 20 validations
max value of NDCG: 0.39934734662393084
max value of HIT: 0.6448414522058823
