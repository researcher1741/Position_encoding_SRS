 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	0.1
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13102447145077165 HIT: 0.2868795955882353

#### val Acc: 0, NDCG: 0.1286135979971666 HIT: 0.2848115808823529
Epoch: 1, plus 0 steps train_loss: 0.7447

#### test Acc: 0, NDCG: 0.14059211837354366 HIT: 0.3109030330882353

#### val Acc: 0, NDCG: 0.13233710974174043 HIT: 0.2930319393382353
Epoch: 2, plus 0 steps train_loss: 0.7357

#### test Acc: 0, NDCG: 0.1265475241419941 HIT: 0.28566176470588234

#### val Acc: 0, NDCG: 0.1259218986075435 HIT: 0.28232421875
Epoch: 3, plus 0 steps train_loss: 0.7292

#### test Acc: 0, NDCG: 0.11507496266715697 HIT: 0.25639935661764707

#### val Acc: 0, NDCG: 0.11474947573328345 HIT: 0.2598403033088236
Epoch: 4, plus 0 steps train_loss: 0.7222

#### test Acc: 0, NDCG: 0.1317904451273558 HIT: 0.2914751838235294

#### val Acc: 0, NDCG: 0.1352919867122228 HIT: 0.2974896599264706
Epoch: 5, plus 0 steps train_loss: 0.7161

#### test Acc: 0, NDCG: 0.13298879373122882 HIT: 0.2888614430147059

#### val Acc: 0, NDCG: 0.1292990415642361 HIT: 0.28832146139705883
Epoch: 6, plus 0 steps train_loss: 0.7113

#### test Acc: 0, NDCG: 0.1507312960765535 HIT: 0.3121438419117647

#### val Acc: 0, NDCG: 0.1741665911544764 HIT: 0.3455595128676471
Epoch: 7, plus 0 steps train_loss: 0.71

#### test Acc: 0, NDCG: 0.13974426701682385 HIT: 0.29978745404411766

#### val Acc: 0, NDCG: 0.14895158500743919 HIT: 0.31052964154411766
Epoch: 8, plus 0 steps train_loss: 0.7061

#### test Acc: 0, NDCG: 0.1441601899916661 HIT: 0.3069221047794118

#### val Acc: 0, NDCG: 0.14486235844856576 HIT: 0.3047679227941177
Epoch: 9, plus 0 steps train_loss: 0.7069

#### test Acc: 0, NDCG: 0.15355216308749822 HIT: 0.32214499080882353

#### val Acc: 0, NDCG: 0.15270300235351905 HIT: 0.3170955882352941
Epoch: 10, plus 0 steps train_loss: 0.7058

#### test Acc: 0, NDCG: 0.16571769822667326 HIT: 0.33371438419117644

#### val Acc: 0, NDCG: 0.1695112701455072 HIT: 0.34161879595588235
Epoch: 12, plus 0 steps train_loss: 0.7033

#### test Acc: 0, NDCG: 0.2404685534075071 HIT: 0.4136086856617647

#### val Acc: 0, NDCG: 0.25875930554004867 HIT: 0.43463924632352946
Epoch: 14, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.19020395325041947 HIT: 0.3702493106617647

#### val Acc: 0, NDCG: 0.19711114063986523 HIT: 0.37236328125
Epoch: 16, plus 0 steps train_loss: 0.7029

#### test Acc: 0, NDCG: 0.19788441310867316 HIT: 0.39387063419117646

#### val Acc: 0, NDCG: 0.20957672858759838 HIT: 0.40927734375
Epoch: 18, plus 0 steps train_loss: 0.698

#### test Acc: 0, NDCG: 0.2117751552109411 HIT: 0.39295151654411764

#### val Acc: 0, NDCG: 0.22471275087218162 HIT: 0.4050666360294118
Epoch: 20, plus 0 steps train_loss: 0.6937

#### test Acc: 0, NDCG: 0.3054080748346015 HIT: 0.4835363051470588

#### val Acc: 0, NDCG: 0.32568462762764605 HIT: 0.4978573069852941
Epoch: 22, plus 0 steps train_loss: 0.689

#### test Acc: 0, NDCG: 0.3942251582678022 HIT: 0.5606617647058824

#### val Acc: 0, NDCG: 0.4198958117530287 HIT: 0.5816865808823529
Epoch: 24, plus 0 steps train_loss: 0.6931

#### test Acc: 0, NDCG: 0.37756706405503 HIT: 0.5510684742647058

#### val Acc: 0, NDCG: 0.39584477478082103 HIT: 0.5609375
Epoch: 26, plus 0 steps train_loss: 0.6915

#### test Acc: 0, NDCG: 0.2656440836182671 HIT: 0.45978285845588235

#### val Acc: 0, NDCG: 0.2837423553334554 HIT: 0.46897977941176466
Epoch: 28, plus 0 steps train_loss: 0.6745

#### test Acc: 0, NDCG: 0.2070948207977204 HIT: 0.40748506433823534

#### val Acc: 0, NDCG: 0.21577719225791547 HIT: 0.41159811580882355
Epoch: 30, plus 0 steps train_loss: 0.6777

#### test Acc: 0, NDCG: 0.22036798328051002 HIT: 0.4292796415441177

#### val Acc: 0, NDCG: 0.23494699226348792 HIT: 0.4510282628676471
Epoch: 32, plus 0 steps train_loss: 0.6719

#### test Acc: 0, NDCG: 0.20794656587936772 HIT: 0.4210477941176471

#### val Acc: 0, NDCG: 0.20947325543228548 HIT: 0.4239717371323529
Epoch: 36, plus 0 steps train_loss: 0.658

#### test Acc: 0, NDCG: 0.26476811227049357 HIT: 0.4954044117647059

#### val Acc: 0, NDCG: 0.2685995249663168 HIT: 0.48840188419117647
Epoch: 40, plus 0 steps train_loss: 0.6677

#### test Acc: 0, NDCG: 0.25019551053947464 HIT: 0.47130055147058825

#### val Acc: 0, NDCG: 0.2703480148992726 HIT: 0.49074563419117645
Epoch: 44, plus 0 steps train_loss: 0.6548

#### test Acc: 0, NDCG: 0.23576328936547722 HIT: 0.46494140625

#### val Acc: 0, NDCG: 0.2333814161038799 HIT: 0.4556410845588236
Epoch: 48, plus 0 steps train_loss: 0.6528

#### test Acc: 0, NDCG: 0.261662828804183 HIT: 0.4932559742647059

#### val Acc: 0, NDCG: 0.26969180355710476 HIT: 0.49704159007352944
Epoch: 52, plus 0 steps train_loss: 0.6466

#### test Acc: 0, NDCG: 0.23777563826855194 HIT: 0.4580135569852941

#### val Acc: 0, NDCG: 0.25506112186693575 HIT: 0.4739832261029412
Epoch: 56, plus 0 steps train_loss: 0.6501

#### test Acc: 0, NDCG: 0.24593891199249523 HIT: 0.46767003676470587

#### val Acc: 0, NDCG: 0.2473911135722305 HIT: 0.45728975183823534
Epoch: 60, plus 0 steps train_loss: 0.6313

#### test Acc: 0, NDCG: 0.2526851205857198 HIT: 0.4707778033088236

#### val Acc: 0, NDCG: 0.25753421653283187 HIT: 0.4781192555147059
Epoch: 64, plus 0 steps train_loss: 0.6384

#### test Acc: 0, NDCG: 0.26797642567041535 HIT: 0.48377182904411764

#### val Acc: 0, NDCG: 0.27542349873079763 HIT: 0.48936695772058825
Epoch: 68, plus 0 steps train_loss: 0.6286

#### test Acc: 0, NDCG: 0.2663015325831533 HIT: 0.4730698529411764

#### val Acc: 0, NDCG: 0.2773479109726914 HIT: 0.4790153952205882
Epoch: 72, plus 0 steps train_loss: 0.6375

#### test Acc: 0, NDCG: 0.27985467029897737 HIT: 0.47877412683823534

#### val Acc: 0, NDCG: 0.29403871423613165 HIT: 0.4971622242647059
Epoch: 80, plus 0 steps train_loss: 0.6153

#### test Acc: 0, NDCG: 0.2849063169567835 HIT: 0.4874425551470588

#### val Acc: 0, NDCG: 0.3017239185712653 HIT: 0.4997644761029412
Epoch: 88, plus 0 steps train_loss: 0.5827

#### test Acc: 0, NDCG: 0.28975331428821616 HIT: 0.48948759191176466

#### val Acc: 0, NDCG: 0.3134631638073922 HIT: 0.5153722426470588
Epoch: 96, plus 0 steps train_loss: 0.5716

#### test Acc: 0, NDCG: 0.3024135253256771 HIT: 0.49513442095588234

#### val Acc: 0, NDCG: 0.3148486589188647 HIT: 0.5103860294117647
Epoch: 104, plus 0 steps train_loss: 0.5688

#### test Acc: 0, NDCG: 0.2963502695909139 HIT: 0.4855066636029412

#### val Acc: 0, NDCG: 0.3169124324088383 HIT: 0.5081227022058823
Epoch: 112, plus 0 steps train_loss: 0.544

#### test Acc: 0, NDCG: 0.2827815903110693 HIT: 0.4664751838235294

#### val Acc: 0, NDCG: 0.3079407226914694 HIT: 0.49708754595588234
Epoch: 120, plus 0 steps train_loss: 0.5405

#### test Acc: 0, NDCG: 0.3090395662071316 HIT: 0.49681181066176466

#### val Acc: 0, NDCG: 0.31993422636459706 HIT: 0.5094898897058824
Epoch: 128, plus 0 steps train_loss: 0.5589

#### test Acc: 0, NDCG: 0.3139801286023842 HIT: 0.4991613051470588

#### val Acc: 0, NDCG: 0.32223675180844336 HIT: 0.5141716452205882
Epoch: 136, plus 0 steps train_loss: 0.5272

#### test Acc: 0, NDCG: 0.3038821356539348 HIT: 0.4897001378676471

#### val Acc: 0, NDCG: 0.321938034470497 HIT: 0.5089384191176471
Epoch: 144, plus 0 steps train_loss: 0.537

#### test Acc: 0, NDCG: 0.29951384943251363 HIT: 0.4904469209558823

#### val Acc: 0, NDCG: 0.3123541841550891 HIT: 0.5102998621323529
Epoch: 160, plus 0 steps train_loss: 0.5382

#### test Acc: 0, NDCG: 0.3029471831729768 HIT: 0.49940257352941175

#### val Acc: 0, NDCG: 0.31153540834021887 HIT: 0.5096162683823529
Epoch: 176, plus 0 steps train_loss: 0.5351

#### test Acc: 0, NDCG: 0.3002271353737414 HIT: 0.48426011029411764

#### val Acc: 0, NDCG: 0.31360321991879153 HIT: 0.5076688878676471
Epoch: 192, plus 0 steps train_loss: 0.5269

#### test Acc: 0, NDCG: 0.30776269896172803 HIT: 0.5022001378676471

#### val Acc: 0, NDCG: 0.321019136829319 HIT: 0.5254825367647059
Epoch: 208, plus 0 steps train_loss: 0.5338

#### test Acc: 0, NDCG: 0.3161528542306052 HIT: 0.5099034926470588

#### val Acc: 0, NDCG: 0.31864168516343955 HIT: 0.5165211397058823
Epoch: 224, plus 0 steps train_loss: 0.5129

#### test Acc: 0, NDCG: 0.31698103312527626 HIT: 0.5080193014705883

#### val Acc: 0, NDCG: 0.32598374490927934 HIT: 0.5188017003676471
Epoch: 240, plus 0 steps train_loss: 0.5093

#### test Acc: 0, NDCG: 0.31317822530176354 HIT: 0.49920151654411765

#### val Acc: 0, NDCG: 0.3227601927736216 HIT: 0.5140797334558823
Epoch: 256, plus 0 steps train_loss: 0.5043

#### test Acc: 0, NDCG: 0.3228754942041696 HIT: 0.5194910386029412

#### val Acc: 0, NDCG: 0.34225823492754903 HIT: 0.5452263327205882
Epoch: 272, plus 0 steps train_loss: 0.4986

#### test Acc: 0, NDCG: 0.32565443610349815 HIT: 0.5137063419117647

#### val Acc: 0, NDCG: 0.34740336742500866 HIT: 0.5419404871323529
Epoch: 288, plus 0 steps train_loss: 0.4923

#### test Acc: 0, NDCG: 0.3274048652984217 HIT: 0.5126665900735294

#### val Acc: 0, NDCG: 0.33568108422641646 HIT: 0.5260167738970588
Epoch: 304, plus 0 steps train_loss: 0.4868

#### test Acc: 0, NDCG: 0.33024102780164155 HIT: 0.5112362132352941

#### val Acc: 0, NDCG: 0.347238347351744 HIT: 0.5329388786764706
Epoch: 320, plus 0 steps train_loss: 0.4935

#### test Acc: 0, NDCG: 0.33382446144395794 HIT: 0.5219037224264705

#### val Acc: 0, NDCG: 0.33560498895636776 HIT: 0.5212316176470588
Epoch: 352, plus 0 steps train_loss: 0.4784

#### test Acc: 0, NDCG: 0.3361237845198951 HIT: 0.5140567555147059

#### val Acc: 0, NDCG: 0.34392973738555965 HIT: 0.5310489430147058
Epoch: 384, plus 0 steps train_loss: 0.475

#### test Acc: 0, NDCG: 0.3306622319024534 HIT: 0.5095818014705882

#### val Acc: 0, NDCG: 0.34770792003541456 HIT: 0.5396541819852941
Epoch: 416, plus 0 steps train_loss: 0.4818

#### test Acc: 0, NDCG: 0.345476918271112 HIT: 0.5254940257352941

#### val Acc: 0, NDCG: 0.34758296724303545 HIT: 0.5323759191176471
Epoch: 448, plus 0 steps train_loss: 0.4665

#### test Acc: 0, NDCG: 0.3355613999688172 HIT: 0.5164464613970587

#### val Acc: 0, NDCG: 0.33857819131152556 HIT: 0.5249770220588236
Epoch: 480, plus 0 steps train_loss: 0.4523

#### test Acc: 0, NDCG: 0.3308556109395999 HIT: 0.50947265625

#### val Acc: 0, NDCG: 0.35072068281869256 HIT: 0.5381606158088236
Epoch: 512, plus 0 steps train_loss: 0.4662

#### test Acc: 0, NDCG: 0.3349451687591357 HIT: 0.5123678768382354

#### val Acc: 0, NDCG: 0.3416565314795056 HIT: 0.5214556525735294
Epoch: 544, plus 0 steps train_loss: 0.4552

#### test Acc: 0, NDCG: 0.3348331675283539 HIT: 0.5185719209558823

#### val Acc: 0, NDCG: 0.3473305908159515 HIT: 0.5311063878676471
Epoch: 576, plus 0 steps train_loss: 0.4386

#### test Acc: 0, NDCG: 0.33683560551496244 HIT: 0.5162626378676471

#### val Acc: 0, NDCG: 0.349623715307557 HIT: 0.5324448529411765
Epoch: 608, plus 0 steps train_loss: 0.4447

#### test Acc: 0, NDCG: 0.3513579787903739 HIT: 0.5301872702205882

#### val Acc: 0, NDCG: 0.35535580007887335 HIT: 0.53994140625
Epoch: 640, plus 0 steps train_loss: 0.4549

#### test Acc: 0, NDCG: 0.34129003149050907 HIT: 0.51904296875

#### val Acc: 0, NDCG: 0.35617862932158023 HIT: 0.5445657169117647
Epoch: 704, plus 0 steps train_loss: 0.4564

#### test Acc: 0, NDCG: 0.35142488381568665 HIT: 0.5350241268382353

#### val Acc: 0, NDCG: 0.35738914218727497 HIT: 0.5431123621323529
Epoch: 768, plus 0 steps train_loss: 0.4417

#### test Acc: 0, NDCG: 0.33750264733634044 HIT: 0.5192612591911765

#### val Acc: 0, NDCG: 0.3514513454537854 HIT: 0.5346622242647059
Epoch: 832, plus 0 steps train_loss: 0.4235

#### test Acc: 0, NDCG: 0.34612648378575905 HIT: 0.5267750459558823

#### val Acc: 0, NDCG: 0.3555889832632584 HIT: 0.5412396599264706
Epoch: 896, plus 0 steps train_loss: 0.4348

#### test Acc: 0, NDCG: 0.34544701304012015 HIT: 0.5211339613970588

#### val Acc: 0, NDCG: 0.36050034501841793 HIT: 0.5414349724264705
Epoch: 960, plus 0 steps train_loss: 0.4266

#### test Acc: 0, NDCG: 0.3432396160868717 HIT: 0.5229721966911764

#### val Acc: 0, NDCG: 0.3627482071305861 HIT: 0.5472943474264705
Epoch: 1013, plus 25 steps train_loss: 0.3985
Done: it took 285689.32792139053
max value of NDCG: 0.3942251582678022
max value of HIT: 0.5606617647058824

After 20 validations
max value of NDCG: 0.35142488381568665
max value of HIT: 0.5350241268382353
