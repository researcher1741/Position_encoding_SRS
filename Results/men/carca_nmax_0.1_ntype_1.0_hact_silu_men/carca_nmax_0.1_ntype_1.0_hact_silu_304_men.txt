 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	1.0
max_norm:             	0.1
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.1339088201014728 HIT: 0.29370404411764706

#### val Acc: 0, NDCG: 0.136450527495044 HIT: 0.29814453125
Epoch: 1, plus 0 steps train_loss: 0.7342

#### test Acc: 0, NDCG: 0.1392583724107354 HIT: 0.3013671875

#### val Acc: 0, NDCG: 0.13413307303322686 HIT: 0.29528952205882353
Epoch: 2, plus 0 steps train_loss: 0.7327

#### test Acc: 0, NDCG: 0.1290025513152942 HIT: 0.2845243566176471

#### val Acc: 0, NDCG: 0.1306788429808529 HIT: 0.2914119944852941
Epoch: 3, plus 0 steps train_loss: 0.7274

#### test Acc: 0, NDCG: 0.1375706182795314 HIT: 0.30126953125

#### val Acc: 0, NDCG: 0.13405066096449086 HIT: 0.29196920955882355
Epoch: 4, plus 0 steps train_loss: 0.7199

#### test Acc: 0, NDCG: 0.13460529059904308 HIT: 0.2958697150735294

#### val Acc: 0, NDCG: 0.1371990849423697 HIT: 0.2972828584558823
Epoch: 5, plus 0 steps train_loss: 0.7114

#### test Acc: 0, NDCG: 0.13549117787096246 HIT: 0.29613970588235294

#### val Acc: 0, NDCG: 0.13787823186136247 HIT: 0.2966509650735294
Epoch: 6, plus 0 steps train_loss: 0.7125

#### test Acc: 0, NDCG: 0.15377969739905945 HIT: 0.3132869944852941

#### val Acc: 0, NDCG: 0.16295673282053658 HIT: 0.32026654411764705
Epoch: 7, plus 0 steps train_loss: 0.7065

#### test Acc: 0, NDCG: 0.15156549535348482 HIT: 0.31140280330882353

#### val Acc: 0, NDCG: 0.15798291152425042 HIT: 0.3195657169117647
Epoch: 8, plus 0 steps train_loss: 0.7055

#### test Acc: 0, NDCG: 0.216753484879486 HIT: 0.38216911764705885

#### val Acc: 0, NDCG: 0.2372484437105368 HIT: 0.3986960018382353
Epoch: 9, plus 0 steps train_loss: 0.7031

#### test Acc: 0, NDCG: 0.17269211775137694 HIT: 0.33464499080882354

#### val Acc: 0, NDCG: 0.1829930937786462 HIT: 0.3495404411764706
Epoch: 10, plus 0 steps train_loss: 0.7049

#### test Acc: 0, NDCG: 0.3761794890288581 HIT: 0.5321576286764705

#### val Acc: 0, NDCG: 0.38530070045237047 HIT: 0.5352768841911765
Epoch: 12, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.38858861925227406 HIT: 0.5334903492647058

#### val Acc: 0, NDCG: 0.40567628969157354 HIT: 0.5446576286764706
Epoch: 14, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.28310061620085214 HIT: 0.44281364889705876

#### val Acc: 0, NDCG: 0.30010896844018575 HIT: 0.45958180147058825
Epoch: 16, plus 0 steps train_loss: 0.7009

#### test Acc: 0, NDCG: 0.5906477396445572 HIT: 0.6995921415441176

#### val Acc: 0, NDCG: 0.6013826611222015 HIT: 0.7080710018382353
Epoch: 18, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.5121011257167988 HIT: 0.6401769301470588

#### val Acc: 0, NDCG: 0.5005804551929964 HIT: 0.6288028492647059
Epoch: 20, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.40345928705599005 HIT: 0.5531709558823529

#### val Acc: 0, NDCG: 0.40845268362251586 HIT: 0.5570829503676471
Epoch: 22, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.47629776718866446 HIT: 0.6193589154411765

#### val Acc: 0, NDCG: 0.47756840530887484 HIT: 0.6167049632352941
Epoch: 24, plus 0 steps train_loss: 0.6925

#### test Acc: 0, NDCG: 0.3032243682315984 HIT: 0.4907341452205882

#### val Acc: 0, NDCG: 0.3058686247815595 HIT: 0.49224494485294124
Epoch: 26, plus 0 steps train_loss: 0.6858

#### test Acc: 0, NDCG: 0.25021346069575257 HIT: 0.4375746783088236

#### val Acc: 0, NDCG: 0.26229797752981504 HIT: 0.4421300551470588
Epoch: 28, plus 0 steps train_loss: 0.6733

#### test Acc: 0, NDCG: 0.2885957466412554 HIT: 0.4671357996323529

#### val Acc: 0, NDCG: 0.30262088177301305 HIT: 0.47512637867647056
Epoch: 30, plus 0 steps train_loss: 0.6676

#### test Acc: 0, NDCG: 0.24803607698812474 HIT: 0.44065946691176466

#### val Acc: 0, NDCG: 0.2602364353860795 HIT: 0.45627872242647055
Epoch: 32, plus 0 steps train_loss: 0.6654

#### test Acc: 0, NDCG: 0.22944486912990994 HIT: 0.4255687040441177

#### val Acc: 0, NDCG: 0.2366122882567284 HIT: 0.4369772518382353
Epoch: 36, plus 0 steps train_loss: 0.6632

#### test Acc: 0, NDCG: 0.2283239286322481 HIT: 0.4341337316176471

#### val Acc: 0, NDCG: 0.22870717616169398 HIT: 0.4348058363970588
Epoch: 40, plus 0 steps train_loss: 0.6596

#### test Acc: 0, NDCG: 0.23531012187137165 HIT: 0.4396656709558823

#### val Acc: 0, NDCG: 0.23874973487699705 HIT: 0.4397346047794118
Epoch: 44, plus 0 steps train_loss: 0.6604

#### test Acc: 0, NDCG: 0.24410935200963085 HIT: 0.45387178308823534

#### val Acc: 0, NDCG: 0.2586158077203062 HIT: 0.4698529411764706
Epoch: 48, plus 0 steps train_loss: 0.6566

#### test Acc: 0, NDCG: 0.24606028353427062 HIT: 0.4580078125

#### val Acc: 0, NDCG: 0.2583174735681909 HIT: 0.47462660845588234
Epoch: 52, plus 0 steps train_loss: 0.6556

#### test Acc: 0, NDCG: 0.2535371352045924 HIT: 0.4691636029411764

#### val Acc: 0, NDCG: 0.2683751065116459 HIT: 0.48517348345588235
Epoch: 56, plus 0 steps train_loss: 0.6445

#### test Acc: 0, NDCG: 0.25733055797460624 HIT: 0.4762120863970588

#### val Acc: 0, NDCG: 0.26596932998726713 HIT: 0.4821403952205882
Epoch: 60, plus 0 steps train_loss: 0.6311

#### test Acc: 0, NDCG: 0.2743592730922809 HIT: 0.48630514705882355

#### val Acc: 0, NDCG: 0.28704345299004114 HIT: 0.5064797794117647
Epoch: 64, plus 0 steps train_loss: 0.6424

#### test Acc: 0, NDCG: 0.26476948471927353 HIT: 0.4820886948529412

#### val Acc: 0, NDCG: 0.2785105246748011 HIT: 0.5020909926470588
Epoch: 68, plus 0 steps train_loss: 0.6268

#### test Acc: 0, NDCG: 0.2753070454736247 HIT: 0.4915728400735294

#### val Acc: 0, NDCG: 0.28125046524891 HIT: 0.49040670955882354
Epoch: 72, plus 0 steps train_loss: 0.628

#### test Acc: 0, NDCG: 0.27245849406082423 HIT: 0.4965418198529412

#### val Acc: 0, NDCG: 0.2808102431421288 HIT: 0.49766773897058825
Epoch: 80, plus 0 steps train_loss: 0.6111

#### test Acc: 0, NDCG: 0.30114682786241065 HIT: 0.5138786764705883

#### val Acc: 0, NDCG: 0.30742857641360255 HIT: 0.5127412683823529
Epoch: 88, plus 0 steps train_loss: 0.5994

#### test Acc: 0, NDCG: 0.28849931171329335 HIT: 0.49570886948529413

#### val Acc: 0, NDCG: 0.30331275056096396 HIT: 0.5061982996323529
Epoch: 96, plus 0 steps train_loss: 0.5832

#### test Acc: 0, NDCG: 0.30344261624019964 HIT: 0.5139188878676471

#### val Acc: 0, NDCG: 0.31969686799070157 HIT: 0.5219439338235294
Epoch: 104, plus 0 steps train_loss: 0.5723

#### test Acc: 0, NDCG: 0.2939874230261625 HIT: 0.5016256893382354

#### val Acc: 0, NDCG: 0.30304317254931595 HIT: 0.5094094669117647
Epoch: 112, plus 0 steps train_loss: 0.5673

#### test Acc: 0, NDCG: 0.30951028954688703 HIT: 0.5120346966911764

#### val Acc: 0, NDCG: 0.3285847534461172 HIT: 0.5309685202205883
Epoch: 120, plus 0 steps train_loss: 0.552

#### test Acc: 0, NDCG: 0.3108901359015575 HIT: 0.5049287683823529

#### val Acc: 0, NDCG: 0.3231593284084185 HIT: 0.5201114430147059
Epoch: 128, plus 0 steps train_loss: 0.5665

#### test Acc: 0, NDCG: 0.31034020927822203 HIT: 0.49766773897058825

#### val Acc: 0, NDCG: 0.3249236406163085 HIT: 0.5120059742647058
Epoch: 136, plus 0 steps train_loss: 0.543

#### test Acc: 0, NDCG: 0.3057067623035395 HIT: 0.4960133272058823

#### val Acc: 0, NDCG: 0.325090552150839 HIT: 0.5201286764705882
Epoch: 144, plus 0 steps train_loss: 0.5519

#### test Acc: 0, NDCG: 0.3091623137079704 HIT: 0.4993106617647059

#### val Acc: 0, NDCG: 0.3267269726625551 HIT: 0.5166302849264706
Epoch: 160, plus 0 steps train_loss: 0.5249

#### test Acc: 0, NDCG: 0.32007746559257616 HIT: 0.5102136948529412

#### val Acc: 0, NDCG: 0.3294955506535041 HIT: 0.5271829044117646
Epoch: 176, plus 0 steps train_loss: 0.5382

#### test Acc: 0, NDCG: 0.3214628548567263 HIT: 0.5111960018382353

#### val Acc: 0, NDCG: 0.3367217509818915 HIT: 0.5318761488970588
Epoch: 192, plus 0 steps train_loss: 0.5081

#### test Acc: 0, NDCG: 0.3298191138953446 HIT: 0.5172736672794118

#### val Acc: 0, NDCG: 0.33885693179799276 HIT: 0.5280962775735294
Epoch: 208, plus 0 steps train_loss: 0.4986

#### test Acc: 0, NDCG: 0.33369273815733896 HIT: 0.5298253676470588

#### val Acc: 0, NDCG: 0.34493095085922854 HIT: 0.5478400735294118
Epoch: 224, plus 0 steps train_loss: 0.5

#### test Acc: 0, NDCG: 0.33222018027855477 HIT: 0.5189682904411764

#### val Acc: 0, NDCG: 0.3490137683099338 HIT: 0.5480353860294118
Epoch: 240, plus 0 steps train_loss: 0.4987

#### test Acc: 0, NDCG: 0.33633332310592723 HIT: 0.54140625

#### val Acc: 0, NDCG: 0.337443648695125 HIT: 0.5480526194852942
Epoch: 256, plus 0 steps train_loss: 0.4916

#### test Acc: 0, NDCG: 0.3355953396579333 HIT: 0.5361443014705882

#### val Acc: 0, NDCG: 0.3488234636755859 HIT: 0.5562959558823529
Epoch: 272, plus 0 steps train_loss: 0.4925

#### test Acc: 0, NDCG: 0.33996419777232634 HIT: 0.5365176930147059

#### val Acc: 0, NDCG: 0.3485948052251563 HIT: 0.5576459099264706
Epoch: 288, plus 0 steps train_loss: 0.4912

#### test Acc: 0, NDCG: 0.3372609039735882 HIT: 0.5443474264705882

#### val Acc: 0, NDCG: 0.35700942376853473 HIT: 0.5724207261029413
Epoch: 304, plus 0 steps train_loss: 0.4857

#### test Acc: 0, NDCG: 0.33993463122721923 HIT: 0.5505284926470588

#### val Acc: 0, NDCG: 0.35985385790111507 HIT: 0.5696461397058823
Epoch: 320, plus 0 steps train_loss: 0.4779

#### test Acc: 0, NDCG: 0.34128859376062254 HIT: 0.5426355698529413

#### val Acc: 0, NDCG: 0.3537507852261348 HIT: 0.5630514705882353
Epoch: 352, plus 0 steps train_loss: 0.486

#### test Acc: 0, NDCG: 0.34678846967534904 HIT: 0.5488625919117647

#### val Acc: 0, NDCG: 0.362546238956914 HIT: 0.5751436121323529
Epoch: 384, plus 0 steps train_loss: 0.4593

#### test Acc: 0, NDCG: 0.34646883596258815 HIT: 0.5433249080882353

#### val Acc: 0, NDCG: 0.36293512399714883 HIT: 0.5749712775735294
Epoch: 416, plus 0 steps train_loss: 0.464

#### test Acc: 0, NDCG: 0.3366512120146737 HIT: 0.5368566176470588

#### val Acc: 0, NDCG: 0.36082326162380585 HIT: 0.5640222886029412
Epoch: 448, plus 0 steps train_loss: 0.4553

#### test Acc: 0, NDCG: 0.3458582584546359 HIT: 0.5386603860294118

#### val Acc: 0, NDCG: 0.3563759385020698 HIT: 0.5602136948529413
Epoch: 480, plus 0 steps train_loss: 0.4624

#### test Acc: 0, NDCG: 0.3388128327346342 HIT: 0.5339786305147058

#### val Acc: 0, NDCG: 0.35506591719823666 HIT: 0.5563074448529413
Epoch: 512, plus 0 steps train_loss: 0.4501

#### test Acc: 0, NDCG: 0.35131587346269194 HIT: 0.5442784926470587

#### val Acc: 0, NDCG: 0.3628794344747037 HIT: 0.5579963235294118
Epoch: 544, plus 0 steps train_loss: 0.4366

#### test Acc: 0, NDCG: 0.3464333576957798 HIT: 0.5399586397058823

#### val Acc: 0, NDCG: 0.35533304930070087 HIT: 0.5576688878676471
Epoch: 576, plus 0 steps train_loss: 0.4418

#### test Acc: 0, NDCG: 0.3457211032176847 HIT: 0.5445886948529413

#### val Acc: 0, NDCG: 0.3640995228819507 HIT: 0.5600815716911764
Epoch: 608, plus 0 steps train_loss: 0.4368

#### test Acc: 0, NDCG: 0.3538173073946616 HIT: 0.5446748621323529

#### val Acc: 0, NDCG: 0.36175260064677983 HIT: 0.5584731158088235
Epoch: 640, plus 0 steps train_loss: 0.4382

#### test Acc: 0, NDCG: 0.3483054232998807 HIT: 0.5329733455882353

#### val Acc: 0, NDCG: 0.3636757397084682 HIT: 0.5485581341911765
Epoch: 704, plus 0 steps train_loss: 0.4242

#### test Acc: 0, NDCG: 0.3479850266322738 HIT: 0.5388212316176471

#### val Acc: 0, NDCG: 0.3635748065477448 HIT: 0.5501206341911764
Epoch: 768, plus 0 steps train_loss: 0.4264

#### test Acc: 0, NDCG: 0.3513609869140359 HIT: 0.5337718290441177

#### val Acc: 0, NDCG: 0.3691674726343156 HIT: 0.5584329044117646
Epoch: 832, plus 0 steps train_loss: 0.4178

#### test Acc: 0, NDCG: 0.35438924536687144 HIT: 0.5362189797794118

#### val Acc: 0, NDCG: 0.354342403933262 HIT: 0.5429170496323529
Epoch: 896, plus 0 steps train_loss: 0.4219

#### test Acc: 0, NDCG: 0.34548033422730356 HIT: 0.5275620404411765

#### val Acc: 0, NDCG: 0.3627075877224021 HIT: 0.5436925551470588
Epoch: 960, plus 0 steps train_loss: 0.404

#### test Acc: 0, NDCG: 0.3473215523888338 HIT: 0.5285615808823529

#### val Acc: 0, NDCG: 0.3599203248161043 HIT: 0.5438361672794118
Epoch: 1013, plus 25 steps train_loss: 0.4258
Done: it took 287326.73077249527
max value of NDCG: 0.5906477396445572
max value of HIT: 0.6995921415441176

After 20 validations
max value of NDCG: 0.35438924536687144
max value of HIT: 0.5505284926470588
