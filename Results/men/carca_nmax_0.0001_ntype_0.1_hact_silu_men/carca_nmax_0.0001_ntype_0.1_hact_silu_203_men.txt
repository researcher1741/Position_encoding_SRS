 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	0.0001
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12588737802003744 HIT: 0.2807674632352941

#### val Acc: 0, NDCG: 0.12771698855711897 HIT: 0.2787109375
Epoch: 1, plus 0 steps train_loss: 0.7561

#### test Acc: 0, NDCG: 0.13013489607334755 HIT: 0.28289866727941176

#### val Acc: 0, NDCG: 0.12485616076060244 HIT: 0.2733513327205882
Epoch: 2, plus 0 steps train_loss: 0.758

#### test Acc: 0, NDCG: 0.12443618851112515 HIT: 0.27899241727941176

#### val Acc: 0, NDCG: 0.12742854126376207 HIT: 0.27639016544117645
Epoch: 3, plus 0 steps train_loss: 0.745

#### test Acc: 0, NDCG: 0.13010714215780209 HIT: 0.28595473345588235

#### val Acc: 0, NDCG: 0.1276507998806061 HIT: 0.28247357536764706
Epoch: 4, plus 0 steps train_loss: 0.7428

#### test Acc: 0, NDCG: 0.12848255999555627 HIT: 0.2821576286764706

#### val Acc: 0, NDCG: 0.13291700614266805 HIT: 0.2901826746323529
Epoch: 5, plus 0 steps train_loss: 0.7389

#### test Acc: 0, NDCG: 0.1348878858463969 HIT: 0.29357766544117647

#### val Acc: 0, NDCG: 0.12951875487944825 HIT: 0.2856158088235294
Epoch: 6, plus 0 steps train_loss: 0.7345

#### test Acc: 0, NDCG: 0.13037247041441838 HIT: 0.2832835477941177

#### val Acc: 0, NDCG: 0.12729015865407795 HIT: 0.2808421415441177
Epoch: 7, plus 0 steps train_loss: 0.7243

#### test Acc: 0, NDCG: 0.1272104679763534 HIT: 0.27995174632352937

#### val Acc: 0, NDCG: 0.1297569119269109 HIT: 0.28405905330882353
Epoch: 8, plus 0 steps train_loss: 0.7203

#### test Acc: 0, NDCG: 0.12781504862444276 HIT: 0.28406479779411764

#### val Acc: 0, NDCG: 0.127057503972208 HIT: 0.28061236213235297
Epoch: 9, plus 0 steps train_loss: 0.725

#### test Acc: 0, NDCG: 0.13124332981952708 HIT: 0.28826401654411765

#### val Acc: 0, NDCG: 0.12580456940890442 HIT: 0.2802791819852941
Epoch: 10, plus 0 steps train_loss: 0.7203

#### test Acc: 0, NDCG: 0.13053118287510737 HIT: 0.28664407169117645

#### val Acc: 0, NDCG: 0.13300866880458911 HIT: 0.29425551470588235
Epoch: 12, plus 0 steps train_loss: 0.7208

#### test Acc: 0, NDCG: 0.13114555446247603 HIT: 0.2864085477941177

#### val Acc: 0, NDCG: 0.1258359950085658 HIT: 0.27976792279411766
Epoch: 14, plus 0 steps train_loss: 0.7136

#### test Acc: 0, NDCG: 0.12840698157210934 HIT: 0.28336397058823526

#### val Acc: 0, NDCG: 0.1270402269575179 HIT: 0.2793772977941177
Epoch: 16, plus 0 steps train_loss: 0.7095

#### test Acc: 0, NDCG: 0.12933296457124666 HIT: 0.2825137867647059

#### val Acc: 0, NDCG: 0.134334718649553 HIT: 0.29280790441176474
Epoch: 18, plus 0 steps train_loss: 0.7112

#### test Acc: 0, NDCG: 0.12858108582376926 HIT: 0.2843175551470588

#### val Acc: 0, NDCG: 0.1260455312188678 HIT: 0.2783203125
Epoch: 20, plus 0 steps train_loss: 0.708

#### test Acc: 0, NDCG: 0.1308221039390436 HIT: 0.28686810661764706

#### val Acc: 0, NDCG: 0.12672154538978014 HIT: 0.28253676470588235
Epoch: 22, plus 0 steps train_loss: 0.706

#### test Acc: 0, NDCG: 0.1293037235855773 HIT: 0.28402458639705885

#### val Acc: 0, NDCG: 0.13239794427636403 HIT: 0.2920036764705882
Epoch: 24, plus 0 steps train_loss: 0.7067

#### test Acc: 0, NDCG: 0.13063845250531406 HIT: 0.2858743106617647

#### val Acc: 0, NDCG: 0.1308192762574629 HIT: 0.2867130055147059
Epoch: 26, plus 0 steps train_loss: 0.7024

#### test Acc: 0, NDCG: 0.13254797526746195 HIT: 0.2895450367647059

#### val Acc: 0, NDCG: 0.1306651713488034 HIT: 0.28428308823529413
Epoch: 28, plus 0 steps train_loss: 0.703

#### test Acc: 0, NDCG: 0.12745633127944522 HIT: 0.28099724264705883

#### val Acc: 0, NDCG: 0.12719519786772354 HIT: 0.2820829503676471
Epoch: 30, plus 0 steps train_loss: 0.7023

#### test Acc: 0, NDCG: 0.13168390058132223 HIT: 0.2912281709558823

#### val Acc: 0, NDCG: 0.13169404965271955 HIT: 0.29007927389705884
Epoch: 32, plus 0 steps train_loss: 0.7029

#### test Acc: 0, NDCG: 0.13467650945157264 HIT: 0.29202665441176473

#### val Acc: 0, NDCG: 0.13415969782881187 HIT: 0.29447954963235295
Epoch: 36, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.13332525289478642 HIT: 0.2920496323529412

#### val Acc: 0, NDCG: 0.1267244622299984 HIT: 0.2835592830882353
Epoch: 40, plus 0 steps train_loss: 0.7007

#### test Acc: 0, NDCG: 0.12756525680768888 HIT: 0.2859432444852941

#### val Acc: 0, NDCG: 0.13648734216611833 HIT: 0.2971622242647059
Epoch: 44, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.1292030376556364 HIT: 0.2885857077205882

#### val Acc: 0, NDCG: 0.12813555006902658 HIT: 0.2799977022058823
Epoch: 48, plus 0 steps train_loss: 0.7007

#### test Acc: 0, NDCG: 0.12929317732203088 HIT: 0.2862706801470588

#### val Acc: 0, NDCG: 0.1321089359925788 HIT: 0.28992991727941175
Epoch: 52, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.12878678499815285 HIT: 0.28408203125

#### val Acc: 0, NDCG: 0.12954692228258402 HIT: 0.28540900735294117
Epoch: 56, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.12914233255561153 HIT: 0.2849494485294118

#### val Acc: 0, NDCG: 0.13153228584991009 HIT: 0.2880744485294118
Epoch: 60, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.12823439707742187 HIT: 0.28128446691176473

#### val Acc: 0, NDCG: 0.13384335089735036 HIT: 0.2903033088235294
Epoch: 64, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.1803078810316945 HIT: 0.3343405330882353

#### val Acc: 0, NDCG: 0.1961061681032849 HIT: 0.3500114889705882
Epoch: 68, plus 0 steps train_loss: 0.6985

#### test Acc: 0, NDCG: 0.21157691701055875 HIT: 0.36632008272058825

#### val Acc: 0, NDCG: 0.22669694879741034 HIT: 0.37641888786764705
Epoch: 72, plus 0 steps train_loss: 0.6969

#### test Acc: 0, NDCG: 0.3471584816348257 HIT: 0.4909122242647059

#### val Acc: 0, NDCG: 0.3644246874712312 HIT: 0.5055261948529413
Epoch: 80, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.4981351040630493 HIT: 0.6204503676470587

#### val Acc: 0, NDCG: 0.5104317976316445 HIT: 0.6312270220588235
Epoch: 88, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.5719851421141801 HIT: 0.6844267003676471

#### val Acc: 0, NDCG: 0.584472744999443 HIT: 0.6947208180147059
Epoch: 96, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.434749941984654 HIT: 0.569921875

#### val Acc: 0, NDCG: 0.44865658071208997 HIT: 0.5750229779411764
Epoch: 104, plus 0 steps train_loss: 0.6953

#### test Acc: 0, NDCG: 0.5997539108296044 HIT: 0.7093922334558823

#### val Acc: 0, NDCG: 0.6115821543064752 HIT: 0.7195255055147058
Epoch: 112, plus 0 steps train_loss: 0.6934

#### test Acc: 0, NDCG: 0.5865693592091803 HIT: 0.6947265625

#### val Acc: 0, NDCG: 0.6059618907482347 HIT: 0.7137178308823529
Epoch: 120, plus 0 steps train_loss: 0.6893

#### test Acc: 0, NDCG: 0.5374541480314616 HIT: 0.6523724724264706

#### val Acc: 0, NDCG: 0.5425421405700125 HIT: 0.6581341911764705
Epoch: 128, plus 0 steps train_loss: 0.6909

#### test Acc: 0, NDCG: 0.46987954870375787 HIT: 0.5956112132352941

#### val Acc: 0, NDCG: 0.4864019551818351 HIT: 0.6058363970588235
Epoch: 136, plus 0 steps train_loss: 0.6894

#### test Acc: 0, NDCG: 0.46799450031789663 HIT: 0.5971047794117647

#### val Acc: 0, NDCG: 0.4896759419969453 HIT: 0.6077837775735294
Epoch: 144, plus 0 steps train_loss: 0.6889

#### test Acc: 0, NDCG: 0.2883186175515161 HIT: 0.42535041360294124

#### val Acc: 0, NDCG: 0.31159580424187144 HIT: 0.4429227941176471
Epoch: 160, plus 0 steps train_loss: 0.6867

#### test Acc: 0, NDCG: 0.585871251014281 HIT: 0.6931181066176471

#### val Acc: 0, NDCG: 0.580310131286798 HIT: 0.6894875919117647
Epoch: 176, plus 0 steps train_loss: 0.6852

#### test Acc: 0, NDCG: 0.5410253694366025 HIT: 0.6660960477941177

#### val Acc: 0, NDCG: 0.5430913272593265 HIT: 0.6675551470588236
Epoch: 192, plus 0 steps train_loss: 0.6806

#### test Acc: 0, NDCG: 0.21822975953174323 HIT: 0.42458639705882356

#### val Acc: 0, NDCG: 0.23150343389872208 HIT: 0.4391027113970588
Epoch: 208, plus 0 steps train_loss: 0.6691

#### test Acc: 0, NDCG: 0.237607107355878 HIT: 0.4514705882352941

#### val Acc: 0, NDCG: 0.26172478871805077 HIT: 0.4764073988970588
Epoch: 224, plus 0 steps train_loss: 0.6638

#### test Acc: 0, NDCG: 0.24263861045120666 HIT: 0.4603975183823529

#### val Acc: 0, NDCG: 0.2436468013708319 HIT: 0.45163717830882355
Epoch: 240, plus 0 steps train_loss: 0.6557

#### test Acc: 0, NDCG: 0.25561286833248287 HIT: 0.47096737132352945

#### val Acc: 0, NDCG: 0.25412743859147285 HIT: 0.46526884191176465
Epoch: 256, plus 0 steps train_loss: 0.6489

#### test Acc: 0, NDCG: 0.2639326856481666 HIT: 0.47666015625

#### val Acc: 0, NDCG: 0.2751531015435617 HIT: 0.4895909926470588
Epoch: 272, plus 0 steps train_loss: 0.6427

#### test Acc: 0, NDCG: 0.27069896475281185 HIT: 0.4881261488970588

#### val Acc: 0, NDCG: 0.2799116674018963 HIT: 0.4944278492647059
Epoch: 288, plus 0 steps train_loss: 0.6481

#### test Acc: 0, NDCG: 0.2658291518183453 HIT: 0.4809053308823529

#### val Acc: 0, NDCG: 0.2733661110126929 HIT: 0.48768382352941175
Epoch: 304, plus 0 steps train_loss: 0.6378

#### test Acc: 0, NDCG: 0.2742862725176642 HIT: 0.4873851102941177

#### val Acc: 0, NDCG: 0.27865130074907624 HIT: 0.48821806066176465
Epoch: 320, plus 0 steps train_loss: 0.6312

#### test Acc: 0, NDCG: 0.2783108379904596 HIT: 0.49944278492647054

#### val Acc: 0, NDCG: 0.28324386082902164 HIT: 0.5020163143382353
Epoch: 352, plus 0 steps train_loss: 0.6354

#### test Acc: 0, NDCG: 0.2768881193810815 HIT: 0.4993221507352941

#### val Acc: 0, NDCG: 0.28589399858621095 HIT: 0.50107421875
Epoch: 384, plus 0 steps train_loss: 0.6313

#### test Acc: 0, NDCG: 0.2819663935293703 HIT: 0.5030445772058824

#### val Acc: 0, NDCG: 0.2866740318871465 HIT: 0.5103630514705882
Epoch: 416, plus 0 steps train_loss: 0.6308

#### test Acc: 0, NDCG: 0.29479018398765217 HIT: 0.5288775275735295

#### val Acc: 0, NDCG: 0.3034224292549721 HIT: 0.5292796415441177
Epoch: 448, plus 0 steps train_loss: 0.6295

#### test Acc: 0, NDCG: 0.29536139428387276 HIT: 0.5254423253676471

#### val Acc: 0, NDCG: 0.2984381599523648 HIT: 0.5272001378676471
Epoch: 480, plus 0 steps train_loss: 0.6074

#### test Acc: 0, NDCG: 0.29506742582657824 HIT: 0.5229894301470588

#### val Acc: 0, NDCG: 0.2997390554811822 HIT: 0.5255399816176471
Epoch: 512, plus 0 steps train_loss: 0.6309

#### test Acc: 0, NDCG: 0.29254494218298144 HIT: 0.5180721507352941

#### val Acc: 0, NDCG: 0.3056842535380734 HIT: 0.5338062959558824
Epoch: 544, plus 0 steps train_loss: 0.6232

#### test Acc: 0, NDCG: 0.3005022411735825 HIT: 0.53623046875

#### val Acc: 0, NDCG: 0.31126694999263904 HIT: 0.5423943014705882
Epoch: 576, plus 0 steps train_loss: 0.6116

#### test Acc: 0, NDCG: 0.3048533483574453 HIT: 0.5413832720588235

#### val Acc: 0, NDCG: 0.3139018399396203 HIT: 0.5504423253676471
Epoch: 608, plus 0 steps train_loss: 0.6153

#### test Acc: 0, NDCG: 0.30028247689578624 HIT: 0.5392865349264706

#### val Acc: 0, NDCG: 0.30783521119427015 HIT: 0.55068359375
Epoch: 640, plus 0 steps train_loss: 0.6026

#### test Acc: 0, NDCG: 0.3116953133201307 HIT: 0.5585075827205882

#### val Acc: 0, NDCG: 0.30897540252392913 HIT: 0.5499368106617647
Epoch: 704, plus 0 steps train_loss: 0.6163

#### test Acc: 0, NDCG: 0.302987407133416 HIT: 0.5456916360294117

#### val Acc: 0, NDCG: 0.3008556603980237 HIT: 0.5472196691176471
Epoch: 768, plus 0 steps train_loss: 0.6087

#### test Acc: 0, NDCG: 0.31005613023662737 HIT: 0.5570082720588235

#### val Acc: 0, NDCG: 0.31362709806152833 HIT: 0.5574908088235294
Epoch: 832, plus 0 steps train_loss: 0.6085

#### test Acc: 0, NDCG: 0.31624133393699083 HIT: 0.5700310202205883

#### val Acc: 0, NDCG: 0.3186153715292136 HIT: 0.5672621783088235
Epoch: 896, plus 0 steps train_loss: 0.5944

#### test Acc: 0, NDCG: 0.309079528770266 HIT: 0.5572437959558824

#### val Acc: 0, NDCG: 0.31483594226804984 HIT: 0.5582375919117647
Epoch: 960, plus 0 steps train_loss: 0.6014

#### test Acc: 0, NDCG: 0.31027812148250833 HIT: 0.5545266544117646

#### val Acc: 0, NDCG: 0.30998056901730214 HIT: 0.5585420496323529
Epoch: 1013, plus 25 steps train_loss: 0.5746
Done: it took 278446.1393084526
max value of NDCG: 0.5997539108296044
max value of HIT: 0.7093922334558823

After 20 validations
max value of NDCG: 0.5997539108296044
max value of HIT: 0.7093922334558823
