 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.0001
max_norm:             	None
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.1275104242435241 HIT: 0.28002642463235294

#### val Acc: 0, NDCG: 0.1302337182736463 HIT: 0.28421989889705884
Epoch: 1, plus 0 steps train_loss: 0.7635

#### test Acc: 0, NDCG: 0.13043854470426117 HIT: 0.2873391544117647

#### val Acc: 0, NDCG: 0.12818762839026057 HIT: 0.2862764246323529
Epoch: 2, plus 0 steps train_loss: 0.7468

#### test Acc: 0, NDCG: 0.1280065254116057 HIT: 0.27896943933823526

#### val Acc: 0, NDCG: 0.1279383342927521 HIT: 0.2823127297794118
Epoch: 3, plus 0 steps train_loss: 0.7471

#### test Acc: 0, NDCG: 0.1282828138838025 HIT: 0.2836799172794118

#### val Acc: 0, NDCG: 0.13237893548076635 HIT: 0.2925666360294118
Epoch: 4, plus 0 steps train_loss: 0.7437

#### test Acc: 0, NDCG: 0.1324904725928022 HIT: 0.2883501838235294

#### val Acc: 0, NDCG: 0.12916463643470208 HIT: 0.28381204044117647
Epoch: 5, plus 0 steps train_loss: 0.722

#### test Acc: 0, NDCG: 0.16574156603952334 HIT: 0.3189395680147059

#### val Acc: 0, NDCG: 0.16200752810868477 HIT: 0.31461971507352937
Epoch: 6, plus 0 steps train_loss: 0.7171

#### test Acc: 0, NDCG: 0.21506134226707227 HIT: 0.37683823529411764

#### val Acc: 0, NDCG: 0.21311575384382056 HIT: 0.37385684742647063
Epoch: 7, plus 0 steps train_loss: 0.709

#### test Acc: 0, NDCG: 0.34088992721935374 HIT: 0.49006204044117646

#### val Acc: 0, NDCG: 0.34265629092638744 HIT: 0.4874425551470588
Epoch: 8, plus 0 steps train_loss: 0.7161

#### test Acc: 0, NDCG: 0.33319728553268446 HIT: 0.48475413602941175

#### val Acc: 0, NDCG: 0.33336182546960064 HIT: 0.49073988970588234
Epoch: 9, plus 0 steps train_loss: 0.7091

#### test Acc: 0, NDCG: 0.37099745804473355 HIT: 0.5238625919117647

#### val Acc: 0, NDCG: 0.37814519590109685 HIT: 0.5274988511029413
Epoch: 10, plus 0 steps train_loss: 0.7104

#### test Acc: 0, NDCG: 0.4232257246150595 HIT: 0.56865234375

#### val Acc: 0, NDCG: 0.43082249953311696 HIT: 0.5790096507352941
Epoch: 12, plus 0 steps train_loss: 0.7134

#### test Acc: 0, NDCG: 0.4439614410257923 HIT: 0.5888212316176471

#### val Acc: 0, NDCG: 0.4656124333643268 HIT: 0.6014533547794118
Epoch: 14, plus 0 steps train_loss: 0.7054

#### test Acc: 0, NDCG: 0.45378530720905663 HIT: 0.5937385110294118

#### val Acc: 0, NDCG: 0.4693410908768632 HIT: 0.6095530790441177
Epoch: 16, plus 0 steps train_loss: 0.703

#### test Acc: 0, NDCG: 0.4599094838512322 HIT: 0.60283203125

#### val Acc: 0, NDCG: 0.47148986549128213 HIT: 0.6113396139705882
Epoch: 18, plus 0 steps train_loss: 0.7026

#### test Acc: 0, NDCG: 0.4637171557842857 HIT: 0.6026711856617647

#### val Acc: 0, NDCG: 0.4620009970429969 HIT: 0.6007352941176471
Epoch: 20, plus 0 steps train_loss: 0.7049

#### test Acc: 0, NDCG: 0.4832730880897936 HIT: 0.6185431985294118

#### val Acc: 0, NDCG: 0.4891976086466059 HIT: 0.6224781709558823
Epoch: 22, plus 0 steps train_loss: 0.7001

#### test Acc: 0, NDCG: 0.4881449642898197 HIT: 0.6161994485294118

#### val Acc: 0, NDCG: 0.5050460549697527 HIT: 0.6366670496323529
Epoch: 24, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.4763628367029346 HIT: 0.6151022518382353

#### val Acc: 0, NDCG: 0.4976807067619271 HIT: 0.6346392463235294
Epoch: 26, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.4785725598584273 HIT: 0.6155388327205882

#### val Acc: 0, NDCG: 0.501042376628208 HIT: 0.6324620863970588
Epoch: 28, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.4644641270754376 HIT: 0.6003791360294117

#### val Acc: 0, NDCG: 0.4839284013875173 HIT: 0.6169404871323529
Epoch: 30, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.49549414624233057 HIT: 0.6289234834558823

#### val Acc: 0, NDCG: 0.5165144342141691 HIT: 0.6454446231617647
Epoch: 32, plus 0 steps train_loss: 0.6971

#### test Acc: 0, NDCG: 0.5835024262489045 HIT: 0.6892405790441176

#### val Acc: 0, NDCG: 0.5782268564053633 HIT: 0.6930491727941177
Epoch: 36, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.5832172815289054 HIT: 0.6901539522058824

#### val Acc: 0, NDCG: 0.5918890201309492 HIT: 0.7059110753676471
Epoch: 40, plus 0 steps train_loss: 0.6975

#### test Acc: 0, NDCG: 0.5832457501270882 HIT: 0.6910558363970588

#### val Acc: 0, NDCG: 0.5914976496074906 HIT: 0.7035098805147059
Epoch: 44, plus 0 steps train_loss: 0.6949

#### test Acc: 0, NDCG: 0.540551915903331 HIT: 0.6621955422794118

#### val Acc: 0, NDCG: 0.5498031614691913 HIT: 0.6673138786764705
Epoch: 48, plus 0 steps train_loss: 0.6935

#### test Acc: 0, NDCG: 0.5386063019286375 HIT: 0.6639935661764705

#### val Acc: 0, NDCG: 0.5441039477572964 HIT: 0.6655560661764706
Epoch: 52, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.45869352524359774 HIT: 0.5977309283088236

#### val Acc: 0, NDCG: 0.4751460370322551 HIT: 0.6134363511029413
Epoch: 56, plus 0 steps train_loss: 0.6891

#### test Acc: 0, NDCG: 0.3085231484479583 HIT: 0.4829905790441177

#### val Acc: 0, NDCG: 0.3307638851857824 HIT: 0.5021139705882354
Epoch: 60, plus 0 steps train_loss: 0.6808

#### test Acc: 0, NDCG: 0.22372433358370167 HIT: 0.4493853400735294

#### val Acc: 0, NDCG: 0.22575031209815882 HIT: 0.4488913143382353
Epoch: 64, plus 0 steps train_loss: 0.661

#### test Acc: 0, NDCG: 0.23134336625430496 HIT: 0.46120749080882356

#### val Acc: 0, NDCG: 0.23573355334530338 HIT: 0.4664694393382353
Epoch: 68, plus 0 steps train_loss: 0.6599

#### test Acc: 0, NDCG: 0.24741911381744813 HIT: 0.48288717830882355

#### val Acc: 0, NDCG: 0.24327434538355064 HIT: 0.47357536764705876
Epoch: 72, plus 0 steps train_loss: 0.6479

#### test Acc: 0, NDCG: 0.24731068495160816 HIT: 0.48538028492647056

#### val Acc: 0, NDCG: 0.2548326167490498 HIT: 0.4944967830882353
Epoch: 80, plus 0 steps train_loss: 0.6392

#### test Acc: 0, NDCG: 0.27126505757580055 HIT: 0.5171185661764706

#### val Acc: 0, NDCG: 0.27774630212768114 HIT: 0.5259765625
Epoch: 88, plus 0 steps train_loss: 0.6402

#### test Acc: 0, NDCG: 0.27910551400379136 HIT: 0.5321806066176471

#### val Acc: 0, NDCG: 0.2797162282737415 HIT: 0.5301355698529412
Epoch: 96, plus 0 steps train_loss: 0.6302

#### test Acc: 0, NDCG: 0.27749587843661017 HIT: 0.5279124540441177

#### val Acc: 0, NDCG: 0.2890095298614252 HIT: 0.5436580882352942
Epoch: 104, plus 0 steps train_loss: 0.6148

#### test Acc: 0, NDCG: 0.29548010566519745 HIT: 0.5545323988970587

#### val Acc: 0, NDCG: 0.30504352415559277 HIT: 0.5572552849264706
Epoch: 112, plus 0 steps train_loss: 0.5979

#### test Acc: 0, NDCG: 0.2989477421728192 HIT: 0.5579905790441176

#### val Acc: 0, NDCG: 0.3104236682644694 HIT: 0.5692210477941176
Epoch: 120, plus 0 steps train_loss: 0.594

#### test Acc: 0, NDCG: 0.3070856567632451 HIT: 0.5689682904411765

#### val Acc: 0, NDCG: 0.3127127598101469 HIT: 0.5804802389705882
Epoch: 128, plus 0 steps train_loss: 0.615

#### test Acc: 0, NDCG: 0.3087340653758903 HIT: 0.5657973345588235

#### val Acc: 0, NDCG: 0.317233018553504 HIT: 0.5763556985294118
Epoch: 136, plus 0 steps train_loss: 0.5852

#### test Acc: 0, NDCG: 0.3099662623998704 HIT: 0.5640337775735295

#### val Acc: 0, NDCG: 0.3140481921086275 HIT: 0.5734030330882354
Epoch: 144, plus 0 steps train_loss: 0.5933

#### test Acc: 0, NDCG: 0.32859523763785015 HIT: 0.5884995404411765

#### val Acc: 0, NDCG: 0.3349283500835833 HIT: 0.5941521139705882
Epoch: 160, plus 0 steps train_loss: 0.5721

#### test Acc: 0, NDCG: 0.33611902854279535 HIT: 0.5933995863970588

#### val Acc: 0, NDCG: 0.3434474718121364 HIT: 0.6035903033088236
Epoch: 176, plus 0 steps train_loss: 0.5652

#### test Acc: 0, NDCG: 0.34396290452632633 HIT: 0.6003676470588235

#### val Acc: 0, NDCG: 0.349487349495552 HIT: 0.6075654871323529
Epoch: 192, plus 0 steps train_loss: 0.546

#### test Acc: 0, NDCG: 0.3568071644874561 HIT: 0.6126551011029412

#### val Acc: 0, NDCG: 0.3535227546682672 HIT: 0.60888671875
Epoch: 208, plus 0 steps train_loss: 0.5536

#### test Acc: 0, NDCG: 0.3558509517572256 HIT: 0.6125861672794117

#### val Acc: 0, NDCG: 0.36408320677999056 HIT: 0.6255629595588236
Epoch: 224, plus 0 steps train_loss: 0.5559

#### test Acc: 0, NDCG: 0.36119471916280865 HIT: 0.6110753676470588

#### val Acc: 0, NDCG: 0.3652921571076944 HIT: 0.6177964154411765
Epoch: 240, plus 0 steps train_loss: 0.5477

#### test Acc: 0, NDCG: 0.36499575211125124 HIT: 0.6132927389705882

#### val Acc: 0, NDCG: 0.37179321713483404 HIT: 0.62626953125
Epoch: 256, plus 0 steps train_loss: 0.5281

#### test Acc: 0, NDCG: 0.3689705578423307 HIT: 0.6205480238970588

#### val Acc: 0, NDCG: 0.3846244651636217 HIT: 0.6402458639705882
Epoch: 272, plus 0 steps train_loss: 0.5445

#### test Acc: 0, NDCG: 0.36927170816870064 HIT: 0.6197840073529413

#### val Acc: 0, NDCG: 0.37475305117382035 HIT: 0.6285903033088236
Epoch: 288, plus 0 steps train_loss: 0.5469

#### test Acc: 0, NDCG: 0.3719041816084621 HIT: 0.6192670036764706

#### val Acc: 0, NDCG: 0.378149808010899 HIT: 0.63212890625
Epoch: 304, plus 0 steps train_loss: 0.5288

#### test Acc: 0, NDCG: 0.3769026327638359 HIT: 0.6287913602941176

#### val Acc: 0, NDCG: 0.38050394134585636 HIT: 0.6366268382352941
Epoch: 320, plus 0 steps train_loss: 0.5319

#### test Acc: 0, NDCG: 0.37685708215247116 HIT: 0.6225126378676471

#### val Acc: 0, NDCG: 0.3852395481470415 HIT: 0.6368508731617647
Epoch: 352, plus 0 steps train_loss: 0.5198

#### test Acc: 0, NDCG: 0.38413005669901645 HIT: 0.6264533547794118

#### val Acc: 0, NDCG: 0.39119014630048043 HIT: 0.6401539522058823
Epoch: 384, plus 0 steps train_loss: 0.5031

#### test Acc: 0, NDCG: 0.39299988418135545 HIT: 0.6371783088235294

#### val Acc: 0, NDCG: 0.40074802428828527 HIT: 0.6510512408088236
Epoch: 416, plus 0 steps train_loss: 0.5059

#### test Acc: 0, NDCG: 0.3874007125641964 HIT: 0.6336569393382353

#### val Acc: 0, NDCG: 0.39926069347335646 HIT: 0.6458295036764705
Epoch: 448, plus 0 steps train_loss: 0.5096

#### test Acc: 0, NDCG: 0.38097588749808353 HIT: 0.6237074908088236

#### val Acc: 0, NDCG: 0.4016737259862815 HIT: 0.6482077205882353
Epoch: 480, plus 0 steps train_loss: 0.4862

#### test Acc: 0, NDCG: 0.39170313098060316 HIT: 0.6394818474264705

#### val Acc: 0, NDCG: 0.40425999636323223 HIT: 0.6551585477941176
Epoch: 512, plus 0 steps train_loss: 0.4737

#### test Acc: 0, NDCG: 0.3961485936392707 HIT: 0.6415556066176471

#### val Acc: 0, NDCG: 0.40351508719815116 HIT: 0.6533432904411764
Epoch: 544, plus 0 steps train_loss: 0.4805

#### test Acc: 0, NDCG: 0.3935126333827627 HIT: 0.6346564797794118

#### val Acc: 0, NDCG: 0.40738626616878654 HIT: 0.6507755055147059
Epoch: 576, plus 0 steps train_loss: 0.4736

#### test Acc: 0, NDCG: 0.385405919088543 HIT: 0.6257352941176471

#### val Acc: 0, NDCG: 0.40489772062895657 HIT: 0.6468520220588235
Epoch: 608, plus 0 steps train_loss: 0.4998

#### test Acc: 0, NDCG: 0.40323134406723093 HIT: 0.6466279871323529

#### val Acc: 0, NDCG: 0.4080064767700392 HIT: 0.6527630974264705
Epoch: 640, plus 0 steps train_loss: 0.4886

#### test Acc: 0, NDCG: 0.3988471120746556 HIT: 0.6434340533088235

#### val Acc: 0, NDCG: 0.4050290520560386 HIT: 0.6514303768382353
Epoch: 704, plus 0 steps train_loss: 0.4855

#### test Acc: 0, NDCG: 0.39929096412458187 HIT: 0.6383329503676471

#### val Acc: 0, NDCG: 0.4113741404361007 HIT: 0.6574505974264706
Epoch: 768, plus 0 steps train_loss: 0.4619

#### test Acc: 0, NDCG: 0.39562337851135265 HIT: 0.6404698988970587

#### val Acc: 0, NDCG: 0.4125459659088011 HIT: 0.6545438878676471
Epoch: 832, plus 0 steps train_loss: 0.4619

#### test Acc: 0, NDCG: 0.3980446246841326 HIT: 0.6419117647058823

#### val Acc: 0, NDCG: 0.41129674677002176 HIT: 0.6560431985294117
Epoch: 896, plus 0 steps train_loss: 0.4566

#### test Acc: 0, NDCG: 0.3990927016290943 HIT: 0.6429744944852941

#### val Acc: 0, NDCG: 0.4080278488874594 HIT: 0.6505457261029413
Epoch: 960, plus 0 steps train_loss: 0.4647

#### test Acc: 0, NDCG: 0.4020396254260154 HIT: 0.6457548253676471

#### val Acc: 0, NDCG: 0.4074997017754699 HIT: 0.6557387408088236
Epoch: 1013, plus 25 steps train_loss: 0.4728
Done: it took 272153.558095932
max value of NDCG: 0.5835024262489045
max value of HIT: 0.6910558363970588

After 20 validations
max value of NDCG: 0.5835024262489045
max value of HIT: 0.6910558363970588
