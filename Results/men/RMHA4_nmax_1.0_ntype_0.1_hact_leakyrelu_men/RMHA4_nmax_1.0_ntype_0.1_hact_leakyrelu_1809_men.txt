 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	1.0
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12815981168441912 HIT: 0.2848575367647059

#### val Acc: 0, NDCG: 0.1300588080805609 HIT: 0.28823529411764703
Epoch: 1, plus 0 steps train_loss: 0.8066

#### test Acc: 0, NDCG: 0.1331705659693204 HIT: 0.29167049632352937

#### val Acc: 0, NDCG: 0.1271862717334442 HIT: 0.2820197610294118
Epoch: 2, plus 0 steps train_loss: 0.7759

#### test Acc: 0, NDCG: 0.1298953361654471 HIT: 0.2852251838235294

#### val Acc: 0, NDCG: 0.13121627126132593 HIT: 0.29048138786764705
Epoch: 3, plus 0 steps train_loss: 0.7612

#### test Acc: 0, NDCG: 0.13371307393696313 HIT: 0.29280790441176474

#### val Acc: 0, NDCG: 0.13196788292520698 HIT: 0.28806295955882355
Epoch: 4, plus 0 steps train_loss: 0.7537

#### test Acc: 0, NDCG: 0.12697900483262375 HIT: 0.28113511029411764

#### val Acc: 0, NDCG: 0.1272537944448446 HIT: 0.27670036764705885
Epoch: 5, plus 0 steps train_loss: 0.7378

#### test Acc: 0, NDCG: 0.13868605515152263 HIT: 0.29458295036764703

#### val Acc: 0, NDCG: 0.13733771054586633 HIT: 0.2917796415441177
Epoch: 6, plus 0 steps train_loss: 0.7258

#### test Acc: 0, NDCG: 0.1645445677471402 HIT: 0.3220703125

#### val Acc: 0, NDCG: 0.15883293356772493 HIT: 0.3162741268382353
Epoch: 7, plus 0 steps train_loss: 0.7111

#### test Acc: 0, NDCG: 0.22494482646533048 HIT: 0.3760569852941177

#### val Acc: 0, NDCG: 0.22349370319454653 HIT: 0.38347886029411765
Epoch: 8, plus 0 steps train_loss: 0.7192

#### test Acc: 0, NDCG: 0.277761604759527 HIT: 0.4265050551470588

#### val Acc: 0, NDCG: 0.28709629589870966 HIT: 0.4404813878676471
Epoch: 9, plus 0 steps train_loss: 0.7117

#### test Acc: 0, NDCG: 0.31383625334120924 HIT: 0.46458524816176466

#### val Acc: 0, NDCG: 0.31890879325952726 HIT: 0.4641027113970588
Epoch: 10, plus 0 steps train_loss: 0.7097

#### test Acc: 0, NDCG: 0.3137607171423849 HIT: 0.4628102022058823

#### val Acc: 0, NDCG: 0.32916821672691043 HIT: 0.47991153492647054
Epoch: 12, plus 0 steps train_loss: 0.7095

#### test Acc: 0, NDCG: 0.3902989306592454 HIT: 0.5361615349264706

#### val Acc: 0, NDCG: 0.4007296067907169 HIT: 0.5411707261029413
Epoch: 14, plus 0 steps train_loss: 0.7062

#### test Acc: 0, NDCG: 0.42106396897194925 HIT: 0.5587258731617647

#### val Acc: 0, NDCG: 0.43498334362639357 HIT: 0.5719496783088236
Epoch: 16, plus 0 steps train_loss: 0.7058

#### test Acc: 0, NDCG: 0.39155435540594363 HIT: 0.5319565716911765

#### val Acc: 0, NDCG: 0.4094661730843712 HIT: 0.5493106617647059
Epoch: 18, plus 0 steps train_loss: 0.7054

#### test Acc: 0, NDCG: 0.41332766996104436 HIT: 0.5533088235294118

#### val Acc: 0, NDCG: 0.43401461178463474 HIT: 0.5709731158088236
Epoch: 20, plus 0 steps train_loss: 0.7074

#### test Acc: 0, NDCG: 0.4904993334886926 HIT: 0.6219898897058823

#### val Acc: 0, NDCG: 0.4993960340307745 HIT: 0.6272690716911764
Epoch: 22, plus 0 steps train_loss: 0.7042

#### test Acc: 0, NDCG: 0.500548568123398 HIT: 0.6300896139705883

#### val Acc: 0, NDCG: 0.5115011645494125 HIT: 0.6390510110294118
Epoch: 24, plus 0 steps train_loss: 0.7003

#### test Acc: 0, NDCG: 0.5159100176566814 HIT: 0.6411764705882353

#### val Acc: 0, NDCG: 0.5170803678456926 HIT: 0.6459673713235294
Epoch: 26, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.5018967297301355 HIT: 0.6254480698529412

#### val Acc: 0, NDCG: 0.5236923483256424 HIT: 0.6489832261029412
Epoch: 28, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.5338893757567738 HIT: 0.6609375

#### val Acc: 0, NDCG: 0.5405967844578536 HIT: 0.6622300091911765
Epoch: 30, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.5439050045788838 HIT: 0.6710592830882354

#### val Acc: 0, NDCG: 0.5563597402482434 HIT: 0.6759191176470588
Epoch: 32, plus 0 steps train_loss: 0.6953

#### test Acc: 0, NDCG: 0.5630847760925463 HIT: 0.6846794577205882

#### val Acc: 0, NDCG: 0.5554249215241844 HIT: 0.6767635569852941
Epoch: 36, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.5599133641913181 HIT: 0.6830250459558823

#### val Acc: 0, NDCG: 0.5536098140975441 HIT: 0.6717888327205882
Epoch: 40, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.5071368374619605 HIT: 0.6404986213235294

#### val Acc: 0, NDCG: 0.5303584861649819 HIT: 0.6562614889705882
Epoch: 44, plus 0 steps train_loss: 0.6954

#### test Acc: 0, NDCG: 0.44482550191588527 HIT: 0.6002814797794118

#### val Acc: 0, NDCG: 0.463981940129937 HIT: 0.61455078125
Epoch: 48, plus 0 steps train_loss: 0.6907

#### test Acc: 0, NDCG: 0.19320915104159192 HIT: 0.39239430147058824

#### val Acc: 0, NDCG: 0.20341057560405354 HIT: 0.39798368566176473
Epoch: 52, plus 0 steps train_loss: 0.6783

#### test Acc: 0, NDCG: 0.20140398436239212 HIT: 0.4108570772058823

#### val Acc: 0, NDCG: 0.20547845105662005 HIT: 0.4247300091911764
Epoch: 56, plus 0 steps train_loss: 0.6654

#### test Acc: 0, NDCG: 0.2154597717185764 HIT: 0.4389188878676471

#### val Acc: 0, NDCG: 0.22139346691330006 HIT: 0.4444221047794118
Epoch: 60, plus 0 steps train_loss: 0.6605

#### test Acc: 0, NDCG: 0.21742002262076468 HIT: 0.44284237132352944

#### val Acc: 0, NDCG: 0.22759879305035358 HIT: 0.45713465073529413
Epoch: 64, plus 0 steps train_loss: 0.6499

#### test Acc: 0, NDCG: 0.23037312865819773 HIT: 0.4641544117647059

#### val Acc: 0, NDCG: 0.23304052331238317 HIT: 0.4674287683823529
Epoch: 68, plus 0 steps train_loss: 0.6503

#### test Acc: 0, NDCG: 0.23287091765581627 HIT: 0.4656939338235294

#### val Acc: 0, NDCG: 0.23692502940276886 HIT: 0.4716911764705882
Epoch: 72, plus 0 steps train_loss: 0.6391

#### test Acc: 0, NDCG: 0.24339230957975966 HIT: 0.47633272058823534

#### val Acc: 0, NDCG: 0.24969643356238191 HIT: 0.4851160386029412
Epoch: 80, plus 0 steps train_loss: 0.6413

#### test Acc: 0, NDCG: 0.258268529600517 HIT: 0.49677734375

#### val Acc: 0, NDCG: 0.26684989160509603 HIT: 0.5089269301470588
Epoch: 88, plus 0 steps train_loss: 0.6348

#### test Acc: 0, NDCG: 0.26492137634821517 HIT: 0.5089556525735295

#### val Acc: 0, NDCG: 0.2775460514018235 HIT: 0.5236960018382353
Epoch: 96, plus 0 steps train_loss: 0.6356

#### test Acc: 0, NDCG: 0.27350655174687566 HIT: 0.5222426470588235

#### val Acc: 0, NDCG: 0.27359177434144366 HIT: 0.5216394761029413
Epoch: 104, plus 0 steps train_loss: 0.6217

#### test Acc: 0, NDCG: 0.28253987053887275 HIT: 0.53427734375

#### val Acc: 0, NDCG: 0.28542269386260777 HIT: 0.5313648897058824
Epoch: 112, plus 0 steps train_loss: 0.6112

#### test Acc: 0, NDCG: 0.2943668887819391 HIT: 0.5408835018382353

#### val Acc: 0, NDCG: 0.29049518958135256 HIT: 0.5389361213235294
Epoch: 120, plus 0 steps train_loss: 0.5989

#### test Acc: 0, NDCG: 0.2880890333985737 HIT: 0.5324678308823529

#### val Acc: 0, NDCG: 0.2902102014228088 HIT: 0.5325252757352941
Epoch: 128, plus 0 steps train_loss: 0.5944

#### test Acc: 0, NDCG: 0.29781157780177864 HIT: 0.5425321691176471

#### val Acc: 0, NDCG: 0.30258640362694067 HIT: 0.5493451286764706
Epoch: 136, plus 0 steps train_loss: 0.6051

#### test Acc: 0, NDCG: 0.3013564225332898 HIT: 0.5486040900735294

#### val Acc: 0, NDCG: 0.3042662513082922 HIT: 0.5530962775735294
Epoch: 144, plus 0 steps train_loss: 0.5955

#### test Acc: 0, NDCG: 0.3095944989244334 HIT: 0.5567153033088236

#### val Acc: 0, NDCG: 0.31898340752130155 HIT: 0.5708869485294118
Epoch: 160, plus 0 steps train_loss: 0.5761

#### test Acc: 0, NDCG: 0.3214862937591839 HIT: 0.5754308363970588

#### val Acc: 0, NDCG: 0.3306474470979636 HIT: 0.5741555606617647
Epoch: 176, plus 0 steps train_loss: 0.5881

#### test Acc: 0, NDCG: 0.3248017135083597 HIT: 0.5766371783088236

#### val Acc: 0, NDCG: 0.3298072073030391 HIT: 0.5760799632352941
Epoch: 192, plus 0 steps train_loss: 0.5911

#### test Acc: 0, NDCG: 0.33388504627982313 HIT: 0.5778722426470588

#### val Acc: 0, NDCG: 0.33655538822889897 HIT: 0.5804285386029412
Epoch: 208, plus 0 steps train_loss: 0.5922

#### test Acc: 0, NDCG: 0.3391650745091658 HIT: 0.5822552849264706

#### val Acc: 0, NDCG: 0.3421729225399043 HIT: 0.5855755974264706
Epoch: 224, plus 0 steps train_loss: 0.5728

#### test Acc: 0, NDCG: 0.3460472254185758 HIT: 0.5881893382352941

#### val Acc: 0, NDCG: 0.3444193640857248 HIT: 0.59013671875
Epoch: 240, plus 0 steps train_loss: 0.5578

#### test Acc: 0, NDCG: 0.34892165860891816 HIT: 0.5886833639705882

#### val Acc: 0, NDCG: 0.35179857592124614 HIT: 0.6022231158088236
Epoch: 256, plus 0 steps train_loss: 0.5278

#### test Acc: 0, NDCG: 0.3520049294307254 HIT: 0.5987936580882354

#### val Acc: 0, NDCG: 0.3578053827949836 HIT: 0.6077090992647058
Epoch: 272, plus 0 steps train_loss: 0.566

#### test Acc: 0, NDCG: 0.3513598688271074 HIT: 0.5956744025735294

#### val Acc: 0, NDCG: 0.36019586497867784 HIT: 0.6061868106617647
Epoch: 288, plus 0 steps train_loss: 0.5423

#### test Acc: 0, NDCG: 0.3664506194584509 HIT: 0.60927734375

#### val Acc: 0, NDCG: 0.36944851513914245 HIT: 0.6269186580882353
Epoch: 304, plus 0 steps train_loss: 0.5228

#### test Acc: 0, NDCG: 0.36169234960842206 HIT: 0.6108168658088236

#### val Acc: 0, NDCG: 0.368732121154334 HIT: 0.6169117647058824
Epoch: 320, plus 0 steps train_loss: 0.5309

#### test Acc: 0, NDCG: 0.37083802736809185 HIT: 0.6135282628676471

#### val Acc: 0, NDCG: 0.37614825437344984 HIT: 0.6268439797794118
Epoch: 352, plus 0 steps train_loss: 0.5382

#### test Acc: 0, NDCG: 0.3674353233456113 HIT: 0.6182732077205882

#### val Acc: 0, NDCG: 0.3809543647110904 HIT: 0.6315314797794118
Epoch: 384, plus 0 steps train_loss: 0.5231

#### test Acc: 0, NDCG: 0.3758701408071258 HIT: 0.6228573069852941

#### val Acc: 0, NDCG: 0.3879154069203954 HIT: 0.6385397518382353
Epoch: 416, plus 0 steps train_loss: 0.5117

#### test Acc: 0, NDCG: 0.3814623846802972 HIT: 0.6290498621323529

#### val Acc: 0, NDCG: 0.3896074364585117 HIT: 0.6384823069852941
Epoch: 448, plus 0 steps train_loss: 0.4992

#### test Acc: 0, NDCG: 0.37959957125646226 HIT: 0.6300838694852942

#### val Acc: 0, NDCG: 0.398541715519073 HIT: 0.6479549632352941
Epoch: 480, plus 0 steps train_loss: 0.4908

#### test Acc: 0, NDCG: 0.38104271481331414 HIT: 0.6257984834558823

#### val Acc: 0, NDCG: 0.394950800599889 HIT: 0.6490062040441177
Epoch: 512, plus 0 steps train_loss: 0.5172

#### test Acc: 0, NDCG: 0.3873671062410687 HIT: 0.6369715073529412

#### val Acc: 0, NDCG: 0.39103947682785484 HIT: 0.6404411764705882
Epoch: 544, plus 0 steps train_loss: 0.4978

#### test Acc: 0, NDCG: 0.3926496522153188 HIT: 0.6376436121323529

#### val Acc: 0, NDCG: 0.3955777122900722 HIT: 0.6444623161764705
Epoch: 576, plus 0 steps train_loss: 0.4953

#### test Acc: 0, NDCG: 0.3885038054184319 HIT: 0.6398954503676471

#### val Acc: 0, NDCG: 0.40004013269708094 HIT: 0.6500631893382354
Epoch: 608, plus 0 steps train_loss: 0.4829

#### test Acc: 0, NDCG: 0.38601682473198834 HIT: 0.6348460477941177

#### val Acc: 0, NDCG: 0.39699533089745953 HIT: 0.6426011029411764
Epoch: 640, plus 0 steps train_loss: 0.4731

#### test Acc: 0, NDCG: 0.39989165738028587 HIT: 0.6471220128676471

#### val Acc: 0, NDCG: 0.4080657536472253 HIT: 0.6564970128676471
Epoch: 704, plus 0 steps train_loss: 0.4666

#### test Acc: 0, NDCG: 0.39325872573496695 HIT: 0.6428883272058823

#### val Acc: 0, NDCG: 0.3980960033396511 HIT: 0.6447437959558824
Epoch: 768, plus 0 steps train_loss: 0.4655

#### test Acc: 0, NDCG: 0.3973326034507198 HIT: 0.6436982996323529

#### val Acc: 0, NDCG: 0.40450016143177325 HIT: 0.6518439797794118
Epoch: 832, plus 0 steps train_loss: 0.477

#### test Acc: 0, NDCG: 0.39382870854900504 HIT: 0.6397173713235295

#### val Acc: 0, NDCG: 0.4009491586982235 HIT: 0.6426240808823529
Epoch: 896, plus 0 steps train_loss: 0.4688

#### test Acc: 0, NDCG: 0.39675550279780086 HIT: 0.6422104779411765

#### val Acc: 0, NDCG: 0.40652947562085895 HIT: 0.6517463235294118
Epoch: 960, plus 0 steps train_loss: 0.4565

#### test Acc: 0, NDCG: 0.3947531920197214 HIT: 0.6371897977941177

#### val Acc: 0, NDCG: 0.39700939089131904 HIT: 0.6453527113970587
Epoch: 1013, plus 25 steps train_loss: 0.4796
Done: it took 281053.07285141945
max value of NDCG: 0.5630847760925463
max value of HIT: 0.6846794577205882

After 20 validations
max value of NDCG: 0.5630847760925463
max value of HIT: 0.6846794577205882
