 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.0001
max_norm:             	0.1
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13219502201458208 HIT: 0.2875344669117647

#### val Acc: 0, NDCG: 0.12926068102325078 HIT: 0.28288717830882354
Epoch: 1, plus 0 steps train_loss: 0.7617

#### test Acc: 0, NDCG: 0.12724192283095923 HIT: 0.28324908088235295

#### val Acc: 0, NDCG: 0.13011380487643737 HIT: 0.2922219669117647
Epoch: 2, plus 0 steps train_loss: 0.7579

#### test Acc: 0, NDCG: 0.12862969920050565 HIT: 0.28289292279411765

#### val Acc: 0, NDCG: 0.1297386877228858 HIT: 0.28303079044117646
Epoch: 3, plus 0 steps train_loss: 0.7524

#### test Acc: 0, NDCG: 0.12832411424544204 HIT: 0.28114085477941175

#### val Acc: 0, NDCG: 0.1300026498576961 HIT: 0.2856330422794118
Epoch: 4, plus 0 steps train_loss: 0.7492

#### test Acc: 0, NDCG: 0.13027340944199284 HIT: 0.2857421875

#### val Acc: 0, NDCG: 0.1278780971556069 HIT: 0.278515625
Epoch: 5, plus 0 steps train_loss: 0.7474

#### test Acc: 0, NDCG: 0.1262011317655355 HIT: 0.2804630055147059

#### val Acc: 0, NDCG: 0.1278979000869227 HIT: 0.28247357536764706
Epoch: 6, plus 0 steps train_loss: 0.7419

#### test Acc: 0, NDCG: 0.13313906838905595 HIT: 0.29300321691176473

#### val Acc: 0, NDCG: 0.13344899070580232 HIT: 0.29410615808823526
Epoch: 7, plus 0 steps train_loss: 0.738

#### test Acc: 0, NDCG: 0.13468477432842124 HIT: 0.29740923713235295

#### val Acc: 0, NDCG: 0.13047100697032432 HIT: 0.2886316636029412
Epoch: 8, plus 0 steps train_loss: 0.7335

#### test Acc: 0, NDCG: 0.12841702552380946 HIT: 0.28512178308823527

#### val Acc: 0, NDCG: 0.13041381228922858 HIT: 0.2871380974264706
Epoch: 9, plus 0 steps train_loss: 0.733

#### test Acc: 0, NDCG: 0.13053342392317838 HIT: 0.28707490808823527

#### val Acc: 0, NDCG: 0.1330761863356338 HIT: 0.2866096047794118
Epoch: 10, plus 0 steps train_loss: 0.7243

#### test Acc: 0, NDCG: 0.13168327262452367 HIT: 0.28978630514705883

#### val Acc: 0, NDCG: 0.131377001370871 HIT: 0.2891429227941177
Epoch: 12, plus 0 steps train_loss: 0.7242

#### test Acc: 0, NDCG: 0.13014639752342447 HIT: 0.28686810661764706

#### val Acc: 0, NDCG: 0.12881208379453077 HIT: 0.2814453125
Epoch: 14, plus 0 steps train_loss: 0.7212

#### test Acc: 0, NDCG: 0.1319088813059109 HIT: 0.28901654411764705

#### val Acc: 0, NDCG: 0.12807039077412263 HIT: 0.2819450827205882
Epoch: 16, plus 0 steps train_loss: 0.7179

#### test Acc: 0, NDCG: 0.12653457818387898 HIT: 0.27641888786764707

#### val Acc: 0, NDCG: 0.12963867725238337 HIT: 0.2860006893382353
Epoch: 18, plus 0 steps train_loss: 0.7197

#### test Acc: 0, NDCG: 0.1284386332196958 HIT: 0.28465073529411766

#### val Acc: 0, NDCG: 0.12771488636165917 HIT: 0.28628216911764703
Epoch: 20, plus 0 steps train_loss: 0.7083

#### test Acc: 0, NDCG: 0.12830648758011948 HIT: 0.2824391084558823

#### val Acc: 0, NDCG: 0.13400217174112355 HIT: 0.29281364889705885
Epoch: 22, plus 0 steps train_loss: 0.7097

#### test Acc: 0, NDCG: 0.13087802741325216 HIT: 0.2879940257352941

#### val Acc: 0, NDCG: 0.12811440643045077 HIT: 0.28161764705882353
Epoch: 24, plus 0 steps train_loss: 0.7085

#### test Acc: 0, NDCG: 0.1296425086297473 HIT: 0.2860466452205882

#### val Acc: 0, NDCG: 0.13054495839222477 HIT: 0.2903894761029412
Epoch: 26, plus 0 steps train_loss: 0.7072

#### test Acc: 0, NDCG: 0.1323440637327848 HIT: 0.29248046875

#### val Acc: 0, NDCG: 0.1344075343185737 HIT: 0.29265280330882354
Epoch: 28, plus 0 steps train_loss: 0.7034

#### test Acc: 0, NDCG: 0.13282544078381925 HIT: 0.2872414981617647

#### val Acc: 0, NDCG: 0.13206333194700673 HIT: 0.2923426011029412
Epoch: 30, plus 0 steps train_loss: 0.7054

#### test Acc: 0, NDCG: 0.13030303475491242 HIT: 0.29069967830882354

#### val Acc: 0, NDCG: 0.13048842466643404 HIT: 0.28812040441176473
Epoch: 32, plus 0 steps train_loss: 0.7051

#### test Acc: 0, NDCG: 0.1346569850198126 HIT: 0.2964441636029412

#### val Acc: 0, NDCG: 0.1296377796318953 HIT: 0.2856158088235294
Epoch: 36, plus 0 steps train_loss: 0.7063

#### test Acc: 0, NDCG: 0.13078210992658307 HIT: 0.28707490808823527

#### val Acc: 0, NDCG: 0.13378330128898924 HIT: 0.2843118106617647
Epoch: 40, plus 0 steps train_loss: 0.7035

#### test Acc: 0, NDCG: 0.19987910819851482 HIT: 0.3528377757352941

#### val Acc: 0, NDCG: 0.21141704811521905 HIT: 0.3639763327205882
Epoch: 44, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.2369117505417238 HIT: 0.3899356617647059

#### val Acc: 0, NDCG: 0.26066860556562116 HIT: 0.4107996323529412
Epoch: 48, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.34964189220541425 HIT: 0.4867647058823529

#### val Acc: 0, NDCG: 0.36495473998882894 HIT: 0.5061925551470587
Epoch: 52, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.48029579269638517 HIT: 0.6078584558823529

#### val Acc: 0, NDCG: 0.493645703448186 HIT: 0.6182157628676471
Epoch: 56, plus 0 steps train_loss: 0.7003

#### test Acc: 0, NDCG: 0.5044164644020501 HIT: 0.6241498161764706

#### val Acc: 0, NDCG: 0.518090769269587 HIT: 0.6393899356617647
Epoch: 60, plus 0 steps train_loss: 0.6978

#### test Acc: 0, NDCG: 0.5294737832814599 HIT: 0.6426528033088236

#### val Acc: 0, NDCG: 0.5509407224619027 HIT: 0.6649241727941176
Epoch: 64, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.5214149088673861 HIT: 0.6400907628676471

#### val Acc: 0, NDCG: 0.5227022643179434 HIT: 0.6392463235294118
Epoch: 68, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.5819312657928638 HIT: 0.6942612591911764

#### val Acc: 0, NDCG: 0.5905185674677461 HIT: 0.6965245863970588
Epoch: 72, plus 0 steps train_loss: 0.6964

#### test Acc: 0, NDCG: 0.5848337663066818 HIT: 0.6914119944852941

#### val Acc: 0, NDCG: 0.5976770118040771 HIT: 0.7064682904411764
Epoch: 80, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.5171773184562936 HIT: 0.6308536305147059

#### val Acc: 0, NDCG: 0.5303479501746503 HIT: 0.6494542738970588
Epoch: 88, plus 0 steps train_loss: 0.6948

#### test Acc: 0, NDCG: 0.6142589559713209 HIT: 0.7151941636029412

#### val Acc: 0, NDCG: 0.6282633822883876 HIT: 0.7256089154411764
Epoch: 96, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.5988831077618879 HIT: 0.7107019761029412

#### val Acc: 0, NDCG: 0.6086843989314723 HIT: 0.7125746783088236
Epoch: 104, plus 0 steps train_loss: 0.6929

#### test Acc: 0, NDCG: 0.6104787811919363 HIT: 0.7138269761029412

#### val Acc: 0, NDCG: 0.6303121736103774 HIT: 0.7303596047794118
Epoch: 112, plus 0 steps train_loss: 0.6921

#### test Acc: 0, NDCG: 0.6176096648072037 HIT: 0.7215762867647059

#### val Acc: 0, NDCG: 0.6256011840638622 HIT: 0.7279756433823529
Epoch: 120, plus 0 steps train_loss: 0.692

#### test Acc: 0, NDCG: 0.5856605507023356 HIT: 0.6995749080882353

#### val Acc: 0, NDCG: 0.5871716007028626 HIT: 0.6969209558823529
Epoch: 128, plus 0 steps train_loss: 0.6912

#### test Acc: 0, NDCG: 0.6044965666540348 HIT: 0.7100700827205882

#### val Acc: 0, NDCG: 0.6228352629220115 HIT: 0.7203527113970588
Epoch: 136, plus 0 steps train_loss: 0.6878

#### test Acc: 0, NDCG: 0.48539771636320994 HIT: 0.6082720588235294

#### val Acc: 0, NDCG: 0.5027637464584604 HIT: 0.6268267463235294
Epoch: 144, plus 0 steps train_loss: 0.6874

#### test Acc: 0, NDCG: 0.5842881550631162 HIT: 0.7079044117647059

#### val Acc: 0, NDCG: 0.599852263228793 HIT: 0.7159237132352941
Epoch: 160, plus 0 steps train_loss: 0.6839

#### test Acc: 0, NDCG: 0.5709013893453221 HIT: 0.6907743566176471

#### val Acc: 0, NDCG: 0.5727098833837341 HIT: 0.6939682904411765
Epoch: 176, plus 0 steps train_loss: 0.6858

#### test Acc: 0, NDCG: 0.5782249722550162 HIT: 0.6965705422794117

#### val Acc: 0, NDCG: 0.5905520098011332 HIT: 0.7063361672794117
Epoch: 192, plus 0 steps train_loss: 0.682

#### test Acc: 0, NDCG: 0.5981381878016203 HIT: 0.7115808823529413

#### val Acc: 0, NDCG: 0.614863800154019 HIT: 0.7289636948529412
Epoch: 208, plus 0 steps train_loss: 0.6784

#### test Acc: 0, NDCG: 0.6035711619603461 HIT: 0.7214671415441176

#### val Acc: 0, NDCG: 0.616406789824447 HIT: 0.7254653033088235
Epoch: 224, plus 0 steps train_loss: 0.6787

#### test Acc: 0, NDCG: 0.5953577705919348 HIT: 0.7080422794117647

#### val Acc: 0, NDCG: 0.6087993826368006 HIT: 0.7202435661764706
Epoch: 240, plus 0 steps train_loss: 0.6724

#### test Acc: 0, NDCG: 0.6108111393121958 HIT: 0.7250861672794118

#### val Acc: 0, NDCG: 0.6153853214598144 HIT: 0.7280388327205882
Epoch: 256, plus 0 steps train_loss: 0.6719

#### test Acc: 0, NDCG: 0.5976538449127874 HIT: 0.7103113511029412

#### val Acc: 0, NDCG: 0.6066114035854129 HIT: 0.72080078125
Epoch: 272, plus 0 steps train_loss: 0.6744

#### test Acc: 0, NDCG: 0.48015642986892065 HIT: 0.6266486672794118

#### val Acc: 0, NDCG: 0.49625405500928893 HIT: 0.6442727481617647
Epoch: 288, plus 0 steps train_loss: 0.6748

#### test Acc: 0, NDCG: 0.42340024606532245 HIT: 0.5857766544117646

#### val Acc: 0, NDCG: 0.4520274166324243 HIT: 0.6097771139705882
Epoch: 304, plus 0 steps train_loss: 0.6756

#### test Acc: 0, NDCG: 0.4047646345766112 HIT: 0.5692153033088235

#### val Acc: 0, NDCG: 0.4267515445483351 HIT: 0.5920266544117647
Epoch: 320, plus 0 steps train_loss: 0.6703

#### test Acc: 0, NDCG: 0.3167387690358312 HIT: 0.5007238051470588

#### val Acc: 0, NDCG: 0.3524798845461958 HIT: 0.5354951746323529
Epoch: 352, plus 0 steps train_loss: 0.6704

#### test Acc: 0, NDCG: 0.33500185926279685 HIT: 0.516796875

#### val Acc: 0, NDCG: 0.34413003470935954 HIT: 0.5212660845588235
Epoch: 384, plus 0 steps train_loss: 0.6623

#### test Acc: 0, NDCG: 0.3275907929198074 HIT: 0.5105698529411764

#### val Acc: 0, NDCG: 0.34418276657524943 HIT: 0.5169749540441176
Epoch: 416, plus 0 steps train_loss: 0.6613

#### test Acc: 0, NDCG: 0.35490659897676746 HIT: 0.5245519301470588

#### val Acc: 0, NDCG: 0.3717652356126807 HIT: 0.5357594209558824
Epoch: 448, plus 0 steps train_loss: 0.6537

#### test Acc: 0, NDCG: 0.26376317788401604 HIT: 0.4735409007352941

#### val Acc: 0, NDCG: 0.2698676656954525 HIT: 0.4848115808823529
Epoch: 480, plus 0 steps train_loss: 0.6526

#### test Acc: 0, NDCG: 0.26287408663348943 HIT: 0.46711282169117646

#### val Acc: 0, NDCG: 0.26457713990985965 HIT: 0.4681008731617647
Epoch: 512, plus 0 steps train_loss: 0.645

#### test Acc: 0, NDCG: 0.2595834458130772 HIT: 0.45732421875

#### val Acc: 0, NDCG: 0.2637937899970687 HIT: 0.46002412683823535
Epoch: 544, plus 0 steps train_loss: 0.6288

#### test Acc: 0, NDCG: 0.2591296194115157 HIT: 0.4635167738970588

#### val Acc: 0, NDCG: 0.2617261139085737 HIT: 0.4705652573529412
Epoch: 576, plus 0 steps train_loss: 0.6382

#### test Acc: 0, NDCG: 0.273975904664085 HIT: 0.48301930147058825

#### val Acc: 0, NDCG: 0.2764839548572994 HIT: 0.4885340073529412
Epoch: 608, plus 0 steps train_loss: 0.6367

#### test Acc: 0, NDCG: 0.2794950444411451 HIT: 0.4812959558823529

#### val Acc: 0, NDCG: 0.2863725329598473 HIT: 0.4886431525735294
Epoch: 640, plus 0 steps train_loss: 0.621

#### test Acc: 0, NDCG: 0.2969332342851389 HIT: 0.5042164522058823

#### val Acc: 0, NDCG: 0.3007916985821258 HIT: 0.5063534007352941
Epoch: 704, plus 0 steps train_loss: 0.6314

#### test Acc: 0, NDCG: 0.3121512063332758 HIT: 0.5199333639705882

#### val Acc: 0, NDCG: 0.32303014300875177 HIT: 0.5229664522058823
Epoch: 768, plus 0 steps train_loss: 0.6236

#### test Acc: 0, NDCG: 0.2990925869706195 HIT: 0.4987362132352941

#### val Acc: 0, NDCG: 0.3115644359723446 HIT: 0.5108226102941177
Epoch: 832, plus 0 steps train_loss: 0.6254

#### test Acc: 0, NDCG: 0.3048705473443023 HIT: 0.5074276194852941

#### val Acc: 0, NDCG: 0.30904487373846196 HIT: 0.5170726102941177
Epoch: 896, plus 0 steps train_loss: 0.6227

#### test Acc: 0, NDCG: 0.30518328678380413 HIT: 0.5059914981617647

#### val Acc: 0, NDCG: 0.31508391528808244 HIT: 0.5209156709558823
Epoch: 960, plus 0 steps train_loss: 0.6205

#### test Acc: 0, NDCG: 0.3077049444513893 HIT: 0.5094094669117647

#### val Acc: 0, NDCG: 0.3109382757079529 HIT: 0.5123276654411765
Epoch: 1013, plus 25 steps train_loss: 0.6322
Done: it took 280132.9179904461
max value of NDCG: 0.6176096648072037
max value of HIT: 0.7250861672794118

After 20 validations
max value of NDCG: 0.6176096648072037
max value of HIT: 0.7250861672794118
