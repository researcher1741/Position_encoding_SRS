 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.0001
max_norm:             	0.1
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.1290359348942584 HIT: 0.28483455882352937

#### val Acc: 0, NDCG: 0.13252110939962794 HIT: 0.28994140625
Epoch: 1, plus 0 steps train_loss: 0.8204

#### test Acc: 0, NDCG: 0.13052060311381383 HIT: 0.28548943014705885

#### val Acc: 0, NDCG: 0.12627534411287994 HIT: 0.27898667279411765
Epoch: 2, plus 0 steps train_loss: 0.7841

#### test Acc: 0, NDCG: 0.12680955053183848 HIT: 0.27934283088235295

#### val Acc: 0, NDCG: 0.12942494863763232 HIT: 0.28922334558823526
Epoch: 3, plus 0 steps train_loss: 0.7722

#### test Acc: 0, NDCG: 0.12870600706265228 HIT: 0.2887120863970588

#### val Acc: 0, NDCG: 0.1289461873691226 HIT: 0.2846622242647059
Epoch: 4, plus 0 steps train_loss: 0.7581

#### test Acc: 0, NDCG: 0.12834237300580348 HIT: 0.28478860294117647

#### val Acc: 0, NDCG: 0.1329305378607735 HIT: 0.2890912224264706
Epoch: 5, plus 0 steps train_loss: 0.7474

#### test Acc: 0, NDCG: 0.13018188353865728 HIT: 0.28833869485294117

#### val Acc: 0, NDCG: 0.12689172395980425 HIT: 0.27891199448529413
Epoch: 6, plus 0 steps train_loss: 0.7489

#### test Acc: 0, NDCG: 0.13034927194867435 HIT: 0.2827837775735294

#### val Acc: 0, NDCG: 0.1284424483018322 HIT: 0.28566176470588234
Epoch: 7, plus 0 steps train_loss: 0.7441

#### test Acc: 0, NDCG: 0.12608467567832618 HIT: 0.2798828125

#### val Acc: 0, NDCG: 0.12791977390009812 HIT: 0.2837833180147059
Epoch: 8, plus 0 steps train_loss: 0.7376

#### test Acc: 0, NDCG: 0.13175549725406027 HIT: 0.28852251838235293

#### val Acc: 0, NDCG: 0.12809644951943128 HIT: 0.2814625459558823
Epoch: 9, plus 0 steps train_loss: 0.7314

#### test Acc: 0, NDCG: 0.1326485964003306 HIT: 0.2888556985294118

#### val Acc: 0, NDCG: 0.12465899124406202 HIT: 0.2803596047794118
Epoch: 10, plus 0 steps train_loss: 0.7322

#### test Acc: 0, NDCG: 0.1301083990752203 HIT: 0.2861040900735294

#### val Acc: 0, NDCG: 0.1313136138110452 HIT: 0.28477711397058825
Epoch: 12, plus 0 steps train_loss: 0.7256

#### test Acc: 0, NDCG: 0.1335058637091004 HIT: 0.2912396599264706

#### val Acc: 0, NDCG: 0.12992294031224993 HIT: 0.28365119485294116
Epoch: 14, plus 0 steps train_loss: 0.7251

#### test Acc: 0, NDCG: 0.1305035109512887 HIT: 0.28609834558823527

#### val Acc: 0, NDCG: 0.13669094008158386 HIT: 0.2997185202205882
Epoch: 16, plus 0 steps train_loss: 0.7239

#### test Acc: 0, NDCG: 0.12758309102886184 HIT: 0.2808536305147059

#### val Acc: 0, NDCG: 0.13032183851836368 HIT: 0.2887982536764706
Epoch: 18, plus 0 steps train_loss: 0.7207

#### test Acc: 0, NDCG: 0.12594905750380375 HIT: 0.2811236213235294

#### val Acc: 0, NDCG: 0.1288482589550751 HIT: 0.2855526194852941
Epoch: 20, plus 0 steps train_loss: 0.712

#### test Acc: 0, NDCG: 0.12554682749973595 HIT: 0.27802734375

#### val Acc: 0, NDCG: 0.1289963242602723 HIT: 0.2907513786764706
Epoch: 22, plus 0 steps train_loss: 0.7134

#### test Acc: 0, NDCG: 0.12940449912808719 HIT: 0.2871725643382353

#### val Acc: 0, NDCG: 0.1281921992637101 HIT: 0.28498965992647063
Epoch: 24, plus 0 steps train_loss: 0.711

#### test Acc: 0, NDCG: 0.13266305390281774 HIT: 0.29406594669117647

#### val Acc: 0, NDCG: 0.12977512379311712 HIT: 0.28561006433823527
Epoch: 26, plus 0 steps train_loss: 0.7128

#### test Acc: 0, NDCG: 0.13602180484510476 HIT: 0.29789177389705884

#### val Acc: 0, NDCG: 0.13068573531245867 HIT: 0.28546070772058824
Epoch: 28, plus 0 steps train_loss: 0.7071

#### test Acc: 0, NDCG: 0.1577467057244487 HIT: 0.309375

#### val Acc: 0, NDCG: 0.16983413672639336 HIT: 0.32670036764705884
Epoch: 30, plus 0 steps train_loss: 0.708

#### test Acc: 0, NDCG: 0.2649941225932523 HIT: 0.41515969669117647

#### val Acc: 0, NDCG: 0.28496128861149383 HIT: 0.4362247242647059
Epoch: 32, plus 0 steps train_loss: 0.7053

#### test Acc: 0, NDCG: 0.27737610703616067 HIT: 0.42795840992647055

#### val Acc: 0, NDCG: 0.27786417418809484 HIT: 0.41943359375
Epoch: 36, plus 0 steps train_loss: 0.7017

#### test Acc: 0, NDCG: 0.3475232919825985 HIT: 0.4900965073529412

#### val Acc: 0, NDCG: 0.37009490697036523 HIT: 0.5113223805147059
Epoch: 40, plus 0 steps train_loss: 0.701

#### test Acc: 0, NDCG: 0.3818882416455443 HIT: 0.5234547334558823

#### val Acc: 0, NDCG: 0.3858557091420029 HIT: 0.5248334099264705
Epoch: 44, plus 0 steps train_loss: 0.7005

#### test Acc: 0, NDCG: 0.2898342449386902 HIT: 0.43655215992647056

#### val Acc: 0, NDCG: 0.3118714815340527 HIT: 0.45964499080882354
Epoch: 48, plus 0 steps train_loss: 0.7022

#### test Acc: 0, NDCG: 0.34763530909971324 HIT: 0.4911190257352941

#### val Acc: 0, NDCG: 0.36622325463301053 HIT: 0.5109892003676471
Epoch: 52, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.2752463931552482 HIT: 0.4240406709558823

#### val Acc: 0, NDCG: 0.2883960728358612 HIT: 0.4324793198529412
Epoch: 56, plus 0 steps train_loss: 0.6981

#### test Acc: 0, NDCG: 0.436961278085579 HIT: 0.5727194393382353

#### val Acc: 0, NDCG: 0.4507111377952319 HIT: 0.5873161764705882
Epoch: 60, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.45824639106552567 HIT: 0.5877757352941176

#### val Acc: 0, NDCG: 0.465996195946338 HIT: 0.5991096047794118
Epoch: 64, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.5131347872444552 HIT: 0.6404411764705882

#### val Acc: 0, NDCG: 0.5257178414018411 HIT: 0.6512465533088235
Epoch: 68, plus 0 steps train_loss: 0.6984

#### test Acc: 0, NDCG: 0.5417859317147091 HIT: 0.6607823988970588

#### val Acc: 0, NDCG: 0.5560716056351322 HIT: 0.6759478400735295
Epoch: 72, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.5814614212882674 HIT: 0.6988740808823529

#### val Acc: 0, NDCG: 0.5938034791665905 HIT: 0.7113683363970588
Epoch: 80, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.5392145927343581 HIT: 0.6632582720588236

#### val Acc: 0, NDCG: 0.5580373608368431 HIT: 0.6778377757352941
Epoch: 88, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.6110173503766904 HIT: 0.7161420036764705

#### val Acc: 0, NDCG: 0.6177006387599913 HIT: 0.7188648897058824
Epoch: 96, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.6399565505113121 HIT: 0.7350988051470588

#### val Acc: 0, NDCG: 0.640927770694198 HIT: 0.7358743106617647
Epoch: 104, plus 0 steps train_loss: 0.6926

#### test Acc: 0, NDCG: 0.631300297728264 HIT: 0.7280962775735295

#### val Acc: 0, NDCG: 0.6574572685809442 HIT: 0.7505514705882353
Epoch: 112, plus 0 steps train_loss: 0.693

#### test Acc: 0, NDCG: 0.5952239625215646 HIT: 0.7077320772058824

#### val Acc: 0, NDCG: 0.6112261069192266 HIT: 0.7216279871323529
Epoch: 120, plus 0 steps train_loss: 0.6924

#### test Acc: 0, NDCG: 0.5969956304707436 HIT: 0.7104434742647059

#### val Acc: 0, NDCG: 0.6215871872027698 HIT: 0.7318301930147059
Epoch: 128, plus 0 steps train_loss: 0.6914

#### test Acc: 0, NDCG: 0.6032600644912518 HIT: 0.7184397977941177

#### val Acc: 0, NDCG: 0.6056058498180403 HIT: 0.7117417279411764
Epoch: 136, plus 0 steps train_loss: 0.69

#### test Acc: 0, NDCG: 0.5970301151242934 HIT: 0.7087201286764706

#### val Acc: 0, NDCG: 0.611597786856438 HIT: 0.7222713694852941
Epoch: 144, plus 0 steps train_loss: 0.6912

#### test Acc: 0, NDCG: 0.5196016547754537 HIT: 0.6557215073529412

#### val Acc: 0, NDCG: 0.5325581632994065 HIT: 0.6719956341911765
Epoch: 160, plus 0 steps train_loss: 0.6859

#### test Acc: 0, NDCG: 0.42929675697060066 HIT: 0.5973747702205883

#### val Acc: 0, NDCG: 0.45471952721348535 HIT: 0.6179974724264705
Epoch: 176, plus 0 steps train_loss: 0.6864

#### test Acc: 0, NDCG: 0.23021577337000032 HIT: 0.4502297794117647

#### val Acc: 0, NDCG: 0.23086645562287136 HIT: 0.4484777113970588
Epoch: 192, plus 0 steps train_loss: 0.6833

#### test Acc: 0, NDCG: 0.23447461545415668 HIT: 0.4533605238970588

#### val Acc: 0, NDCG: 0.237919313304478 HIT: 0.4577952665441177
Epoch: 208, plus 0 steps train_loss: 0.6706

#### test Acc: 0, NDCG: 0.2323207361149163 HIT: 0.4480296415441177

#### val Acc: 0, NDCG: 0.24151297763670546 HIT: 0.4577607996323529
Epoch: 224, plus 0 steps train_loss: 0.6591

#### test Acc: 0, NDCG: 0.2261211548047845 HIT: 0.44671989889705876

#### val Acc: 0, NDCG: 0.2338867309177241 HIT: 0.45422219669117647
Epoch: 240, plus 0 steps train_loss: 0.6606

#### test Acc: 0, NDCG: 0.2319639986381834 HIT: 0.45275735294117647

#### val Acc: 0, NDCG: 0.23730690631847046 HIT: 0.45167738970588234
Epoch: 256, plus 0 steps train_loss: 0.6533

#### test Acc: 0, NDCG: 0.2278272975015577 HIT: 0.4428825827205882

#### val Acc: 0, NDCG: 0.22559300497586188 HIT: 0.43397863051470587
Epoch: 272, plus 0 steps train_loss: 0.6503

#### test Acc: 0, NDCG: 0.24474387995646066 HIT: 0.46202895220588236

#### val Acc: 0, NDCG: 0.2535368076758379 HIT: 0.4759248621323529
Epoch: 288, plus 0 steps train_loss: 0.6446

#### test Acc: 0, NDCG: 0.24212630085271297 HIT: 0.4561293658088236

#### val Acc: 0, NDCG: 0.2435770022585848 HIT: 0.4605870863970588
Epoch: 304, plus 0 steps train_loss: 0.6494

#### test Acc: 0, NDCG: 0.24322170131186432 HIT: 0.4661764705882353

#### val Acc: 0, NDCG: 0.24938885164750185 HIT: 0.4728687959558823
Epoch: 320, plus 0 steps train_loss: 0.6496

#### test Acc: 0, NDCG: 0.2471631046099371 HIT: 0.4682961856617647

#### val Acc: 0, NDCG: 0.2548844471413076 HIT: 0.47661994485294124
Epoch: 352, plus 0 steps train_loss: 0.6371

#### test Acc: 0, NDCG: 0.24304421285482097 HIT: 0.4594324448529412

#### val Acc: 0, NDCG: 0.2508940227902249 HIT: 0.4648092830882353
Epoch: 384, plus 0 steps train_loss: 0.6341

#### test Acc: 0, NDCG: 0.25325851763294416 HIT: 0.47653952205882355

#### val Acc: 0, NDCG: 0.2572677667028783 HIT: 0.4788660386029412
Epoch: 416, plus 0 steps train_loss: 0.6372

#### test Acc: 0, NDCG: 0.2638054554724413 HIT: 0.48547219669117647

#### val Acc: 0, NDCG: 0.2699850047910285 HIT: 0.49802389705882355
Epoch: 448, plus 0 steps train_loss: 0.6267

#### test Acc: 0, NDCG: 0.2747854925612712 HIT: 0.5070369944852942

#### val Acc: 0, NDCG: 0.27837298056975224 HIT: 0.5110868566176471
Epoch: 480, plus 0 steps train_loss: 0.6258

#### test Acc: 0, NDCG: 0.27229916883529964 HIT: 0.5145852481617647

#### val Acc: 0, NDCG: 0.266659366709714 HIT: 0.5051470588235294
Epoch: 512, plus 0 steps train_loss: 0.6147

#### test Acc: 0, NDCG: 0.2750948185822696 HIT: 0.5084558823529413

#### val Acc: 0, NDCG: 0.2804865910036939 HIT: 0.5210018382352941
Epoch: 544, plus 0 steps train_loss: 0.6217

#### test Acc: 0, NDCG: 0.27325607039713445 HIT: 0.5051872702205882

#### val Acc: 0, NDCG: 0.28392090224576116 HIT: 0.5246380974264706
Epoch: 576, plus 0 steps train_loss: 0.6181

#### test Acc: 0, NDCG: 0.29128856559296784 HIT: 0.5339556525735294

#### val Acc: 0, NDCG: 0.29491800229739085 HIT: 0.5464499080882353
Epoch: 608, plus 0 steps train_loss: 0.604

#### test Acc: 0, NDCG: 0.28502763375122503 HIT: 0.5276079963235294

#### val Acc: 0, NDCG: 0.2907151670303746 HIT: 0.5312442555147059
Epoch: 640, plus 0 steps train_loss: 0.6149

#### test Acc: 0, NDCG: 0.2895072931403629 HIT: 0.5332261029411764

#### val Acc: 0, NDCG: 0.2956783300257887 HIT: 0.5466222426470588
Epoch: 704, plus 0 steps train_loss: 0.6095

#### test Acc: 0, NDCG: 0.30219054260870026 HIT: 0.5516946231617647

#### val Acc: 0, NDCG: 0.2987599353317968 HIT: 0.5487017463235294
Epoch: 768, plus 0 steps train_loss: 0.6035

#### test Acc: 0, NDCG: 0.3005041530918716 HIT: 0.5556640625

#### val Acc: 0, NDCG: 0.3002035077986813 HIT: 0.5549230238970588
Epoch: 832, plus 0 steps train_loss: 0.5959

#### test Acc: 0, NDCG: 0.2960932036818425 HIT: 0.5465418198529413

#### val Acc: 0, NDCG: 0.30115197151202466 HIT: 0.5537454044117647
Epoch: 896, plus 0 steps train_loss: 0.5961

#### test Acc: 0, NDCG: 0.30527374312767164 HIT: 0.5527458639705882

#### val Acc: 0, NDCG: 0.3060342288154053 HIT: 0.5554515165441176
Epoch: 960, plus 0 steps train_loss: 0.6085

#### test Acc: 0, NDCG: 0.3045573503753433 HIT: 0.5557444852941177

#### val Acc: 0, NDCG: 0.3046200815521059 HIT: 0.5540498621323529
Epoch: 1013, plus 25 steps train_loss: 0.5957
Done: it took 280702.3042201996
max value of NDCG: 0.6399565505113121
max value of HIT: 0.7350988051470588

After 20 validations
max value of NDCG: 0.6399565505113121
max value of HIT: 0.7350988051470588
