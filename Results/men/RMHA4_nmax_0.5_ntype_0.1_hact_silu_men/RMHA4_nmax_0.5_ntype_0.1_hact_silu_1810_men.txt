 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.1
max_norm:             	0.5
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12852488987968158 HIT: 0.28629940257352937

#### val Acc: 0, NDCG: 0.1290443003996592 HIT: 0.2858340992647059
Epoch: 1, plus 0 steps train_loss: 0.7796

#### test Acc: 0, NDCG: 0.12511076234600207 HIT: 0.2821403952205882

#### val Acc: 0, NDCG: 0.13554095263272692 HIT: 0.29311810661764703
Epoch: 2, plus 0 steps train_loss: 0.7549

#### test Acc: 0, NDCG: 0.1276854269625884 HIT: 0.2800149356617647

#### val Acc: 0, NDCG: 0.1304624425863289 HIT: 0.28992991727941175
Epoch: 3, plus 0 steps train_loss: 0.7482

#### test Acc: 0, NDCG: 0.12777168352396664 HIT: 0.27752182904411765

#### val Acc: 0, NDCG: 0.13007160725045472 HIT: 0.29214728860294115
Epoch: 4, plus 0 steps train_loss: 0.7283

#### test Acc: 0, NDCG: 0.13187514231506028 HIT: 0.28706916360294116

#### val Acc: 0, NDCG: 0.1277572027917045 HIT: 0.2808995863970588
Epoch: 5, plus 0 steps train_loss: 0.715

#### test Acc: 0, NDCG: 0.12811856076743583 HIT: 0.2773494944852941

#### val Acc: 0, NDCG: 0.13100773449228792 HIT: 0.2894818474264706
Epoch: 6, plus 0 steps train_loss: 0.7123

#### test Acc: 0, NDCG: 0.12723063987156172 HIT: 0.27902688419117644

#### val Acc: 0, NDCG: 0.12805864641803383 HIT: 0.28335248161764703
Epoch: 7, plus 0 steps train_loss: 0.7122

#### test Acc: 0, NDCG: 0.1259798384599349 HIT: 0.2812614889705882

#### val Acc: 0, NDCG: 0.12811233874910383 HIT: 0.28309397977941175
Epoch: 8, plus 0 steps train_loss: 0.7089

#### test Acc: 0, NDCG: 0.13055453475529358 HIT: 0.2844611672794118

#### val Acc: 0, NDCG: 0.1261933384030281 HIT: 0.2802619485294118
Epoch: 9, plus 0 steps train_loss: 0.7098

#### test Acc: 0, NDCG: 0.12879822855352446 HIT: 0.2824908088235294

#### val Acc: 0, NDCG: 0.1238767906386415 HIT: 0.2754193474264706
Epoch: 10, plus 0 steps train_loss: 0.7071

#### test Acc: 0, NDCG: 0.13188013194669987 HIT: 0.29138901654411764

#### val Acc: 0, NDCG: 0.1304814393585097 HIT: 0.2851275275735294
Epoch: 12, plus 0 steps train_loss: 0.7033

#### test Acc: 0, NDCG: 0.13293579474115896 HIT: 0.2901022518382353

#### val Acc: 0, NDCG: 0.1306726488363681 HIT: 0.28192210477941176
Epoch: 14, plus 0 steps train_loss: 0.7047

#### test Acc: 0, NDCG: 0.13250502483229282 HIT: 0.28806870404411766

#### val Acc: 0, NDCG: 0.13093944206256453 HIT: 0.28324333639705884
Epoch: 16, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.13196303775359797 HIT: 0.28999310661764705

#### val Acc: 0, NDCG: 0.13319669956103086 HIT: 0.28640280330882356
Epoch: 18, plus 0 steps train_loss: 0.7027

#### test Acc: 0, NDCG: 0.14034575848741715 HIT: 0.29725413602941175

#### val Acc: 0, NDCG: 0.14148393163557305 HIT: 0.29881089154411766
Epoch: 20, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.1594585716039681 HIT: 0.3171817555147059

#### val Acc: 0, NDCG: 0.1640870000738615 HIT: 0.3177274816176471
Epoch: 22, plus 0 steps train_loss: 0.6992

#### test Acc: 0, NDCG: 0.18542983956702855 HIT: 0.34330767463235295

#### val Acc: 0, NDCG: 0.19740471323967745 HIT: 0.3579388786764706
Epoch: 24, plus 0 steps train_loss: 0.7013

#### test Acc: 0, NDCG: 0.19072821574595902 HIT: 0.34657628676470587

#### val Acc: 0, NDCG: 0.19660686564528218 HIT: 0.3551930147058823
Epoch: 26, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.20269733205803253 HIT: 0.35962775735294117

#### val Acc: 0, NDCG: 0.2188860826084933 HIT: 0.378515625
Epoch: 28, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.29471791491100974 HIT: 0.44404296875

#### val Acc: 0, NDCG: 0.3048645535333192 HIT: 0.45852481617647056
Epoch: 30, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.29994339728495567 HIT: 0.4496553308823529

#### val Acc: 0, NDCG: 0.3137816093931603 HIT: 0.47072035845588234
Epoch: 32, plus 0 steps train_loss: 0.6946

#### test Acc: 0, NDCG: 0.1942953077112481 HIT: 0.36951401654411764

#### val Acc: 0, NDCG: 0.2002895850237457 HIT: 0.3749368106617647
Epoch: 36, plus 0 steps train_loss: 0.6922

#### test Acc: 0, NDCG: 0.21164975657910068 HIT: 0.38683938419117647

#### val Acc: 0, NDCG: 0.22858351798924206 HIT: 0.4031824448529412
Epoch: 40, plus 0 steps train_loss: 0.6929

#### test Acc: 0, NDCG: 0.1766953268585904 HIT: 0.36344784007352937

#### val Acc: 0, NDCG: 0.1741628521895559 HIT: 0.3597771139705882
Epoch: 44, plus 0 steps train_loss: 0.6927

#### test Acc: 0, NDCG: 0.19886201414558152 HIT: 0.40178653492647054

#### val Acc: 0, NDCG: 0.19959136409465955 HIT: 0.39679457720588235
Epoch: 48, plus 0 steps train_loss: 0.6874

#### test Acc: 0, NDCG: 0.2099754711179984 HIT: 0.41423483455882354

#### val Acc: 0, NDCG: 0.2138460596097894 HIT: 0.4210994944852941
Epoch: 52, plus 0 steps train_loss: 0.6909

#### test Acc: 0, NDCG: 0.22361774233648632 HIT: 0.44308938419117644

#### val Acc: 0, NDCG: 0.2250286358289896 HIT: 0.44094094669117645
Epoch: 56, plus 0 steps train_loss: 0.681

#### test Acc: 0, NDCG: 0.2524240838664661 HIT: 0.5034409466911764

#### val Acc: 0, NDCG: 0.25261675222565966 HIT: 0.5075482536764706
Epoch: 60, plus 0 steps train_loss: 0.6548

#### test Acc: 0, NDCG: 0.260467199109126 HIT: 0.5140452665441176

#### val Acc: 0, NDCG: 0.25134766656801444 HIT: 0.5011546415441177
Epoch: 64, plus 0 steps train_loss: 0.6543

#### test Acc: 0, NDCG: 0.2561336345196369 HIT: 0.5071461397058823

#### val Acc: 0, NDCG: 0.26317539249862426 HIT: 0.5154756433823529
Epoch: 68, plus 0 steps train_loss: 0.6241

#### test Acc: 0, NDCG: 0.2651982084349852 HIT: 0.5142693014705882

#### val Acc: 0, NDCG: 0.2697884401371863 HIT: 0.52373046875
Epoch: 72, plus 0 steps train_loss: 0.6203

#### test Acc: 0, NDCG: 0.2718017542378528 HIT: 0.5226907169117647

#### val Acc: 0, NDCG: 0.28191975522461454 HIT: 0.5411247702205882
Epoch: 80, plus 0 steps train_loss: 0.6211

#### test Acc: 0, NDCG: 0.2782412211632401 HIT: 0.5328527113970588

#### val Acc: 0, NDCG: 0.288918117816262 HIT: 0.5485926011029412
Epoch: 88, plus 0 steps train_loss: 0.5982

#### test Acc: 0, NDCG: 0.2952333509152874 HIT: 0.5516716452205882

#### val Acc: 0, NDCG: 0.2936951848078663 HIT: 0.5514993106617647
Epoch: 96, plus 0 steps train_loss: 0.6156

#### test Acc: 0, NDCG: 0.29916870252462513 HIT: 0.5591681985294118

#### val Acc: 0, NDCG: 0.30959607785642407 HIT: 0.5701976102941176
Epoch: 104, plus 0 steps train_loss: 0.5993

#### test Acc: 0, NDCG: 0.29926792561257953 HIT: 0.5591452205882353

#### val Acc: 0, NDCG: 0.3015514191718559 HIT: 0.5646254595588236
Epoch: 112, plus 0 steps train_loss: 0.5801

#### test Acc: 0, NDCG: 0.3101964172602988 HIT: 0.5746036305147059

#### val Acc: 0, NDCG: 0.31061799985530303 HIT: 0.5735753676470587
Epoch: 120, plus 0 steps train_loss: 0.5813

#### test Acc: 0, NDCG: 0.3218590482355686 HIT: 0.58828125

#### val Acc: 0, NDCG: 0.32581884747003004 HIT: 0.5940085018382353
Epoch: 128, plus 0 steps train_loss: 0.584

#### test Acc: 0, NDCG: 0.3261572264819594 HIT: 0.5907801011029412

#### val Acc: 0, NDCG: 0.3233172356103632 HIT: 0.5862879136029412
Epoch: 136, plus 0 steps train_loss: 0.5851

#### test Acc: 0, NDCG: 0.32619021267840487 HIT: 0.5845071231617647

#### val Acc: 0, NDCG: 0.33150050192117597 HIT: 0.5884708180147059
Epoch: 144, plus 0 steps train_loss: 0.5951

#### test Acc: 0, NDCG: 0.33739014360750674 HIT: 0.5995806525735294

#### val Acc: 0, NDCG: 0.3481394459513296 HIT: 0.6095703125
Epoch: 160, plus 0 steps train_loss: 0.5656

#### test Acc: 0, NDCG: 0.3491542933796975 HIT: 0.6072725183823529

#### val Acc: 0, NDCG: 0.3535739014080855 HIT: 0.6115923713235294
Epoch: 176, plus 0 steps train_loss: 0.563

#### test Acc: 0, NDCG: 0.34412328502204714 HIT: 0.6030043658088236

#### val Acc: 0, NDCG: 0.35814123204131554 HIT: 0.6213465073529412
Epoch: 192, plus 0 steps train_loss: 0.5608

#### test Acc: 0, NDCG: 0.3621620520148533 HIT: 0.6184512867647058

#### val Acc: 0, NDCG: 0.37231133058324506 HIT: 0.6344209558823529
Epoch: 208, plus 0 steps train_loss: 0.5477

#### test Acc: 0, NDCG: 0.36542937444303786 HIT: 0.6265395220588236

#### val Acc: 0, NDCG: 0.3724006677947766 HIT: 0.6257352941176471
Epoch: 224, plus 0 steps train_loss: 0.5386

#### test Acc: 0, NDCG: 0.3722994293039254 HIT: 0.6207490808823529

#### val Acc: 0, NDCG: 0.3759818113313314 HIT: 0.6299689797794118
Epoch: 240, plus 0 steps train_loss: 0.5432

#### test Acc: 0, NDCG: 0.37672294000402323 HIT: 0.6311868106617646

#### val Acc: 0, NDCG: 0.3872678638679535 HIT: 0.6430549172794118
Epoch: 256, plus 0 steps train_loss: 0.527

#### test Acc: 0, NDCG: 0.3783374448831987 HIT: 0.6361328125

#### val Acc: 0, NDCG: 0.3914976170193301 HIT: 0.6511833639705882
Epoch: 272, plus 0 steps train_loss: 0.5234

#### test Acc: 0, NDCG: 0.3738324555477149 HIT: 0.6215475643382353

#### val Acc: 0, NDCG: 0.3971951276261879 HIT: 0.6544289981617647
Epoch: 288, plus 0 steps train_loss: 0.5346

#### test Acc: 0, NDCG: 0.38622831874275027 HIT: 0.6387350643382353

#### val Acc: 0, NDCG: 0.3990877121820384 HIT: 0.6513269761029412
Epoch: 304, plus 0 steps train_loss: 0.5082

#### test Acc: 0, NDCG: 0.38445327125958867 HIT: 0.6362821691176471

#### val Acc: 0, NDCG: 0.400716485280835 HIT: 0.65927734375
Epoch: 320, plus 0 steps train_loss: 0.5108

#### test Acc: 0, NDCG: 0.3875490927102148 HIT: 0.6348345588235295

#### val Acc: 0, NDCG: 0.4008121707842709 HIT: 0.6532169117647059
Epoch: 352, plus 0 steps train_loss: 0.5093

#### test Acc: 0, NDCG: 0.3939528944635221 HIT: 0.6399528952205882

#### val Acc: 0, NDCG: 0.40177162355586454 HIT: 0.6541877297794118
Epoch: 384, plus 0 steps train_loss: 0.4872

#### test Acc: 0, NDCG: 0.40367361954270553 HIT: 0.6490234375

#### val Acc: 0, NDCG: 0.4114705752645801 HIT: 0.6623736213235294
Epoch: 416, plus 0 steps train_loss: 0.5069

#### test Acc: 0, NDCG: 0.395295467268835 HIT: 0.6507755055147059

#### val Acc: 0, NDCG: 0.4093843616646371 HIT: 0.6649356617647059
Epoch: 448, plus 0 steps train_loss: 0.4917

#### test Acc: 0, NDCG: 0.3945136568262372 HIT: 0.6380112591911764

#### val Acc: 0, NDCG: 0.4117333070819118 HIT: 0.6619083180147058
Epoch: 480, plus 0 steps train_loss: 0.4863

#### test Acc: 0, NDCG: 0.40406481666197996 HIT: 0.6490349264705882

#### val Acc: 0, NDCG: 0.41778182964289085 HIT: 0.6645278033088236
Epoch: 512, plus 0 steps train_loss: 0.4934

#### test Acc: 0, NDCG: 0.39809864482692586 HIT: 0.6467256433823529

#### val Acc: 0, NDCG: 0.41806302978639964 HIT: 0.6652286305147059
Epoch: 544, plus 0 steps train_loss: 0.4883

#### test Acc: 0, NDCG: 0.4047044716426818 HIT: 0.6488625919117647

#### val Acc: 0, NDCG: 0.4144734129909985 HIT: 0.6616325827205882
Epoch: 576, plus 0 steps train_loss: 0.4827

#### test Acc: 0, NDCG: 0.40676012204739537 HIT: 0.6528550091911764

#### val Acc: 0, NDCG: 0.41781168162165416 HIT: 0.6676355698529413
Epoch: 608, plus 0 steps train_loss: 0.46

#### test Acc: 0, NDCG: 0.4085495572343067 HIT: 0.6580767463235294

#### val Acc: 0, NDCG: 0.4189318901120542 HIT: 0.6705824908088236
Epoch: 640, plus 0 steps train_loss: 0.4805

#### test Acc: 0, NDCG: 0.40551177685356044 HIT: 0.6534639246323529

#### val Acc: 0, NDCG: 0.4224945006176468 HIT: 0.6670036764705882
Epoch: 704, plus 0 steps train_loss: 0.4615

#### test Acc: 0, NDCG: 0.41724621475904655 HIT: 0.6618566176470588

#### val Acc: 0, NDCG: 0.4194870812803154 HIT: 0.6602136948529412
Epoch: 768, plus 0 steps train_loss: 0.4682

#### test Acc: 0, NDCG: 0.4042128801110252 HIT: 0.6468290441176471

#### val Acc: 0, NDCG: 0.42420100611498635 HIT: 0.6668198529411764
Epoch: 832, plus 0 steps train_loss: 0.4427

#### test Acc: 0, NDCG: 0.40581685015568053 HIT: 0.6436580882352941

#### val Acc: 0, NDCG: 0.42155198241645253 HIT: 0.6657341452205883
Epoch: 896, plus 0 steps train_loss: 0.4545

#### test Acc: 0, NDCG: 0.4035483030563093 HIT: 0.6417738970588236

#### val Acc: 0, NDCG: 0.4282024774116505 HIT: 0.6722139246323529
Epoch: 960, plus 0 steps train_loss: 0.4473

#### test Acc: 0, NDCG: 0.4076365026463639 HIT: 0.6440085018382353

#### val Acc: 0, NDCG: 0.42071288109149824 HIT: 0.6629078584558823
Epoch: 1013, plus 25 steps train_loss: 0.4739
Done: it took 276390.0676622391
max value of NDCG: 0.41724621475904655
max value of HIT: 0.6618566176470588

After 20 validations
max value of NDCG: 0.41724621475904655
max value of HIT: 0.6618566176470588
