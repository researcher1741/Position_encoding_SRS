 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.01
max_norm:             	None
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.13254753096690378 HIT: 0.28845932904411764

#### val Acc: 0, NDCG: 0.1266912611340283 HIT: 0.2812385110294118
Epoch: 1, plus 0 steps train_loss: 0.7585

#### test Acc: 0, NDCG: 0.1328577390258784 HIT: 0.29357766544117647

#### val Acc: 0, NDCG: 0.13224219870789536 HIT: 0.2913660386029412
Epoch: 2, plus 0 steps train_loss: 0.7448

#### test Acc: 0, NDCG: 0.1309399996032296 HIT: 0.28672449448529413

#### val Acc: 0, NDCG: 0.1310892304296914 HIT: 0.28956801470588234
Epoch: 3, plus 0 steps train_loss: 0.7362

#### test Acc: 0, NDCG: 0.1354198831080589 HIT: 0.2916417738970588

#### val Acc: 0, NDCG: 0.1361258610264129 HIT: 0.28994140625
Epoch: 4, plus 0 steps train_loss: 0.7235

#### test Acc: 0, NDCG: 0.1689630330991619 HIT: 0.32522977941176473

#### val Acc: 0, NDCG: 0.18092031566538233 HIT: 0.3402630974264706
Epoch: 5, plus 0 steps train_loss: 0.7174

#### test Acc: 0, NDCG: 0.14098454147764505 HIT: 0.3041302849264706

#### val Acc: 0, NDCG: 0.150338607143702 HIT: 0.3065659466911764
Epoch: 6, plus 0 steps train_loss: 0.7121

#### test Acc: 0, NDCG: 0.14122322115704222 HIT: 0.2979894301470588

#### val Acc: 0, NDCG: 0.14786857934433023 HIT: 0.30668658088235295
Epoch: 7, plus 0 steps train_loss: 0.7105

#### test Acc: 0, NDCG: 0.13677299008001684 HIT: 0.29473805147058824

#### val Acc: 0, NDCG: 0.13800796764132653 HIT: 0.2955422794117647
Epoch: 8, plus 0 steps train_loss: 0.7104

#### test Acc: 0, NDCG: 0.1362951333826279 HIT: 0.2934857536764706

#### val Acc: 0, NDCG: 0.13904225248776197 HIT: 0.30144186580882354
Epoch: 9, plus 0 steps train_loss: 0.7087

#### test Acc: 0, NDCG: 0.15711904341289612 HIT: 0.3139016544117647

#### val Acc: 0, NDCG: 0.17455043302330983 HIT: 0.33718405330882356
Epoch: 10, plus 0 steps train_loss: 0.7046

#### test Acc: 0, NDCG: 0.15922944913195416 HIT: 0.3200482536764706

#### val Acc: 0, NDCG: 0.1698534891978807 HIT: 0.33416245404411765
Epoch: 12, plus 0 steps train_loss: 0.705

#### test Acc: 0, NDCG: 0.18924901824640633 HIT: 0.3501665900735294

#### val Acc: 0, NDCG: 0.21131059494532045 HIT: 0.3706858915441177
Epoch: 14, plus 0 steps train_loss: 0.7017

#### test Acc: 0, NDCG: 0.2134897923191089 HIT: 0.37454618566176473

#### val Acc: 0, NDCG: 0.2270649750915182 HIT: 0.38357077205882356
Epoch: 16, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.18402992242349875 HIT: 0.34373276654411766

#### val Acc: 0, NDCG: 0.19654025931583213 HIT: 0.3563648897058823
Epoch: 18, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.2245330592052907 HIT: 0.38724724264705884

#### val Acc: 0, NDCG: 0.2571070428188583 HIT: 0.41835363051470587
Epoch: 20, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.20391184929163925 HIT: 0.37383961397058824

#### val Acc: 0, NDCG: 0.21920625755236176 HIT: 0.38578239889705884
Epoch: 22, plus 0 steps train_loss: 0.6999

#### test Acc: 0, NDCG: 0.15442600049505337 HIT: 0.32626953125

#### val Acc: 0, NDCG: 0.16687493111343682 HIT: 0.3390567555147059
Epoch: 24, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.16106350868314495 HIT: 0.3346737132352941

#### val Acc: 0, NDCG: 0.16985001603240443 HIT: 0.3452952665441177
Epoch: 26, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.17488569391273573 HIT: 0.3506146599264706

#### val Acc: 0, NDCG: 0.18578685927527136 HIT: 0.36424057904411766
Epoch: 28, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.20072484145921554 HIT: 0.38250229779411765

#### val Acc: 0, NDCG: 0.2101506006654777 HIT: 0.38537454044117647
Epoch: 30, plus 0 steps train_loss: 0.6932

#### test Acc: 0, NDCG: 0.20274888429672897 HIT: 0.39080307904411765

#### val Acc: 0, NDCG: 0.21850078553659324 HIT: 0.40187270220588234
Epoch: 32, plus 0 steps train_loss: 0.6944

#### test Acc: 0, NDCG: 0.19815888671636386 HIT: 0.40251608455882354

#### val Acc: 0, NDCG: 0.20108324033504338 HIT: 0.4006893382352941
Epoch: 36, plus 0 steps train_loss: 0.6766

#### test Acc: 0, NDCG: 0.20848898678680916 HIT: 0.4194450827205882

#### val Acc: 0, NDCG: 0.20952527514199945 HIT: 0.41550436580882355
Epoch: 40, plus 0 steps train_loss: 0.6689

#### test Acc: 0, NDCG: 0.2246579667023061 HIT: 0.44931640625

#### val Acc: 0, NDCG: 0.22511788283628165 HIT: 0.4486328125
Epoch: 44, plus 0 steps train_loss: 0.6561

#### test Acc: 0, NDCG: 0.235622276411235 HIT: 0.46364315257352945

#### val Acc: 0, NDCG: 0.23301556020996433 HIT: 0.4648954503676471
Epoch: 48, plus 0 steps train_loss: 0.6611

#### test Acc: 0, NDCG: 0.2416517927753679 HIT: 0.4741670496323529

#### val Acc: 0, NDCG: 0.24532648116359163 HIT: 0.47868795955882354
Epoch: 52, plus 0 steps train_loss: 0.6442

#### test Acc: 0, NDCG: 0.2536991658357687 HIT: 0.5051068474264706

#### val Acc: 0, NDCG: 0.2522820497211337 HIT: 0.4892176011029412
Epoch: 56, plus 0 steps train_loss: 0.6401

#### test Acc: 0, NDCG: 0.25988218519381745 HIT: 0.5091279871323529

#### val Acc: 0, NDCG: 0.26418206617295803 HIT: 0.5125804227941176
Epoch: 60, plus 0 steps train_loss: 0.6384

#### test Acc: 0, NDCG: 0.26300252088983733 HIT: 0.5114028033088236

#### val Acc: 0, NDCG: 0.2696457802396345 HIT: 0.5178366268382353
Epoch: 64, plus 0 steps train_loss: 0.6364

#### test Acc: 0, NDCG: 0.269286517512383 HIT: 0.5242359834558823

#### val Acc: 0, NDCG: 0.27523391764408806 HIT: 0.5233857996323529
Epoch: 68, plus 0 steps train_loss: 0.6247

#### test Acc: 0, NDCG: 0.27627340355670854 HIT: 0.5271943933823529

#### val Acc: 0, NDCG: 0.28047319374780755 HIT: 0.5306985294117647
Epoch: 72, plus 0 steps train_loss: 0.6267

#### test Acc: 0, NDCG: 0.2790689919297081 HIT: 0.5256433823529412

#### val Acc: 0, NDCG: 0.28969764427005545 HIT: 0.5368738511029412
Epoch: 80, plus 0 steps train_loss: 0.6291

#### test Acc: 0, NDCG: 0.28704986826372614 HIT: 0.5335994944852941

#### val Acc: 0, NDCG: 0.2931978514731627 HIT: 0.5411879595588236
Epoch: 88, plus 0 steps train_loss: 0.6191

#### test Acc: 0, NDCG: 0.2874918486253089 HIT: 0.5309914981617647

#### val Acc: 0, NDCG: 0.2939540197433171 HIT: 0.5404239430147059
Epoch: 96, plus 0 steps train_loss: 0.6009

#### test Acc: 0, NDCG: 0.2831764447635668 HIT: 0.5268439797794118

#### val Acc: 0, NDCG: 0.2966810457386413 HIT: 0.5411075367647059
Epoch: 104, plus 0 steps train_loss: 0.584

#### test Acc: 0, NDCG: 0.30883270187221423 HIT: 0.5532169117647059

#### val Acc: 0, NDCG: 0.3148003218976263 HIT: 0.5598288143382353
Epoch: 112, plus 0 steps train_loss: 0.6069

#### test Acc: 0, NDCG: 0.300850336241283 HIT: 0.5395737591911764

#### val Acc: 0, NDCG: 0.31116350923199265 HIT: 0.5584099264705882
Epoch: 120, plus 0 steps train_loss: 0.5847

#### test Acc: 0, NDCG: 0.3108515164075897 HIT: 0.5554400275735294

#### val Acc: 0, NDCG: 0.31186515292798994 HIT: 0.5608283547794117
Epoch: 128, plus 0 steps train_loss: 0.5906

#### test Acc: 0, NDCG: 0.31280551703162507 HIT: 0.5556008731617647

#### val Acc: 0, NDCG: 0.3211735694669885 HIT: 0.5629940257352941
Epoch: 136, plus 0 steps train_loss: 0.5859

#### test Acc: 0, NDCG: 0.3224084851246338 HIT: 0.5633559283088235

#### val Acc: 0, NDCG: 0.32501161890015623 HIT: 0.5733972886029413
Epoch: 144, plus 0 steps train_loss: 0.5833

#### test Acc: 0, NDCG: 0.3282713898033016 HIT: 0.5755170036764705

#### val Acc: 0, NDCG: 0.3370490987529506 HIT: 0.5849781709558823
Epoch: 160, plus 0 steps train_loss: 0.5655

#### test Acc: 0, NDCG: 0.3334489825143242 HIT: 0.5816176470588236

#### val Acc: 0, NDCG: 0.3416947705705521 HIT: 0.5888039981617647
Epoch: 176, plus 0 steps train_loss: 0.5592

#### test Acc: 0, NDCG: 0.3388298747243041 HIT: 0.5828297334558823

#### val Acc: 0, NDCG: 0.34493714134595377 HIT: 0.5937787224264706
Epoch: 192, plus 0 steps train_loss: 0.5672

#### test Acc: 0, NDCG: 0.34375523459447 HIT: 0.5937097886029412

#### val Acc: 0, NDCG: 0.35282929009208164 HIT: 0.5956227022058823
Epoch: 208, plus 0 steps train_loss: 0.5482

#### test Acc: 0, NDCG: 0.3463400038561889 HIT: 0.5937212775735294

#### val Acc: 0, NDCG: 0.3529910315012641 HIT: 0.5943244485294118
Epoch: 224, plus 0 steps train_loss: 0.5584

#### test Acc: 0, NDCG: 0.35230286093701885 HIT: 0.5976217830882353

#### val Acc: 0, NDCG: 0.3646274010230706 HIT: 0.608203125
Epoch: 240, plus 0 steps train_loss: 0.5343

#### test Acc: 0, NDCG: 0.3592287615397826 HIT: 0.6005112591911764

#### val Acc: 0, NDCG: 0.3595601994552946 HIT: 0.6049402573529412
Epoch: 256, plus 0 steps train_loss: 0.5398

#### test Acc: 0, NDCG: 0.3550078397911859 HIT: 0.5989315257352941

#### val Acc: 0, NDCG: 0.36150537206119193 HIT: 0.6087603400735294
Epoch: 272, plus 0 steps train_loss: 0.5272

#### test Acc: 0, NDCG: 0.36002442307845467 HIT: 0.6039636948529412

#### val Acc: 0, NDCG: 0.3654147826568498 HIT: 0.6111787683823529
Epoch: 288, plus 0 steps train_loss: 0.5419

#### test Acc: 0, NDCG: 0.3655635890201416 HIT: 0.6135052849264706

#### val Acc: 0, NDCG: 0.36716146692703877 HIT: 0.6086511948529412
Epoch: 304, plus 0 steps train_loss: 0.5251

#### test Acc: 0, NDCG: 0.37001347714616517 HIT: 0.6152113970588236

#### val Acc: 0, NDCG: 0.37042446723985534 HIT: 0.6097081801470587
Epoch: 320, plus 0 steps train_loss: 0.5261

#### test Acc: 0, NDCG: 0.36759816975022386 HIT: 0.6094324448529412

#### val Acc: 0, NDCG: 0.36861374303158484 HIT: 0.6106904871323529
Epoch: 352, plus 0 steps train_loss: 0.5206

#### test Acc: 0, NDCG: 0.3778822483519832 HIT: 0.6208295036764706

#### val Acc: 0, NDCG: 0.3848674075587766 HIT: 0.6318359375
Epoch: 384, plus 0 steps train_loss: 0.5141

#### test Acc: 0, NDCG: 0.3836609178631392 HIT: 0.62958984375

#### val Acc: 0, NDCG: 0.3871216975697562 HIT: 0.6379480698529412
Epoch: 416, plus 0 steps train_loss: 0.5142

#### test Acc: 0, NDCG: 0.3698707947754313 HIT: 0.6185259650735294

#### val Acc: 0, NDCG: 0.38251252220108756 HIT: 0.6319680606617647
Epoch: 448, plus 0 steps train_loss: 0.5034

#### test Acc: 0, NDCG: 0.382807168598296 HIT: 0.6254940257352941

#### val Acc: 0, NDCG: 0.391346678684668 HIT: 0.6424402573529412
Epoch: 480, plus 0 steps train_loss: 0.5019

#### test Acc: 0, NDCG: 0.3874126196721868 HIT: 0.6311982996323529

#### val Acc: 0, NDCG: 0.39506861149642863 HIT: 0.6384133731617647
Epoch: 512, plus 0 steps train_loss: 0.5042

#### test Acc: 0, NDCG: 0.3898185182676513 HIT: 0.6320886948529412

#### val Acc: 0, NDCG: 0.3888236755605929 HIT: 0.6321518841911764
Epoch: 544, plus 0 steps train_loss: 0.4987

#### test Acc: 0, NDCG: 0.3804941559705958 HIT: 0.6161649816176471

#### val Acc: 0, NDCG: 0.3978631597839456 HIT: 0.6404469209558823
Epoch: 576, plus 0 steps train_loss: 0.4811

#### test Acc: 0, NDCG: 0.39274633645102486 HIT: 0.6375172334558823

#### val Acc: 0, NDCG: 0.4018830262298514 HIT: 0.6412109375
Epoch: 608, plus 0 steps train_loss: 0.4972

#### test Acc: 0, NDCG: 0.38621351329514664 HIT: 0.6288028492647059

#### val Acc: 0, NDCG: 0.3921656164955555 HIT: 0.6342888327205882
Epoch: 640, plus 0 steps train_loss: 0.4885

#### test Acc: 0, NDCG: 0.3935318573160342 HIT: 0.6351907169117647

#### val Acc: 0, NDCG: 0.40475703817100805 HIT: 0.6465188419117647
Epoch: 704, plus 0 steps train_loss: 0.4748

#### test Acc: 0, NDCG: 0.39625912119646606 HIT: 0.6341567095588235

#### val Acc: 0, NDCG: 0.4037737682919748 HIT: 0.6522288602941176
Epoch: 768, plus 0 steps train_loss: 0.474

#### test Acc: 0, NDCG: 0.3980376560233291 HIT: 0.6399988511029412

#### val Acc: 0, NDCG: 0.40768843425333356 HIT: 0.6547794117647059
Epoch: 832, plus 0 steps train_loss: 0.4769

#### test Acc: 0, NDCG: 0.3916407836382504 HIT: 0.6295323988970588

#### val Acc: 0, NDCG: 0.40662578494532803 HIT: 0.6472541360294117
Epoch: 896, plus 0 steps train_loss: 0.4638

#### test Acc: 0, NDCG: 0.39624304670353594 HIT: 0.6332146139705882

#### val Acc: 0, NDCG: 0.404878905189083 HIT: 0.6487189797794117
Epoch: 960, plus 0 steps train_loss: 0.49

#### test Acc: 0, NDCG: 0.3941056344563779 HIT: 0.6337890625

#### val Acc: 0, NDCG: 0.40814599870247925 HIT: 0.6490234375
Epoch: 1013, plus 25 steps train_loss: 0.4528
Done: it took 300683.7275969982
max value of NDCG: 0.3980376560233291
max value of HIT: 0.6399988511029412

After 20 validations
max value of NDCG: 0.3980376560233291
max value of HIT: 0.6399988511029412
