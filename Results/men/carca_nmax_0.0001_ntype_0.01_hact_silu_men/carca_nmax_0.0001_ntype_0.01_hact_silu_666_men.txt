 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.01
max_norm:             	0.0001
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
RMHA_decoder:         	False
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_encoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12818205189677306 HIT: 0.2837603400735294

#### val Acc: 0, NDCG: 0.126175095663901 HIT: 0.2788143382352941
Epoch: 1, plus 0 steps train_loss: 0.7544

#### test Acc: 0, NDCG: 0.12771197372349946 HIT: 0.28022748161764705

#### val Acc: 0, NDCG: 0.1258486266855425 HIT: 0.2787971047794118
Epoch: 2, plus 0 steps train_loss: 0.7558

#### test Acc: 0, NDCG: 0.12987164812173324 HIT: 0.2901826746323529

#### val Acc: 0, NDCG: 0.1277928198847184 HIT: 0.2836626838235294
Epoch: 3, plus 0 steps train_loss: 0.7458

#### test Acc: 0, NDCG: 0.13011435511693223 HIT: 0.28689108455882356

#### val Acc: 0, NDCG: 0.12577484769115982 HIT: 0.28113511029411764
Epoch: 4, plus 0 steps train_loss: 0.7415

#### test Acc: 0, NDCG: 0.12861489233155712 HIT: 0.28539177389705883

#### val Acc: 0, NDCG: 0.12819511941469394 HIT: 0.27940602022058825
Epoch: 5, plus 0 steps train_loss: 0.736

#### test Acc: 0, NDCG: 0.13088614249367514 HIT: 0.28448988970588235

#### val Acc: 0, NDCG: 0.12687834353985447 HIT: 0.28226102941176473
Epoch: 6, plus 0 steps train_loss: 0.738

#### test Acc: 0, NDCG: 0.13165790373152667 HIT: 0.28624770220588236

#### val Acc: 0, NDCG: 0.13058913187744153 HIT: 0.2921817555147059
Epoch: 7, plus 0 steps train_loss: 0.7235

#### test Acc: 0, NDCG: 0.13167390662863138 HIT: 0.29096392463235293

#### val Acc: 0, NDCG: 0.12719517731860897 HIT: 0.28347311580882356
Epoch: 8, plus 0 steps train_loss: 0.7243

#### test Acc: 0, NDCG: 0.1305816763580514 HIT: 0.28956801470588234

#### val Acc: 0, NDCG: 0.12570272375327898 HIT: 0.2733053768382353
Epoch: 9, plus 0 steps train_loss: 0.7261

#### test Acc: 0, NDCG: 0.13274751767270132 HIT: 0.2856330422794118

#### val Acc: 0, NDCG: 0.13284763498350236 HIT: 0.29028607536764706
Epoch: 10, plus 0 steps train_loss: 0.7227

#### test Acc: 0, NDCG: 0.13439675682492863 HIT: 0.2944450827205882

#### val Acc: 0, NDCG: 0.13306107365193132 HIT: 0.29299172794117645
Epoch: 12, plus 0 steps train_loss: 0.7154

#### test Acc: 0, NDCG: 0.1299933053478564 HIT: 0.2878619025735294

#### val Acc: 0, NDCG: 0.130753429156344 HIT: 0.2861270680147059
Epoch: 14, plus 0 steps train_loss: 0.7201

#### test Acc: 0, NDCG: 0.13522446948636568 HIT: 0.29814453125

#### val Acc: 0, NDCG: 0.13255066941435176 HIT: 0.2874540441176471
Epoch: 16, plus 0 steps train_loss: 0.7071

#### test Acc: 0, NDCG: 0.13024038205346986 HIT: 0.28824678308823526

#### val Acc: 0, NDCG: 0.13310074057851054 HIT: 0.29021714154411765
Epoch: 18, plus 0 steps train_loss: 0.7144

#### test Acc: 0, NDCG: 0.129794700832004 HIT: 0.2823529411764706

#### val Acc: 0, NDCG: 0.13605003084409087 HIT: 0.2942267922794118
Epoch: 20, plus 0 steps train_loss: 0.7066

#### test Acc: 0, NDCG: 0.1291440813625828 HIT: 0.2869025735294118

#### val Acc: 0, NDCG: 0.13060205347068243 HIT: 0.29112477022058825
Epoch: 22, plus 0 steps train_loss: 0.7065

#### test Acc: 0, NDCG: 0.13026031121890658 HIT: 0.2869715073529412

#### val Acc: 0, NDCG: 0.12791235828363817 HIT: 0.2834846047794118
Epoch: 24, plus 0 steps train_loss: 0.7063

#### test Acc: 0, NDCG: 0.12572010545401577 HIT: 0.2766659007352941

#### val Acc: 0, NDCG: 0.1312640851391578 HIT: 0.2872414981617647
Epoch: 26, plus 0 steps train_loss: 0.7042

#### test Acc: 0, NDCG: 0.1277838894496777 HIT: 0.28155445772058824

#### val Acc: 0, NDCG: 0.13082373612648596 HIT: 0.28511029411764705
Epoch: 28, plus 0 steps train_loss: 0.7028

#### test Acc: 0, NDCG: 0.12660337920276674 HIT: 0.2778205422794118

#### val Acc: 0, NDCG: 0.13133566805672758 HIT: 0.2920726102941177
Epoch: 30, plus 0 steps train_loss: 0.7047

#### test Acc: 0, NDCG: 0.1321072132263071 HIT: 0.29315257352941176

#### val Acc: 0, NDCG: 0.13316716198198525 HIT: 0.29356617647058825
Epoch: 32, plus 0 steps train_loss: 0.7067

#### test Acc: 0, NDCG: 0.12759488112207287 HIT: 0.28353630514705885

#### val Acc: 0, NDCG: 0.12917152130619172 HIT: 0.28428308823529413
Epoch: 36, plus 0 steps train_loss: 0.6997

#### test Acc: 0, NDCG: 0.12895611794378303 HIT: 0.28500114889705885

#### val Acc: 0, NDCG: 0.12843373474009742 HIT: 0.28386374080882354
Epoch: 40, plus 0 steps train_loss: 0.7016

#### test Acc: 0, NDCG: 0.1332941107156838 HIT: 0.29251493566176473

#### val Acc: 0, NDCG: 0.12627195927657206 HIT: 0.27471852022058824
Epoch: 44, plus 0 steps train_loss: 0.701

#### test Acc: 0, NDCG: 0.12585751013493868 HIT: 0.2772805606617647

#### val Acc: 0, NDCG: 0.12955656676271765 HIT: 0.2831456801470588
Epoch: 48, plus 0 steps train_loss: 0.6991

#### test Acc: 0, NDCG: 0.12974262630127192 HIT: 0.2862649356617647

#### val Acc: 0, NDCG: 0.1320609290504159 HIT: 0.28664407169117645
Epoch: 52, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.12936882980744 HIT: 0.2809627757352941

#### val Acc: 0, NDCG: 0.1353741652198684 HIT: 0.29585822610294116
Epoch: 56, plus 0 steps train_loss: 0.6977

#### test Acc: 0, NDCG: 0.15257740638286546 HIT: 0.3047564338235294

#### val Acc: 0, NDCG: 0.15905154711951183 HIT: 0.3140625
Epoch: 60, plus 0 steps train_loss: 0.6963

#### test Acc: 0, NDCG: 0.15112752063723206 HIT: 0.29611672794117644

#### val Acc: 0, NDCG: 0.1687096091118779 HIT: 0.3237419577205882
Epoch: 64, plus 0 steps train_loss: 0.6989

#### test Acc: 0, NDCG: 0.19104129691420302 HIT: 0.3405962775735294

#### val Acc: 0, NDCG: 0.2187127309832914 HIT: 0.3669577205882353
Epoch: 68, plus 0 steps train_loss: 0.6961

#### test Acc: 0, NDCG: 0.20571389129382306 HIT: 0.34873046875

#### val Acc: 0, NDCG: 0.2417343750711897 HIT: 0.38596047794117644
Epoch: 72, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.15877435197627177 HIT: 0.30953010110294116

#### val Acc: 0, NDCG: 0.1754847972126551 HIT: 0.3287396599264706
Epoch: 80, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.38090315243282985 HIT: 0.5130687040441176

#### val Acc: 0, NDCG: 0.40558728954695533 HIT: 0.5328527113970588
Epoch: 88, plus 0 steps train_loss: 0.6959

#### test Acc: 0, NDCG: 0.6927041045859433 HIT: 0.7803021599264706

#### val Acc: 0, NDCG: 0.7002647144459393 HIT: 0.7851217830882353
Epoch: 96, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.6088482992259823 HIT: 0.7107938878676471

#### val Acc: 0, NDCG: 0.6240898311748404 HIT: 0.7211224724264705
Epoch: 104, plus 0 steps train_loss: 0.6949

#### test Acc: 0, NDCG: 0.6797624025530808 HIT: 0.7669692095588235

#### val Acc: 0, NDCG: 0.6855721140597776 HIT: 0.7722081801470588
Epoch: 112, plus 0 steps train_loss: 0.6943

#### test Acc: 0, NDCG: 0.6662221476955802 HIT: 0.7593864889705882

#### val Acc: 0, NDCG: 0.6965682860457288 HIT: 0.7833754595588236
Epoch: 120, plus 0 steps train_loss: 0.6937

#### test Acc: 0, NDCG: 0.6558515239378996 HIT: 0.7540843290441177

#### val Acc: 0, NDCG: 0.6544258618110825 HIT: 0.7495289522058823
Epoch: 128, plus 0 steps train_loss: 0.6946

#### test Acc: 0, NDCG: 0.6050488209594742 HIT: 0.7109777113970588

#### val Acc: 0, NDCG: 0.6271952299259093 HIT: 0.7249942555147059
Epoch: 136, plus 0 steps train_loss: 0.6888

#### test Acc: 0, NDCG: 0.7148421251037916 HIT: 0.7962545955882353

#### val Acc: 0, NDCG: 0.724604580345961 HIT: 0.8007869944852942
Epoch: 144, plus 0 steps train_loss: 0.6874

#### test Acc: 0, NDCG: 0.7234171549650572 HIT: 0.8048023897058825

#### val Acc: 0, NDCG: 0.723553679868112 HIT: 0.8025735294117646
Epoch: 160, plus 0 steps train_loss: 0.6859

#### test Acc: 0, NDCG: 0.732720850990452 HIT: 0.8106675091911765

#### val Acc: 0, NDCG: 0.7374034024049572 HIT: 0.8170496323529411
Epoch: 176, plus 0 steps train_loss: 0.6839

#### test Acc: 0, NDCG: 0.6935685485917797 HIT: 0.7789234834558824

#### val Acc: 0, NDCG: 0.7089332342677271 HIT: 0.7921587775735295
Epoch: 192, plus 0 steps train_loss: 0.6816

#### test Acc: 0, NDCG: 0.5843214951683303 HIT: 0.69892578125

#### val Acc: 0, NDCG: 0.5935792987192652 HIT: 0.6990004595588235
Epoch: 208, plus 0 steps train_loss: 0.6842

#### test Acc: 0, NDCG: 0.6378181550596314 HIT: 0.7398092830882353

#### val Acc: 0, NDCG: 0.6511087396894487 HIT: 0.7465016084558823
Epoch: 224, plus 0 steps train_loss: 0.6812

#### test Acc: 0, NDCG: 0.5496715545858561 HIT: 0.6657628676470588

#### val Acc: 0, NDCG: 0.5707269223326173 HIT: 0.6851332720588236
Epoch: 240, plus 0 steps train_loss: 0.6724

#### test Acc: 0, NDCG: 0.46599308913923576 HIT: 0.6129308363970588

#### val Acc: 0, NDCG: 0.48465615753303304 HIT: 0.6218290441176471
Epoch: 256, plus 0 steps train_loss: 0.6746

#### test Acc: 0, NDCG: 0.32780157896574663 HIT: 0.5080250459558824

#### val Acc: 0, NDCG: 0.34360758243482076 HIT: 0.5168543198529412
Epoch: 272, plus 0 steps train_loss: 0.6791

#### test Acc: 0, NDCG: 0.27704961702972675 HIT: 0.4762235753676471

#### val Acc: 0, NDCG: 0.3016662423237203 HIT: 0.49293428308823534
Epoch: 288, plus 0 steps train_loss: 0.6689

#### test Acc: 0, NDCG: 0.25146842180129175 HIT: 0.4615923713235294

#### val Acc: 0, NDCG: 0.25957969680371856 HIT: 0.4724494485294118
Epoch: 304, plus 0 steps train_loss: 0.6562

#### test Acc: 0, NDCG: 0.26226739152099265 HIT: 0.4820140165441177

#### val Acc: 0, NDCG: 0.2600924323912177 HIT: 0.4732192095588236
Epoch: 320, plus 0 steps train_loss: 0.6576

#### test Acc: 0, NDCG: 0.25450225599778026 HIT: 0.4685374540441177

#### val Acc: 0, NDCG: 0.26035388508521784 HIT: 0.4716739430147059
Epoch: 352, plus 0 steps train_loss: 0.646

#### test Acc: 0, NDCG: 0.2647255325940642 HIT: 0.47702780330882355

#### val Acc: 0, NDCG: 0.2772295481067726 HIT: 0.48907398897058824
Epoch: 384, plus 0 steps train_loss: 0.6385

#### test Acc: 0, NDCG: 0.2758298492915106 HIT: 0.49669692095588236

#### val Acc: 0, NDCG: 0.2766153011865567 HIT: 0.49518612132352946
Epoch: 416, plus 0 steps train_loss: 0.624

#### test Acc: 0, NDCG: 0.2828282992362951 HIT: 0.5117934283088236

#### val Acc: 0, NDCG: 0.2803840471489455 HIT: 0.5032111672794117
Epoch: 448, plus 0 steps train_loss: 0.6251

#### test Acc: 0, NDCG: 0.28767892581766596 HIT: 0.5127297794117647

#### val Acc: 0, NDCG: 0.29034999792741234 HIT: 0.5117417279411764
Epoch: 480, plus 0 steps train_loss: 0.6269

#### test Acc: 0, NDCG: 0.2923021725631788 HIT: 0.5213062959558823

#### val Acc: 0, NDCG: 0.29143549189462614 HIT: 0.5153492647058824
Epoch: 512, plus 0 steps train_loss: 0.6252

#### test Acc: 0, NDCG: 0.2932597964634963 HIT: 0.5212833180147058

#### val Acc: 0, NDCG: 0.2976299511597401 HIT: 0.5257984834558823
Epoch: 544, plus 0 steps train_loss: 0.6181

#### test Acc: 0, NDCG: 0.2969435073257999 HIT: 0.5287971047794118

#### val Acc: 0, NDCG: 0.30868300345616995 HIT: 0.5355238970588235
Epoch: 576, plus 0 steps train_loss: 0.6148

#### test Acc: 0, NDCG: 0.29472121047157723 HIT: 0.5272231158088235

#### val Acc: 0, NDCG: 0.3036259897583936 HIT: 0.5387293198529413
Epoch: 608, plus 0 steps train_loss: 0.615

#### test Acc: 0, NDCG: 0.30884248039930257 HIT: 0.5382869944852942

#### val Acc: 0, NDCG: 0.3143793469932936 HIT: 0.5438648897058823
Epoch: 640, plus 0 steps train_loss: 0.597

#### test Acc: 0, NDCG: 0.30723390869358463 HIT: 0.5400160845588236

#### val Acc: 0, NDCG: 0.31396178746230075 HIT: 0.5447840073529412
Epoch: 704, plus 0 steps train_loss: 0.6103

#### test Acc: 0, NDCG: 0.30405847184541546 HIT: 0.5405388327205882

#### val Acc: 0, NDCG: 0.30793495866712733 HIT: 0.5433019301470587
Epoch: 768, plus 0 steps train_loss: 0.6006

#### test Acc: 0, NDCG: 0.3026617967125316 HIT: 0.5317612591911764

#### val Acc: 0, NDCG: 0.3071478436501405 HIT: 0.5407858455882353
Epoch: 832, plus 0 steps train_loss: 0.5948

#### test Acc: 0, NDCG: 0.3059407826346291 HIT: 0.5412166819852942

#### val Acc: 0, NDCG: 0.31531086513574036 HIT: 0.5558306525735295
Epoch: 896, plus 0 steps train_loss: 0.5911

#### test Acc: 0, NDCG: 0.3043675784657286 HIT: 0.5361443014705882

#### val Acc: 0, NDCG: 0.30679927075276614 HIT: 0.5388499540441176
Epoch: 960, plus 0 steps train_loss: 0.5971

#### test Acc: 0, NDCG: 0.3082311301377878 HIT: 0.5464326746323529

#### val Acc: 0, NDCG: 0.31207311234422563 HIT: 0.5448357077205882
Epoch: 1013, plus 25 steps train_loss: 0.5861
Done: it took 301379.24259853363
max value of NDCG: 0.732720850990452
max value of HIT: 0.8106675091911765

After 20 validations
max value of NDCG: 0.732720850990452
max value of HIT: 0.8106675091911765
