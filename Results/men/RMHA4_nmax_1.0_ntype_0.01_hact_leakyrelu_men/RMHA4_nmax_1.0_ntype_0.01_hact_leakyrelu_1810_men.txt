 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.01
max_norm:             	1.0
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	leakyrelu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.1337439365405972 HIT: 0.2886661305147059

#### val Acc: 0, NDCG: 0.12801698616188892 HIT: 0.28065257352941175
Epoch: 1, plus 0 steps train_loss: 0.7631

#### test Acc: 0, NDCG: 0.13134159932204986 HIT: 0.28609260110294116

#### val Acc: 0, NDCG: 0.12850172684958897 HIT: 0.2863396139705882
Epoch: 2, plus 0 steps train_loss: 0.7503

#### test Acc: 0, NDCG: 0.13215883684620805 HIT: 0.2868853400735294

#### val Acc: 0, NDCG: 0.13153974026127363 HIT: 0.2905158547794118
Epoch: 3, plus 0 steps train_loss: 0.7525

#### test Acc: 0, NDCG: 0.12995362596725737 HIT: 0.2881548713235294

#### val Acc: 0, NDCG: 0.13137124865264535 HIT: 0.28924057904411765
Epoch: 4, plus 0 steps train_loss: 0.7438

#### test Acc: 0, NDCG: 0.13536686768206643 HIT: 0.2951344209558823

#### val Acc: 0, NDCG: 0.13174052323805313 HIT: 0.28939568014705885
Epoch: 5, plus 0 steps train_loss: 0.7313

#### test Acc: 0, NDCG: 0.12446713520559619 HIT: 0.28172104779411766

#### val Acc: 0, NDCG: 0.13120493347658607 HIT: 0.2914924172794118
Epoch: 6, plus 0 steps train_loss: 0.7214

#### test Acc: 0, NDCG: 0.13344980913618523 HIT: 0.28957375919117645

#### val Acc: 0, NDCG: 0.1350675626454203 HIT: 0.2929974724264706
Epoch: 7, plus 0 steps train_loss: 0.7136

#### test Acc: 0, NDCG: 0.12808596575259087 HIT: 0.28093979779411765

#### val Acc: 0, NDCG: 0.134726327782431 HIT: 0.2933938419117647
Epoch: 8, plus 0 steps train_loss: 0.7099

#### test Acc: 0, NDCG: 0.12891432522098537 HIT: 0.2877297794117647

#### val Acc: 0, NDCG: 0.13525716715458366 HIT: 0.29308938419117647
Epoch: 9, plus 0 steps train_loss: 0.7114

#### test Acc: 0, NDCG: 0.13878551929118607 HIT: 0.2995921415441177

#### val Acc: 0, NDCG: 0.13717087883424303 HIT: 0.29216452205882354
Epoch: 10, plus 0 steps train_loss: 0.7081

#### test Acc: 0, NDCG: 0.14082789407201624 HIT: 0.2989142922794118

#### val Acc: 0, NDCG: 0.14785329520163998 HIT: 0.3060144761029412
Epoch: 12, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.13738895566333623 HIT: 0.29539292279411766

#### val Acc: 0, NDCG: 0.1415275188881294 HIT: 0.29963235294117646
Epoch: 14, plus 0 steps train_loss: 0.7077

#### test Acc: 0, NDCG: 0.14044026668855242 HIT: 0.29950022977941176

#### val Acc: 0, NDCG: 0.1397741144299288 HIT: 0.29885110294117645
Epoch: 16, plus 0 steps train_loss: 0.7035

#### test Acc: 0, NDCG: 0.17762587995117518 HIT: 0.33508157169117647

#### val Acc: 0, NDCG: 0.19045310107186153 HIT: 0.35140165441176474
Epoch: 18, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.1677759945291911 HIT: 0.3247644761029412

#### val Acc: 0, NDCG: 0.18659814730513877 HIT: 0.3411075367647059
Epoch: 20, plus 0 steps train_loss: 0.7034

#### test Acc: 0, NDCG: 0.18423868224003379 HIT: 0.33513327205882354

#### val Acc: 0, NDCG: 0.2089494588433284 HIT: 0.3669634650735294
Epoch: 22, plus 0 steps train_loss: 0.7014

#### test Acc: 0, NDCG: 0.19812584484991644 HIT: 0.35982881433823527

#### val Acc: 0, NDCG: 0.20406951987268568 HIT: 0.3698357077205882
Epoch: 24, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.20553299803988562 HIT: 0.3637637867647059

#### val Acc: 0, NDCG: 0.23600645211378893 HIT: 0.39951746323529413
Epoch: 26, plus 0 steps train_loss: 0.6986

#### test Acc: 0, NDCG: 0.26521748998072003 HIT: 0.4219496783088236

#### val Acc: 0, NDCG: 0.2885101357999703 HIT: 0.4465705422794118
Epoch: 28, plus 0 steps train_loss: 0.6957

#### test Acc: 0, NDCG: 0.34422474161126054 HIT: 0.4998736213235294

#### val Acc: 0, NDCG: 0.3583724694839162 HIT: 0.5096966911764705
Epoch: 30, plus 0 steps train_loss: 0.7015

#### test Acc: 0, NDCG: 0.37152285063215407 HIT: 0.5306640625

#### val Acc: 0, NDCG: 0.3886846376685463 HIT: 0.5374425551470587
Epoch: 32, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.2879716848768584 HIT: 0.45764016544117647

#### val Acc: 0, NDCG: 0.308214285333296 HIT: 0.47268497242647056
Epoch: 36, plus 0 steps train_loss: 0.6939

#### test Acc: 0, NDCG: 0.27655857746665835 HIT: 0.45530215992647055

#### val Acc: 0, NDCG: 0.29512867448021585 HIT: 0.4651711856617647
Epoch: 40, plus 0 steps train_loss: 0.6935

#### test Acc: 0, NDCG: 0.44085651451733543 HIT: 0.5889878216911765

#### val Acc: 0, NDCG: 0.4537675078958072 HIT: 0.6007410386029413
Epoch: 44, plus 0 steps train_loss: 0.6932

#### test Acc: 0, NDCG: 0.47804199941677006 HIT: 0.6267635569852941

#### val Acc: 0, NDCG: 0.48276214265689027 HIT: 0.6298426011029412
Epoch: 48, plus 0 steps train_loss: 0.6885

#### test Acc: 0, NDCG: 0.4782907302672673 HIT: 0.6255227481617647

#### val Acc: 0, NDCG: 0.4940191835996403 HIT: 0.6405962775735294
Epoch: 52, plus 0 steps train_loss: 0.6897

#### test Acc: 0, NDCG: 0.6227886254625353 HIT: 0.7340130974264706

#### val Acc: 0, NDCG: 0.6302240540610512 HIT: 0.7418830422794118
Epoch: 56, plus 0 steps train_loss: 0.6825

#### test Acc: 0, NDCG: 0.2369579960034392 HIT: 0.44558249080882356

#### val Acc: 0, NDCG: 0.24074620654436307 HIT: 0.44488166360294124
Epoch: 60, plus 0 steps train_loss: 0.6711

#### test Acc: 0, NDCG: 0.22935267118593367 HIT: 0.45318244485294124

#### val Acc: 0, NDCG: 0.2252890570887495 HIT: 0.44249195772058825
Epoch: 64, plus 0 steps train_loss: 0.667

#### test Acc: 0, NDCG: 0.2293393307072234 HIT: 0.45930032169117646

#### val Acc: 0, NDCG: 0.2349412289935356 HIT: 0.4649241727941177
Epoch: 68, plus 0 steps train_loss: 0.6445

#### test Acc: 0, NDCG: 0.23990721537249815 HIT: 0.4727883731617647

#### val Acc: 0, NDCG: 0.24696466004423862 HIT: 0.4782169117647059
Epoch: 72, plus 0 steps train_loss: 0.654

#### test Acc: 0, NDCG: 0.24999814329712816 HIT: 0.48707490808823534

#### val Acc: 0, NDCG: 0.2634282843815855 HIT: 0.5041130514705883
Epoch: 80, plus 0 steps train_loss: 0.6449

#### test Acc: 0, NDCG: 0.2755829054122689 HIT: 0.5203010110294117

#### val Acc: 0, NDCG: 0.28172965253002324 HIT: 0.5304170496323529
Epoch: 88, plus 0 steps train_loss: 0.611

#### test Acc: 0, NDCG: 0.285246751478078 HIT: 0.5406652113970588

#### val Acc: 0, NDCG: 0.2915846631041285 HIT: 0.5368336397058824
Epoch: 96, plus 0 steps train_loss: 0.6214

#### test Acc: 0, NDCG: 0.2893469319512546 HIT: 0.5362706801470588

#### val Acc: 0, NDCG: 0.29948712179509684 HIT: 0.5485581341911765
Epoch: 104, plus 0 steps train_loss: 0.6079

#### test Acc: 0, NDCG: 0.28757574496244964 HIT: 0.5388269761029412

#### val Acc: 0, NDCG: 0.29520123297143597 HIT: 0.5440314797794118
Epoch: 112, plus 0 steps train_loss: 0.6021

#### test Acc: 0, NDCG: 0.300885431902869 HIT: 0.5531192555147059

#### val Acc: 0, NDCG: 0.3031784717338009 HIT: 0.5512580422794118
Epoch: 120, plus 0 steps train_loss: 0.5965

#### test Acc: 0, NDCG: 0.3028438231630477 HIT: 0.5454044117647059

#### val Acc: 0, NDCG: 0.3038374343001954 HIT: 0.5500459558823529
Epoch: 128, plus 0 steps train_loss: 0.592

#### test Acc: 0, NDCG: 0.31124622842069083 HIT: 0.5520048253676471

#### val Acc: 0, NDCG: 0.3109557567731093 HIT: 0.5585765165441177
Epoch: 136, plus 0 steps train_loss: 0.6002

#### test Acc: 0, NDCG: 0.30959265498315774 HIT: 0.55361328125

#### val Acc: 0, NDCG: 0.31805585272841685 HIT: 0.5617417279411765
Epoch: 144, plus 0 steps train_loss: 0.5927

#### test Acc: 0, NDCG: 0.3212462827603952 HIT: 0.5673885569852941

#### val Acc: 0, NDCG: 0.3276165710298322 HIT: 0.5674977022058824
Epoch: 160, plus 0 steps train_loss: 0.5787

#### test Acc: 0, NDCG: 0.327303863965322 HIT: 0.5713177849264706

#### val Acc: 0, NDCG: 0.33084133173326896 HIT: 0.5728285845588236
Epoch: 176, plus 0 steps train_loss: 0.5747

#### test Acc: 0, NDCG: 0.33314588326645944 HIT: 0.5722196691176471

#### val Acc: 0, NDCG: 0.338665196200331 HIT: 0.5776137408088236
Epoch: 192, plus 0 steps train_loss: 0.5814

#### test Acc: 0, NDCG: 0.33582079515203433 HIT: 0.5794921875

#### val Acc: 0, NDCG: 0.34665574936236 HIT: 0.5884995404411765
Epoch: 208, plus 0 steps train_loss: 0.5702

#### test Acc: 0, NDCG: 0.3439363659748628 HIT: 0.58251953125

#### val Acc: 0, NDCG: 0.3545037869666551 HIT: 0.5890395220588236
Epoch: 224, plus 0 steps train_loss: 0.5591

#### test Acc: 0, NDCG: 0.3525645754867739 HIT: 0.5859145220588236

#### val Acc: 0, NDCG: 0.3554269415103933 HIT: 0.5890682444852942
Epoch: 240, plus 0 steps train_loss: 0.5718

#### test Acc: 0, NDCG: 0.34868385262354473 HIT: 0.5831284466911765

#### val Acc: 0, NDCG: 0.3578779482983457 HIT: 0.5963350183823529
Epoch: 256, plus 0 steps train_loss: 0.5462

#### test Acc: 0, NDCG: 0.3563718161811841 HIT: 0.5920955882352941

#### val Acc: 0, NDCG: 0.36282832127548126 HIT: 0.6022116268382354
Epoch: 272, plus 0 steps train_loss: 0.5398

#### test Acc: 0, NDCG: 0.3544551107414944 HIT: 0.5892290900735294

#### val Acc: 0, NDCG: 0.3669277996020897 HIT: 0.6005170036764705
Epoch: 288, plus 0 steps train_loss: 0.5471

#### test Acc: 0, NDCG: 0.3619866223042327 HIT: 0.5974609375

#### val Acc: 0, NDCG: 0.3699966770250254 HIT: 0.6070082720588236
Epoch: 304, plus 0 steps train_loss: 0.5402

#### test Acc: 0, NDCG: 0.36089777740093915 HIT: 0.5981962316176471

#### val Acc: 0, NDCG: 0.3667937195566403 HIT: 0.6026826746323529
Epoch: 320, plus 0 steps train_loss: 0.5435

#### test Acc: 0, NDCG: 0.3587490889832868 HIT: 0.58984375

#### val Acc: 0, NDCG: 0.3678456737747955 HIT: 0.6027975643382353
Epoch: 352, plus 0 steps train_loss: 0.5355

#### test Acc: 0, NDCG: 0.3655962861061052 HIT: 0.5953182444852941

#### val Acc: 0, NDCG: 0.37460634065725573 HIT: 0.6093520220588236
Epoch: 384, plus 0 steps train_loss: 0.5244

#### test Acc: 0, NDCG: 0.37337151631109766 HIT: 0.6073184742647059

#### val Acc: 0, NDCG: 0.37761483873897905 HIT: 0.6106043198529412
Epoch: 416, plus 0 steps train_loss: 0.5259

#### test Acc: 0, NDCG: 0.36341380690350983 HIT: 0.5989602481617646

#### val Acc: 0, NDCG: 0.38038104675503154 HIT: 0.6099034926470588
Epoch: 448, plus 0 steps train_loss: 0.5104

#### test Acc: 0, NDCG: 0.3663658680019909 HIT: 0.5953067555147059

#### val Acc: 0, NDCG: 0.38226138399024334 HIT: 0.6064280790441177
Epoch: 480, plus 0 steps train_loss: 0.5088

#### test Acc: 0, NDCG: 0.3752937933520418 HIT: 0.6051987591911765

#### val Acc: 0, NDCG: 0.3866947362436409 HIT: 0.6190544577205882
Epoch: 512, plus 0 steps train_loss: 0.5051

#### test Acc: 0, NDCG: 0.37212955174298223 HIT: 0.6065774356617647

#### val Acc: 0, NDCG: 0.3783622178520586 HIT: 0.6152458639705882
Epoch: 544, plus 0 steps train_loss: 0.5292

#### test Acc: 0, NDCG: 0.37446037166402607 HIT: 0.6041015625

#### val Acc: 0, NDCG: 0.38132403353704325 HIT: 0.6123621323529412
Epoch: 576, plus 0 steps train_loss: 0.5026

#### test Acc: 0, NDCG: 0.3762283442385078 HIT: 0.6032686121323529

#### val Acc: 0, NDCG: 0.3802417738531703 HIT: 0.6098977481617647
Epoch: 608, plus 0 steps train_loss: 0.5015

#### test Acc: 0, NDCG: 0.37687014930506957 HIT: 0.6128389246323529

#### val Acc: 0, NDCG: 0.3893342313715679 HIT: 0.6223403033088235
Epoch: 640, plus 0 steps train_loss: 0.4986

#### test Acc: 0, NDCG: 0.3770520370232946 HIT: 0.6098000919117647

#### val Acc: 0, NDCG: 0.3861158472766841 HIT: 0.6116785386029412
Epoch: 704, plus 0 steps train_loss: 0.4943

#### test Acc: 0, NDCG: 0.3792097666989746 HIT: 0.6063419117647059

#### val Acc: 0, NDCG: 0.3883448642069439 HIT: 0.6142405790441177
Epoch: 768, plus 0 steps train_loss: 0.4945

#### test Acc: 0, NDCG: 0.3701378497270316 HIT: 0.5985064338235294

#### val Acc: 0, NDCG: 0.39521656331064337 HIT: 0.6262637867647058
Epoch: 832, plus 0 steps train_loss: 0.4612

#### test Acc: 0, NDCG: 0.3750425149662849 HIT: 0.6000114889705882

#### val Acc: 0, NDCG: 0.3869219751945559 HIT: 0.6208409926470588
Epoch: 896, plus 0 steps train_loss: 0.4992

#### test Acc: 0, NDCG: 0.3773453553387612 HIT: 0.6068991268382353

#### val Acc: 0, NDCG: 0.3921458580943763 HIT: 0.6194221047794117
Epoch: 960, plus 0 steps train_loss: 0.4787

#### test Acc: 0, NDCG: 0.37371440413844204 HIT: 0.5953469669117647

#### val Acc: 0, NDCG: 0.38637448561325 HIT: 0.6138671875
Epoch: 1013, plus 25 steps train_loss: 0.5003
Done: it took 289946.82029366493
max value of NDCG: 0.6227886254625353
max value of HIT: 0.7340130974264706

After 20 validations
max value of NDCG: 0.6227886254625353
max value of HIT: 0.7340130974264706
