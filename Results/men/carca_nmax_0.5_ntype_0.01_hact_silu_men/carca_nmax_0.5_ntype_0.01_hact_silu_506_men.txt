 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.01
max_norm:             	0.5
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_blocks:           	3
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 50819341
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12845910449842052 HIT: 0.28660386029411766

#### val Acc: 0, NDCG: 0.1280409845276613 HIT: 0.28938419117647063
Epoch: 1, plus 0 steps train_loss: 0.7606

#### test Acc: 0, NDCG: 0.13000642438808657 HIT: 0.2848920036764706

#### val Acc: 0, NDCG: 0.12972017901252086 HIT: 0.28958524816176473
Epoch: 2, plus 0 steps train_loss: 0.7529

#### test Acc: 0, NDCG: 0.12830406288779803 HIT: 0.2835018382352941

#### val Acc: 0, NDCG: 0.13496645523030543 HIT: 0.29620289522058824
Epoch: 3, plus 0 steps train_loss: 0.7452

#### test Acc: 0, NDCG: 0.12864637348597083 HIT: 0.28680491727941176

#### val Acc: 0, NDCG: 0.13168923753670475 HIT: 0.29116498161764703
Epoch: 4, plus 0 steps train_loss: 0.7438

#### test Acc: 0, NDCG: 0.1295287420143167 HIT: 0.28400160845588235

#### val Acc: 0, NDCG: 0.13565015495134983 HIT: 0.2948471966911764
Epoch: 5, plus 0 steps train_loss: 0.741

#### test Acc: 0, NDCG: 0.12908267857657535 HIT: 0.28890739889705885

#### val Acc: 0, NDCG: 0.12967352716042255 HIT: 0.2851849724264706
Epoch: 6, plus 0 steps train_loss: 0.7321

#### test Acc: 0, NDCG: 0.13011346613408661 HIT: 0.28497242647058824

#### val Acc: 0, NDCG: 0.12721920542859827 HIT: 0.28015280330882353
Epoch: 7, plus 0 steps train_loss: 0.7273

#### test Acc: 0, NDCG: 0.12858504559155604 HIT: 0.2822840073529412

#### val Acc: 0, NDCG: 0.1311263055052666 HIT: 0.2894933363970588
Epoch: 8, plus 0 steps train_loss: 0.7242

#### test Acc: 0, NDCG: 0.12806345161966876 HIT: 0.28681640625

#### val Acc: 0, NDCG: 0.13301070760571143 HIT: 0.29204388786764707
Epoch: 9, plus 0 steps train_loss: 0.723

#### test Acc: 0, NDCG: 0.1283960515379377 HIT: 0.28344439338235294

#### val Acc: 0, NDCG: 0.1330338569411161 HIT: 0.2956112132352941
Epoch: 10, plus 0 steps train_loss: 0.716

#### test Acc: 0, NDCG: 0.1260604097288618 HIT: 0.28022173713235293

#### val Acc: 0, NDCG: 0.13212926309691891 HIT: 0.29146369485294116
Epoch: 12, plus 0 steps train_loss: 0.7214

#### test Acc: 0, NDCG: 0.1287357899364425 HIT: 0.28552964154411764

#### val Acc: 0, NDCG: 0.1306558792444332 HIT: 0.2906135110294118
Epoch: 14, plus 0 steps train_loss: 0.716

#### test Acc: 0, NDCG: 0.1328881174205361 HIT: 0.29134306066176474

#### val Acc: 0, NDCG: 0.1301132773368174 HIT: 0.2808306525735294
Epoch: 16, plus 0 steps train_loss: 0.7116

#### test Acc: 0, NDCG: 0.13575566009708492 HIT: 0.2993049172794118

#### val Acc: 0, NDCG: 0.12967961386741791 HIT: 0.28442670036764706
Epoch: 18, plus 0 steps train_loss: 0.7131

#### test Acc: 0, NDCG: 0.1319507156716313 HIT: 0.29052734375

#### val Acc: 0, NDCG: 0.13140630911474463 HIT: 0.29399701286764707
Epoch: 20, plus 0 steps train_loss: 0.7064

#### test Acc: 0, NDCG: 0.13394448113589402 HIT: 0.29287109375

#### val Acc: 0, NDCG: 0.13192633831477812 HIT: 0.2912109375
Epoch: 22, plus 0 steps train_loss: 0.712

#### test Acc: 0, NDCG: 0.1290541728579781 HIT: 0.2843175551470588

#### val Acc: 0, NDCG: 0.1327425959726341 HIT: 0.2937212775735294
Epoch: 24, plus 0 steps train_loss: 0.7071

#### test Acc: 0, NDCG: 0.1323909287419389 HIT: 0.2866096047794118

#### val Acc: 0, NDCG: 0.1318891626465996 HIT: 0.2920726102941177
Epoch: 26, plus 0 steps train_loss: 0.7041

#### test Acc: 0, NDCG: 0.13184084576254534 HIT: 0.29399126838235295

#### val Acc: 0, NDCG: 0.13046870221530266 HIT: 0.2841739430147059
Epoch: 28, plus 0 steps train_loss: 0.7036

#### test Acc: 0, NDCG: 0.12992323482531323 HIT: 0.2837660845588236

#### val Acc: 0, NDCG: 0.13123367383730766 HIT: 0.28820657169117647
Epoch: 30, plus 0 steps train_loss: 0.7011

#### test Acc: 0, NDCG: 0.12875776507198292 HIT: 0.2828067555147059

#### val Acc: 0, NDCG: 0.12851048731030038 HIT: 0.2836052389705882
Epoch: 32, plus 0 steps train_loss: 0.7042

#### test Acc: 0, NDCG: 0.1304900062386315 HIT: 0.2866096047794118

#### val Acc: 0, NDCG: 0.12714717976505163 HIT: 0.2841854319852941
Epoch: 36, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.12989609317170223 HIT: 0.28465073529411766

#### val Acc: 0, NDCG: 0.12705761827525627 HIT: 0.28234719669117647
Epoch: 40, plus 0 steps train_loss: 0.704

#### test Acc: 0, NDCG: 0.13033643638243902 HIT: 0.2866957720588236

#### val Acc: 0, NDCG: 0.13527894663421022 HIT: 0.2954159007352941
Epoch: 44, plus 0 steps train_loss: 0.699

#### test Acc: 0, NDCG: 0.13306018606538852 HIT: 0.2922047334558823

#### val Acc: 0, NDCG: 0.12889596889961458 HIT: 0.2827090992647059
Epoch: 48, plus 0 steps train_loss: 0.6996

#### test Acc: 0, NDCG: 0.13334529687633448 HIT: 0.29180836397058824

#### val Acc: 0, NDCG: 0.12838890913546439 HIT: 0.28393267463235294
Epoch: 52, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.13420576972745474 HIT: 0.2948414522058823

#### val Acc: 0, NDCG: 0.13102070487246956 HIT: 0.28748851102941175
Epoch: 56, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.129407463922762 HIT: 0.28434053308823526

#### val Acc: 0, NDCG: 0.13584479195844068 HIT: 0.29662798713235294
Epoch: 60, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.1263844186618853 HIT: 0.2790326286764706

#### val Acc: 0, NDCG: 0.13321346161368774 HIT: 0.2904641544117647
Epoch: 64, plus 0 steps train_loss: 0.6965

#### test Acc: 0, NDCG: 0.1334304298254681 HIT: 0.2906594669117647

#### val Acc: 0, NDCG: 0.13392647243222489 HIT: 0.2914464613970588
Epoch: 68, plus 0 steps train_loss: 0.6967

#### test Acc: 0, NDCG: 0.13080602259485824 HIT: 0.29015395220588236

#### val Acc: 0, NDCG: 0.12787604616672746 HIT: 0.28629940257352937
Epoch: 72, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.13246733725898568 HIT: 0.29041245404411764

#### val Acc: 0, NDCG: 0.1349462223166384 HIT: 0.29419806985294117
Epoch: 80, plus 0 steps train_loss: 0.697

#### test Acc: 0, NDCG: 0.13629222550397674 HIT: 0.30164866727941175

#### val Acc: 0, NDCG: 0.12964331292025064 HIT: 0.28841911764705885
Epoch: 88, plus 0 steps train_loss: 0.6952

#### test Acc: 0, NDCG: 0.1418365477582377 HIT: 0.31058708639705884

#### val Acc: 0, NDCG: 0.13907126335768388 HIT: 0.29714499080882356
Epoch: 96, plus 0 steps train_loss: 0.6958

#### test Acc: 0, NDCG: 0.15390862515715764 HIT: 0.3305549172794118

#### val Acc: 0, NDCG: 0.1531005567223902 HIT: 0.32473000919117645
Epoch: 104, plus 0 steps train_loss: 0.6953

#### test Acc: 0, NDCG: 0.1685047372542604 HIT: 0.3498908547794118

#### val Acc: 0, NDCG: 0.16887437729917915 HIT: 0.34546760110294117
Epoch: 112, plus 0 steps train_loss: 0.6921

#### test Acc: 0, NDCG: 0.2265908246943041 HIT: 0.39518037683823526

#### val Acc: 0, NDCG: 0.235833763147014 HIT: 0.4052849264705882
Epoch: 120, plus 0 steps train_loss: 0.6922

#### test Acc: 0, NDCG: 0.22871490722661453 HIT: 0.4226964613970588

#### val Acc: 0, NDCG: 0.2371421172202865 HIT: 0.4259076286764706
Epoch: 128, plus 0 steps train_loss: 0.6827

#### test Acc: 0, NDCG: 0.24096335632922364 HIT: 0.4442612591911764

#### val Acc: 0, NDCG: 0.25381467744944264 HIT: 0.4493623621323529
Epoch: 136, plus 0 steps train_loss: 0.6826

#### test Acc: 0, NDCG: 0.28333471235521285 HIT: 0.47578125

#### val Acc: 0, NDCG: 0.3016502696640783 HIT: 0.4923426011029412
Epoch: 144, plus 0 steps train_loss: 0.676

#### test Acc: 0, NDCG: 0.2897188351097137 HIT: 0.4779469209558823

#### val Acc: 0, NDCG: 0.2981232825457855 HIT: 0.4775390625
Epoch: 160, plus 0 steps train_loss: 0.6695

#### test Acc: 0, NDCG: 0.28615278239810343 HIT: 0.4790900735294118

#### val Acc: 0, NDCG: 0.308002701163639 HIT: 0.4981215533088236
Epoch: 176, plus 0 steps train_loss: 0.6734

#### test Acc: 0, NDCG: 0.2606383356404375 HIT: 0.4532686121323529

#### val Acc: 0, NDCG: 0.2835470226250945 HIT: 0.4771254595588236
Epoch: 192, plus 0 steps train_loss: 0.6576

#### test Acc: 0, NDCG: 0.2502187777798392 HIT: 0.44892578125

#### val Acc: 0, NDCG: 0.26620930540983323 HIT: 0.45965647977941176
Epoch: 208, plus 0 steps train_loss: 0.6469

#### test Acc: 0, NDCG: 0.269145403197199 HIT: 0.4831858915441177

#### val Acc: 0, NDCG: 0.2795567972265421 HIT: 0.4835477941176471
Epoch: 224, plus 0 steps train_loss: 0.6454

#### test Acc: 0, NDCG: 0.26530033827858135 HIT: 0.48199103860294124

#### val Acc: 0, NDCG: 0.27312240681186967 HIT: 0.4881318933823529
Epoch: 240, plus 0 steps train_loss: 0.6449

#### test Acc: 0, NDCG: 0.26517724601488807 HIT: 0.4841394761029412

#### val Acc: 0, NDCG: 0.28023794419153336 HIT: 0.5006376378676471
Epoch: 256, plus 0 steps train_loss: 0.6515

#### test Acc: 0, NDCG: 0.2648754618548165 HIT: 0.4939970128676471

#### val Acc: 0, NDCG: 0.2767893026047076 HIT: 0.4962316176470588
Epoch: 272, plus 0 steps train_loss: 0.6512

#### test Acc: 0, NDCG: 0.26779240079471284 HIT: 0.4929630055147059

#### val Acc: 0, NDCG: 0.2836217383822809 HIT: 0.5028837316176471
Epoch: 288, plus 0 steps train_loss: 0.6341

#### test Acc: 0, NDCG: 0.28117940646365713 HIT: 0.5040498621323529

#### val Acc: 0, NDCG: 0.293679322421122 HIT: 0.5065774356617647
Epoch: 304, plus 0 steps train_loss: 0.6233

#### test Acc: 0, NDCG: 0.2846053165967057 HIT: 0.5194163602941176

#### val Acc: 0, NDCG: 0.29169924187749896 HIT: 0.5125114889705882
Epoch: 320, plus 0 steps train_loss: 0.6271

#### test Acc: 0, NDCG: 0.28684659877143015 HIT: 0.5171817555147059

#### val Acc: 0, NDCG: 0.3052417128298725 HIT: 0.5284409466911765
Epoch: 352, plus 0 steps train_loss: 0.6246

#### test Acc: 0, NDCG: 0.28585641551150004 HIT: 0.5166302849264706

#### val Acc: 0, NDCG: 0.30199557829847434 HIT: 0.5300551470588235
Epoch: 384, plus 0 steps train_loss: 0.6218

#### test Acc: 0, NDCG: 0.2925016856493819 HIT: 0.5281020220588235

#### val Acc: 0, NDCG: 0.3072149522528959 HIT: 0.5350528492647059
Epoch: 416, plus 0 steps train_loss: 0.6302

#### test Acc: 0, NDCG: 0.29258675873052076 HIT: 0.5274011948529412

#### val Acc: 0, NDCG: 0.30719185808321314 HIT: 0.5389361213235294
Epoch: 448, plus 0 steps train_loss: 0.6159

#### test Acc: 0, NDCG: 0.301909439236135 HIT: 0.5367819393382354

#### val Acc: 0, NDCG: 0.31752067358595115 HIT: 0.5480124080882354
Epoch: 480, plus 0 steps train_loss: 0.6153

#### test Acc: 0, NDCG: 0.3048830434894902 HIT: 0.5344324448529412

#### val Acc: 0, NDCG: 0.3226355638341925 HIT: 0.5534524356617647
Epoch: 512, plus 0 steps train_loss: 0.6022

#### test Acc: 0, NDCG: 0.3042420000253804 HIT: 0.5484260110294118

#### val Acc: 0, NDCG: 0.3174687149752785 HIT: 0.5541015625
Epoch: 544, plus 0 steps train_loss: 0.6059

#### test Acc: 0, NDCG: 0.30790172640632846 HIT: 0.54912109375

#### val Acc: 0, NDCG: 0.32543805724150227 HIT: 0.5541590073529412
Epoch: 576, plus 0 steps train_loss: 0.6126

#### test Acc: 0, NDCG: 0.3121324612306731 HIT: 0.5553308823529413

#### val Acc: 0, NDCG: 0.32215698053269737 HIT: 0.5548483455882354
Epoch: 608, plus 0 steps train_loss: 0.6022

#### test Acc: 0, NDCG: 0.30241345073608683 HIT: 0.5446748621323529

#### val Acc: 0, NDCG: 0.3276580310692786 HIT: 0.5593175551470588
Epoch: 640, plus 0 steps train_loss: 0.6172

#### test Acc: 0, NDCG: 0.31300259759230076 HIT: 0.5521599264705882

#### val Acc: 0, NDCG: 0.3276784228131858 HIT: 0.56875
Epoch: 704, plus 0 steps train_loss: 0.5934

#### test Acc: 0, NDCG: 0.30938803461540154 HIT: 0.5534639246323529

#### val Acc: 0, NDCG: 0.3310640834237244 HIT: 0.5733800551470588
Epoch: 768, plus 0 steps train_loss: 0.5986

#### test Acc: 0, NDCG: 0.31261677287894907 HIT: 0.5604549632352941

#### val Acc: 0, NDCG: 0.3245420584326464 HIT: 0.5662454044117646
Epoch: 832, plus 0 steps train_loss: 0.5982

#### test Acc: 0, NDCG: 0.31924513617934025 HIT: 0.5607019761029413

#### val Acc: 0, NDCG: 0.3236527265231857 HIT: 0.5641544117647059
Epoch: 896, plus 0 steps train_loss: 0.608

#### test Acc: 0, NDCG: 0.3163807111753727 HIT: 0.5645163143382353

#### val Acc: 0, NDCG: 0.333437501172754 HIT: 0.5761029411764705
Epoch: 960, plus 0 steps train_loss: 0.6091

#### test Acc: 0, NDCG: 0.3139646881027597 HIT: 0.5566348805147059

#### val Acc: 0, NDCG: 0.32915472732887646 HIT: 0.5727251838235294
Epoch: 1013, plus 25 steps train_loss: 0.6057
Done: it took 288846.9385738373
max value of NDCG: 0.31924513617934025
max value of HIT: 0.5645163143382353

After 20 validations
max value of NDCG: 0.31924513617934025
max value of HIT: 0.5645163143382353
