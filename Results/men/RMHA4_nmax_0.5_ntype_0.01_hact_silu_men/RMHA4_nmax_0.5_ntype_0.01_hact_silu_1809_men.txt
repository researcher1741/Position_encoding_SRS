 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.01
max_norm:             	0.5
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12982081018608313 HIT: 0.2863913143382353

#### val Acc: 0, NDCG: 0.13131038448915483 HIT: 0.28478860294117647
Epoch: 1, plus 0 steps train_loss: 0.7536

#### test Acc: 0, NDCG: 0.12724599034524728 HIT: 0.28372587316176473

#### val Acc: 0, NDCG: 0.13304418959179762 HIT: 0.2903033088235294
Epoch: 2, plus 0 steps train_loss: 0.7621

#### test Acc: 0, NDCG: 0.1279534196895444 HIT: 0.2878561580882353

#### val Acc: 0, NDCG: 0.12833162940828907 HIT: 0.28624195772058825
Epoch: 3, plus 0 steps train_loss: 0.7396

#### test Acc: 0, NDCG: 0.1301009452036646 HIT: 0.28967141544117647

#### val Acc: 0, NDCG: 0.13202281735553012 HIT: 0.29161879595588236
Epoch: 4, plus 0 steps train_loss: 0.7317

#### test Acc: 0, NDCG: 0.13180972408709676 HIT: 0.2898150275735294

#### val Acc: 0, NDCG: 0.13304635997434755 HIT: 0.2895795036764706
Epoch: 5, plus 0 steps train_loss: 0.7281

#### test Acc: 0, NDCG: 0.13420844284102276 HIT: 0.28875229779411765

#### val Acc: 0, NDCG: 0.12936862951281172 HIT: 0.28022748161764705
Epoch: 6, plus 0 steps train_loss: 0.7189

#### test Acc: 0, NDCG: 0.15823259506568524 HIT: 0.31482651654411764

#### val Acc: 0, NDCG: 0.16279940383912272 HIT: 0.3193244485294118
Epoch: 7, plus 0 steps train_loss: 0.7094

#### test Acc: 0, NDCG: 0.17883304688593657 HIT: 0.33611557904411765

#### val Acc: 0, NDCG: 0.18564211907537123 HIT: 0.3396484375
Epoch: 8, plus 0 steps train_loss: 0.7059

#### test Acc: 0, NDCG: 0.2042886498655539 HIT: 0.3553366268382353

#### val Acc: 0, NDCG: 0.21097339904053988 HIT: 0.3672679227941177
Epoch: 9, plus 0 steps train_loss: 0.7052

#### test Acc: 0, NDCG: 0.20181137630815799 HIT: 0.35544577205882355

#### val Acc: 0, NDCG: 0.22007740240359505 HIT: 0.37791245404411766
Epoch: 10, plus 0 steps train_loss: 0.7033

#### test Acc: 0, NDCG: 0.2008458224793336 HIT: 0.3573299632352941

#### val Acc: 0, NDCG: 0.20727210341586746 HIT: 0.36134535845588234
Epoch: 12, plus 0 steps train_loss: 0.7038

#### test Acc: 0, NDCG: 0.21860605227719274 HIT: 0.3779584099264706

#### val Acc: 0, NDCG: 0.23044929103537556 HIT: 0.38396714154411765
Epoch: 14, plus 0 steps train_loss: 0.7055

#### test Acc: 0, NDCG: 0.2542772788802367 HIT: 0.4057215073529412

#### val Acc: 0, NDCG: 0.2664596604509253 HIT: 0.41851447610294124
Epoch: 16, plus 0 steps train_loss: 0.7016

#### test Acc: 0, NDCG: 0.27902878548539906 HIT: 0.43243910845588235

#### val Acc: 0, NDCG: 0.28756885377428293 HIT: 0.4366498161764706
Epoch: 18, plus 0 steps train_loss: 0.7006

#### test Acc: 0, NDCG: 0.27702701870626306 HIT: 0.42901539522058824

#### val Acc: 0, NDCG: 0.29485884839310234 HIT: 0.44997702205882356
Epoch: 20, plus 0 steps train_loss: 0.6988

#### test Acc: 0, NDCG: 0.295826428564795 HIT: 0.44480698529411766

#### val Acc: 0, NDCG: 0.3113169187662423 HIT: 0.45510110294117645
Epoch: 22, plus 0 steps train_loss: 0.6998

#### test Acc: 0, NDCG: 0.3875736376500532 HIT: 0.5330135569852941

#### val Acc: 0, NDCG: 0.39822245461263484 HIT: 0.5430778952205882
Epoch: 24, plus 0 steps train_loss: 0.6987

#### test Acc: 0, NDCG: 0.3381501072202445 HIT: 0.48821231617647054

#### val Acc: 0, NDCG: 0.3525636669326588 HIT: 0.49879940257352945
Epoch: 26, plus 0 steps train_loss: 0.6993

#### test Acc: 0, NDCG: 0.29440258065821323 HIT: 0.44646139705882354

#### val Acc: 0, NDCG: 0.30961964944071446 HIT: 0.4550379136029412
Epoch: 28, plus 0 steps train_loss: 0.696

#### test Acc: 0, NDCG: 0.34582798167043893 HIT: 0.49426125919117647

#### val Acc: 0, NDCG: 0.3568090811089251 HIT: 0.5011546415441177
Epoch: 30, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.4085726044723234 HIT: 0.5494427849264706

#### val Acc: 0, NDCG: 0.4114173340636624 HIT: 0.5465245863970588
Epoch: 32, plus 0 steps train_loss: 0.6974

#### test Acc: 0, NDCG: 0.45908512270585017 HIT: 0.6001206341911764

#### val Acc: 0, NDCG: 0.4748714910381523 HIT: 0.6127297794117647
Epoch: 36, plus 0 steps train_loss: 0.6979

#### test Acc: 0, NDCG: 0.2982247914341064 HIT: 0.4508731617647059

#### val Acc: 0, NDCG: 0.31540418018239247 HIT: 0.4580824908088236
Epoch: 40, plus 0 steps train_loss: 0.6951

#### test Acc: 0, NDCG: 0.42921431575950447 HIT: 0.5663315716911764

#### val Acc: 0, NDCG: 0.443851801700024 HIT: 0.5836741727941177
Epoch: 44, plus 0 steps train_loss: 0.6937

#### test Acc: 0, NDCG: 0.4929352162081339 HIT: 0.6254365808823529

#### val Acc: 0, NDCG: 0.5025584593010963 HIT: 0.6354377297794118
Epoch: 48, plus 0 steps train_loss: 0.6852

#### test Acc: 0, NDCG: 0.3877324984474685 HIT: 0.5449391084558823

#### val Acc: 0, NDCG: 0.3881344605793033 HIT: 0.5463235294117647
Epoch: 52, plus 0 steps train_loss: 0.6836

#### test Acc: 0, NDCG: 0.21703715262266537 HIT: 0.4319967830882353

#### val Acc: 0, NDCG: 0.22788515887226096 HIT: 0.44972426470588234
Epoch: 56, plus 0 steps train_loss: 0.6701

#### test Acc: 0, NDCG: 0.2293871795687476 HIT: 0.4558019301470588

#### val Acc: 0, NDCG: 0.23443711519691054 HIT: 0.4678079044117647
Epoch: 60, plus 0 steps train_loss: 0.659

#### test Acc: 0, NDCG: 0.23272131186066597 HIT: 0.4585477941176471

#### val Acc: 0, NDCG: 0.23424270837820232 HIT: 0.4651654411764706
Epoch: 64, plus 0 steps train_loss: 0.6527

#### test Acc: 0, NDCG: 0.240193157983258 HIT: 0.4749310661764706

#### val Acc: 0, NDCG: 0.24203635265002718 HIT: 0.47748161764705876
Epoch: 68, plus 0 steps train_loss: 0.6453

#### test Acc: 0, NDCG: 0.245210279827142 HIT: 0.4788488051470588

#### val Acc: 0, NDCG: 0.24795692080523798 HIT: 0.4876551011029412
Epoch: 72, plus 0 steps train_loss: 0.6359

#### test Acc: 0, NDCG: 0.2608880770761426 HIT: 0.507421875

#### val Acc: 0, NDCG: 0.2647393187388854 HIT: 0.5169347426470587
Epoch: 80, plus 0 steps train_loss: 0.6269

#### test Acc: 0, NDCG: 0.27335882779448956 HIT: 0.5285271139705883

#### val Acc: 0, NDCG: 0.27658220185350135 HIT: 0.5280503216911765
Epoch: 88, plus 0 steps train_loss: 0.6249

#### test Acc: 0, NDCG: 0.2736898739134535 HIT: 0.5203871783088235

#### val Acc: 0, NDCG: 0.28661508624426274 HIT: 0.5385225183823529
Epoch: 96, plus 0 steps train_loss: 0.6186

#### test Acc: 0, NDCG: 0.28447960935968275 HIT: 0.5397633272058824

#### val Acc: 0, NDCG: 0.289305141327771 HIT: 0.5428998161764705
Epoch: 104, plus 0 steps train_loss: 0.6061

#### test Acc: 0, NDCG: 0.2977278778764007 HIT: 0.5533203125

#### val Acc: 0, NDCG: 0.30217221394956273 HIT: 0.5558478860294118
Epoch: 112, plus 0 steps train_loss: 0.6001

#### test Acc: 0, NDCG: 0.3062957434075339 HIT: 0.5596794577205882

#### val Acc: 0, NDCG: 0.3062020539971397 HIT: 0.5688074448529412
Epoch: 120, plus 0 steps train_loss: 0.5922

#### test Acc: 0, NDCG: 0.3085583437131645 HIT: 0.5655847886029413

#### val Acc: 0, NDCG: 0.31197714560413015 HIT: 0.5690716911764706
Epoch: 128, plus 0 steps train_loss: 0.5865

#### test Acc: 0, NDCG: 0.31199260702162024 HIT: 0.5672219669117646

#### val Acc: 0, NDCG: 0.3215568372754578 HIT: 0.5801642922794118
Epoch: 136, plus 0 steps train_loss: 0.5914

#### test Acc: 0, NDCG: 0.3203979549183911 HIT: 0.5816521139705882

#### val Acc: 0, NDCG: 0.32195629398407893 HIT: 0.5837833180147058
Epoch: 144, plus 0 steps train_loss: 0.5782

#### test Acc: 0, NDCG: 0.33046724486543566 HIT: 0.5960822610294118

#### val Acc: 0, NDCG: 0.33746746316432663 HIT: 0.5980009191176471
Epoch: 160, plus 0 steps train_loss: 0.5732

#### test Acc: 0, NDCG: 0.33017566940975807 HIT: 0.5921300551470587

#### val Acc: 0, NDCG: 0.34205889881024665 HIT: 0.6005629595588236
Epoch: 176, plus 0 steps train_loss: 0.5635

#### test Acc: 0, NDCG: 0.3397051163675079 HIT: 0.6032513786764706

#### val Acc: 0, NDCG: 0.34529293847503145 HIT: 0.6074678308823529
Epoch: 192, plus 0 steps train_loss: 0.5719

#### test Acc: 0, NDCG: 0.3431982154761958 HIT: 0.5989372702205882

#### val Acc: 0, NDCG: 0.3477641779374493 HIT: 0.6051068474264706
Epoch: 208, plus 0 steps train_loss: 0.572

#### test Acc: 0, NDCG: 0.3559225501188311 HIT: 0.6123736213235295

#### val Acc: 0, NDCG: 0.3592528819165491 HIT: 0.6186810661764706
Epoch: 224, plus 0 steps train_loss: 0.5618

#### test Acc: 0, NDCG: 0.3582643657727683 HIT: 0.6173138786764706

#### val Acc: 0, NDCG: 0.3569590620101468 HIT: 0.6138844209558824
Epoch: 240, plus 0 steps train_loss: 0.5379

#### test Acc: 0, NDCG: 0.35310432522123864 HIT: 0.6002585018382354

#### val Acc: 0, NDCG: 0.3640825657416092 HIT: 0.6225873161764706
Epoch: 256, plus 0 steps train_loss: 0.5332

#### test Acc: 0, NDCG: 0.36074652877233226 HIT: 0.612890625

#### val Acc: 0, NDCG: 0.3683530087048175 HIT: 0.6251436121323529
Epoch: 272, plus 0 steps train_loss: 0.5474

#### test Acc: 0, NDCG: 0.3615592473301377 HIT: 0.6144875919117647

#### val Acc: 0, NDCG: 0.36827328287715233 HIT: 0.6222943474264706
Epoch: 288, plus 0 steps train_loss: 0.5367

#### test Acc: 0, NDCG: 0.3709120071686654 HIT: 0.6241785386029413

#### val Acc: 0, NDCG: 0.3767030535364547 HIT: 0.6349666819852942
Epoch: 304, plus 0 steps train_loss: 0.5123

#### test Acc: 0, NDCG: 0.36910326465385573 HIT: 0.6240004595588236

#### val Acc: 0, NDCG: 0.37780354103104824 HIT: 0.6295668658088236
Epoch: 320, plus 0 steps train_loss: 0.5294

#### test Acc: 0, NDCG: 0.3727783549520497 HIT: 0.6235064338235294

#### val Acc: 0, NDCG: 0.38563608369010105 HIT: 0.6372414981617647
Epoch: 352, plus 0 steps train_loss: 0.5262

#### test Acc: 0, NDCG: 0.37803318642529427 HIT: 0.6278607536764705

#### val Acc: 0, NDCG: 0.39268197316074727 HIT: 0.6446461397058824
Epoch: 384, plus 0 steps train_loss: 0.5228

#### test Acc: 0, NDCG: 0.38386849452284627 HIT: 0.6341911764705882

#### val Acc: 0, NDCG: 0.3946667995284372 HIT: 0.6479664522058823
Epoch: 416, plus 0 steps train_loss: 0.5009

#### test Acc: 0, NDCG: 0.3849002780717965 HIT: 0.6424977022058823

#### val Acc: 0, NDCG: 0.3963886347748909 HIT: 0.6416877297794118
Epoch: 448, plus 0 steps train_loss: 0.4983

#### test Acc: 0, NDCG: 0.3881341336954789 HIT: 0.64462890625

#### val Acc: 0, NDCG: 0.40228738362249433 HIT: 0.6537166819852941
Epoch: 480, plus 0 steps train_loss: 0.4861

#### test Acc: 0, NDCG: 0.39107270476975986 HIT: 0.6376321231617647

#### val Acc: 0, NDCG: 0.39958444307813556 HIT: 0.6470128676470588
Epoch: 512, plus 0 steps train_loss: 0.5036

#### test Acc: 0, NDCG: 0.3899906776088563 HIT: 0.6419462316176471

#### val Acc: 0, NDCG: 0.40404209449232853 HIT: 0.658203125
Epoch: 544, plus 0 steps train_loss: 0.4855

#### test Acc: 0, NDCG: 0.39840658190644324 HIT: 0.6488913143382353

#### val Acc: 0, NDCG: 0.4009870538797406 HIT: 0.65302734375
Epoch: 576, plus 0 steps train_loss: 0.4798

#### test Acc: 0, NDCG: 0.38922054085182584 HIT: 0.6389188878676471

#### val Acc: 0, NDCG: 0.4077128016695847 HIT: 0.6630514705882353
Epoch: 608, plus 0 steps train_loss: 0.4807

#### test Acc: 0, NDCG: 0.39294225290243767 HIT: 0.6390854779411764

#### val Acc: 0, NDCG: 0.4072527553433976 HIT: 0.6601045496323529
Epoch: 640, plus 0 steps train_loss: 0.4698

#### test Acc: 0, NDCG: 0.3925589116691592 HIT: 0.6393899356617647

#### val Acc: 0, NDCG: 0.40940213039019724 HIT: 0.6598460477941177
Epoch: 704, plus 0 steps train_loss: 0.4593

#### test Acc: 0, NDCG: 0.3957851073536158 HIT: 0.638671875

#### val Acc: 0, NDCG: 0.4025054732679725 HIT: 0.6516027113970588
Epoch: 768, plus 0 steps train_loss: 0.4696

#### test Acc: 0, NDCG: 0.39304411470949213 HIT: 0.6420726102941177

#### val Acc: 0, NDCG: 0.4051094262200324 HIT: 0.6504538143382353
Epoch: 832, plus 0 steps train_loss: 0.4682

#### test Acc: 0, NDCG: 0.39469698549414306 HIT: 0.6441750919117647

#### val Acc: 0, NDCG: 0.40735581592391323 HIT: 0.6502240349264705
Epoch: 896, plus 0 steps train_loss: 0.468

#### test Acc: 0, NDCG: 0.4049756568456531 HIT: 0.6519761029411765

#### val Acc: 0, NDCG: 0.41091353840879313 HIT: 0.6579503676470588
Epoch: 960, plus 0 steps train_loss: 0.4635

#### test Acc: 0, NDCG: 0.4003065236220681 HIT: 0.6428193933823529

#### val Acc: 0, NDCG: 0.4025817523604496 HIT: 0.6526424632352941
Epoch: 1013, plus 25 steps train_loss: 0.4643
Done: it took 301421.4283230305
max value of NDCG: 0.4929352162081339
max value of HIT: 0.6519761029411765

After 20 validations
max value of NDCG: 0.4929352162081339
max value of HIT: 0.6519761029411765
