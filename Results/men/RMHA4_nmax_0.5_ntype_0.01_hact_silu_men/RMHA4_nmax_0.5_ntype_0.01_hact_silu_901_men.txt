 The dataset Men contains 34244 users and 110636 items in total
average sequence length: {5.44}
ItemFeatures DF dimensions (110637, 2048)

#######  Training configuration
norm_type:            	0.01
max_norm:             	0.5
dataset:              	Men
train_dir:            	default
batch_size:           	512
lr:                   	6e-06
std:                  	0.01
maxlen:               	35
hidden_units:         	390
num_heads:            	3
pad_token_id:         	0
num_epochs:           	1000
dropout_rate:         	0.3
cxt_size:             	6
n_workers:            	1
top_k:                	10
test_size:            	10000
validation_point:     	1
print_every_n_point:  	1
exponential_print:    	True
last_items:           	False
reverse:              	True
only_finals:          	True
sampling_mode:        	False
add_users:            	False
mask_user:            	False
user_act:             	silu
user_FF:              	True
loss_type:            	CE
positional_encoding_type: 	
position_concatenation: 	False
RMHA_encoder:         	True
ROPE_encoder:         	False
decoder_head:         	masked
max_relative_position: 	4
normalization_type:   	ln
num_groups:           	3
residual_connection_encoder_FF: 	mul
residual_connection_encoder: 	mul
residual_connection_decoder: 	False
dropout_btn_MHA_FF:   	False
num_encoder_blocks:   	3
num_decoder_blocks:   	1
ln_in_AH_decoder:     	False
ln_in_AH_encoder:     	True
ln_in_Q_decoder:      	False
ln_in_Q_encoder:      	True
layer_norm_eps:       	1e-08
hidden_act:           	silu
hidden_act_out:       	sigmoid
intercalate_act:      	True
mask_before_FF_decoder: 	True
PN:                   	False
embedding_d:          	390
embedding_g:          	1950
intermediate_size:    	1170
hidden_dropout_prob:  	0.3
attention_probs_dropout_prob: 	0.3
saving:               	False
RMHA_decoder:         	False

#######
Loading Configuration ...
Number of steps in the Train dataset: 66883
Number of steps in the Validation dataset: 20
Number of steps in the Test dataset: 20
Loading Model ...
Amount of model parameters 51283831
Loading scheduler and optimizer ...
Evaluation every 66 steps, i.e, 1.0 epochs

#### test Acc: 0, NDCG: 0.12946782045412086 HIT: 0.28106617647058824

#### val Acc: 0, NDCG: 0.12860685107415049 HIT: 0.2818301930147059
Epoch: 1, plus 0 steps train_loss: 0.7663

#### test Acc: 0, NDCG: 0.13018635835326933 HIT: 0.2865291819852941

#### val Acc: 0, NDCG: 0.12788786883838962 HIT: 0.28266888786764705
Epoch: 2, plus 0 steps train_loss: 0.7576

#### test Acc: 0, NDCG: 0.1337188453155874 HIT: 0.29348000919117645

#### val Acc: 0, NDCG: 0.12979632437132635 HIT: 0.28855124080882355
Epoch: 3, plus 0 steps train_loss: 0.7582

#### test Acc: 0, NDCG: 0.12826643260941017 HIT: 0.2818761488970588

#### val Acc: 0, NDCG: 0.1308139109539046 HIT: 0.2885799632352941
Epoch: 4, plus 0 steps train_loss: 0.7403

#### test Acc: 0, NDCG: 0.13413537353183053 HIT: 0.2898265165441177

#### val Acc: 0, NDCG: 0.13772634393224262 HIT: 0.2950482536764706
Epoch: 5, plus 0 steps train_loss: 0.7172

#### test Acc: 0, NDCG: 0.21378170232398075 HIT: 0.36642922794117644

#### val Acc: 0, NDCG: 0.22084591960792715 HIT: 0.3674747242647059
Epoch: 6, plus 0 steps train_loss: 0.709

#### test Acc: 0, NDCG: 0.2999899293116862 HIT: 0.4462373621323529

#### val Acc: 0, NDCG: 0.31743760430833595 HIT: 0.46823874080882355
Epoch: 7, plus 0 steps train_loss: 0.7123

#### test Acc: 0, NDCG: 0.36521188518964887 HIT: 0.5023609834558823

#### val Acc: 0, NDCG: 0.36875578681616145 HIT: 0.5100126378676471
Epoch: 8, plus 0 steps train_loss: 0.7097

#### test Acc: 0, NDCG: 0.39716132887101707 HIT: 0.5365521599264705

#### val Acc: 0, NDCG: 0.40019207391444933 HIT: 0.5353917738970588
Epoch: 9, plus 0 steps train_loss: 0.7062

#### test Acc: 0, NDCG: 0.44317651903595634 HIT: 0.579296875

#### val Acc: 0, NDCG: 0.43931067615299035 HIT: 0.5700712316176471
Epoch: 10, plus 0 steps train_loss: 0.7086

#### test Acc: 0, NDCG: 0.40413164558011944 HIT: 0.5426987591911765

#### val Acc: 0, NDCG: 0.42595262028142117 HIT: 0.5610236672794118
Epoch: 12, plus 0 steps train_loss: 0.7056

#### test Acc: 0, NDCG: 0.4005756491733309 HIT: 0.5365062040441176

#### val Acc: 0, NDCG: 0.41028759363534906 HIT: 0.5459214154411764
Epoch: 14, plus 0 steps train_loss: 0.7048

#### test Acc: 0, NDCG: 0.2561563606232655 HIT: 0.4026309742647059

#### val Acc: 0, NDCG: 0.27891023858317265 HIT: 0.42868221507352944
Epoch: 16, plus 0 steps train_loss: 0.7046

#### test Acc: 0, NDCG: 0.23275899422791446 HIT: 0.3839786305147059

#### val Acc: 0, NDCG: 0.25801349730613404 HIT: 0.4076803768382353
Epoch: 18, plus 0 steps train_loss: 0.7032

#### test Acc: 0, NDCG: 0.2337540466128692 HIT: 0.38347311580882354

#### val Acc: 0, NDCG: 0.259386020868502 HIT: 0.40749080882352945
Epoch: 20, plus 0 steps train_loss: 0.7

#### test Acc: 0, NDCG: 0.2745626904503282 HIT: 0.4248851102941177

#### val Acc: 0, NDCG: 0.28753776886499305 HIT: 0.4343175551470588
Epoch: 22, plus 0 steps train_loss: 0.7002

#### test Acc: 0, NDCG: 0.2577150523667361 HIT: 0.4043370863970588

#### val Acc: 0, NDCG: 0.28013624610155236 HIT: 0.42859604779411764
Epoch: 24, plus 0 steps train_loss: 0.6973

#### test Acc: 0, NDCG: 0.27270934158389615 HIT: 0.4167509191176471

#### val Acc: 0, NDCG: 0.295240408201598 HIT: 0.4396082261029412
Epoch: 26, plus 0 steps train_loss: 0.6983

#### test Acc: 0, NDCG: 0.3205464466391012 HIT: 0.46428653492647054

#### val Acc: 0, NDCG: 0.34774767049746436 HIT: 0.49114774816176465
Epoch: 28, plus 0 steps train_loss: 0.6994

#### test Acc: 0, NDCG: 0.3664339235558051 HIT: 0.5059053308823529

#### val Acc: 0, NDCG: 0.38112323102106893 HIT: 0.5179859834558823
Epoch: 30, plus 0 steps train_loss: 0.6966

#### test Acc: 0, NDCG: 0.300342253232745 HIT: 0.44680032169117645

#### val Acc: 0, NDCG: 0.3243133564001131 HIT: 0.4710363051470588
Epoch: 32, plus 0 steps train_loss: 0.6968

#### test Acc: 0, NDCG: 0.22547858480789168 HIT: 0.37306410845588234

#### val Acc: 0, NDCG: 0.25575679351672026 HIT: 0.40260799632352945
Epoch: 36, plus 0 steps train_loss: 0.6955

#### test Acc: 0, NDCG: 0.30321280625167213 HIT: 0.4508731617647059

#### val Acc: 0, NDCG: 0.31851737210540754 HIT: 0.4646484375
Epoch: 40, plus 0 steps train_loss: 0.6947

#### test Acc: 0, NDCG: 0.3122695336583245 HIT: 0.4628848805147059

#### val Acc: 0, NDCG: 0.3475240206590267 HIT: 0.5015625
Epoch: 44, plus 0 steps train_loss: 0.6905

#### test Acc: 0, NDCG: 0.4009161386136683 HIT: 0.5528894761029413

#### val Acc: 0, NDCG: 0.41880956719636336 HIT: 0.5650390625
Epoch: 48, plus 0 steps train_loss: 0.6913

#### test Acc: 0, NDCG: 0.5839736222428328 HIT: 0.6970875459558823

#### val Acc: 0, NDCG: 0.5948200183657558 HIT: 0.7050551470588236
Epoch: 52, plus 0 steps train_loss: 0.6848

#### test Acc: 0, NDCG: 0.5755255287174663 HIT: 0.6944106158088236

#### val Acc: 0, NDCG: 0.5882700801653401 HIT: 0.7076861213235295
Epoch: 56, plus 0 steps train_loss: 0.6748

#### test Acc: 0, NDCG: 0.21471655535512757 HIT: 0.4279756433823529

#### val Acc: 0, NDCG: 0.21805357955019197 HIT: 0.4309914981617647
Epoch: 60, plus 0 steps train_loss: 0.6716

#### test Acc: 0, NDCG: 0.22712448503740115 HIT: 0.45163143382352944

#### val Acc: 0, NDCG: 0.23042589444051798 HIT: 0.4539119944852941
Epoch: 64, plus 0 steps train_loss: 0.6632

#### test Acc: 0, NDCG: 0.2350269778711282 HIT: 0.4675321691176471

#### val Acc: 0, NDCG: 0.23341825078519637 HIT: 0.4617704503676471
Epoch: 68, plus 0 steps train_loss: 0.6485

#### test Acc: 0, NDCG: 0.24667879952146715 HIT: 0.4782628676470588

#### val Acc: 0, NDCG: 0.24834812813445847 HIT: 0.48170955882352945
Epoch: 72, plus 0 steps train_loss: 0.6462

#### test Acc: 0, NDCG: 0.2588710421451776 HIT: 0.4910615808823529

#### val Acc: 0, NDCG: 0.2576107292392653 HIT: 0.4938131893382353
Epoch: 80, plus 0 steps train_loss: 0.6425

#### test Acc: 0, NDCG: 0.2629610990903507 HIT: 0.5031709558823529

#### val Acc: 0, NDCG: 0.2624180281482821 HIT: 0.49816176470588236
Epoch: 88, plus 0 steps train_loss: 0.6457

#### test Acc: 0, NDCG: 0.27337280668380914 HIT: 0.5229836856617647

#### val Acc: 0, NDCG: 0.28721727807811537 HIT: 0.5388786764705882
Epoch: 96, plus 0 steps train_loss: 0.6288

#### test Acc: 0, NDCG: 0.28348979703379273 HIT: 0.5327780330882353

#### val Acc: 0, NDCG: 0.2954484294276515 HIT: 0.5406135110294118
Epoch: 104, plus 0 steps train_loss: 0.613

#### test Acc: 0, NDCG: 0.29922740765771316 HIT: 0.5528033088235295

#### val Acc: 0, NDCG: 0.3021913558028406 HIT: 0.5530503216911764
Epoch: 112, plus 0 steps train_loss: 0.5928

#### test Acc: 0, NDCG: 0.3057698742704689 HIT: 0.5598575367647058

#### val Acc: 0, NDCG: 0.3098863002724593 HIT: 0.5578871783088235
Epoch: 120, plus 0 steps train_loss: 0.5985

#### test Acc: 0, NDCG: 0.31122083804837486 HIT: 0.5638499540441176

#### val Acc: 0, NDCG: 0.32305631335663815 HIT: 0.5758214613970588
Epoch: 128, plus 0 steps train_loss: 0.5845

#### test Acc: 0, NDCG: 0.3098680019762599 HIT: 0.5681468290441176

#### val Acc: 0, NDCG: 0.31204393547600306 HIT: 0.5559685202205882
Epoch: 136, plus 0 steps train_loss: 0.6016

#### test Acc: 0, NDCG: 0.3155884179176982 HIT: 0.5645680147058824

#### val Acc: 0, NDCG: 0.31889017831885025 HIT: 0.5653722426470588
Epoch: 144, plus 0 steps train_loss: 0.5722

#### test Acc: 0, NDCG: 0.32844113174537565 HIT: 0.5773724724264706

#### val Acc: 0, NDCG: 0.33183203862656774 HIT: 0.5827780330882353
Epoch: 160, plus 0 steps train_loss: 0.5728

#### test Acc: 0, NDCG: 0.33557343168336967 HIT: 0.5867991727941176

#### val Acc: 0, NDCG: 0.33605825191978445 HIT: 0.5860926011029413
Epoch: 176, plus 0 steps train_loss: 0.5701

#### test Acc: 0, NDCG: 0.3432073532143452 HIT: 0.5942267922794118

#### val Acc: 0, NDCG: 0.34767858638337157 HIT: 0.5940199908088235
Epoch: 192, plus 0 steps train_loss: 0.575

#### test Acc: 0, NDCG: 0.3476892208737158 HIT: 0.5957548253676471

#### val Acc: 0, NDCG: 0.353757304645005 HIT: 0.5994312959558823
Epoch: 208, plus 0 steps train_loss: 0.5713

#### test Acc: 0, NDCG: 0.3429598206067016 HIT: 0.5877527573529412

#### val Acc: 0, NDCG: 0.356834788108277 HIT: 0.6070829503676471
Epoch: 224, plus 0 steps train_loss: 0.5446

#### test Acc: 0, NDCG: 0.357302917250521 HIT: 0.6059857536764706

#### val Acc: 0, NDCG: 0.3631141832196975 HIT: 0.6083754595588236
Epoch: 240, plus 0 steps train_loss: 0.565

#### test Acc: 0, NDCG: 0.36090250862555373 HIT: 0.6056123621323529

#### val Acc: 0, NDCG: 0.3735058082704035 HIT: 0.6141831341911764
Epoch: 256, plus 0 steps train_loss: 0.557

#### test Acc: 0, NDCG: 0.3608785786155679 HIT: 0.6040556066176471

#### val Acc: 0, NDCG: 0.3732467550081958 HIT: 0.6199678308823529
Epoch: 272, plus 0 steps train_loss: 0.5484

#### test Acc: 0, NDCG: 0.3649455428632279 HIT: 0.6137465533088236

#### val Acc: 0, NDCG: 0.38048543958054376 HIT: 0.6287626378676471
Epoch: 288, plus 0 steps train_loss: 0.5474

#### test Acc: 0, NDCG: 0.3764790639479705 HIT: 0.6211052389705882

#### val Acc: 0, NDCG: 0.3800609432577339 HIT: 0.6298770680147059
Epoch: 304, plus 0 steps train_loss: 0.5301

#### test Acc: 0, NDCG: 0.37563127213854997 HIT: 0.6172564338235295

#### val Acc: 0, NDCG: 0.37550574709353124 HIT: 0.6327435661764705
Epoch: 320, plus 0 steps train_loss: 0.5312

#### test Acc: 0, NDCG: 0.37448184594758016 HIT: 0.6281364889705883

#### val Acc: 0, NDCG: 0.3895086084844359 HIT: 0.6369715073529412
Epoch: 352, plus 0 steps train_loss: 0.5356

#### test Acc: 0, NDCG: 0.3835792510652689 HIT: 0.6335133272058824

#### val Acc: 0, NDCG: 0.39555280470639714 HIT: 0.6415498621323529
Epoch: 384, plus 0 steps train_loss: 0.5136

#### test Acc: 0, NDCG: 0.390710498450601 HIT: 0.6329503676470588

#### val Acc: 0, NDCG: 0.3960585040592589 HIT: 0.6430319393382353
Epoch: 416, plus 0 steps train_loss: 0.5144

#### test Acc: 0, NDCG: 0.3835717415363836 HIT: 0.6266716452205883

#### val Acc: 0, NDCG: 0.39734973548736646 HIT: 0.6462086397058824
Epoch: 448, plus 0 steps train_loss: 0.5086

#### test Acc: 0, NDCG: 0.3958076732623631 HIT: 0.6478917738970588

#### val Acc: 0, NDCG: 0.3996120759830598 HIT: 0.6534639246323529
Epoch: 480, plus 0 steps train_loss: 0.4876

#### test Acc: 0, NDCG: 0.393082448956157 HIT: 0.6416245404411764

#### val Acc: 0, NDCG: 0.408370032005299 HIT: 0.6612362132352941
Epoch: 512, plus 0 steps train_loss: 0.4926

#### test Acc: 0, NDCG: 0.38907405842905385 HIT: 0.6379193474264706

#### val Acc: 0, NDCG: 0.404424924185828 HIT: 0.6526999080882353
Epoch: 544, plus 0 steps train_loss: 0.4784

#### test Acc: 0, NDCG: 0.3940820044413698 HIT: 0.6393152573529413

#### val Acc: 0, NDCG: 0.3992600411025606 HIT: 0.6500804227941177
Epoch: 576, plus 0 steps train_loss: 0.4919

#### test Acc: 0, NDCG: 0.39420790290860236 HIT: 0.6445829503676471

#### val Acc: 0, NDCG: 0.4051378863766166 HIT: 0.6545438878676471
Epoch: 608, plus 0 steps train_loss: 0.4805

#### test Acc: 0, NDCG: 0.3993139367808893 HIT: 0.6440544577205882

#### val Acc: 0, NDCG: 0.40916660296058616 HIT: 0.6560891544117646
Epoch: 640, plus 0 steps train_loss: 0.4876

#### test Acc: 0, NDCG: 0.3981698941850581 HIT: 0.6447840073529412

#### val Acc: 0, NDCG: 0.4105960496293918 HIT: 0.6530330882352942
Epoch: 704, plus 0 steps train_loss: 0.4672

#### test Acc: 0, NDCG: 0.39034203222109076 HIT: 0.6318129595588236

#### val Acc: 0, NDCG: 0.4126422608456628 HIT: 0.6614372702205882
Epoch: 768, plus 0 steps train_loss: 0.4787

#### test Acc: 0, NDCG: 0.3948158688756219 HIT: 0.6393095128676471

#### val Acc: 0, NDCG: 0.4147204458592591 HIT: 0.6589958639705882
Epoch: 832, plus 0 steps train_loss: 0.4857

#### test Acc: 0, NDCG: 0.3958787910548471 HIT: 0.6403090533088236

#### val Acc: 0, NDCG: 0.41575838000387966 HIT: 0.6658835018382353
Epoch: 896, plus 0 steps train_loss: 0.4511

#### test Acc: 0, NDCG: 0.3955042745902858 HIT: 0.6403550091911765

#### val Acc: 0, NDCG: 0.4122414962075484 HIT: 0.6531824448529412
Epoch: 960, plus 0 steps train_loss: 0.4611

#### test Acc: 0, NDCG: 0.40156213066182583 HIT: 0.6472139246323529

#### val Acc: 0, NDCG: 0.41057012612457333 HIT: 0.6588235294117647
Epoch: 1013, plus 25 steps train_loss: 0.4577
Done: it took 300245.9746992588
max value of NDCG: 0.5839736222428328
max value of HIT: 0.6970875459558823

After 20 validations
max value of NDCG: 0.5839736222428328
max value of HIT: 0.6970875459558823
