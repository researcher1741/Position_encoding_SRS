{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c363243-84bc-4881-9a8b-21ad14ed3f95",
   "metadata": {},
   "source": [
    "## EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668f0482-d6dc-4564-ab9d-1bf8eb423ee0",
   "metadata": {},
   "source": [
    "### embeddings extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fd973760-06af-4e6c-8425-12042f926d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from src.data_preprocessing import datapreproces\n",
    "dataset_name = \"Beauty\"\n",
    "# data, num_batch, args, Features, CXTDict, UserFeatures = datapreproces(dataset_name)\n",
    "# [user_train, user_valid, user_test, users_total_num, items_total_num] = data\n",
    "index_list = [1,0]\n",
    "users = [1,2]\n",
    "seq_cxt = [CXTDict[(user, index_list[0])] for user in users]\n",
    "seq_cxt = np.array(seq_cxt)\n",
    "emb_items = nn.Embedding(Features.shape[0] + 1, 90, padding_idx=0, norm_type=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f1a440e1-758b-4659-a574-edaa0a30e596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9471,  1.0317,  0.4846, -1.5641, -0.2368,  1.3876,  0.7347, -1.1573,\n",
       "          0.2910,  1.3973, -1.6543, -0.5115,  0.3209, -0.5572, -0.1066,  1.9494,\n",
       "          0.7083,  1.6507, -0.0610,  1.1979, -0.8466, -0.4442,  0.6275,  0.2956,\n",
       "         -0.1482,  0.5476, -0.4038, -1.8332, -0.3552, -0.6705,  0.1667,  0.7754,\n",
       "         -0.3378,  0.7090,  0.2868, -0.1666, -0.5058,  0.1329, -1.5623, -2.3170,\n",
       "         -0.0599,  0.3859,  0.3412, -0.4067, -0.5002, -0.2441,  1.9822, -0.1858,\n",
       "         -0.0726, -1.2569, -0.8453, -0.9545, -0.3456, -1.4746,  0.4829, -0.0375,\n",
       "          0.0382,  1.2739, -1.0067,  1.4165, -0.4220, -0.9866, -0.0749,  0.5436,\n",
       "         -1.9779, -0.9052, -0.4024,  2.0748,  0.2989, -0.0536,  0.4692,  1.2699,\n",
       "          0.5089, -2.1045, -1.5540,  0.9174,  0.1993, -1.8354,  0.1797, -0.3698,\n",
       "          0.4699, -0.8442,  0.5123, -0.3943,  0.6913,  0.5210, -0.5548,  0.1412,\n",
       "          0.7923, -0.2882],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_items(torch.tensor(index_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8f019d3-068d-4a25-b487-5fb63c3b9222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "        [33.99,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ]]),\n",
       " array([[ 0.92857143,  0.91666667,  0.77419355,  0.85714286,  0.89863014,\n",
       "         11.75      ],\n",
       "        [ 1.        ,  0.25      ,  0.61290323,  0.28571429,  0.21369863,\n",
       "          3.        ]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features[0:2,:], seq_cxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ac58e81-430e-4be9-96ed-569ea7ee2524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6507])\n",
      "torch.Size([2, 6507])\n"
     ]
    }
   ],
   "source": [
    "emb = nn.Embedding(Features.shape[0], Features.shape[1])\n",
    "emb._parameters['weight'] = Features\n",
    "index_list = [1,0]\n",
    "array = torch.tensor(emb._parameters['weight'][index_list])\n",
    "# array = torch.tensor([[[1,2,3],[31,32,33]], [[11,12,13],[21,22,23]]])\n",
    "print(f\"{array.size()}\")\n",
    "input_shape = array.size()\n",
    "array.view(-1, input_shape[-1])\n",
    "print(f\"{array.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2ca4582b-ce12-487e-b668-eb421e14ebbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10, 35, 60]),\n",
       " tensor([[False,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True]]),\n",
       " tensor([[[False, False, False],\n",
       "          [ True,  True,  True],\n",
       "          [ True,  True,  True],\n",
       "          [ True,  True,  True],\n",
       "          [ True,  True,  True]],\n",
       " \n",
       "         [[ True,  True,  True],\n",
       "          [ True,  True,  True],\n",
       "          [ True,  True,  True],\n",
       "          [ True,  True,  True],\n",
       "          [ True,  True,  True]],\n",
       " \n",
       "         [[ True,  True,  True],\n",
       "          [ True,  True,  True],\n",
       "          [ True,  True,  True],\n",
       "          [ True,  True,  True],\n",
       "          [ True,  True,  True]]]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(15)\n",
    "x = x.view(3, -1)\n",
    "def get_mask1(tensor):\n",
    "    return tensor.to(torch.bool) if tensor is not None else None\n",
    "def get_mask(tensor):\n",
    "    return torch.BoolTensor(tensor == 0) if tensor is not None else None\n",
    "timeline_mask = torch.BoolTensor(x == 0)\n",
    "# x *= ~timeline_mask\n",
    "x.sum(dim=-1), get_mask1(x), ~get_mask(x).unsqueeze(-1).repeat(1, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "646bdb6f-1bd6-4715-a21b-2dfb83c5e491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True]],\n",
       "\n",
       "        [[ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True]],\n",
       "\n",
       "        [[ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~timeline_mask.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f69e7b3f-a421-4ae1-b955-10aa86cee807",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 10:26:53.528697: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 2982288240 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "seq_feat = tf.nn.embedding_lookup(Features, index_list, name=\"seq_feat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f4842cc-cca0-4085-be49-6b88d0196704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 6507]),\n",
       " array([[ 0.92857143,  0.91666667,  0.77419355,  0.85714286,  0.89863014,\n",
       "         11.75      ],\n",
       "        [ 1.        ,  0.25      ,  0.61290323,  0.28571429,  0.21369863,\n",
       "          3.        ]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_feat.shape, seq_cxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e429b74d-5a27-4a2f-952e-e6a73668a671",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'inputs')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m seq_feat_in \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([seq_feat, seq_cxt], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m hidden_units \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m90\u001b[39m\n\u001b[0;32m----> 3\u001b[0m seq_feat_emb \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_feat_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_units\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mkernel_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_normal_initializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstddev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeat_emb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# tf.concat([seq_in, seq_feat_emb], 2)\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py:1131\u001b[0m, in \u001b[0;36mDense.__init__\u001b[0;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m   1129\u001b[0m   kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m'\u001b[39m),)\n\u001b[0;32m-> 1131\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDense\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivity_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregularizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivity_regularizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(units) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(units, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m units\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m activations\u001b[38;5;241m.\u001b[39mget(activation)\n",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:456\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 456\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:294\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m allowed_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_input_shape\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautocast\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    292\u001b[0m }\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# Validate optional keyword arguments.\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m \u001b[43mgeneric_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# Mutable properties\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# Indicates whether the layer's weights are updated during training\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;66;03m# and whether the layer's updates are run during training.\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable \u001b[38;5;241m=\u001b[39m trainable\n",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:792\u001b[0m, in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kwarg \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    791\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwarg \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_kwargs:\n\u001b[0;32m--> 792\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(error_message, kwarg)\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'inputs')"
     ]
    }
   ],
   "source": [
    "seq_feat_in = tf.concat([seq_feat, seq_cxt], -1)\n",
    "hidden_units = 90\n",
    "seq_feat_emb = tf.keras.layers.Dense(inputs=seq_feat_in, units=hidden_units * 5,\n",
    "                                            activation=None,\n",
    "                                            kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                                            name=\"feat_emb\")\n",
    "# tf.concat([seq_in, seq_feat_emb], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf555b-3895-4811-a3a3-88e374312377",
   "metadata": {},
   "source": [
    "### Embeddings Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e12f70-63c6-4db0-b1a6-f928641f6452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn\n",
    "\n",
    "class SinPositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=5000, concat=False):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            d_model - Hidden dimensionality of the input.\n",
    "            max_len - Maximum length of a sequence to expect.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Create matrix of [SeqLen, HiddenDim] representing the positional encoding for max_len inputs\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # even\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # odds\n",
    "        pe = pe.unsqueeze(0)\n",
    "        \n",
    "        self.register_buffer('pe', pe, persistent=False)\n",
    "        self.concat = concat\n",
    "        if concat:\n",
    "            self.encoding = nn.Linear(d_model * 2, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.concat:\n",
    "            x = x + self.pe[:, :x.size(1)]\n",
    "        else:\n",
    "            x = torch.cat(x, self.pe[:, :x.size(1)])\n",
    "            x = self.encoding(x)\n",
    "        return x\n",
    "max_len = 75\n",
    "d_model = 10\n",
    "concat = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bfeccda-1620-4249-b474-6231c1c9633a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e2ea19cb9dbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdiv_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiv_term\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# even\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiv_term\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# odds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "pe = torch.zeros(max_len, d_model)\n",
    "position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "pe[:, 0::2] = torch.sin(position * div_term)  # even\n",
    "pe[:, 1::2] = torch.cos(position * div_term)  # odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "667ff044-e712-47e4-bc3c-14940694c7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([75, 10]),\n",
       " tensor([-0.9851,  0.1717, -0.7434,  0.6688,  0.9588, -0.2840,  0.2904,  0.9569,\n",
       "          0.0467,  0.9989]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe.shape, pe[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdb0195f-0c22-46ba-a92d-b533f9a0a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = torch.arange(8).view(4,2)\n",
    "pe2 = torch.flip(pe, [0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "709479f9-7e7d-4545-8703-c6d8d6ed34b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 2, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = pe.unsqueeze(-1)\n",
    "pe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31d026ea-8c27-4a0e-9fb3-05e739ec6649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 1]), torch.Size([7]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.cat([torch.zeros(2), torch.arange(8)])\n",
    "t2 = tensor[tensor!=0]\n",
    "t1 = tensor[tensor!=0].unsqueeze(-1)\n",
    "t1.size(), t2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b573cede-3422-4752-a582-a68e78d82134",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = t1.size()  # batch x length\n",
    "seq = t1.view(-1, input_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b081814-dc1b-480a-9dbe-9a8f7812f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = tensor.clone()\n",
    "attention_mask[attention_mask!=0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c5c8aa5-d717-4174-84a5-32bc421ec144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c27d018-260d-4664-96ba-00e74c2d03fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c83b543-086d-4730-8275-91256799cc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81606e45c99e417793b089256571f734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab127a675f14d2a924eb69a2ed32461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ab124639734c309e8fba53bbb081f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5efd032302a043378e47c3297764e9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "context = tokenizer(['It will rain in the', 'It will rain in the city but not here'], return_tensors='pt', padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "588e003b-c56a-468b-846a-1600da90c3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1135, 1209, 4458, 1107, 1103,  102,    0,    0,    0,    0],\n",
       "        [ 101, 1135, 1209, 4458, 1107, 1103, 1331, 1133, 1136, 1303,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52be581a-8d43-4ae9-a60d-7f5150686be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861db97a-c098-429c-86b5-53f3250d46b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (head_mask[idx] if head_mask is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b2e529-1856-42a0-8807-a5fd0d75c49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6008a4f-1e22-4058-83e1-5fd14897f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data_preprocessing import datapreproces\n",
    "from src.sampler import *\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "dataset_name =  \"Beauty\" # sys.argv[1]\n",
    "\n",
    "data, num_batch, args, ItemFeatures, CXTDict, UserFeatures = datapreproces(dataset_name)\n",
    "[user_train, user_valid, user_test, users_total_num, items_total_num] = data\n",
    "\n",
    "sampler = WarpSampler(user_train, users_total_num, items_total_num, CXTDict,\n",
    "                      args.cxt_size, batch_size=args.batch_size,\n",
    "                      maxlen=args.maxlen, n_workers=3)\n",
    "\n",
    "# model = Model(users_total_num, items_total_num, args, ItemFeatures, UserFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a486f-86b5-4b22-b99a-e323feb1fb00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1fc8d47e-4d28-4c57-84b7-b2a009caa476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=args.batch_size\n",
    "maxlen=args.maxlen\n",
    "cxtsize = args.cxt_size\n",
    "cxtdict=CXTDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "892ed827-a4a9-4437-9090-1e73859a8a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Process(Process-1, started daemon)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler.processors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "771dc722-5e57-4dd9-8931-28316e7dfbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = np.random.randint(1, users_total_num + 1)\n",
    "while len(user_train[user]) <= 1: user = np.random.randint(1, users_total_num + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "58912cc7-1a9f-4323-98b1-9f8efa8590cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44149, 1017, 2999]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_train[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a1158f1c-d85f-478b-adfc-682d8661edb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_neq(l, r, s):\n",
    "    \"\"\" random integer between l and r but avoiding s \"\"\"\n",
    "    t = np.random.randint(l, r)\n",
    "    while t in s:\n",
    "        t = np.random.randint(l, r)\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "688f3e62-68e2-4ba3-bc6c-1f8163c64a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1017\n",
      "44149\n"
     ]
    }
   ],
   "source": [
    "# Sequence Padding\n",
    "seq = np.zeros([maxlen], dtype=np.int32)\n",
    "pos = np.zeros([maxlen], dtype=np.int32)\n",
    "neg = np.zeros([maxlen], dtype=np.int32)\n",
    "# Sequence Padding\n",
    "seqcxt = np.zeros([maxlen, cxtsize], dtype=np.float32)\n",
    "poscxt = np.zeros([maxlen, cxtsize], dtype=np.float32)\n",
    "negcxt = np.zeros([maxlen, cxtsize], dtype=np.float32)\n",
    "\n",
    "nxt = user_train[user][-1]\n",
    "idx = maxlen - 1\n",
    "\n",
    "ts = set(user_train[user])\n",
    "for i in reversed(user_train[user][:-1]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9718a914-9bf7-4ab9-8268-7fb1c517935e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75,), 75, 6, 2999, 74, {1017, 2999, 44149})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg.shape,maxlen, cxtsize, nxt, idx,ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "46d033ef-ed1d-4703-8937-8f7e73a66c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5, 6, 7, 8, 9, 10, 12, 13, 14]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k,v in user_train.items() if len(v) < 6][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "60396e05-7edb-4d1f-8ebe-aad8161297a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(113, 291),\n",
       " (114, 96),\n",
       " (163, 150),\n",
       " (177, 115),\n",
       " (189, 155),\n",
       " (226, 181),\n",
       " (311, 80),\n",
       " (324, 82),\n",
       " (396, 107),\n",
       " (422, 202)]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,len(v)) for k,v in user_train.items() if len(v) > 75][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c6545-6c6d-4739-be4d-92fe152eeecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The dataset Beauty contains 52204 users and 57289 items in total\n",
      "average sequence length: {5.63}\n",
      "ItemFeatures DF dimensions (57290, 6507)\n",
      "iterations_num 1469053\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-23ad7bc85cbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWarpSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers_total_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems_total_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCXTDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems_total_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mItemFeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Model' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data_preprocessing import datapreproces\n",
    "from src.sampler import *\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "dataset_name = \"Beauty\"\n",
    "\n",
    "data, num_batch, args, ItemFeatures, CXTDict, UserFeatures = datapreproces(dataset_name)\n",
    "[user_train, user_valid, user_test, users_total_num, items_total_num] = data\n",
    "\n",
    "sampler = WarpSampler(user_train, users_total_num, args, items_total_num, CXTDict)\n",
    "model = Model(items_total_num, args, ItemFeatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c074220-116d-42db-8d92-37d9e412dce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0bf62c-01a0-4d2c-9ea1-4cd0c809d59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45ddfc64-920f-4b35-af38-3f9890b302d6",
   "metadata": {},
   "source": [
    "## LOSSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7135d703-062c-48a5-a846-5098828ee141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6931)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class BPRLoss(nn.Module):\n",
    "    \"\"\" BPRLoss, based on Bayesian Personalized Ranking\n",
    "\n",
    "    Args:\n",
    "        - gamma(float): Small value to avoid division by zero\n",
    "\n",
    "    Shape:\n",
    "        - Pos_score: (N)\n",
    "        - Neg_score: (N), same shape as the Pos_score\n",
    "        - Output: scalar.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gamma=1e-10):\n",
    "        super(BPRLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, pos_score, neg_score):\n",
    "        loss = -torch.log(self.gamma + torch.sigmoid(pos_score - neg_score)).mean()\n",
    "        return loss\n",
    "loss = BPRLoss()\n",
    "loss(torch.tensor(list(range(100))), torch.tensor(list(range(100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db2516-6d88-4d87-8750-5cc2a7d93a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
